[["index.html", "Text For SCI204 Microbiology at Roxbury Community College Welcome", " Text For SCI204 Microbiology at Roxbury Community College Assembled by Nikolaus Sucher Welcome This is a Text for the Microbiology course (SCI204) at RCC. The cover image shows a transmission electron micrograph of Middle East respiratory syndrome coronavirus. Credit: National Institute of Allergy and Infectious Diseases (NIAID) This work is licensed under the Creative Commons Attribution-Share Alike 3.0 Unported United States License. "],["acknowledgements.html", "Acknowledgements", " Acknowledgements This text was assembled using various pages from Wikipedia as my source. I copied text passages from many Wikipedia pages, remixed, edited, adapted and suplemented them with my own words to assemble the chapters of this text. I am making this text available as an open educational resource under Creative Commons Attribution-Share Alike 3.0 Unported United States License (same as Wikipedia) for others to do as I did and freely copy, remix, edit and adapt as required. Illustrations with associated hyperlinks are from Wikimedia Commons, which should be consulted for copyright details. Pictures and illustrations that I generated myself are subject to the Creative Commons Attribution-Share Alike 3.0 Unported United States License. I want to thank all the contributors and supporters of Wikipedia for making it possible and keeping it relevant. "],["the-main-themes-of-microbiology.html", "1 The Main Themes Of Microbiology 1.1 General Characteristics And Evolution Of Microorganisms 1.2 Ecology Of Microorganisms 1.3 Human Interactions With Microbes 1.4 Role Of Microorganisms In Disease 1.5 Role Of Microorganisms In Agriculture And Horticulture 1.6 History Of Microbiology 1.7 Taxonomy: Classification And Naming Of Microorganisms", " 1 The Main Themes Of Microbiology Microbiology (from Greek μῑκρος, mīkros, “small”; βίος, bios, “life”; and -λογία, -logia) is the scientific study of microorganisms, those being unicellular (single cell), multicellular (cell colony), or acellular (lacking cells). A unicellular organism, also known as a single-celled organism, is an organism that consists of a single cell, unlike a multicellular organism that consists of multiple cells. Unicellular organisms fall into two general categories: prokaryotic organisms and eukaryotic organisms. All prokaryotes are unicellular and are classified into bacteria and archaea. Many eukaryotes are multicellular, but many are unicellular such as protozoa, unicellular algae, and unicellular fungi. Unicellular organisms are thought to be the oldest form of life, with early protocells possibly emerging 3.8–4.0 billion years ago. Multicellular organisms are organisms that consist of more than one cell, in contrast to unicellular organisms. All species of animals, land plants and most fungi are multicellular, as are many algae, whereas a few organisms are partially uni- and partially multicellular, like slime molds and social amoebae such as the genus Dictyostelium. Microbiology encompasses numerous sub-disciplines including virology, bacteriology, protistology, mycology, immunology and parasitology. 1.1 General Characteristics And Evolution Of Microorganisms A microorganism, or microbe,[a] is a microscopic organism, which may exist in its single-celled form or a colony of cells. Viruses have been variably classified as organisms, as they have been considered either as very simple microorganisms or very complex molecules. Prions, never considered as microorganisms, have been investigated by virologists, however, as the clinical effects traced to them were originally presumed due to chronic viral infections, and virologists took search—discovering “infectious proteins”. The possible existence of unseen microbial life was suspected from ancient times, such as in Jain scriptures from sixth century BC India. The scientific study of microorganisms began with their observation under the microscope in the 1670s by Antonie van Leeuwenhoek. In the 1850s, Louis Pasteur found that microorganisms caused food spoilage, debunking the theory of spontaneous generation. In the 1880s, Robert Koch discovered that microorganisms caused the diseases tuberculosis, cholera, diphtheria, and anthrax. Microorganisms include all unicellular organisms and so are extremely diverse. Viruses are generally regarded as not living and therefore not considered as microorganisms, although a subfield of microbiology is virology, the study of viruses. Of the three domains of life identified by Carl Woese, all of the Archaea and Bacteria are microorganisms. These were previously grouped in the two domain system as Prokaryotes, the other being the eukaryotes. The third domain Eukaryota includes all multicellular organisms and many unicellular protists and protozoans. Some protists are related to animals and some to green plants. Many of the multicellular organisms are microscopic, namely micro-animals, some fungi, and some algae. They live in almost every habitat from the poles to the equator, deserts, geysers, rocks, and the deep sea. Some are adapted to extremes such as very hot or very cold conditions, others to high pressure, and a few, such as Deinococcus radiodurans, to high radiation environments. Microorganisms also make up the microbiota found in and on all multicellular organisms. There is evidence that 3.45-billion-year-old Australian rocks once contained microorganisms, the earliest direct evidence of life on Earth. Microbes are important in human culture and health in many ways, serving to ferment foods and treat sewage, and to produce fuel, enzymes, and other bioactive compounds. Microbes are essential tools in biology as model organisms and have been put to use in biological warfare and bioterrorism. Microbes are a vital component of fertile soil. In the human body, microorganisms make up the human microbiota, including the essential gut flora. The pathogens responsible for many infectious diseases are microbes and, as such, are the target of hygiene measures. Single-celled microorganisms were the first forms of life to develop on Earth, approximately 3.5 billion years ago. Further evolution was slow, and for about 3 billion years in the Precambrian eon, (much of the history of life on Earth), all organisms were microorganisms. Bacteria, algae and fungi have been identified in amber that is 220 million years old, which shows that the morphology of microorganisms has changed little since at least the Triassic period. The newly discovered biological role played by nickel, however – especially that brought about by volcanic eruptions from the Siberian Traps – may have accelerated the evolution of methanogens towards the end of the Permian–Triassic extinction event. Microorganisms tend to have a relatively fast rate of evolution. Most microorganisms can reproduce rapidly, and bacteria are also able to freely exchange genes through conjugation, transformation and transduction, even between widely divergent species. This horizontal gene transfer, coupled with a high mutation rate and other means of transformation, allows microorganisms to swiftly evolve (via natural selection) to survive in new environments and respond to environmental stresses. This rapid evolution is important in medicine, as it has led to the development of multidrug resistant pathogenic bacteria, superbugs, that are resistant to antibiotics. A possible transitional form of microorganism between a prokaryote and a eukaryote was discovered in 2012 by Japanese scientists. Parakaryon myojinensis is a unique microorganism larger than a typical prokaryote, but with nuclear material enclosed in a membrane as in a eukaryote, and the presence of endosymbionts. This is seen to be the first plausible evolutionary form of microorganism, showing a stage of development from the prokaryote to the eukaryote. 1.1.1 Archaea Archaea are prokaryotic unicellular organisms, and form the first domain of life, in Carl Woese’s three-domain system. A prokaryote is defined as having no cell nucleus or other membrane bound-organelle. Archaea share this defining feature with the bacteria with which they were once grouped. In 1990 the microbiologist Woese proposed the three-domain system that divided living things into bacteria, archaea and eukaryotes, and thereby split the prokaryote domain. Archaea differ from bacteria in both their genetics and biochemistry. For example, while bacterial cell membranes are made from phosphoglycerides with ester bonds, archaean membranes are made of ether lipids. Archaea were originally described as extremophiles living in extreme environments, such as hot springs, but have since been found in all types of habitats. Only now are scientists beginning to realize how common archaea are in the environment, with Crenarchaeota being the most common form of life in the ocean, dominating ecosystems below 150 m in depth. These organisms are also common in soil and play a vital role in ammonia oxidation. The combined domains of archaea and bacteria make up the most diverse and abundant group of organisms on Earth and inhabit practically all environments where the temperature is below +140 °C. They are found in water, soil, air, as the microbiome of an organism, hot springs and even deep beneath the Earth’s crust in rocks. The number of prokaryotes is estimated to be around five nonillion, or 5 × 1030, accounting for at least half the biomass on Earth. The biodiversity of the prokaryotes is unknown, but may be very large. A May 2016 estimate, based on laws of scaling from known numbers of species against the size of organism, gives an estimate of perhaps 1 trillion species on the planet, of which most would be microorganisms. Currently, only one-thousandth of one percent of that total have been described. Archael cells of some species aggregate and transfer DNA from one cell to another through direct contact, particularly under stressful environmental conditions that cause DNA damage. 1.1.2 Bacteria Bacteria like archaea are prokaryotic – unicellular, and having no cell nucleus or other membrane-bound organelle. Bacteria are microscopic, with a few extremely rare exceptions, such as Thiomargarita namibiensis. Bacteria function and reproduce as individual cells, but they can often aggregate in multicellular colonies. Some species such as myxobacteria can aggregate into complex swarming structures, operating as multicellular groups as part of their life cycle, or form clusters in bacterial colonies such as E.coli. Their genome is usually a circular bacterial chromosome – a single loop of DNA, although they can also harbor small pieces of DNA called plasmids. These plasmids can be transferred between cells through bacterial conjugation. Bacteria have an enclosing cell wall, which provides strength and rigidity to their cells. They reproduce by binary fission or sometimes by budding, but do not undergo meiotic sexual reproduction. However, many bacterial species can transfer DNA between individual cells by a horizontal gene transfer process referred to as natural transformation. Some species form extraordinarily resilient spores, but for bacteria this is a mechanism for survival, not reproduction. Under optimal conditions bacteria can grow extremely rapidly and their numbers can double as quickly as every 20 minutes. 1.1.3 Eukaryotes Most living things that are visible to the naked eye in their adult form are eukaryotes, including humans. However, many eukaryotes are also microorganisms. Unlike bacteria and archaea, eukaryotes contain organelles such as the cell nucleus, the Golgi apparatus and mitochondria in their cells. The nucleus is an organelle that houses the DNA that makes up a cell’s genome. DNA (Deoxyribonucleic acid) itself is arranged in complex chromosomes. Mitochondria are organelles vital in metabolism as they are the site of the citric acid cycle and oxidative phosphorylation. They evolved from symbiotic bacteria and retain a remnant genome. Like bacteria, plant cells have cell walls, and contain organelles such as chloroplasts in addition to the organelles in other eukaryotes. Chloroplasts produce energy from light by photosynthesis, and were also originally symbiotic bacteria. Unicellular eukaryotes consist of a single cell throughout their life cycle. This qualification is significant since most multicellular eukaryotes consist of a single cell called a zygote only at the beginning of their life cycles. Microbial eukaryotes can be either haploid or diploid, and some organisms have multiple cell nuclei. Unicellular eukaryotes usually reproduce asexually by mitosis under favorable conditions. However, under stressful conditions such as nutrient limitations and other conditions associated with DNA damage, they tend to reproduce sexually by meiosis and syngamy. 1.1.4 Protists Of eukaryotic groups, the protists are most commonly unicellular and microscopic. This is a highly diverse group of organisms that are not easy to classify. Several algae species are multicellular protists, and slime molds have unique life cycles that involve switching between unicellular, colonial, and multicellular forms. The number of species of protists is unknown since only a small proportion has been identified. Protist diversity is high in oceans, deep sea-vents, river sediment and an acidic river, suggesting that many eukaryotic microbial communities may yet be discovered. 1.1.5 Fungi The fungi have several unicellular species, such as baker’s yeast (Saccharomyces cerevisiae) and fission yeast (Schizosaccharomyces pombe). Some fungi, such as the pathogenic yeast Candida albicans, can undergo phenotypic switching and grow as single cells in some environments, and filamentous hyphae in others. 1.1.6 Plants The green algae are a large group of photosynthetic eukaryotes that include many microscopic organisms. Although some green algae are classified as protists, others such as charophyta are classified with embryophyte plants, which are the most familiar group of land plants. Algae can grow as single cells, or in long chains of cells. The green algae include unicellular and colonial flagellates, usually but not always with two flagella per cell, as well as various colonial, coccoid, and filamentous forms. In the Charales, which are the algae most closely related to higher plants, cells differentiate into several distinct tissues within the organism. There are about 6000 species of green algae. 1.2 Ecology Of Microorganisms Microorganisms are found in almost every habitat present in nature, including hostile environments such as the North and South poles, deserts, geysers, and rocks. They also include all the marine microorganisms of the oceans and deep sea. Some types of microorganisms have adapted to extreme environments and sustained colonies; these organisms are known as extremophiles. Extremophiles have been isolated from rocks as much as 7 kilometres below the Earth’s surface, and it has been suggested that the amount of organisms living below the Earth’s surface is comparable with the amount of life on or above the surface. Extremophiles have been known to survive for a prolonged time in a vacuum, and can be highly resistant to radiation, which may even allow them to survive in space. Many types of microorganisms have intimate symbiotic relationships with other larger organisms; some of which are mutually beneficial (mutualism), while others can be damaging to the host organism (parasitism). If microorganisms can cause disease in a host they are known as pathogens and then they are sometimes referred to as microbes. Microorganisms play critical roles in Earth’s biogeochemical cycles as they are responsible for decomposition and nitrogen fixation. Bacteria use regulatory networks that allow them to adapt to almost every environmental niche on earth. A network of interactions among diverse types of molecules including DNA, RNA, proteins and metabolites, is utilised by the bacteria to achieve regulation of gene expression. In bacteria, the principal function of regulatory networks is to control the response to environmental changes, for example nutritional status and environmental stress. A complex organization of networks permits the microorganism to coordinate and integrate multiple environmental signals. 1.2.1 Microbiome The word microbiome (from the Greek micro meaning “small” and bíos meaning “life”) was first used by J.L. Mohr in 1952 in The Scientific Monthly to mean the microorganisms found in a specific environment. It was defined in 1988 by Whipps et al. as “a characteristic microbial community occupying a reasonably well-defined habitat which has distinct physio-chemical properties. The term thus not only refers to the microorganisms involved but also encompasses their theatre of activity”. In 2020, an international panel of experts published the outcome of their discussions on the definition of the microbiome. They proposed a definition of the microbiome based on a revival of the “compact, clear, and comprehensive description of the term” as originally provided by Whipps et al., but supplemented with two explanatory sentences. The first explanatory sentence pronounces the dynamic character of the microbiome: The microbiome is defined as a characteristic microbial community occupying a reasonably well-defined habitat which has distinct physio-chemical properties. The microbiome not only refers to the microorganisms involved but also encompass their theatre of activity, which results in the formation of specific ecological niches. The microbiome, which forms a dynamic and interactive micro-ecosystem prone to change in time and scale, is integrated in macro-ecosystems including eukaryotic hosts, and here crucial for their functioning and health. The second explanatory sentence clearly separates the term microbiota from the term microbiome: The microbiota consists of the assembly of microorganisms belonging to different kingdoms (Prokaryotes [Bacteria, Archaea], Eukaryotes [e.g., Protozoa, Fungi, and Algae]), while their theatre of activity includes microbial structures, metabolites, mobile genetic elements (such as transposons, phages, and viruses), and relic DNA embedded in the environmental conditions of the habitat. Secondary metabolites play an essential role in mediating complex interspecies interactions and ensure survival in competitive environments. Quorum sensing induced by small molecules allows bacteria to control cooperative activities and adapts their phenotypes to the biotic environment, resulting, e.g., in cell-cell adhesion or biofilm formation. Direct interspecies electron transfer (DIET) is an important mechanism for communication in most anaerobic ecosystems. In addition, volatile compounds can act as long-term messengers for cross-kingdom communication over long distances. Microbiome research originated in microbiology and started back in the seventeenth century. The development of new techniques and equipment has boosted microbiological research and caused paradigm shifts in understanding health and disease. Since infectious diseases have affected human populations throughout most of history, medical microbiology was the earliest focus of research and public interest. Additionally, food microbiology is an old field of empirical applications. The development of the first microscopes allowed the discovery of a new, unknown world and led to the identification of microorganisms. Access to the previously invisible world opened the eyes and the minds of the researchers of the seventeenth century. Antonie van Leeuwenhoek investigated diverse bacteria of various shapes, fungi, and protozoa, which he called animalcules, mainly from water, mud, and dental plaque samples, and discovered biofilms as a first indication of microorganisms interacting within complex communities. Robert Koch’s explanation of the origin of human and animal diseases as a consequence of microbial infection and development of the concept of pathogenicity was an important milestone in microbiology. These findings shifted the focus of the research community and the public on the role of microorganisms as disease-forming agents that needed to be eliminated. However, comprehensive research over the past century has shown only a small proportion of microorganisms are associated with disease or pathogenicity. The overwhelming majority of microbes are essential for ecosystem functioning and known for beneficial interactions with other microbes as well as macroorganisms. At the end of the nineteenth century, microbial ecology started with the pioneering work by Martinus W. Beijerinck and Sergei Winogradsky. The newly established science of environmental microbiology resulted in another paradigm shift: microorganisms are everywhere in natural environments, often associated with hosts and, for the first time, beneficial effects on their hosts were reported. Subsequently, the concept that microorganisms exist as single cells began to change as it became increasingly obvious that microbes occur within complex assemblages in which species interactions and communication are critical to population dynamics and functional activities. Discovery of DNA, the development of sequencing technologies, PCR, and cloning techniques enabled the investigation of microbial communities using cultivation-independent, DNA and RNA-based approaches. A further important step was the introduction of phylogenetic markers such as the 16S rRNA gene for microbial community analysis by Carl Woese and George E. Fox in 1977. Today, we are able to barcode bacteria, archaea, fungi, algae, and protists in their natural habitats, e.g., by targeting their 16S and 18S rRNA genes, internal transcribed spacer (ITS), or, alternatively, specific functional regions of genes coding for specific enzymes. Another major paradigm shift was initiated at the beginning of this century and continues through today, as new sequencing technologies and accumulated sequence data have highlighted both the ubiquity of microbial communities in association within higher organisms and the critical roles of microbes in human, animal, and plant health. These new possibilities have revolutionized microbial ecology, because the analysis of genomes and metagenomes in a high-throughput manner provides efficient methods for addressing the functional potential of individual microorganisms as well as of whole communities in their natural habitats. Multiomics technologies including metatranscriptome, metaproteome and metabolome approaches now provide detailed information on microbial activities in the environment. Based on the rich foundation of data, the cultivation of microbes, which was often ignored or underestimated over the last thirty years, has gained new importance, and high throughput culturomics is now an important part of the toolbox to study microbiomes. The high potential and power of combining multiple “omics” techniques to analyze host-microbe interactions are highlighted in several reviews. Microbial communities have commonly been defined as the collection of microorganisms living together. More specifically, microbial communities are defined as multi-species assemblages, in which (micro) organisms interact with each other in a contiguous environment. In 1988, Whipps and colleagues working on the ecology of rhizosphere microorganisms provided the first definition of the term microbiome. They described the microbiome as a combination of the words micro and biome, naming a “characteristic microbial community” in a “reasonably well-defined habitat which has distinct physio-chemical properties” as their “theatre of activity”. This definition represents a substantial advancement of the definition of a microbial community, as it defines a microbial community with distinct properties and functions and its interactions with its environment, resulting in the formation of specific ecological niches. However, many other microbiome definitions have been published in the last few decades. The currently most cited definition by Lederberg describes microbiomes within an ecological context, as a community of commensal, symbiotic, and pathogenic microorganisms within a body space or other environment. Marchesi and Ravel focused in their definition on the genomes and microbial (and viral) gene expression patterns and proteomes in a given environment and its prevailing biotic and abiotic conditions. All these definitions imply that general concepts of macro-ecology could be easily applied to microbe-microbe as well as to microbe-host interactions. However, the extent to which these concepts, developed for macro-eukaryotes, can be applied to prokaryotes with their different lifestyles regarding dormancy, variation of phenotype, and horizontal gene transfer as well as to micro-eukaryotes that is not quite clear. This raises the challenge of considering an entirely novel body of conceptual ecology models and theory for microbiome ecology, particularly in relation to the diverse hierarchies of interactions of microbes with one another and with the host biotic and abiotic environments. In 2020, a panel of international experts, organised by the EU-funded MicrobiomeSupport project, published the results of their deliberations on the definition of the microbiome. The panel was composed of about 40 leaders from diverse microbiome areas, and about one hundred further experts from around the world contributed through an online survey. They proposed a definition of the microbiome based on a revival of the compact, clear, and comprehensive description of the term as originally provided by Whipps et al. in 1988, amended with a set of recommendations considering subsequent technological developments and research findings. They clearly separate the terms microbiome and microbiota and provide a comprehensive discussion considering the composition of microbiota, the heterogeneity and dynamics of microbiomes in time and space, the stability and resilience of microbial networks, the definition of core microbiomes, and functionally relevant keystone species as well as co-evolutionary principles of microbe-host and inter-species interactions within the microbiome. The panel extended the Whipps et al. definition, which contains all important points that are valid even 30 years after its publication in 1988, by two explanatory sentences differentiating the terms microbiome and microbiota and pronouncing its dynamic character, as follows: The microbiome is defined as a characteristic microbial community occupying a reasonable well-defined habitat which has distinct physio-chemical properties. The microbiome not only refers to the microorganisms involved but also encompass their theatre of activity, which results in the formation of specific ecological niches. The microbiome, which forms a dynamic and interactive micro-ecosystem prone to change in time and scale, is integrated in macro-ecosystems including eukaryotic hosts, and here crucial for their functioning and health. The microbiota consists of the assembly of microorganisms belonging to different kingdoms (prokaryotes (bacteria, archaea), eukaryotes (algae, protozoa, fungi etc), while “their theatre of activity” includes microbial structures, metabolites, mobile genetic elements (such as transposons, phages, and viruses), and relic DNA embedded in the environmental conditions of the habitat. 1.2.2 Microbiota – members of the microbiome The microbiota comprises all living members forming the microbiome. Most microbiome researchers agree bacteria, archaea, fungi, algae, and small protists should be considered as members of the microbiome. The integration of phages, viruses, plasmids, and mobile genetic elements is a more controversial issue in the definition of the microbiome. There is also no clear consensus as to whether extracellular DNA derived from dead cells, so-called “relic DNA”, belongs to the microbiome. Relic DNA can be up to 40% of the sequenced DNA in soil, and was up to 33% of the total bacterial DNA on average in a broader analysis of habitats with the highest proportion of 80% in some samples. Despite its omnipresence and abundance, relic DNA had a minimal effect on estimates of taxonomic and phylogenetic diversity. When it comes to the use of specific terms, a clear differentiation between microbiome and microbiota helps to avoid the controversy concerning the members of a microbiome. Microbiota is usually defined as the assemblage of living microorganisms present in a defined environment. As phages, viruses, plasmids, prions, viroids, and free DNA are usually not considered as living microorganisms, they do not belong to the microbiota. The term microbiome, as it was originally postulated by Whipps and coworkers, includes not only the community of the microorganisms but also their “theatre of activity”. The latter involves the whole spectrum of molecules produced by the microorganisms, including their structural elements (nucleic acids, proteins, lipids, polysaccharides), metabolites (signalling molecules, toxins, organic, and inorganic molecules), and molecules produced by coexisting hosts and structured by the surrounding environmental conditions. Therefore, all mobile genetic elements, such as phages, viruses, and “relic” and extracellular DNA, should be included in the term microbiome, but are not a part of microbiota. The term microbiome is also sometimes confused with the metagenome. Metagenome is, however, clearly defined as a collection of genomes and genes from the members of a microbiota. Microbiome studies sometimes focus on the behaviour of a specific group of microbiota, generally in relation to or justified by a clear hypothesis. More and more terms like bacteriome, archaeome, mycobiome, or virome have started appearing in the scientific literature, but these terms do not refer to biomes (a regional ecosystem with a distinct assemblage of (micro) organisms, and physical environment often reflecting a certain climate and soil) as the microbiome itself. Consequently, it would be better to use the original terms (bacterial, archaeal, or fungal community). In contrast to the microbiota, which can be studied separately, the microbiome is always composed by all members, which interact with each other, live in the same habitat, and form their ecological niche together. The well-established term virome is derived from virus and genome and is used to describe viral shotgun metagenomes consisting of a collection of nucleic acids associated with a particular ecosystem or holobiont. Viral metagenomes can be suggested as a semantically and scientifically better term. 1.2.3 Microbial Networks And Interaction Microbes interact with one another, and these symbiotic interactions have diverse consequences for microbial fitness, population dynamics, and functional capacities within the microbiome. These interactions can either be between microorganisms of the same species or between different species, genera, families, and domains of life. The interactive patterns within these webs may be positive (mutualism, synergism, or commensalism), negative (amensalism [including predation, parasitism, antagonism, or competition]), or neutral—where there is no (or no observed) effect on the functional capacities or fitness of interacting species (see diagram at right) Microbial life strategy concepts (i.e., copiotrophic and oligotrophic strategists and competitor–stress tolerator–ruderals framework) can influence outcomes of interactions. For example, microorganisms competing for the same source can also benefit from each other when competing for the same compound at different trophic levels. Stability of a complex microbial ecosystem depends on trophic interactions for the same substrate at different concentration levels. As of 2020 microbial social adaptations in nature have been understudied. Here molecular markers can provide insight into social adaptations by supporting the theories, e.g., of altruists and cheaters in native microbiomes. Secondary metabolites play an essential role in mediating complex interspecies interactions and ensure survival in competitive environments. Quorum sensing induced by small molecules like n-acyl-homoserine lactones or peptides allows bacteria to control cooperative activities and adapts their phenotypes to the biotic environment, resulting, e.g., in cell-cell adhesion or biofilm formation. Direct interspecies electron transfer (DIET) is an important mechanism for communication in most anaerobic ecosystems. In addition, volatile compounds can act as long-term messengers for cross-kingdom communication over long distances. Moreover, the so-called “fungal highways” serve as transportation systems for bacteria as well as for water and nutrients and can therefore play an important role in structuring microbial networks. Despite these examples, communication and interaction within the microbiome remain understudied and would profit from more knowledge on the metabolic interplay of all microbiome members. Here, reductionist experimental models and model microbiomes can help to identify microbes and molecular mechanisms involved in complex interactions. Currently available methods for studying microbiomes, so-called multi-omics, range from high throughput isolation (culturomics) and visualization (microscopy), to targeting the taxonomic composition (metabarcoding), or addressing the metabolic potential (metabarcoding of functional genes, metagenomics) to analyze microbial activity (metatranscriptomics, metaproteomics, metabolomics), as shown in the diagram on the right. Based on metagenome data, microbial genomes can be reconstructed. While first metagenome-assembled genomes were reconstructed from environmental samples, in recent years, several thousands of bacterial genomes were binned without culturing the organisms behind. For example, 154,723 microbial genomes of the global human microbiome were recently reconstructed from 9,428 metagenomes. Computational modeling of microbiomes has been used to compliment experimental methods for investigating microbial function by utilizing multi-omic data to predict complex inter-species and host-species dynamics. A popular in silico method is to combine metabolic network models of microbial taxa present in a community and use a mathematical modeling strategy such as flux balance analysis to predict the metabolic function of the microbial community at a taxon and community-level. As of 2020, understanding is limited due to the missing links between the massive availability of microbiome DNA sequence data on the one hand and limited availability of microbial isolates needed to confirm metagenomic predictions of gene function on the other hand. Metagenome data provides a playground for new predictions, yet much more data is needed to strengthen the links between sequence and rigorous functional predictions. This becomes obvious when considering that the replacement of one single amino acid residue by another may lead to a radical functional change, resulting in an incorrect functional assignment to a given gene sequence. Additionally, cultivation of new strains is needed to help identify the large fraction of unknown sequences obtained from metagenomics analyses, which for poorly studied ecosystems can be more than 70%. Depending on the applied method, even in well-studied microbiomes, 40–70% of the annotated genes in fully sequenced microbial genomes have no known or predicted function. Moreover, current estimates predict that domains with unknown functions will outnumber families of known function very soon. There is a clear need for more classical microbiology including the use of targeted mutants in combination with microbial biochemistry to cope with this challenge. Moreover, there is much more to gain from thorough functional characterization of already discovered protein families with unknown function(s) than from further extending the list of these families. Understanding prokaryotic functional diversity, as of 2019, is challenging as 85 out of the currently established 118 phyla have not had a single species described to this date. The number of prokaryotic phyla may reach hundreds, and archaeal ones are among the least. The growing gap between the diversity of Bacteria and Archaea held in pure culture and those detected by molecular methods has led to the proposal to establish a formal nomenclature for not-yet cultured taxa, primarily based on sequence information. According to this proposal, the concept of Candidatus species would be extended to the groups of closely related genome sequences, and their names would be published following established rules of bacterial nomenclature. In 1985 Staley and Konopka identified “the great plate count anomaly” which describes the fact that 90 to 99.9% of bacterial species cannot be grown under standard laboratory conditions. For some micro-habitats, especially those with high nutrient content and microbial activity, the proportion of representative strains available in culture relative to the molecular species detected by sequencing grew from 35 to 65%, as it was stated for the gut microbiota. Similar advances are needed for microbial populations from other natural habitats as well as for the eukaryotic members of the microbiome. Micro-eukaryotes, e.g., members of protozoa, fungi, and algae, can often be better cultivated and microscopically studied; however, their phylogeny and taxonomy are more complex and less studied. Interestingly, primer-free 16S and 18S rRNA gene sequencing from various environments has shown that among microeukaryotes there is a huge number of previously not detected taxa. 1.2.4 The Human Microbiome The human microbiome is the aggregate of all microbiota that reside on or within human tissues and biofluids along with the corresponding anatomical sites in which they reside, including the skin, mammary glands, seminal fluid, uterus, ovarian follicles, lung, saliva, oral mucosa, conjunctiva, biliary tract, and gastrointestinal tract. Types of human microbiota include bacteria, archaea, fungi, protists and viruses. Though micro-animals can also live on the human body, they are typically excluded from this definition. In the context of genomics, the term human microbiome is sometimes used to refer to the collective genomes of resident microorganisms; however, the term human metagenome has the same meaning. Humans are colonized by many microorganisms, with approximately the same order of magnitude of non-human cells as human cells. Some microorganisms that colonize humans are commensal, meaning they co-exist without harming humans; others have a mutualistic relationship with their human hosts.:700 Conversely, some non-pathogenic microorganisms can harm human hosts via the metabolites they produce, like trimethylamine, which the human body converts to trimethylamine N-oxide via FMO3-mediated oxidation. Certain microorganisms perform tasks that are known to be useful to the human host but the role of most of them is not well understood. Those that are expected to be present, and that under normal circumstances do not cause disease, are sometimes deemed normal flora or normal microbiota. The Human Microbiome Project took on the project of sequencing the genome of the human microbiota, focusing particularly on the microbiota that normally inhabit the skin, mouth, nose, digestive tract, and vagina. It reached a milestone in 2012 when it published its initial results. As of 2014, it was often reported in popular media and in the scientific literature that there are about 10 times as many microbial cells in the human body as there are human cells; this figure was based on estimates that the human microbiome includes around 100 trillion bacterial cells and that an adult human typically has around 10 trillion human cells. In 2014, the American Academy of Microbiology published a FAQ that emphasized that the number of microbial cells and the number of human cells are both estimates, and noted that recent research had arrived at a new estimate of the number of human cells – approximately 37.2 trillion, meaning that the ratio of microbial-to-human cells, if the original estimate of 100 trillion bacterial cells is correct, is closer to 3:1. In 2016, another group published a new estimate of the ratio being roughly 1:1 (1.3:1, with “an uncertainty of 25% and a variation of 53% over the population of standard 70-kg males”). A more recent estimate is a ratio of 1.3 bacterial cells for every one human cell whereas the number of phages and viruses outnumber bacterial cells by at least a order of magnitude more. The number of bacterial genes (assuming 1000 bacterial species in the gut with 2000 genes per species) is estimate to be 2,000,000 genes, 100 times the number of approximately 20,000 human genes. The problem of elucidating the human microbiome is essentially identifying the members of a microbial community which includes bacteria, eukaryotes, and viruses. This is done primarily using DNA-based studies, though RNA, protein and metabolite based studies are also performed. DNA-based microbiome studies typically can be categorized as either targeted amplicon studies or more recently shotgun metagenomic studies. The former focuses on specific known marker genes and is primarily informative taxonomically, while the latter is an entire metagenomic approach which can also be used to study the functional potential of the community. One of the challenges that is present in human microbiome studies, but not in other metagenomic studies is to avoid including the host DNA in the study. Aside from simply elucidating the composition of the human microbiome, one of the major questions involving the human microbiome is whether there is a “core”, that is, whether there is a subset of the community that is shared among most humans. If there is a core, then it would be possible to associate certain community compositions with disease states, which is one of the goals of the Human Microbiome Project. It is known that the human microbiome (such as the gut microbiota) is highly variable both within a single subject and among different individuals, a phenomenon which is also observed in mice. On 13 June 2012, a major milestone of the Human Microbiome Project (HMP) was announced by the NIH director Francis Collins. The announcement was accompanied with a series of coordinated articles published in Nature and several journals in the Public Library of Science (PLoS) on the same day. By mapping the normal microbial make-up of healthy humans using genome sequencing techniques, the researchers of the HMP have created a reference database and the boundaries of normal microbial variation in humans. From 242 healthy U.S. volunteers, more than 5,000 samples were collected from tissues from 15 (men) to 18 (women) body sites such as mouth, nose, skin, lower intestine (stool), and vagina. All the DNA, human and microbial, were analyzed with DNA sequencing machines. The microbial genome data were extracted by identifying the bacterial specific ribosomal RNA, 16S rRNA. The researchers calculated that more than 10,000 microbial species occupy the human ecosystem and they have identified 81 – 99% of the genera. Populations of microbes (such as bacteria and yeasts) inhabit the skin and mucosal surfaces in various parts of the body. Their role forms part of normal, healthy human physiology, however if microbe numbers grow beyond their typical ranges (often due to a compromised immune system) or if microbes populate (such as through poor hygiene or injury) areas of the body normally not colonized or sterile (such as the blood, or the lower respiratory tract, or the abdominal cavity), disease can result (causing, respectively, bacteremia/sepsis, pneumonia, and peritonitis).[medical citation needed] The Human Microbiome Project found that individuals host thousands of bacterial types, different body sites having their own distinctive communities. Skin and vaginal sites showed smaller diversity than the mouth and gut, these showing the greatest richness. The bacterial makeup for a given site on a body varies from person to person, not only in type, but also in abundance. Bacteria of the same species found throughout the mouth are of multiple subtypes, preferring to inhabit distinctly different locations in the mouth. Even the enterotypes in the human gut, previously thought to be well understood, are from a broad spectrum of communities with blurred taxon boundaries. It is estimated that 500 to 1,000 species of bacteria live in the human gut but belong to just a few phyla: Firmicutes and Bacteroidetes dominate but there are also Proteobacteria, Verrucomicrobia, Actinobacteria, Fusobacteria and Cyanobacteria. A number of types of bacteria, such as Actinomyces viscosus and A. naeslundii, live in the mouth, where they are part of a sticky substance called plaque. If this is not removed by brushing, it hardens into calculus (also called tartar). The same bacteria also secrete acids that dissolve tooth enamel, causing tooth decay. The vaginal microflora consist mostly of various lactobacillus species. It was long thought that the most common of these species was Lactobacillus acidophilus, but it has later been shown that L. iners is in fact most common, followed by L. crispatus. Other lactobacilli found in the vagina are L. jensenii, L. delbruekii and L. gasseri. Disturbance of the vaginal flora can lead to infections such as bacterial vaginosis or candidiasis (“yeast infection”). Archaea are present in the human gut, but, in contrast to the enormous variety of bacteria in this organ, the numbers of archaeal species are much more limited. The dominant group are the methanogens, particularly Methanobrevibacter smithii and Methanosphaera stadtmanae. However, colonization by methanogens is variable, and only about 50% of humans have easily detectable populations of these organisms. As of 2007, no clear examples of archaeal pathogens were known, although a relationship has been proposed between the presence of some methanogens and human periodontal disease. Fungi, in particular yeasts, are present in the human gut. The best-studied of these are Candida species due to their ability to become pathogenic in immunocompromised and even in healthy hosts. Yeasts are also present on the skin, such as Malassezia species, where they consume oils secreted from the sebaceous glands. Viruses, especially bacterial viruses (bacteriophages), colonize various body sites. These colonized sites include the skin, gut, lungs, and oral cavity. Virus communities have been associated with some diseases, and do not simply reflect the bacterial communities. Human bodies rely on the innumerable bacterial genes as the source of essential nutrients. Both metagenomic and epidemiological studies indicate vital roles for the human microbiome in preventing a wide range of diseases, from type 2 diabetes and obesity to inflammatory bowel disease, Parkinson’s disease, and even mental health conditions like depression. A symbiotic relationship between the gut microbiota and different bacteria may influence an individual’s immune response. Although in its infancy, microbiome-based treatment is also showing promise, most notably for treating drug-resistant C. difficile infection and in diabetes treatment. Although cancer is generally a disease of host genetics and environmental factors, microorganisms are implicated in some 20% of human cancers. Particularly for potential factors in colon cancer, bacterial density is one million times higher than in the small intestine, and approximately 12-fold more cancers occur in the colon compared to the small intestine, possibly establishing a pathogenic role for microbiota in colon and rectal cancers. Microbial density may be used as a prognostic tool in assessment of colorectal cancers. The microbiota may affect carcinogenesis in three broad ways: (i) altering the balance of tumor cell proliferation and death, (ii) regulating immune system function, and (iii) influencing metabolism of host-produced factors, foods and pharmaceuticals. Tumors arising at boundary surfaces, such as the skin, oropharynx and respiratory, digestive and urogenital tracts, harbor a microbiota. Substantial microbe presence at a tumor site does not establish association or causal links. Instead, microbes may find tumor oxygen tension or nutrient profile supportive. Decreased populations of specific microbes or induced oxidative stress may also increase risks. Of the around 1030 microbes on earth, ten are designated by the International Agency for Research on Cancer as human carcinogens. Microbes may secrete proteins or other factors directly drive cell proliferation in the host, or may up- or down-regulate the host immune system including driving acute or chronic inflammation in ways that contribute to carcinogenesis. Concerning the relationship of immune function and development of inflammation, mucosal surface barriers are subject to environmental risks and must rapidly repair to maintain homeostasis. Compromised host or microbiota resiliency also reduce resistance to malignancy, possibly inducing inflammation and cancer. Once barriers are breached, microbes can elicit proinflammatory or immunosuppressive programs through various pathways. For example, cancer-associated microbes appear to activate NF-κΒ signaling within the tumor microenviroment. Other pattern recognition receptors, such as nucleotide-binding oligomerization domain–like receptor (NLR) family members NOD-2, NLRP3, NLRP6 and NLRP12, may play a role in mediating colorectal cancer. Likewise Helicobacter pylori appears to increase the risk of gastric cancer, due to its driving a chronic inflammatory response in the stomach. With death, the microbiome of the living body collapses and a different composition of microorganisms named necrobiome establishes itself as an important active constituent of the complex physical decomposition process. Its predictable changes over time are thought to be useful to help determine the time of death. 1.2.5 Extremophiles Extremophiles are microorganisms that have adapted so that they can survive and even thrive in extreme environments that are normally fatal to most life-forms. Thermophiles and hyperthermophiles thrive in high temperatures. Psychrophiles thrive in extremely low temperatures. – Temperatures as high as 130 °C (266 °F), as low as −17 °C (1 °F) Halophiles such as Halobacterium salinarum (an archaean) thrive in high salt conditions, up to saturation. Alkaliphiles thrive in an alkaline pH of about 8.5–11. Acidophiles can thrive in a pH of 2.0 or less. Piezophiles thrive at very high pressures: up to 1,000–2,000 atm, down to 0 atm as in a vacuum of space. A few extremophiles such as Deinococcus radiodurans are radioresistant, resisting radiation exposure of up to 5k Gy. Extremophiles are significant in different ways. They extend terrestrial life into much of the Earth’s hydrosphere, crust and atmosphere, their specific evolutionary adaptation mechanisms to their extreme environment can be exploited in biotechnology, and their very existence under such extreme conditions increases the potential for extraterrestrial life. 1.2.6 Soil Microorganisms The nitrogen cycle in soils depends on the fixation of atmospheric nitrogen. This is achieved by a number of diazotrophs. One way this can occur is in the root nodules of legumes that contain symbiotic bacteria of the genera Rhizobium, Mesorhizobium, Sinorhizobium, Bradyrhizobium, and Azorhizobium. The roots of plants create a narrow region known as the rhizosphere that supports many microorganisms known as the root microbiome. 1.3 Human Interactions With Microbes Human interactions with microbes include both practical and symbolic uses of microbes, and negative interactions in the form of human, domestic animal, and crop diseases. Practical use of microbes began in ancient times with fermentation in food processing; bread, beer and wine have been produced by yeasts from the dawn of civilisation, such as in ancient Egypt. More recently, microbes have been used in activities from biological warfare to the production of chemicals by fermentation, as industrial chemists discover how to manufacture a widening variety of organic chemicals including enzymes and bioactive molecules such as hormones and competitive inhibitors for use as medicines. Fermentation is used, too, to produce substitutes for fossil fuels in forms such as ethanol and methane; fuels may also be produced by algae. Anaerobic microorganisms are important in sewage treatment. In scientific research, yeasts and the bacterium Escherichia coli serve as model organisms especially in genetics and related fields. On the symbolic side, an early poem about brewing is the Sumerian “Hymn to Ninkasi”, from 1800 BC. In the Middle Ages, Giovanni Boccaccio’s The Decameron and Geoffrey Chaucer’s The Canterbury Tales: addressed people’s fear of deadly contagion and the moral decline that could result. Novelists have exploited the apocalyptic possibilities of pandemics from Mary Shelley’s 1826 The Last Man and Jack London’s 1912 The Scarlet Plague onwards. Hilaire Belloc wrote a humorous poem to “The Microbe” in 1912. Dramatic plagues and mass infection have formed the story lines of many Hollywood films, starting with Nosferatu in 1922. In 1971, The Andromeda Strain told the tale of an extraterrestrial microbe threatening life on Earth. Microbiologists since Alexander Fleming have used coloured or fluorescing colonies of bacteria to create miniature artworks. Microorganisms such as bacteria and viruses are important as pathogens, causing disease to humans, crop plants, and domestic animals. 1.3.1 Food production Controlled fermentation with microbes in brewing, wine making, baking, pickling and cultured dairy products such as yogurt and cheese, is used to modify ingredients to make foods with desirable properties. The principal microbes involved are yeasts, in the case of beer, wine, and ordinary bread; and bacteria, in the case of anaerobically fermented vegetables, dairy products, and sourdough bread. The cultures variously provide flavour and aroma, inhibit pathogens, increase digestibility and palatability, make bread rise, reduce cooking time, and create useful products including alcohol, organic acids, vitamins, amino acids, and carbon dioxide. Safety is maintained with the help of food microbiology. 1.3.2 Water Treatment Oxidative sewage treatment processes rely on microorganisms to oxidise organic constituents. Anaerobic microorganisms reduce sludge solids producing methane gas and a sterile mineralised residue. In potable water treatment, one method, the slow sand filter, employs a complex gelatinous layer composed of a wide range of microorganisms to remove both dissolved and particulate material from raw water. 1.3.3 Fuel Production Microorganisms are used in fermentation to produce ethanol, and in biogas reactors to produce methane. Scientists are researching the use of algae to produce liquid fuels, and bacteria to convert various forms of agricultural and urban waste into usable fuels. 1.3.4 Production Of Chemicals And Enzymes Microorganisms are used for many commercial and industrial purposes, including the production of chemicals, enzymes and other bioactive molecules, often through protein engineering. For example, acetic acid is produced by the bacterium Acetobacter aceti, while citric acid is produced by the fungus Aspergillus niger. Microorganisms are used to prepare a widening range of bioactive molecules and enzymes. For example, Streptokinase produced by the bacterium Streptococcus and modified by genetic engineering is used to remove clots from the blood vessels of patients who have suffered a heart attack. Cyclosporin A is an immunosuppressive agent in organ transplantation, while statins produced by the yeast Monascus purpureus serve as blood cholesterol lowering agents, competitively inhibiting the enzyme that synthesizes cholesterol. 1.3.5 Use Of Microorganisms In Science Microorganisms are essential tools in biotechnology, biochemistry, genetics, and molecular biology. The yeasts brewer’s yeast (Saccharomyces cerevisiae) and fission yeast (Schizosaccharomyces pombe) are important model organisms in science, since they are simple eukaryotes that can be grown rapidly in large numbers and are easily manipulated. 1.3.6 Use of Microorganisms For Warfare Pathogenic microbes, and toxins that they produce, have been developed as possible agents of warfare. Crude forms of biological warfare have been practiced since antiquity. In the 6th century BC, the Assyrians poisoned enemy wells with a fungus said to render the enemy delirious. In 1346, the bodies of Mongol warriors of the Golden Horde who had died of plague were thrown over the walls of the besieged Crimean city of Kaffa, possibly assisting the spread of the Black Death into Europe. Advances in bacteriology in the 20th century increased the sophistication of possible bio-agents in war. Biological sabotage—in the form of anthrax and glanders—was undertaken on behalf of the Imperial German government during World War I, with indifferent results. In World War II, Britain weaponised tularemia, anthrax, brucellosis, and botulism toxins, but never used them. The USA similarly explored biological warfare agents, developing anthrax spores, brucellosis, and botulism toxins for possible military use. Japan developed biological warfare agents, with the use of experiments on human prisoners, and was about to use them when the war ended. 1.4 Role Of Microorganisms In Disease Microorganisms are the causative agents (pathogens) in many infectious diseases of humans and domestic animals. Pathogenic bacteria cause diseases such as plague, tuberculosis and anthrax. Protozoa cause diseases including malaria, sleeping sickness, dysentery and toxoplasmosis. Microscopic fungi cause diseases such as ringworm, candidiasis and histoplasmosis. Pathogenic viruses cause diseases such as influenza, yellow fever and AIDS. The practice of hygiene was created to prevent infection or food spoiling by eliminating microbes, especially bacteria, from the surroundings. 1.5 Role Of Microorganisms In Agriculture And Horticulture Microorganisms including bacteria, fungi, and viruses are important as plant pathogens, causing disease to crop plants. Fungi cause serious crop diseases such as maize leaf rust, wheat stem rust, and powdery mildew. Bacteria cause plant diseases including leaf spot and crown galls. Viruses cause plant diseases such as leaf mosaic. The oomycete Phytophthora infestans causes potato blight, contributing to the Great Irish Famine of the 1840s. The tulip breaking virus played a role in the tulip mania of the Dutch Golden Age. The famous Semper Augustus tulip, in particular, owed its striking pattern to infection with the plant disease, a kind of mosaic virus, making it the most expensive of all the tulip bulbs sold. 1.6 History Of Microbiology The existence of microorganisms was predicted many centuries before they were first observed, for example by the Jains in India and by Marcus Terentius Varro in ancient Rome. The first recorded microscope observation was of the fruiting bodies of moulds, by Robert Hooke in 1666, but the Jesuit priest Athanasius Kircher was likely the first to see microbes, which he mentioned observing in milk and putrid material in 1658. Antonie van Leeuwenhoek is considered a father of microbiology as he observed and experimented with microscopic organisms in the 1670s, using simple microscopes of his own design. Scientific microbiology developed in the 19th century through the work of Louis Pasteur and in medical microbiology Robert Koch. In 1676, Antonie van Leeuwenhoek, who lived most of his life in Delft, Netherlands, observed bacteria and other microorganisms using a single-lens microscope of his own design. He is considered a father of microbiology as he pioneered the use of simple single-lensed microscopes of his own design. While Van Leeuwenhoek is often cited as the first to observe microbes, Robert Hooke made his first recorded microscopic observation, of the fruiting bodies of moulds, in 1665. It has, however, been suggested that a Jesuit priest called Athanasius Kircher was the first to observe microorganisms. Kircher was among the first to design magic lanterns for projection purposes, so he must have been well acquainted with the properties of lenses. He wrote “Concerning the wonderful structure of things in nature, investigated by Microscope” in 1646, stating “who would believe that vinegar and milk abound with an innumerable multitude of worms.” He also noted that putrid material is full of innumerable creeping animalcules. He published his Scrutinium Pestis (Examination of the Plague) in 1658, stating correctly that the disease was caused by microbes, though what he saw was most likely red or white blood cells rather than the plague agent itself. Innovative laboratory glassware and experimental methods developed by Louis Pasteur and other biologists contributed to the young field of bacteriology in the late 19th century. The field of bacteriology (later a subdiscipline of microbiology) was founded in the 19th century by Ferdinand Cohn, a botanist whose studies on algae and photosynthetic bacteria led him to describe several bacteria including Bacillus and Beggiatoa. Cohn was also the first to formulate a scheme for the taxonomic classification of bacteria, and to discover endospores. Louis Pasteur and Robert Koch were contemporaries of Cohn, and are often considered to be the fathers of modern microbiology and medical microbiology, respectively. Pasteur is most famous for his series of experiments designed to disprove the then widely held theory of spontaneous generation, thereby solidifying microbiology’s identity as a biological science. One of his students, Adrien Certes, is considered the founder of marine microbiology. Pasteur also designed methods for food preservation (pasteurization) and vaccines against several diseases such as anthrax, fowl cholera and rabies. Koch is best known for his contributions to the germ theory of disease, proving that specific diseases were caused by specific pathogenic microorganisms. He developed a series of criteria that have become known as the Koch’s postulates. Koch was one of the first scientists to focus on the isolation of bacteria in pure culture resulting in his description of several novel bacteria including Mycobacterium tuberculosis, the causative agent of tuberculosis. While Pasteur and Koch are often considered the founders of microbiology, their work did not accurately reflect the true diversity of the microbial world because of their exclusive focus on microorganisms having direct medical relevance. It was not until the late 19th century and the work of Martinus Beijerinck and Sergei Winogradsky that the true breadth of microbiology was revealed. Beijerinck made two major contributions to microbiology: the discovery of viruses and the development of enrichment culture techniques. While his work on the tobacco mosaic virus established the basic principles of virology, it was his development of enrichment culturing that had the most immediate impact on microbiology by allowing for the cultivation of a wide range of microbes with wildly different physiologies. Winogradsky was the first to develop the concept of chemolithotrophy and to thereby reveal the essential role played by microorganisms in geochemical processes. He was responsible for the first isolation and description of both nitrifying and nitrogen-fixing bacteria. French-Canadian microbiologist Felix d’Herelle co-discovered bacteriophages in 1917 and was one of the earliest applied microbiologists. Joseph Lister was the first to use phenol disinfectant on the open wounds of patients. The branches of microbiology can be classified into applied sciences, or divided according to taxonomy, as is the case with bacteriology, mycology, protozoology, virology, phycology, and microbial ecology. There is considerable overlap between the specific branches of microbiology with each other and with other disciplines, and certain aspects of these branches can extend beyond the traditional scope of microbiology. A pure research branch of microbiology is termed cellular microbiology. While some fear microbes due to the association of some microbes with various human diseases, many microbes are also responsible for numerous beneficial processes such as industrial fermentation (e.g. the production of alcohol, vinegar and dairy products), antibiotic production and act as molecular vehicles to transfer DNA to complex organisms such as plants and animals. Scientists have also exploited their knowledge of microbes to produce biotechnologically important enzymes such as Taq polymerase, reporter genes for use in other genetic systems and novel molecular biology techniques such as the yeast two-hybrid system. Bacteria can be used for the industrial production of amino acids. Corynebacterium glutamicum is one of the most important bacterial species with an annual production of more than two million tons of amino acids, mainly L-glutamate and L-lysine. Since some bacteria have the ability to synthesize antibiotics, they are used for medicinal purposes, such as Streptomyces to make aminoglycoside antibiotics. A variety of biopolymers, such as polysaccharides, polyesters, and polyamides, are produced by microorganisms. Microorganisms are used for the biotechnological production of biopolymers with tailored properties suitable for high-value medical application such as tissue engineering and drug delivery. Microorganisms are for example used for the biosynthesis of xanthan, alginate, cellulose, cyanophycin, poly(gamma-glutamic acid), levan, hyaluronic acid, organic acids, oligosaccharides polysaccharide and polyhydroxyalkanoates. Microorganisms are beneficial for microbial biodegradation or bioremediation of domestic, agricultural and industrial wastes and subsurface pollution in soils, sediments and marine environments. The ability of each microorganism to degrade toxic waste depends on the nature of each contaminant. Since sites typically have multiple pollutant types, the most effective approach to microbial biodegradation is to use a mixture of bacterial and fungal species and strains, each specific to the biodegradation of one or more types of contaminants. Symbiotic microbial communities confer benefits to their human and animal hosts health including aiding digestion, producing beneficial vitamins and amino acids, and suppressing pathogenic microbes. Some benefit may be conferred by eating fermented foods, probiotics (bacteria potentially beneficial to the digestive system) or prebiotics (substances consumed to promote the growth of probiotic microorganisms). The ways the microbiome influences human and animal health, as well as methods to influence the microbiome are active areas of research. Research has suggested that microorganisms could be useful in the treatment of cancer. Various strains of non-pathogenic clostridia can infiltrate and replicate within solid tumors. Clostridial vectors can be safely administered and their potential to deliver therapeutic proteins has been demonstrated in a variety of preclinical models. Some bacteria are used to study fundamental mechanism. An example of model bacteria used to study motility or the production of polysaccharides and devElopment Is Myxococcus Xanthus. 1.7 Taxonomy: Classification And Naming Of Microorganisms Taxonomy is the identification, naming and classification of organisms. Binomial nomenclature is a formal system of naming species of living things by giving each a name composed of two parts. Systematics is the branch of science that deals with unique properties of species and groups to recognise, describe name and arrange the diverse organisms according to an organised plan. In biology, phylogenetics (Greek: φυλή, φῦλον – phylé, phylon = tribe, clan, race + γενετικός – genetikós = origin, source, birth) is a part of systematics that addresses the inference of the evolutionary history and relationships among or within groups of organisms (e.g. species, or more inclusive taxa). Classifications are now usually based on phylogenetic data. The degree to which classification depends on inferred evolutionary history differs depending on the school of taxonomy: phenetics ignores phylogenetic speculation altogether, trying to represent the similarity between organisms instead; cladistics (phylogenetic systematics) tries to reflect phylogeny in its classifications by only recognizing groups based on shared, derived characters (synapomorphies); evolutionary taxonomy tries to take into account both the branching pattern and “degree of difference” to find a compromise between them. Biological classification is a critical component of the taxonomic process. As a result, it informs the user as to what the relatives of the taxon are hypothesized to be. Biological classification uses taxonomic ranks, including among others (in order from most inclusive to least inclusive): Domain, Kingdom, Phylum, Class, Order, Family, Genus, and Species Figure 1.1: Biological classification. The “definition” of a taxon is encapsulated by its description or its diagnosis or by both combined. There are no set rules governing the definition of taxa, but the naming and publication of new taxa is governed by sets of rules. In zoology, the nomenclature for the more commonly used ranks (superfamily to subspecies), is regulated by the International Code of Zoological Nomenclature (ICZN Code). In the fields of botany, phycology, and mycology, the naming of taxa is governed by the International Code of Nomenclature for algae, fungi, and plants (ICN). Bacterial taxonomy is the taxonomy, i.e. the rank-based classification, of bacteria. Despite there being no official and complete classification of prokaryotes, the names (nomenclature) given to prokaryotes are regulated by the International Code of Nomenclature of Bacteria (Bacteriological Code), a book which contains general considerations, principles, rules, and various notes, and advises in a similar fashion to the nomenclature codes of other groups. In the scientific classification established by Carl Linnaeus, each species has to be assigned to a genus (binary nomenclature), which in turn is a lower level of a hierarchy of ranks (family, suborder, order, subclass, class, division/phyla, kingdom and domain). In the currently accepted classification of life, there are three domains (Eukaryotes, Bacteria and Archaea), which, in terms of taxonomy, despite following the same principles have several different conventions between them and between their subdivisions as they are studied by different disciplines (botany, zoology, mycology and microbiology). For example, in zoology there are type specimens, whereas in microbiology there are type strains. The initial description of a taxon involves five main requirements: The taxon must be given a name based on the 26 letters of the Latin alphabet (a binomial for new species, or uninomial for other ranks). The name must be unique (i.e. not a homonym). The description must be based on at least one name-bearing type specimen. It should include statements about appropriate attributes either to describe (define) the taxon or to differentiate it from other taxa (the diagnosis, ICZN Code, Article 13.1.1, ICN, Article 38). Both codes deliberately separate defining the content of a taxon (its circumscription) from defining its name. These first four requirements must be published in a work that is obtainable in numerous identical copies, as a permanent scientific record. However, often much more information is included, like the geographic range of the taxon, ecological notes, chemistry, behavior, etc. How researchers arrive at their taxa varies: depending on the available data, and resources, methods vary from simple quantitative or qualitative comparisons of striking features, to elaborate computer analyses of large amounts of DNA sequence data. An “authority” may be placed after a scientific name. The authority is the name of the scientist or scientists who first validly published the name. For example, in 1758 Linnaeus gave the Asian elephant the scientific name Elephas maximus, so the name is sometimes written as “Elephas maximus Linnaeus, 1758”. The names of authors are frequently abbreviated: the abbreviation L., for Linnaeus, is commonly used. In botany, there is, in fact, a regulated list of standard abbreviations (see list of botanists by author abbreviation). The system for assigning authorities differs slightly between botany and zoology. However, it is standard that if a species’ name or placement has been changed since the original description, the original authority’s name is placed in parentheses. Figure 1.2: The tree of life. 1.7.1 The Concept of Species in Biology In biology, a species is the basic unit of classification and a taxonomic rank of an organism, as well as a unit of biodiversity. A species is often defined as the largest group of organisms in which any two individuals of the appropriate sexes or mating types can produce fertile offspring, typically by sexual reproduction. Other ways of defining species include their karyotype, DNA sequence, morphology, behaviour or ecological niche. In addition, paleontologists use the concept of the chronospecies since fossil reproduction cannot be examined. Species were seen from the time of Aristotle until the 18th century as fixed categories that could be arranged in a hierarchy, the great chain of being. In the 19th century, biologists grasped that species could evolve given sufficient time. Charles Darwin’s 1859 book On the Origin of Species explained how species could arise by natural selection. That understanding was greatly extended in the 20th century through genetics and population ecology. Genetic variability arises from mutations and recombination, while organisms themselves are mobile, leading to geographical isolation and genetic drift with varying selection pressures. Genes can sometimes be exchanged between species by horizontal gene transfer; new species can arise rapidly through hybridisation and polyploidy; and species may become extinct for a variety of reasons. Biologists and taxonomists have made many attempts to define species, beginning from morphology and moving towards genetics. Early taxonomists such as Linnaeus had no option but to describe what they saw: this was later formalised as the typological or morphological species concept. Ernst Mayr proposed the widely used Biological Species Concept of reproductive isolation in 1942. Later biologists have tried to refine Mayr’s definition. Many of the concepts are quite similar or overlap, so they are not easy to count: the biologist R. L. Mayden recorded about 24 concepts, and the philosopher of science John Wilkins counted 26. Wilkins further grouped the species concepts into seven basic kinds of concepts: (1) agamospecies for asexual organisms (2) biospecies for reproductively isolated sexual organisms (3) ecospecies based on ecological niches (4) evolutionary species based on lineage (5) genetic species based on gene pool (6) morphospecies based on form or phenotype and (7) taxonomic species, a species as determined by a taxonomist. A typological species is a group of organisms in which individuals conform to certain fixed properties (a type), so that even pre-literate people often recognise the same taxon as do modern taxonomists. The clusters of variations or phenotypes within specimens (such as longer or shorter tails) would differentiate the species. This method was used as a “classical” method of determining species, such as with Linnaeus early in evolutionary theory. However, different phenotypes are not necessarily different species (e.g. a four-winged Drosophila born to a two-winged mother is not a different species). Species named in this manner are called morphospecies. A species is given a taxonomic name when a type specimen is described formally, in a publication that assigns it a unique scientific name. The description typically provides means for identifying the new species, differentiating it from other previously described and related or confusable species and provides a validly published name (in botany) or an available name (in zoology) when the paper is accepted for publication. The type material is usually held in a permanent repository, often the research collection of a major museum or university, that allows independent verification and the means to compare specimens. Describers of new species are asked to choose names that, in the words of the International Code of Zoological Nomenclature, are “appropriate, compact, euphonious, memorable, and do not cause offence”. The naming of a particular species, including which genus (and higher taxa) it is placed in, is a hypothesis about the evolutionary relationships and distinguishability of that group of organisms. As further information comes to hand, the hypothesis may be confirmed or refuted. Sometimes, especially in the past when communication was more difficult, taxonomists working in isolation have given two distinct names to individual organisms later identified as the same species. When two named species are discovered to be of the same species, the older species name is given priority and usually retained, and the newer name considered as a junior synonym, a process called synonymisation. Dividing a taxon into multiple, often new, taxa is called splitting. Taxonomists are often referred to as “lumpers” or “splitters” by their colleagues, depending on their personal approach to recognising differences or commonalities between organisms. Figure 1.3: The butterfly genus Heliconius contains many similar species. It is difficult to define a species in a way that applies to all organisms. The debate about species delimitation is called the species problem. The problem was recognized even in 1859, when Darwin wrote in On the Origin of Species: No one definition has satisfied all naturalists; yet every naturalist knows vaguely what he means when he speaks of a species. Generally the term includes the unknown element of a distinct act of creation. The evolutionary process by which biological populations evolve to become distinct or reproductively isolated as species is called speciation. Charles Darwin was the first to describe the role of natural selection in speciation in his 1859 book The Origin of Species. Speciation depends on a measure of reproductive isolation, a reduced gene flow. This occurs most easily in allopatric speciation, where populations are separated geographically and can diverge gradually as mutations accumulate. Reproductive isolation is threatened by hybridisation, but this can be selected against once a pair of populations have incompatible alleles of the same gene, as described in the Bateson–Dobzhansky–Muller model. A different mechanism, phyletic speciation, involves one lineage gradually changing over time into a new and distinct form, without increasing the number of resultant species. Bacteria divide asexually and for the most part do not show regionalisms (“Everything is everywhere”), therefore the concept of species, which works best for animals, becomes entirely a matter of judgement. The number of named species of bacteria and archaea (approximately 13,000) is surprisingly small considering their early evolution, genetic diversity and residence in all ecosystems. The reason for this is the differences in species concepts between the bacteria and macro-organisms, the difficulties in growing/characterising in pure culture (a prerequisite to naming new species, vide supra) and extensive horizontal gene transfer blurring the distinction of species. The most commonly accepted definition is the polyphasic species definition, which takes into account both phenotypic and genetic differences. However, a quicker diagnostic ad hoc threshold to separate species is less than 70% DNA–DNA hybridisation, which corresponds to less than 97% 16S DNA sequence identity. It has been noted that if this were applied to animal classification, the order primates would be a single species. For this reason, more stringent species definitions based on whole genome sequences have been proposed. 1.7.2 Binomial Nomenclature The commonly used names for kinds of organisms are often ambiguous: “cat” could mean the domestic cat or the cat family. Another problem with common names is that they often vary from place to place, so that puma, cougar, catamount, panther, painter and mountain lion all mean Puma concolor in various parts of America, while “panther” may also mean the jaguar (Panthera onca) of Latin America or the leopard (Panthera pardus) of Africa and Asia. In contrast, the scientific names of species are chosen to be unique and universal; they are in two parts used together: the genus as in Puma, and the specific epithet as in concolor. Binomial nomenclature (“two-term naming system”), also called binominal nomenclature (“two-name naming system”) or binary nomenclature, is a formal system of naming species of living things by giving each a name composed of two parts, both of which use Latin grammatical forms, although they can be based on words from other languages. Such a name is called a binomial name (which may be shortened to just “binomial”), a binomen, binominal name or a scientific name; more informally it is also called a Latin name. The first part of the name – the generic name – identifies the genus to which the species belongs, while the second part – the specific name or specific epithet – identifies the species within the genus. For example, humans belong to the genus Homo and within this genus to the species Homo sapiens. Tyrannosaurus rex is probably the most widely known binomial. The formal introduction of this system of naming species is credited to Carl Linnaeus, effectively beginning with his work Species Plantarum in 1753. But Gaspard Bauhin, in as early as 1622, had introduced in his book Pinax theatri botanici (English, Illustrated exposition of plants) many names of genera that were later adopted by Linnaeus. The application of binomial nomenclature is now governed by various internationally agreed codes of rules, of which the two most important are the International Code of Zoological Nomenclature (ICZN) for animals and the International Code of Nomenclature for algae, fungi, and plants (ICNafp). Although the general principles underlying binomial nomenclature are common to these two codes, there are some differences, both in the terminology they use and in their precise rules. In modern usage, the first letter of the first part of the name, the genus, is always capitalized in writing, while that of the second part is not, even when derived from a proper noun such as the name of a person or place. Similarly, both parts are italicized when a binomial name occurs in normal text (or underlined in handwriting). Thus the binomial name of the annual phlox (named after botanist Thomas Drummond) is now written as Phlox drummondii. In scientific works, the authority for a binomial name is usually given, at least when it is first mentioned, and the date of publication may be specified. For Bacteria, valid names must have a Latin or Neolatin name and can only use basic latin letters (w and j inclusive, see History of the Latin alphabet for these), consequently hyphens, accents and other letters are not accepted and should be transliterated correctly (e.g. ß=ss). Ancient Greek being written in the Greek alphabet, needs to be transliterated into the Latin alphabet. 1.7.3 Taxonomy And Systematics Taxonomy (from Ancient Greek taxis, meaning ‘arrangement’, and nomia, meaning ‘method’) is the science of defining and naming groups of biological organisms on the basis of shared characteristics. Organisms are grouped together into taxa (singular: taxon) and these groups are given a taxonomic rank; groups of a given rank can be aggregated to form a super-group of higher rank, thus creating a taxonomic hierarchy. The principal ranks in modern use are domain, kingdom, phylum (division is sometimes used in botany in place of phylum), class, order, family, genus and species. The Swedish botanist Carl Linnaeus (1707–1778) is regarded as the father of taxonomy, as he developed a system known as Linnaean taxonomy for categorization of organisms and binomial nomenclature for naming organisms. With the advent of such fields of study as phylogenetics, cladistics, and systematics, the Linnaean system has progressed to a system of modern biological classification based on the evolutionary relationships between organisms, both living and extinct. Systematics is the branch of science that deals with unique properties of species and groups to recognise, describe name and arrange the diverse organisms according to an organised plan. The word systematics is derived from Latin word systema which means systematic arrangement of organisms.linneous used ‘systema naturae’ as the title of his book. The term “taxonomy” was coined by Augustin Pyramus de Candolle while the term “systematic” was coined by Carl Linnaeus the father of taxonomy. Biological systematics is the study of the diversification of living forms, both past and present, and the relationships among living things through time. Relationships are visualized as evolutionary trees (synonyms: cladograms, phylogenetic trees, phylogenies). Phylogenies have two components: branching order (showing group relationships) and branch length (showing amount of evolution). Phylogenetic trees of species and higher taxa are used to study the evolution of traits (e.g., anatomical or molecular characteristics) and the distribution of organisms (biogeography). Systematics, in other words, is used to understand the evolutionary history of life on Earth. Biological systematics classifies species by using three specific branches. Numerical systematics, or biometry, uses biological statistics to identify and classify animals. Biochemical systematics classifies and identifies animals based on the analysis of the material that makes up the living part of a cell—such as the nucleus, organelles, and cytoplasm. Experimental systematics identifies and classifies animals based on the evolutionary units that comprise a species, as well as their importance in evolution itself. Factors such as mutations, genetic divergence, and hybridization all are considered evolutionary units. With the specific branches, researchers are able to determine the applications and uses for modern-day systematics. These applications include: Studying the diversity of organisms and the differentiation between extinct and living creatures. Biologists study the well-understood relationships by making many different diagrams and “trees” (cladograms, phylogenetic trees, phylogenies, etc.). Including the scientific names of organisms, species descriptions and overviews, taxonomic orders, and classifications of evolutionary and organism histories. Explaining the biodiversity of the planet and its organisms. The systematic study is that of conservation. Manipulating and controlling the natural world. This includes the practice of ‘biological control’, the intentional introduction of natural predators and disease. Linnaeus ushered in a new era of taxonomy. With his major works Systema Naturae 1st Edition in 1735, Species Plantarum in 1753, and Systema Naturae 10th Edition, he revolutionized modern taxonomy. His works implemented a standardized binomial naming system for animal and plant species, which proved to be an elegant solution to a chaotic and disorganized taxonomic literature. He not only introduced the standard of class, order, genus, and species, but also made it possible to identify plants and animals from his book, by using the smaller parts of the flower. Thus, the Linnaean system was born, and is still used in essentially the same way today as it was in the 18th century. Currently, plant and animal taxonomists regard Linnaeus’ work as the “starting point” for valid names (at 1753 and 1758 respectively). Names published before these dates are referred to as “pre-Linnaean”, and not considered valid (with the exception of spiders published in Svenska Spindlar). Even taxonomic names published by Linnaeus himself before these dates are considered pre-Linnaean. Whereas Linnaeus classified for ease of identification, the idea of the Linnaean taxonomy as translating into a sort of dendrogram of the Animal- and Plant Kingdoms was formulated toward the end of the 18th century, well before On the Origin of Species was published. Among early works exploring the idea of a transmutation of species were Erasmus Darwin’s 1796 Zoönomia and Jean-Baptiste Lamarck’s Philosophie Zoologique of 1809. The idea was popularized in the Anglophone world by the speculative but widely read Vestiges of the Natural History of Creation, published anonymously by Robert Chambers in 1844. With Darwin’s theory, a general acceptance quickly appeared that a classification should reflect the Darwinian principle of common descent. Tree of life representations became popular in scientific works, with known fossil groups incorporated. One of the first modern groups tied to fossil ancestors was birds. Using the then newly discovered fossils of Archaeopteryx and Hesperornis, Thomas Henry Huxley pronounced that they had evolved from dinosaurs, a group formally named by Richard Owen in 1842. The resulting description, that of dinosaurs “giving rise to” or being “the ancestors of” birds, is the essential hallmark of evolutionary taxonomic thinking. As more and more fossil groups were found and recognized in the late 19th and early 20th centuries, paleontologists worked to understand the history of animals through the ages by linking together known groups. With the modern evolutionary synthesis of the early 1940s, an essentially modern understanding of the evolution of the major groups was in place. The cladistic method has emerged since the 1960s. In 1958, Julian Huxley used the term clade. Later, in 1960, Cain and Harrison introduced the term cladistic. The salient feature is arranging taxa in a hierarchical evolutionary tree, ignoring ranks. A taxon is called monophyletic, if it includes all the descendants of an ancestral form. Groups that have descendant groups removed from them (e.g. dinosaurs, with birds as offspring group) are termed paraphyletic, while groups representing more than one branch from the tree of life are called polyphyletic. The International Code of Phylogenetic Nomenclature or PhyloCode is intended to regulate the formal naming of clades. Linnaean ranks will be optional under the PhyloCode, which is intended to coexist with the current, rank-based codes. Bacteria were at first classified based solely on their shape (vibrio, bacillus, coccus etc.), presence of endospores, gram stain, aerobic conditions and motility. This system changed with the study of metabolic phenotypes, where metabolic characteristics were used. Recently, with the advent of molecular phylogeny, several genes are used to identify species, the most important of which is the 16S rRNA gene, followed by 23S, ITS region, gyrB and others to confirm a better resolution. The quickest way to identify to match an isolated strain to a species or genus today is done by amplifying it’s 16S gene with universal primers and sequence the 1.4kb amplicon and submit it to a specialised web-based identification database, namely either Ribosomal Database Project, which align the sequence to other 16S sequences using infernal, a secondary structure bases global alignment, or ARB SILVA, which aligns sequences via SINA (SILVA incremental aligner), which does a local alignment of a seed and extends it . Several identification methods exists: Phenotypic analyses fatty acid analyses Growth conditions (Agar plate, Biolog multiwell plates) Genetic analyses DNA-DNA hybridization DNA profiling Sequence GC ratios Phylogenetic analyses 16S-based phylogeny phylogeny based on other genes Multi-gene sequence analysis Whole-genome sequence based analysis 1.7.4 Kingdoms And Domains Well before Linnaeus, plants and animals were considered separate Kingdoms. Linnaeus used this as the top rank, dividing the physical world into the plant, animal and mineral kingdoms. As advances in microscopy made classification of microorganisms possible, the number of kingdoms increased, five and six-kingdom systems being the most common. When Carl Linnaeus introduced the rank-based system of nomenclature into biology in 1735, the highest rank was given the name “kingdom” and was followed by four other main or principal ranks: class, order, genus and species. Later two further main ranks were introduced, making the sequence kingdom, phylum or division, class, order, family, genus and species. In 1990, the rank of domain was introduced above kingdom. Prefixes can be added so subkingdom (subregnum) and infrakingdom (also known as infraregnum) are the two ranks immediately below kingdom. Superkingdom may be considered as an equivalent of domain or empire or as an independent rank between kingdom and domain or subdomain. In some classification systems the additional rank branch (Latin: ramus) can be inserted between subkingdom and infrakingdom, e.g., Protostomia and Deuterostomia in the classification of Cavalier-Smith. Some recent classifications based on modern cladistics have explicitly abandoned the term “kingdom”, noting that the traditional kingdoms are not monophyletic, i.e., do not consist of all the descendants of a common ancestor. By tradition, the binomial names of species are usually typeset in italics; for example, Homo sapiens. Generally, the binomial should be printed in a font style different from that used in the normal text; for example, “Several more Homo sapiens fossils were discovered.” When handwritten, a binomial name should be underlined; for example, Homo sapiens. The first part of the binomial, the genus name, is always written with an initial capital letter. In current usage, the second part is never written with an initial capital. Older sources, particularly botanical works published before the 1950s, use a different convention. If the second part of the name is derived from a proper noun, e.g. the name of a person or place, a capital letter was used. Thus the modern form Berberis darwinii was written as Berberis Darwinii. A capital was also used when the name is formed by two nouns in apposition, e.g. Panthera Leo or Centaurea Cyanus. When used with a common name, the scientific name often follows in parentheses, although this varies with publication. For example, “The house sparrow (Passer domesticus) is decreasing in Europe.” The binomial name should generally be written in full. The exception to this is when several species from the same genus are being listed or discussed in the same paper or report, or the same species is mentioned repeatedly; in which case the genus is written in full when it is first used, but may then be abbreviated to an initial (and a period/full stop). For example, a list of members of the genus Canis might be written as “Canis lupus, C. aureus, C. simensis”. In rare cases, this abbreviated form has spread to more general use; for example, the bacterium Escherichia coli is often referred to as just E. coli, and Tyrannosaurus rex is perhaps even better known simply as T. rex, these two both often appearing in this form in popular writing even where the full genus name has not already been given. 1.7.5 The Three-Domain System The three-domain system is a biological classification first proposed in 1977 by Carl Woese’s that divides cellular life forms into Archaea, Bacteria and Eukaryota. The key difference from earlier classifications is the splitting of archaea and bacteria, previously grouped into the single kingdom Bacteria (a kingdom also sometimes called Monera). The three-domain system adds a level of classification (the domains) “above” the kingdoms present in the previously used five- or six-kingdom systems. This classification system recognizes the fundamental divide between the two prokaryotic groups, insofar as Archaea appear to be more closely related to Eukaryotes than they are to other prokaryotes – bacteria-like organisms with no cell nucleus. The current system sorts the previously known kingdoms into these three domains: Archaea, Bacteria, and Eukarya. Woese argued, on the basis of differences in 16S rRNA genes, that bacteria, archaea, and eukaryotes each arose separately from an ancestor with poorly developed genetic machinery, often called a progenote. To reflect these primary lines of descent, he treated each as a domain, divided into several different kingdoms. Originally his split of the prokaryotes was into Eubacteria (now Bacteria) and Archaebacteria (now Archaea). Woese initially used the term “kingdom” to refer to the three primary phylogenic groupings, and this nomenclature was widely used until the term “domain” was adopted in 1990. Acceptance of the validity of Woese’s phylogenetically valid classification was a slow process. Prominent biologists including Salvador Luria and Ernst Mayr objected to his division of the prokaryotes. Not all criticism of him was restricted to the scientific level. A decade of labor-intensive oligonucleotide cataloging left him with a reputation as “a crank,” and Woese would go on to be dubbed as “Microbiology’s Scarred Revolutionary” by a news article printed in the journal Science. The growing amount of supporting data led the scientific community to accept the Archaea by the mid-1980s. Today, few scientists cling to the idea of a unified Prokarya. 1.7.6 Bergey’s Manual of Systematic Bacteriology Bergey’s Manual of Systematics of Archaea and Bacteria (BMSAB) is the main resource for determining the identity of prokaryotic organisms, emphasizing bacterial species, using every characterizing aspect. The manual was published subsequent to the Bergey’s Manual of Determinative Bacteriology, though the latter is still published as a guide for identifying unknown bacteria. First published in 1923 by David Hendricks Bergey, it is used to classify bacteria based on their structural and functional attributes by arranging them into specific familial orders. However, this process has become more empirical in recent years. The Taxonomic Outline of Bacteria and Archaea is a derived publication indexing taxon names from version two of the manual. It used to be available for free from the Bergey’s manual trust website until September 2018. Michigan State University provides an alternative version that indexes NamesforLife records. The change in volume set to “Systematic Bacteriology” came in a new contract in 1980, whereupon the new style included “relationships between organisms” and had “expanded scope” overall. This new style was picked up for a four-volume set that first began publishing in 1984. The information in the volumes was separated as: Volume 1 included information on all types of Gram-negative bacteria that were considered to have “medical and industrial importance.” Volume 2 included information on all types of Gram-positive bacteria. Volume 3 deals with all of the remaining, slightly different Gram-negative bacteria, along with the Archaea. Volume 4 has information on filamentous actinomycetes and other, similar bacteria. The current volumes differ drastically from previous volumes in that many higher taxa are not defined in terms of phenotype, but solely on 16S phylogeny, as is the case of the classes within Proteobacteria. The current grouping is: Volume 1 (2001): The Archaea and the deeply branching and phototrophic Bacteria Volume 2 (2005): The Proteobacteria—divided into three books: 2A: Introductory essays 2B: The Gammaproteobacteria 2C: Other classes of Proteobacteria Volume 3 (2009): The Firmicutes Volume 4 (2011): The Bacteroidetes, Spirochaetes, Tenericutes (Mollicutes), Acidobacteria, Fibrobacteres, Fusobacteria, Dictyoglomi, Gemmatimonadetes, Lentisphaerae, Verrucomicrobia, Chlamydiae, and Planctomycetes Volume 5 (in two parts) (2012): The Actinobacteria Bergey’s manual of systematics of archaea and bacteria (2015), an online book, replaces the five-volume set. "],["the-chemistry-of-biology.html", "2 The Chemistry Of Biology 2.1 Matter 2.2 The Atom 2.3 The Periodic Table of The Elements 2.4 Chemical Bonds, Molecules, And Compounds 2.5 Energy 2.6 Chemical Reactions 2.7 Radioactive Decay of Atoms 2.8 Ions And Salts 2.9 Solutions 2.10 Acids And Bases 2.11 Reduction-oxidation (Redox) Reactions 2.12 The Chemistry Of Water 2.13 Basic Organic Chemistry For Biology", " 2 The Chemistry Of Biology Chemistry is the scientific discipline involved with elements and compounds composed of atoms, molecules and ions: their composition, structure, properties, behavior and the changes they undergo during a reaction with other substances. In the scope of its subject, chemistry occupies an intermediate position between physics and biology. For example, chemistry explains aspects of plant chemistry (botany), the formation of igneous rocks (geology), how atmospheric ozone is formed and how environmental pollutants are degraded (ecology), the properties of the soil on the moon (astrophysics), how medications work (pharmacology), and how to collect DNA evidence at a crime scene (forensics). Chemistry addresses topics such as how atoms and molecules interact via chemical bonds to form new chemical compounds. There are four types of chemical bonds: covalent bonds, in which compounds share one or more electron(s); ionic bonds, in which a compound donates one or more electrons to another compound to produce ions (cations and anions); hydrogen bonds; and Van der Waals force bonds. The current model of atomic structure is the quantum mechanical model. Traditional chemistry starts with the study of elementary particles, atoms, molecules, substances, metals, crystals and other aggregates of matter. Matter can be studied in solid, liquid, gas and plasma states, in isolation or in combination. The interactions, reactions and transformations that are studied in chemistry are usually the result of interactions between atoms, leading to rearrangements of the chemical bonds which hold atoms together. A chemical reaction is a transformation of some substances into one or more different substances. The basis of such a chemical transformation is the rearrangement of electrons in the chemical bonds between atoms. It can be symbolically depicted through a chemical equation, which usually involves atoms as subjects. The number of atoms on the left and the right in the equation for a chemical transformation is equal. (When the number of atoms on either side is unequal, the transformation is referred to as a nuclear reaction or radioactive decay.) The type of chemical reactions a substance may undergo and the energy changes that may accompany it are constrained by certain basic rules, known as chemical laws. 2.1 Matter In classical physics and general chemistry, matter (from Latin materia meaning “matter, stuff, material”, a derivative of Latin mater meaning “mother”) is any substance that has mass and takes up space by having volume. Matter should not be confused with mass, as the two are not the same in modern physics. Matter is a general term describing any ‘physical substance’. By contrast, mass is not a substance but rather a quantitative property of matter and other substances or systems. All everyday objects that can be touched are ultimately composed of atoms, which are made up of interacting subatomic particles, and in everyday as well as scientific usage, “matter” generally includes atoms and anything made up of them, and any particles (or combination of particles) that act as if they have both rest mass and volume. However it does not include massless particles such as photons, or other energy phenomena or waves such as light or sound. Matter exists in various states (also known as phases). These include classical everyday phases such as solid, liquid, and gas – for example water exists as ice, liquid water, and gaseous steam – but other states are possible, including plasma, Bose–Einstein condensates, fermionic condensates, and quark–gluon plasma. Usually atoms can be imagined as a nucleus of protons and neutrons, and a surrounding “cloud” of orbiting electrons which “take up space”. However this is only somewhat correct, because subatomic particles and their properties are governed by their quantum nature, which means they do not act as everyday objects appear to act – they can act like waves as well as particles and they do not have well-defined sizes or positions. In the Standard Model of particle physics, matter is not a fundamental concept because the elementary constituents of atoms are quantum entities which do not have an inherent “size” or “volume” in any everyday sense of the word. Due to the exclusion principle and other fundamental interactions, some “point particles” known as fermions (quarks, leptons), and many composites and atoms, are effectively forced to keep a distance from other particles under everyday conditions; this creates the property of matter which appears to us as matter taking up space. 2.2 The Atom An atom is the smallest unit of ordinary matter that forms a chemical element. Every solid, liquid, gas, and plasma is composed of neutral or ionized atoms. Atoms are extremely small, typically around 100 picometers across. They are so small that accurately predicting their behavior using classical physics—as if they were tennis balls, for example—is not possible due to quantum effects. The word atom is derived from Ancient Greek ἄτομος (átomos, “indivisible”), from ἀ- (a-, “not”) + τέμνω (témnō, “I cut”), which means “uncuttable”. Every atom is composed of a nucleus and one or more electrons surrounding the nucleus. The nucleus is made of one or more protons and a number of neutrons. Only the most common variety of hydrogen has no neutrons. More than 99.94% of an atom’s mass is in the nucleus. The protons have a positive electric charge, the electrons have a negative electric charge, and the neutrons have no electric charge. If the number of protons and electrons are equal, then the atom is electrically neutral. If an atom has more or fewer electrons than protons, then it has an overall negative or positive charge, respectively — such atoms are called ions. The electrons of an atom are attracted to the protons in an atomic nucleus by the electromagnetic force. The protons and neutrons in the nucleus are attracted to each other by the nuclear force. This force is usually stronger than the electromagnetic force that repels the positively charged protons from one another. Under certain circumstances, the repelling electromagnetic force becomes stronger than the nuclear force. In this case, the nucleus splits and leaves behind different elements. This is a form of nuclear decay. The number of protons in the nucleus is the atomic number and it defines to which chemical element the atom belongs. For example, any atom that contains 29 protons is copper. The number of neutrons defines the isotope of the element. Atoms can attach to one or more other atoms by chemical bonds to form chemical compounds such as molecules or crystals. The ability of atoms to associate and dissociate is responsible for most of the physical changes observed in nature. Chemistry is the discipline that studies these changes. Atoms are extremely small, typically around 100 picometers (1 picometer = 10-12m) across. They are so small that accurately predicting their behavior using classical physics—as if they were billiard balls, for example—is not possible due to quantum effects. Current atomic models use quantum mechanics to better explain and predict this behavior. The word quantum derives from the Latin, meaning “how great” or “how much”. In quantum mechanics, it refers to a discrete unit assigned to certain physical quantities such as the energy of an atom at rest. The discovery that particles are discrete packets of energy with wave-like properties led to the branch of physics dealing with atomic and subatomic systems which is today called quantum mechanics. It underlies the mathematical framework of many fields of physics and chemistry. Quantum mechanics is essential for understanding the behavior of systems at atomic length scales and smaller. If the physical nature of an atom were solely described by classical mechanics, electrons would not orbit the nucleus, since orbiting electrons emit radiation (due to circular motion) and so would quickly lose energy and collide with the nucleus. This framework was unable to explain the stability of atoms. Instead, electrons remain in an uncertain, non-deterministic, smeared, probabilistic wave–particle orbital about the nucleus, defying the traditional assumptions of classical mechanics and electromagnetism. Quantum mechanics is also critically important for understanding how individual atoms are joined by covalent bonds to form molecules. The application of quantum mechanics to chemistry is known as quantum chemistry. Quantum mechanics can also provide quantitative insight into ionic and covalent bonding processes by explicitly showing which molecules are energetically favorable to which others and the magnitudes of the energies involved. Furthermore, most of the calculations performed in modern computational chemistry rely on quantum mechanics. Figure 2.1: An illustration of the helium atom, depicting the nucleus (pink) and the electron cloud distribution (black). The nucleus (upper right) in helium-4 is in reality spherically symmetric and closely resembles the electron cloud, although for more complicated nuclei this is not always the case. The black bar is one angstrom (10−10 m or100 pm). For much of the history of the natural sciences people have contemplated the exact nature of matter. The idea that matter was built of discrete building blocks, the so-called particulate theory of matter, independently appeared in ancient Greece and ancient India among Buddhists, Hindus and Jains in 1st-millennium BC. Ancient philosophers who proposed the particulate theory of matter include Kanada (c. 6th–century BC or after), Leucippus (~490 BC) and Democritus (~470–380 BC). In the early 1800s, John Dalton compiled experimental data gathered by himself and other scientists and observed that chemical elements seemed to combine by weight in ratios of small whole numbers; he called this pattern the “law of multiple proportions”. For instance, there are two types of tin oxide: one is 88.1% tin and 11.9% oxygen, and the other is 78.7% tin and 21.3% oxygen. Adjusting these figures, for every 100 g of tin there is either 13.5 g or 27 g of oxygen respectively. 13.5 and 27 form a ratio of 1:2, a ratio of small whole numbers. Similarly, there are two common types of iron oxide, in which for every 112 g of iron there is either 32 g or 48 g of oxygen respectively, which gives a ratio of 2:3. As a final example, there are three oxides of nitrogen in which for every 140 g of nitrogen, there is 80 g, 160 g, and 320 g of oxygen respectively, which gives a ratio of 1:2:4. This recurring pattern in the data suggested that elements always combine in multiples of discrete units, which Dalton concluded were atoms. In the case of the tin oxides, for every one tin atom, there are either one or two oxygen atoms (SnO and SnO2). In the case of the iron oxides, for every two iron atoms, there are either two or three oxygen atoms (FeO and Fe2O3). In the case of the nitrogen oxides, their formulas are N2O, NO, and NO2. In the late 18th century, a number of scientists found that they could better explain the behavior of gases by describing them as collections of sub-microscopic particles and modelling their behavior using statistics and probability. Unlike Dalton’s atomic theory, the kinetic theory of gases describes not how gases react chemically with each other to form compounds, but how they behave physically: diffusion, viscosity, conductivity, pressure, etc. In 1827, botanist Robert Brown used a microscope to look at dust grains floating in water and discovered that they moved about erratically, a phenomenon that became known as “Brownian motion”. This was thought to be caused by water molecules knocking the grains about. In 1905, Albert Einstein proved the reality of these molecules and their motions by producing the first statistical physics analysis of Brownian motion. French physicist Jean Perrin used Einstein’s work to experimentally determine the mass and dimensions of atoms, thereby verifying Dalton’s atomic theory. In 1897, J.J. Thomson discovered that cathode rays are not electromagnetic waves but made of particles that are 1,800 times lighter than hydrogen (the lightest atom). Therefore, they were not atoms, but a new particle, the first subatomic particle to be discovered. He called these new particles corpuscles but they were later renamed electrons. Thomson also showed that electrons were identical to particles given off by photoelectric and radioactive materials. It was quickly recognized that electrons are the particles that carry electric currents in metal wires, and carry the negative electric charge within atoms. Thus Thomson overturned the belief that atoms are the indivisible, fundamental particles of matter. The misnomer “atom” is still used, even though atoms are not literally “uncuttable”. J. J. Thomson postulated that the negatively-charged electrons were distributed throughout the atom in a uniform sea of positive charge. This was known as the plum pudding model. In 1909, Hans Geiger and Ernest Marsden, working under the direction of Ernest Rutherford, bombarded metal foil with alpha particles to observe how they scattered. They expected all the charged particles to pass straight through with little deflection, because Thomson’s model said that the charges in the atom are so diffuse that their electric fields in the foil could not affect the alpha particles much. Yet Geiger and Marsden spotted alpha particles being deflected by angles greater than 90°, which was supposed to be impossible according to Thomson’s model. To explain this, Rutherford proposed that the positive charge of the atom is concentrated in a tiny nucleus at the center. Only such an intense concentration of charge could produce an electric field strong enough to deflect alpha particles that much. While experimenting with the products of radioactive decay, in 1913 radiochemist Frederick Soddy discovered that there appeared to be more than one type of atom at each position on the periodic table. The term isotope was coined by Margaret Todd as a suitable name for different atoms that belong to the same element. J.J. Thomson created a technique for isotope separation through his work on ionized gases, which subsequently led to the discovery of stable isotopes. The development of the mass spectrometer allowed the mass of atoms to be measured with increased accuracy. The device uses a magnet to bend the trajectory of a beam of ions, and the amount of deflection is determined by the ratio of an atom’s mass to its charge. The chemist Francis William Aston used this instrument to show that isotopes had different masses. The atomic mass of these isotopes varied by integer amounts, called the whole number rule. The explanation for these different isotopes awaited the discovery of the neutron, an uncharged particle with a mass similar to the proton, by the physicist James Chadwick in 1932. Isotopes were then explained as elements with the same number of protons, but different numbers of neutrons within the nucleus. In 1913 the physicist Niels Bohr proposed a model in which the electrons of an atom were assumed to orbit the nucleus but could only do so in a finite set of orbits, and could jump between these orbits only in discrete changes of energy corresponding to absorption or radiation of a photon. This quantization was used to explain why the electrons’ orbits are stable (given that normally, charges in acceleration, including circular motion, lose kinetic energy which is emitted as electromagnetic radiation, see synchrotron radiation) and why elements absorb and emit electromagnetic radiation in discrete spectra. Figure 2.2: Niels Bohr’s 1913 quantum model of the atom, which incorporated an explanation of Johannes Rydberg’s 1888 formula, Max Planck’s 1900 quantum hypothesis, i.e. that atomic energy radiators have discrete energy values (ε = hν), J. J. Thomson’s 1904 plum pudding model, Albert Einstein’s 1905 light quanta postulate, and Ernest Rutherford’s 1907 discovery of the atomic nucleus. Note that the electron does not travel along the black line when emitting a photon. It “jumps”, disappearing from the outer orbit and appearing in the inner one and cannot exist in the space between orbits 2 and 3. The Bohr model of the hydrogen atom (Z = 1) or a hydrogen-like ion (Z &gt; 1), where the negatively charged electron confined to an atomic shell encircles a small, positively charged atomic nucleus and where an electron jumps between orbits, is accompanied by an emitted or absorbed amount of electromagnetic energy (hν). The orbits in which the electron may travel are shown as grey circles; their radius increases as n2, where n is the principal quantum number. The 3 → 2 transition depicted here produces the first line of the Balmer series, and for hydrogen (Z = 1) it results in a photon of wavelength 656 nm (red light). Later in the same year Henry Moseley provided additional experimental evidence in favor of Niels Bohr’s theory. These results refined Ernest Rutherford’s and Antonius Van den Broek’s model, which proposed that the atom contains in its nucleus a number of positive nuclear charges that is equal to its (atomic) number in the periodic table. Until these experiments, atomic number was not known to be a physical and experimental quantity. That it is equal to the atomic nuclear charge remains the accepted atomic model today. Atomic dimensions are thousands of times smaller than the wavelengths of light (400–700 nm) so they cannot be viewed using an optical microscope, although individual atoms can be observed using a scanning tunneling microscope. To visualize the minuteness of the atom, consider that a typical human hair is about 1 million carbon atoms in width. A single drop of water contains about 2 sextillion (2×1021) atoms of oxygen, and twice the number of hydrogen atoms. A single carat diamond with a mass of 2×10−4 kg contains about 10 sextillion (1022) atoms of carbon. If an apple were magnified to the size of the Earth, then an atom would be approximately the size of the original apple. 2.2.1 Structure of The Atom Though the word atom originally denoted a particle that cannot be cut into smaller particles, in modern scientific usage the atom is composed of various subatomic particles. The constituent particles of an atom are the electron, the proton and the neutron. The electron is by far the least massive of these particles at 9.11×10−31 kg, with a negative electrical charge and a size that is too small to be measured using available techniques. Under ordinary conditions, electrons are bound to the positively charged nucleus by the attraction created from opposite electric charges. If an atom has more or fewer electrons than its atomic number, then it becomes respectively negatively or positively charged as a whole; a charged atom is called an ion. Protons have a positive charge and a mass 1,836 times that of the electron, at 1.6726×10−27 kg. The number of protons in an atom is called its atomic number. Neutrons have no electrical charge and have a free mass of 1,839 times the mass of the electron, or 1.6749×10−27 kg. Neutrons are the heaviest of the three constituent particles, but their mass can be reduced by the nuclear binding energy. Neutrons and protons (collectively known as nucleons) have comparable dimensions—on the order of 2.5×10−15 m. In the Standard Model of physics, electrons are truly elementary particles with no internal structure, whereas protons and neutrons are composite particles composed of elementary particles called quarks. There are two types of quarks in atoms, each having a fractional electric charge. Protons are composed of two up quarks (each with charge \\(+\\frac{2}{3}\\)) and one down quark (with a charge of \\(−\\frac{1}{3}\\)). Neutrons consist of one up quark and two down quarks. This distinction accounts for the difference in mass and charge between the two particles. The quarks are held together by the strong interaction (or strong force), which is mediated by gluons. The protons and neutrons, in turn, are held to each other in the nucleus by the nuclear force, which is a residuum of the strong force that has somewhat different range-properties (see the article on the nuclear force for more). The gluon is a member of the family of gauge bosons, which are elementary particles that mediate physical forces. 2.2.2 The Atomic Nucleus The nucleus of an atom consists of neutrons and protons, which in turn are the manifestation of more elementary particles, called quarks, that are held together by the nuclear strong force. The nuclear strong force extends far enough so as to bind the neutrons and protons together against the repulsive electrical force between the positively charged protons. The nuclear strong force has a very short range, and essentially drops to zero just beyond the edge of the nucleus. The collective action of the positively charged nucleus is to hold the electrically negative charged electrons in their orbits about the nucleus. The collection of negatively charged electrons orbiting the nucleus display an affinity for certain configurations and numbers of electrons that make their orbits stable. Which chemical element an atom represents is determined by the number of protons in the nucleus; the neutral atom will have an equal number of electrons orbiting that nucleus. Individual chemical elements can create more stable electron configurations by combining to share their electrons. It is that sharing of electrons to create stable electronic orbits about the nucleus that appears to us as the chemistry of our world. Protons define the entire charge of a nucleus, and hence its chemical identity. Neutrons are electrically neutral, but contribute to the mass of a nucleus to nearly the same extent as the protons. Neutrons can explain the phenomenon of isotopes (same atomic number with different atomic mass). The main role of neutrons is to reduce electrostatic repulsion inside the nucleus. The electrons of an atom are attracted to the protons in an atomic nucleus by the electromagnetic force. The protons and neutrons in the nucleus are attracted to each other by the nuclear force. This force is usually stronger than the electromagnetic force that repels the positively charged protons from one another. Under certain circumstances, the repelling electromagnetic force becomes stronger than the nuclear force. In this case, the nucleus splits and leaves behind different elements. This is a form of nuclear decay. The number of protons in the nucleus is the atomic number and it defines to which chemical element the atom belongs. For example, any atom that contains 6 protons is carbon. The number of neutrons defines the isotope of the element. For example, the most common isotope of carbon is 12C with 6 neutrons. Another carbon isotope found in nature is 14C, which has 8 neutrons. Atoms can attach to one or more other atoms by chemical bonds to form chemical compounds such as molecules or crystals. The ability of atoms to associate and dissociate is responsible for most of the physical changes observed in nature. 2.2.3 The Electron Cloud The electron cloud is a region surrounding the nucleus. The electrons in an atom are attracted to the protons in the nucleus by the electromagnetic force. This force binds the electrons to the nucleus, which means that an external source of energy is needed for the electron to escape. The closer an electron is to the nucleus, the greater the attractive force. Hence the electrons that are closer to the nucleus require more energy to escape than those at greater separations. Electrons, like other particles, have properties of both a particle and a wave. In atomic theory and quantum mechanics, an atomic orbital is a mathematical function describing the location and wave-like behavior of electrons surrounding an atom. The term “orbital” was coined by Robert Mulliken in 1932 as an abbreviation for one-electron orbital wave function. The term atomic orbital is also used to refer to the physical region or space where the electron can be calculated to be present using this function. Each atomic orbital corresponds to a particular energy level of the electron. The electron can change its state to a higher energy level by absorbing sufficient energy to boost it into the new quantum state. Likewise, through spontaneous emission, an electron in a higher energy state can drop to a lower energy state while radiating the excess energy. The electrons in an atom are described by a unique set of values of four so-called quantum numbers n, ℓ, and mℓ, and s. As n increases, the electron is farther from the nucleus, on average, has a higher energy and is, therefore, less tightly bound to the nucleus. For each value of n, ℓ can take integer (whole number) values ranging from 0 to n − 1 and mℓ can take integer values ranging from -ℓ to +ℓ, and s can take a value of (\\(+\\frac{1}{2}\\) or \\(-\\frac{1}{2}\\)) for each value of ℓ and mℓ. Hence, higher-n electron states are more numerous. Thus, each n-shell can accommodate up to a maximum of 2n2 electrons. In chemistry, values n = 1, 2, 3, 4, 5, 6, 7 correspond to the so-called electron shells, which may be thought of as onion-like layers surrounding the nucleus that are filled with electrons. The shell terminology comes from Arnold Sommerfeld’s modification of the Bohr model. Sommerfeld retained Bohr’s planetary model (electrons orbiting the atomic nucleus like planets the sun), but added orbits that formed a thick “shell” instead of the infinitely thin circular orbit of Bohr’s model. The closest shell to the nucleus is called the “1 shell” (also called the “K shell”), followed by the “2 shell” (or “L shell”), then the “3 shell” (or “M shell”), and so on farther and farther from the nucleus. The shells correspond to the principal quantum numbers (n = 1, 2, 3, 4 …) or are labeled alphabetically with the letters used in X-ray notation (K, L, M, …). Each shell is composed of one or more subshells (labeled with the letters s, p, d, and f, which are derived from the terms sharp, principal, diffuse, and fundamental historically used in the description of atomic spectral lines). For example, the first shell (with principal quantum number n = 1 also referred to as K shell) has one subshell, called 1s; the second (with principal quantum number n = 2 also referred to as L shell) shell has two subshells, called 2s (ℓ = 0) and 2p (ℓ = 1 and mℓ = -1, 0, 1); the third shell (with principal quantum number n = 3 also referred to as M shell) has 3s (ℓ = 0), 3p (ℓ = 1 and mℓ = -1, 0, 1), and 3d (ℓ = 2 and mℓ = -2, -1, 0, 1, 2); the fourth shell (with principal quantum number n = 4 also referred to as N shell) has 4s, 4p, 4d and 4f; the fifth shell (with principal quantum number n = 5 also referred to as O shell) has 5s, 5p, 5d, and 5f and can theoretically hold more in the 5g subshell that is not occupied in the ground-state electron configuration of any known element. Figure 2.3: The five filled atomic orbitals of a neon atom separated and arranged in order of increasing energy from left to right, with the last three orbitals being equal in energy. Each orbital holds up to two electrons, which most probably exist in the zones represented by the colored bubbles. Each electron is equally present in both orbital zones, shown here by color only to highlight the different wave phase. Several rules govern the placement of electrons in orbitals in each atom referred to as the atom’s electron configuration. The first dictates that no two electrons in an atom may have the same set of values of quantum numbers (this is the Pauli exclusion principle). These quantum numbers include the three that define orbitals, as well as s, or spin quantum number. Thus, two electrons may occupy a single orbital, so long as they have different values of s. However, only two electrons, because of their spin, can be associated with each orbital. Additionally, an electron always tends to fall to the lowest possible energy state. It is possible for it to occupy any orbital so long as it does not violate the Pauli exclusion principle, but if lower-energy orbitals are available, this condition is unstable. The electron will eventually lose energy (by releasing a photon) and drop into the lower orbital. Thus, electrons fill orbitals in the order specified by the energy sequence given above. This behavior is responsible for the structure of the periodic table. 2.3 The Periodic Table of The Elements The periodic table, also known as the periodic table of elements, is a tabular display of the chemical elements. In chemistry, an element is a pure substance which cannot be broken down by chemical means, consisting of atoms which have identical numbers of protons in their atomic nuclei. The number of protons in the nucleus is the defining property of an element, and is referred to as the atomic number (represented by the symbol Z). The mass number is the sum of the number of protons and neutrons in a nucleus. Although all the nuclei of all atoms belonging to one element will have the same atomic number, they may not necessarily have the same mass number; atoms of an element which have different mass numbers are known as isotopes. For example, all atoms with 6 protons in their nuclei are atoms of the chemical element carbon, but atoms of carbon may have mass numbers of 12 or 13. In the periodic table, elements are arranged by atomic number, electron configuration, and recurring chemical properties. The organization of the periodic table can be used to derive relationships between the various element properties, and also to predict chemical properties and behaviours of undiscovered or newly synthesized elements. Russian chemist Dmitri Mendeleev published the first recognizable periodic table in 1869, developed mainly to illustrate periodic trends of the then-known elements. He also predicted some properties of unidentified elements that were expected to fill gaps within the table. Most of his forecasts proved to be correct. Mendeleev’s idea has been slowly expanded and refined with the discovery or synthesis of further new elements and the development of new theoretical models to explain chemical behaviour. In total, 118 elements have been identified. The first 94 occur naturally on Earth, and the remaining 24 are synthetic elements produced in nuclear reactions. Figure 2.4: A simple depiction of the periodic table of the elements. The structure of the table shows periodic trends. The seven rows of the table, called periods, generally have metals on the left and nonmetals on the right. The columns, called groups, contain elements with similar chemical behaviours. Six groups have accepted names as well as assigned numbers: for example, group 17 elements are the halogens; and group 18 are the noble gases. Also displayed are four simple rectangular areas or blocks associated with the filling of different atomic orbitals. The periodic table may also be divided into several numbered rectangular ‘blocks’. The elements belonging to a given block have this common feature: their highest-energy electrons all belong to the same ℓ-state (but the n associated with that ℓ-state depends upon the period). For instance, the leftmost two columns constitute the ‘s-block’. The outermost electrons of Li and Be respectively belong to the 2s subshell, and those of Na and Mg to the 3s subshell. The following is the order for filling the “subshell” orbitals, which also gives the order of the “blocks” in the periodic table: 1s, 2s, 2p, 3s, 3p, 4s, 3d, 4p, 5s, 4d, 5p, 6s, 4f, 5d, 6p, 7s, 5f, 6d, 7p The “periodic” nature of the filling of orbitals, as well as emergence of the s, p, d, and f “blocks”, is more obvious if this order of filling is given in matrix form, with increasing principal quantum numbers starting the new rows (“periods”) in the matrix. Then, each subshell (composed of the first two quantum numbers) is repeated as many times as required for each pair of electrons it may contain. The result is a compressed periodic table, with each entry representing two successive elements: 1s 2s 2p 2p 2p 3s 3p 3p 3p 4s 3d 3d 3d 3d 3d 4p 4p 4p 5s 4d 4d 4d 4d 4d 5p 5p 5p 6s 4f 4f 4f 4f 4f 4f 4f 5d 5d 5d 5d 5d 6p 6p 6p 7s 5f 5f 5f 5f 5f 5f 5f 6d 6d 6d 6d 6d 7p 7p 7p Although this is the general order of orbital filling, there are exceptions, and the actual electronic energies of each element are also dependent upon additional details of the atoms. The number of electrons in an electrically neutral atom increases with the atomic number. The electrons in the outermost shell of a given atom, called valence electrons, tend to be responsible for an element’s chemical behavior. Elements that contain the same number of valence electrons can be grouped together and display similar chemical properties. The elements at the far right of the table have their outer shell completely filled with electrons, which results in chemically inert elements known as the noble gases. 2.4 Chemical Bonds, Molecules, And Compounds A chemical bond is an attraction between atoms. This attraction may be seen as the result of different behaviors of the outermost or valence electrons of atoms. Chemical bonds between atoms were explained by Gilbert Newton Lewis in 1916, as the interactions between their constituent electrons. As the chemical properties of the elements were known to largely repeat themselves according to the periodic law, in 1919 the American chemist Irving Langmuir suggested that this could be explained if the electrons in an atom were connected or clustered in some manner. Groups of electrons were thought to occupy a set of electron shells about the nucleus. Figure 2.5: Examples of Lewis dot-style representations of chemical bonds between carbon (C), hydrogen (H), and oxygen (O). Lewis dot diagrams were an early attempt to describe chemical bonding and are still widely used today. A chemical bond can be a covalent bond, an ionic bond, a hydrogen bond or just because of Van der Waals force. All bonds can be explained by quantum theory, but, in practice, simplification rules allow chemists to predict the strength, directionality, and polarity of bonds. Covalent bonding is a common type of bonding in which two or more atoms share valence electrons more or less equally. The simplest and most common type is a single bond in which two atoms share two electrons. Other types include the double bond, the triple bond. In non-polar covalent bonds, the electrons are shared equally between the bonding atoms. Molecules that are formed primarily from non-polar covalent bonds are often immiscible in water or other polar solvents, but much more soluble in non-polar solvents such as hexane. A polar covalent bond is a covalent bond with a significant ionic character. This means that the two shared electrons are closer to one of the atoms than the other, creating an imbalance of charge. Atoms will share valence electrons in such a way as to create a noble gas electron configuration (eight electrons in their outermost shell) for each atom. Atoms that tend to combine in such a way that they each have eight electrons in their valence shell are said to follow the octet rule. However, some elements like hydrogen and lithium need only two electrons in their outermost shell to attain this stable configuration; these atoms are said to follow the duet rule, and in this way they are reaching the electron configuration of the noble gas helium, which has two electrons in its outer shell. In a polar covalent bond, one or more electrons are unequally shared between two nuclei. Figure 2.6: A covalent bond between two hydrogen atoms forming a hydrogen molecule. An ionic bond is formed when a metal loses one or more of its electrons, becoming a positively charged cation, and the electrons are then gained by the non-metal atom, becoming a negatively charged anion. The two oppositely charged ions attract one another, and the ionic bond is the electrostatic force of attraction between them. For example, sodium (Na), a metal, loses one electron to become an Na+ cation while chlorine (Cl), a non-metal, gains this electron to become Cl−. The ions are held together due to electrostatic attraction, and that compound sodium chloride (NaCl), or common table salt, is formed. Figure 2.7: Formation of an ionic bond. Sodium and fluorine atoms undergoing a redox reaction to form sodium fluoride. Sodium loses its outer electron to give it a stable electron configuration, and this electron enters the fluorine atom exothermically. The oppositely charged ions – typically a great many of them – are then attracted to each other to form a solid. A molecule (from French molécule, from New Latin molecula (“a molecule”), diminutive of Latin moles (“a mass”); see mole + -cule.) is a group of two or more atoms held together by chemical bonds. A molecule may be homonuclear, that is, it consists of atoms of one chemical element, as with two atoms in the oxygen molecule (O2); or it may be heteronuclear, a chemical compound composed of more than one element, as with water (two hydrogen atoms and one oxygen atom; H2O). Molecules exist as electrically neutral units, unlike ions. When this rule is broken, giving the “molecule” a charge, the result is sometimes named a molecular ion or a polyatomic ion. The “inert” or noble gas elements (helium, neon, argon, krypton, xenon and radon) are composed of lone atoms as their smallest discrete unit, but the other isolated chemical elements consist of either molecules or networks of atoms bonded to each other in some way. Identifiable molecules compose familiar substances such as water, air, and many organic compounds like alcohol, sugar, gasoline, and the various pharmaceuticals. However, not all substances or chemical compounds consist of discrete molecules, and indeed most of the solid substances that make up the solid crust, mantle, and core of the Earth are chemical compounds without molecules. These other types of substances, such as ionic compounds and network solids, are organized in such a way as to lack the existence of identifiable molecules per se. Instead, these substances are discussed in terms of formula units or unit cells as the smallest repeating structure within the substance. Examples of such substances are mineral salts (such as table salt), solids like carbon and diamond, metals, and familiar silica and silicate minerals such as quartz and granite. One of the main characteristics of a molecule is its geometry often called its structure. While the structure of diatomic, triatomic or tetra-atomic molecules may be trivial, (linear, angular pyramidal etc.) the structure of polyatomic molecules, that are constituted of more than six atoms (of several elements) can be crucial for its chemical nature. 2.5 Energy In physics, energy (from the Ancient Greek: ἐνέργεια, romanized: energeia, lit. ‘activity, operation’) is the quantitative property that must be transferred to an object in order to perform work on, or to heat, the object. Energy is a conserved quantity; the law of conservation of energy states that energy can be converted in form, but not created or destroyed. The SI unit of energy is the joule, which is the energy transferred to an object by the work of moving it a distance of 1 metre against a force of 1 newton. The American physist Richard Feynman said during a 1961 lecture: There is a fact, or if you wish, a law, governing all natural phenomena that are known to date. There is no known exception to this law – it is exact so far as we know. The law is called the conservation of energy. It states that there is a certain quantity, which we call energy, that does not change in manifold changes which nature undergoes. That is a most abstract idea, because it is a mathematical principle; it says that there is a numerical quantity which does not change when something happens. It is not a description of a mechanism, or anything concrete; it is just a strange fact that we can calculate some number and when we finish watching nature go through her tricks and calculate the number again, it is the same. — The Feynman Lectures on Physics Common forms of energy include the kinetic energy of a moving object, the potential energy stored by an object’s position in a force field (gravitational, electric or magnetic), the elastic energy stored by stretching solid objects, the chemical energy released when a fuel burns, the radiant energy carried by light, and the thermal energy due to an object’s temperature. Mass and energy are closely related. Due to mass–energy equivalence, any object that has mass when stationary (called rest mass) also has an equivalent amount of energy whose form is called rest energy, and any additional energy (of any form) acquired by the object above that rest energy will increase the object’s total mass just as it increases its total energy. For example, after heating an object, its increase in energy could be measured as a small increase in mass, with a sensitive enough scale. Living organisms require energy to stay alive, such as the energy humans get from food. Human civilization requires energy to function, which it gets from energy resources such as fossil fuels, nuclear fuel, or renewable energy. The processes of Earth’s climate and ecosystem are driven by the radiant energy Earth receives from the sun and the geothermal energy contained within the earth. Figure 2.8: Basic overview of energy and human life. In 1843, James Prescott Joule discovered the link between mechanical work and the generation of heat in a series of experiments. The most famous of them used the “Joule apparatus”: a descending weight, attached to a string, caused rotation of a paddle immersed in water, practically insulated from heat transfer. It showed that the gravitational potential energy lost by the weight in descending was equal to the internal energy gained by the water through friction with the paddle. Figure 2.9: Joule’s apparatus for measuring the mechanical equivalent of heat. A descending weight attached to a string causes a paddle immersed in water to rotate. In the International System of Units (SI), the unit of energy is the joule, named after James Prescott Joule. It is a derived unit. It is equal to the energy expended (or work done) in applying a force of one newton through a distance of one metre. However energy is also expressed in many other units not part of the SI, such as ergs, calories, British Thermal Units, kilowatt-hours and kilocalories, which require a conversion factor when expressed in SI units. The SI unit of energy rate (energy per unit time) is the watt, which is a joule per second. Thus, one joule is one watt-second, and 3600 joules equal one watt-hour. The CGS energy unit is the erg and the imperial and US customary unit is the foot pound. Other energy units such as the electronvolt, food calorie or thermodynamic kcal (based on the temperature change of water in a heating process), and BTU are used in specific areas of science and commerce. In the context of chemistry, energy is an attribute of a substance as a consequence of its atomic, molecular or aggregate structure. Since a chemical transformation is accompanied by a change in one or more of these kinds of structures, it is invariably accompanied by an increase or decrease of energy of the substances involved. Some energy is transferred between the surroundings and the reactants of the reaction in the form of heat or light; thus the products of a reaction may have more or less energy than the reactants. A reaction is said to be exergonic if the final state is lower on the energy scale than the initial state; in the case of endergonic reactions the situation is the reverse. A reaction is said to be exothermic if the reaction releases heat to the surroundings; in the case of endothermic reactions, the reaction absorbs heat from the surroundings. Chemical reactions are invariably not possible unless the reactants surmount an energy barrier known as the activation energy. The activation energy (Ea) of a reaction is measured in joules per mole (J/mol), kilojoules per mole (kJ/mol) or kilocalories per mole (kcal/mol). For a chemical reaction to proceed at a reasonable rate, the temperature of the system should be high enough such that there exists an appreciable number of molecules with translational energy equal to or greater than the activation energy. The term Activation Energy was introduced in 1889 by the Swedish scientist Svante Arrhenius. The Arrhenius equation gives the quantitative basis of the relationship between the activation energy and the rate at which a reaction proceeds. From the equation, the activation energy can be found through the relation \\[ k=A\\mathrm{e}^{-E_a/(RT)} \\] where A is the pre-exponential factor for the reaction, R is the universal gas constant, T is the absolute temperature (usually in kelvins), and k is the reaction rate coefficient. Even without knowing A, Ea can be evaluated from the variation in reaction rate coefficients as a function of temperature (within the validity of the Arrhenius equation).The activation energy necessary for a chemical reaction to occur can be in the form of heat, light, electricity or mechanical force. A substance that modifies the transition state to lower the activation energy is termed a catalyst; a catalyst composed only of protein and (if applicable) small molecule cofactors is termed an enzyme. A catalyst increases the rate of reaction without being consumed in the reaction. In addition, the catalyst lowers the activation energy, but it does not change the energies of the original reactants or products, and so does not change equilibrium. Rather, the reactant energy and the product energy remain the same and only the activation energy is altered (lowered). Figure 2.10: Example of an enzyme-catalysed exothermic reaction. A catalyst is able to reduce the activation energy by forming a transition state in a more favorable manner. Catalysts, by nature, create a more “comfortable” fit for the substrate of a reaction to progress to a transition state. This is possible due to a release of energy that occurs when the substrate binds to the active site of a catalyst. This energy is known as Binding Energy. Upon binding to a catalyst, substrates partake in numerous stabilizing forces while within the active site (i.e. Hydrogen bonding, van der Waals forces). Specific and favorable bonding occurs within the active site until the substrate forms to become the high-energy transition state. Forming the transition state is more favorable with the catalyst because the favorable stabilizing interactions within the active site release energy. A chemical reaction is able to manufacture a high-energy transition state molecule more readily when there is a stabilizing fit within the active site of a catalyst. The binding energy of a reaction is this energy released when favorable interactions between substrate and catalyst occur. The binding energy released assists in achieving the unstable transition state. Reactions otherwise without catalysts need a higher input of energy to achieve the transition state. Non-catalyzed reactions do not have free energy available from active site stabilizing interactions, such as catalytic enzyme reactions. A related concept free energy, which also incorporates entropy considerations, is a very useful means for predicting the feasibility of a reaction and determining the state of equilibrium of a chemical reaction, in chemical thermodynamics. A reaction is feasible only if the total change in the Gibbs free energy is negative, \\[ \\Delta G \\leq 0 \\] if it is equal to zero the chemical reaction is said to be at equilibrium. There exist only limited possible states of energy for electrons, atoms and molecules. These are determined by the rules of quantum mechanics, which require quantization of energy of a bound system. The atoms/molecules in a higher energy state are said to be excited. The molecules/atoms of substance in an excited energy state are often much more reactive; that is, more amenable to chemical reactions. 2.6 Chemical Reactions When a chemical substance is transformed as a result of its interaction with another substance or with energy, a chemical reaction is said to have occurred. A chemical reaction is therefore a concept related to the “reaction” of a substance when it comes in close contact with another, whether as a mixture or a solution; exposure to some form of energy, or both. It results in some energy exchange between the constituents of the reaction as well as with the system environment, which may be designed vessels—often laboratory glassware. Chemical reactions can result in the formation or dissociation of molecules, that is, molecules breaking apart to form two or more molecules or rearrangement of atoms within or across molecules. Chemical reactions usually involve the making or breaking of chemical bonds. Oxidation, reduction, dissociation, acid-base neutralization and molecular rearrangement are some of the commonly used kinds of chemical reactions. A chemical reaction can be symbolically depicted through a chemical equation. In a chemical reaction the number and kind of atoms on both sides of the equation are always equal. This fact is referred to as the the law of conservation of mass. The law implies that mass can neither be created nor destroyed, although it may be rearranged in space, or the entities associated with it may be changed in form. For example, in chemical reactions, the mass of the chemical components before the reaction is equal to the mass of the components after the reaction. Thus, during any chemical reaction and low-energy thermodynamic processes in an isolated system, the total mass of the reactants, or starting materials, must be equal to the mass of the products. 2.7 Radioactive Decay of Atoms Radioactive decay (also known as nuclear decay, radioactivity, radioactive disintegration or nuclear disintegration) is the process by which an unstable atomic nucleus loses energy by radiation. Every element has one or more isotopes that have unstable nuclei that are subject to radioactive decay, causing the nucleus to emit particles or electromagnetic radiation. Radioactivity can occur when the radius of a nucleus is large compared with the radius of the strong force, which only acts over distances on the order of 1 fm. The most common forms of radioactive decay are: Alpha decay: this process is caused when the nucleus emits an alpha particle, which is a helium nucleus consisting of two protons and two neutrons. The result of the emission is a new element with a lower atomic number. Beta decay (and electron capture): these processes are regulated by the weak force, and result from a transformation of a neutron into a proton, or a proton into a neutron. The neutron to proton transition is accompanied by the emission of an electron and an antineutrino, while proton to neutron transition (except in electron capture) causes the emission of a positron and a neutrino. The electron or positron emissions are called beta particles. Beta decay either increases or decreases the atomic number of the nucleus by one. Electron capture is more common than positron emission, because it requires less energy. In this type of decay, an electron is absorbed by the nucleus, rather than a positron emitted from the nucleus. A neutrino is still emitted in this process, and a proton changes to a neutron. Gamma decay: this process results from a change in the energy level of the nucleus to a lower state, resulting in the emission of electromagnetic radiation. The excited state of a nucleus which results in gamma emission usually occurs following the emission of an alpha or a beta particle. Thus, gamma decay usually follows alpha or beta decay. Each radioactive isotope has a characteristic decay time period—the half-life—that is determined by the amount of time needed for half of a sample to decay. This is an exponential decay process that steadily decreases the proportion of the remaining isotope by 50% every half-life. Hence after two half-lives have passed only 25% of the isotope is present, and so forth. Within living things, isotopic labels (both radioactive and nonradioactive) can be used to probe how the complex web of reactions which makes up the metabolism of an organism converts one substance to another. For instance a green plant uses light energy to convert water and carbon dioxide into glucose by photosynthesis. When plants performed photoshytnesis using water in which the oxygen was the heavy oxygen (18O) isotope, this oxygen isotope appeared in the oxygen gas formed by the plant and not in the glucose formed in the chloroplasts within the plant cells. Radioactivity was discovered in 1896 by the French scientist Henri Becquerel, while working with phosphorescent materials. These materials glow in the dark after exposure to light, and he suspected that the glow produced in cathode ray tubes by X-rays might be associated with phosphorescence. He wrapped a photographic plate in black paper and placed various phosphorescent salts on it. All results were negative until he used uranium salts. The uranium salts caused a blackening of the plate in spite of the plate being wrapped in black paper. These radiations were given the name “Becquerel Rays”. It soon became clear that the blackening of the plate had nothing to do with phosphorescence, as the blackening was also produced by non-phosphorescent salts of uranium and by metallic uranium. It became clear from these experiments that there was a form of invisible radiation that could pass through paper and was causing the plate to react as if exposed to light. At first, it seemed as though the new radiation was similar to the then recently discovered X-rays. Further research by Becquerel, Ernest Rutherford, Paul Villard, Pierre Curie, Marie Curie, and others showed that this form of radioactivity was significantly more complicated. Rutherford was the first to realize that all such elements decay in accordance with the same mathematical exponential formula. Rutherford and his student Frederick Soddy were the first to realize that many decay processes resulted in the transmutation of one element to another. Subsequently, the radioactive displacement law of Fajans and Soddy was formulated to describe the products of alpha and beta decay. The early researchers also discovered that many other chemical elements, besides uranium, have radioactive isotopes. A systematic search for the total radioactivity in uranium ores also guided Pierre and Marie Curie to isolate two new elements: polonium and radium. Except for the radioactivity of radium, the chemical similarity of radium to barium made these two elements difficult to distinguish. Marie and Pierre Curie’s study of radioactivity is an important factor in science and medicine. After their research on Becquerel’s rays led them to the discovery of both radium and polonium, they coined the term “radioactivity”. Their research on the penetrating rays in uranium and the discovery of radium launched an era of using radium for the treatment of cancer. Their exploration of radium could be seen as the first peaceful use of nuclear energy and the start of modern nuclear medicine. 2.8 Ions And Salts An ion is a charged species, an atom or a molecule, that has lost or gained one or more electrons. When an atom loses an electron and thus has more protons than electrons, the atom is a positively charged ion or cation. When an atom gains an electron and thus has more electrons than protons, the atom is a negatively charged ion or anion. Cations and anions can form a crystalline lattice of neutral salts, such as the Na+ and Cl− ions forming sodium chloride, or NaCl. Examples of polyatomic ions that do not split up during acid-base reactions are hydroxide (OH−) and phosphate (PO43−). Plasma is composed of gaseous matter that has been completely ionized, usually through high temperature. 2.9 Solutions In chemistry, a solution is a special type of homogenous mixture composed of two or more substances. In such a mixture, a solute is a substance dissolved in another substance, known as a solvent. Homogeneous means that the components of the mixture form a single phase (i.e. liquid, gas or solid). Heterogeneous means that the components of the mixture are of different phase. Usually, the substance present in the greatest amount is considered the solvent. Solvents can be gases, liquids or solids. One or more components present in the solution other than the solvent are called solutes. The solution has the same physical state as the solvent. One important parameter of a solution is the concentration, which is a measure of the amount of solute in a given amount of solution or solvent. The term “aqueous solution” is used when one of the solvents is water. If the solvent is a gas, only gases (non-condensable) or vapors (condensable) are dissolved under a given set of conditions. An example of a gaseous solution is air (oxygen and and carbon dioxide dissolved in nitrogen). If the solvent is a liquid, then almost all gases, liquids, and solids can be dissolved. Here are some examples: Gas in liquid: Oxygen in water Carbon dioxide in water – a less simple example, because the solution is accompanied by a chemical reaction (formation of ions). The visible bubbles in carbonated water are not the dissolved gas, but only an effervescence of carbon dioxide that has come out of solution; the dissolved gas itself is not visible since it is dissolved on a molecular level. Liquid in liquid: The mixing of two or more substances of the same chemistry but different concentrations to form a constant. (Homogenization of solutions) Alcoholic beverages are basically solutions of ethanol in water. Solid in liquid: *Sucrose (table sugar) in water Sodium chloride (NaCl) (table salt) or any other salt in water, which forms an electrolyte: When dissolving, salt dissociates into ions. Solutions in water are especially common, and are called aqueous solutions. Non-aqueous solutions are when the liquid solvent involved is not water. Counter examples are provided by liquid mixtures that are not homogeneous: colloids, suspensions, emulsions are not considered solutions. Body fluids are examples for complex liquid solutions, containing many solutes. Many of these are electrolytes, since they contain solute ions, such as potassium. Furthermore, they contain solute molecules like sugar and urea. Oxygen and carbon dioxide are also essential components of blood chemistry, where significant changes in their concentrations may be a sign of severe illness or injury. If the solvent is a solid, then gases, liquids and solids can be dissolved. The ability of one compound to dissolve in another compound is called solubility. When a liquid can completely dissolve in another liquid the two liquids are miscible (for example alcohol and water). Two substances that can never mix to form a solution are said to be immiscible (for example oil and water). Usually, the greater the temperature of the solvent, the more of a given solid solute it can dissolve. However, most gases and some compounds exhibit solubilities that decrease with increased temperature. The solubility of liquids in liquids is generally less temperature-sensitive than that of solids or gases. The physical properties of compounds such as melting point and boiling point change when other compounds are added. Together they are called colligative properties. There are several ways to quantify the amount of one compound dissolved in the other compounds collectively called concentration. Examples include molarity, volume fraction, and mole fraction. Molarity (also called molar concentration, amount concentration or substance concentration) is a measure of the concentration of a chemical species, in particular of a solute in a solution, in terms of amount of substance per unit volume of solution. In chemistry, the most commonly used unit for molarity is the number of moles per litre, having the unit symbol mol/L or mol⋅dm−3 (cubic decimeter) in SI unit. A solution with a concentration of 1 mol/L is said to be 1 molar, commonly designated as 1 M. Volume percent is the concentration of a certain solute, measured by volume, in a solution. It has as a denominator the volume of the mixture itself, as usual for expressions of concentration, rather than the total of all the individual component’s volumes prior to mixing: \\[ volume \\space percent=\\frac{volume \\space of \\space solute}{volume \\space of \\space solution} \\times 100 \\] Volume percent is usually used when the solution is made by mixing two fluids, such as liquids or gases. For example, the volume concentration of alcohol in beer is usually 5%, i.e. every 100 ml of beer contains 5 ml of alcohol. 2.10 Acids And Bases A substance can often be classified as an acid or a base. There are several different theories which explain acid-base behavior. The simplest is Arrhenius theory, which states that acid is a substance that produces hydronium ions (H3O+) when it is dissolved in water, and a base is one that produces hydroxide ions (OH−) when dissolved in water. According to Brønsted–Lowry acid-base theory, acids are substances that donate a positive hydrogen ion (H+) to another substance in a chemical reaction; by extension, a base is the substance which receives that hydrogen ion. Figure 2.11: 3D diagram showing the pyramidal structure of the hydroxonium ion. Figure 2.12: Lewis structure of the hydroxide ion showing three lone pairs on the oxygen atom A third common theory is Lewis acid-base theory, which is based on the formation of new chemical bonds. Lewis theory explains that an acid is a substance which is capable of accepting a pair of electrons from another substance during the process of bond formation, while a base is a substance which can provide a pair of electrons to form a new bond. According to this theory, the crucial things being exchanged are charges. Acid strength is commonly measured by two methods. One measurement, based on the Arrhenius definition of acidity, is pH. The other measurement, based on the Brønsted–Lowry definition, is the acid dissociation constant (Ka), which measures the relative ability of a substance to act as an acid under the Brønsted–Lowry definition of an acid. That is, substances with a higher Ka are more likely to donate hydrogen ions in chemical reactions than those with lower Ka values. In chemistry, pH (“potential of hydrogen” or \"power of hydrogen) is a scale used to specify the acidity or basicity of an aqueous solution. Lower pH values correspond to solutions which are more acidic in nature, while higher values correspond to solutions which are more basic or alkaline. At room temperature (25 °C or 77 °F), pure water is neutral (neither acidic nor basic) and has a pH of 7. The pH scale is logarithmic and inversely indicates the concentration of hydrogen ions in the solution (a lower pH indicates a higher concentration of hydrogen ions). This is because the formula used to calculate pH approximates the negative of the base 10 logarithm of the molar concentration of hydrogen ions in the solution. More precisely, pH is the negative of the base 10 logarithm of the activity of the hydrogen ion: \\[pH = - \\log_{10} [H_3O^+]\\] At 25 °C, solutions with a pH less than 7 are acidic, and solutions with a pH greater than 7 are basic. The neutral value of the pH depends on the temperature, being lower than 7 if the temperature increases. The pH value can be less than 0 for very strong acids, or greater than 14 for very strong bases. Table 2.1: Average values of pH in common solutions Substance pH Range Type Battery acid &lt; 1 Acid Gastric acid 1.0 – 1.5 Acid Vinegar 2.5 Acid Orange juice 3.3 – 4.2 Acid Black coffee 5 – 5.03 Acid Milk 6.5 – 6.8 Acid Pure water 7 Neutral Sea water 7.5 – 8.4 Base Ammonia 11.0 – 11.5 Base Bleach 12.5 Base Lye 13.0 – 13. Base The pH of different cellular compartments, body fluids, and organs is usually tightly regulated in a process called acid-base homeostasis. The most common disorder in acid-base homeostasis is acidosis, which means an acid overload in the body, generally defined by pH falling below 7.35. Alkalosis is the opposite condition, with blood pH being excessively high. The pH of blood is usually slightly basic with a value of pH 7.365. This value is often referred to as physiological pH in biology and medicine. Plaque can create a local acidic environment that can result in tooth decay by demineralization. Enzymes and other proteins have an optimum pH range and can become inactivated or denatured outside this range. Table 2.2: Values of pH in living systems Compartment ph Gastric acid 1.5-3.5 Lysosomes 4.5 Human skin 4.7 Granules of chromaffin cells 5.5 Urine 6 Cytosol 7.2 Blood (natural pH) 7.34–7.45 Cerebrospinal fluid (CSF) 7.5 Mitochondrial matrix 7.5 Pancreas secretions 8.1 Many biologically important molecules are acids. Nucleic acids, which contain acidic phosphate groups, include DNA and RNA. Nucleic acids contain the genetic code that determines many of an organism’s characteristics, and is passed from parents to offspring. DNA contains the chemical blueprint for the synthesis of proteins which are made up of amino acid subunits. Cell membranes contain fatty acid esters such as phospholipids. An α-amino acid has a central carbon (the α or alpha carbon) which is covalently bonded to a carboxyl group (thus they are carboxylic acids), an amino group, a hydrogen atom and a variable group. The variable group, also called the R group or side chain, determines the identity and many of the properties of a specific amino acid. In glycine, the simplest amino acid, the R group is a hydrogen atom, but in all other amino acids it is contains one or more carbon atoms bonded to hydrogens, and may contain other elements such as sulfur, oxygen or nitrogen. With the exception of glycine, naturally occurring amino acids are chiral and almost invariably occur in the L-configuration. Peptidoglycan, found in some bacterial cell walls contains some D-amino acids. At physiological pH, typically around 7, free amino acids exist in a charged form, where the acidic carboxyl group (-COOH) loses a proton (-COO−) and the basic amine group (-NH2) gains a proton (-NH+3). The entire molecule has a net neutral charge and is a zwitterion, with the exception of amino acids with basic or acidic side chains. Aspartic acid, for example, possesses one protonated amine and two deprotonated carboxyl groups, for a net charge of −1 at physiological pH. Fatty acids and fatty acid derivatives are another group of carboxylic acids that play a significant role in biology. These contain long hydrocarbon chains and a carboxylic acid group on one end. The cell membrane of nearly all organisms is primarily made up of a phospholipid bilayer, a micelle of hydrophobic fatty acid esters with polar, hydrophilic phosphate “head” groups. Membranes contain additional components, some of which can participate in acid-base reactions. In humans and many other animals, hydrochloric acid is a part of the gastric acid secreted within the stomach to help hydrolyze proteins and polysaccharides, as well as converting the inactive pro-enzyme, pepsinogen into the enzyme, pepsin. Some organisms produce acids for defense; for example, ants produce formic acid. Acid-base equilibrium plays a critical role in regulating mammalian breathing. Oxygen gas (O2) drives cellular respiration, the process by which animals release the chemical potential energy stored in food, producing carbon dioxide (CO2) as a byproduct. Oxygen and carbon dioxide are exchanged in the lungs, and the body responds to changing energy demands by adjusting the rate of ventilation. For example, during periods of exertion the body rapidly breaks down stored carbohydrates and fat, releasing CO2 into the blood stream. In aqueous solutions such as blood CO2 exists in equilibrium with carbonic acid and bicarbonate ion. CO2 + H2O ⇌ H2CO3 ⇌ H+ + HCO3− It is the decrease in pH that signals the brain to breathe faster and deeper, expelling the excess CO2 and resupplying the cells with O2. Cell membranes are generally impermeable to charged or large, polar molecules because of the lipophilic fatty acyl chains comprising their interior. Many biologically important molecules, including a number of pharmaceutical agents, are organic weak acids which can cross the membrane in their protonated, uncharged form but not in their charged form (i.e. as the conjugate base). For this reason the activity of many drugs can be enhanced or inhibited by the use of antacids or acidic foods. The charged form, however, is often more soluble in blood and cytosol, both aqueous environments. When the extracellular environment is more acidic than the neutral pH within the cell, certain acids will exist in their neutral form and will be membrane soluble, allowing them to cross the phospholipid bilayer. Acids that lose a proton at the intracellular pH will exist in their soluble, charged form and are thus able to diffuse through the cytosol to their target. Ibuprofen, aspirin and penicillin are examples of drugs that are weak acids. 2.11 Reduction-oxidation (Redox) Reactions Redox (reduction-oxidation) reactions include all chemical reactions in which atoms have their oxidation state changed by either gaining electrons (reduction) or losing electrons (oxidation). Substances that have the ability to oxidize other substances are said to be oxidative and are known as oxidizing agents, oxidants or oxidizers. An oxidant removes electrons from another substance. Similarly, substances that have the ability to reduce other substances are said to be reductive and are known as reducing agents, reductants, or reducers. The chemical species from which the electron is removed is said to have been oxidized, while the chemical species to which the electron is added is said to have been reduced. In other words: Oxidation is the loss of electrons or an increase in the oxidation state of an atom, an ion, or of certain atoms in a molecule. Reduction is the gain of electrons or a decrease in the oxidation state of an atom, an ion, or of certain atoms in a molecule. “Redox” is a portmanteau of the words “reduction” and “oxidation”. The word oxidation originally implied reaction with oxygen to form an oxide, since dioxygen (O2)(g)) was historically the first recognized oxidizing agent. Later, the term was expanded to encompass oxygen-like substances that accomplished parallel chemical reactions. Ultimately, the meaning was generalized to include all processes involving loss of electrons. The word reduction originally referred to the loss in weight upon heating a metallic ore such as a metal oxide to extract the metal. In other words, ore was “reduced” to metal. Antoine Lavoisier showed that this loss of weight was due to the loss of oxygen as a gas. Later, scientists realized that the metal atom gains electrons in this process. The meaning of reduction then became generalized to include all processes involving a gain of electrons. The term “hydrogenation” could often be used instead of reduction, since hydrogen is the reducing agent in a large number of reactions, especially in organic chemistry and biochemistry. But, unlike oxidation, which has been generalized beyond its root element, hydrogenation has maintained its specific connection to reactions that add hydrogen to another substance (e.g., the hydrogenation of unsaturated fats into saturated fats, R−CH=CH−R + H2 → R−CH2−CH2 −R). The word “redox” was first used in 1928. Many reactions in organic chemistry are redox reactions due to changes in oxidation states but without distinct electron transfer. For example, during the combustion of wood with molecular oxygen, the oxidation state of carbon atoms in the wood increases and that of oxygen atoms decreases as carbon dioxide and water are formed. The oxygen atoms undergo reduction, formally gaining electrons, while the carbon atoms undergo oxidation, losing electrons. Thus oxygen is the oxidizing agent and carbon is the reducing agent in this reaction. Although oxidation reactions are commonly associated with the formation of oxides from oxygen molecules, oxygen is not necessarily included in such reactions, as other chemical species can serve the same function. Redox reactions can occur relatively slowly, as in the formation of rust, or much more rapidly, as in the case of burning fuel. There are simple redox processes, such as the oxidation of carbon to yield carbon dioxide (CO2) or the reduction of carbon by hydrogen to yield methane (CH4), and more complex processes such as the oxidation of glucose (C6H12O6) in the human body. Analysis of bond energies and ionization energies in water allow calculation of the redox potentials. A reductant transfers electrons to another substance and is thus oxidized itself. And because it “donates” electrons it is also called an electron donor. Oxidation and reduction properly refer to a change in oxidation number—the actual transfer of electrons may never occur. Thus, oxidation is better defined as an increase in oxidation number, and reduction as a decrease in oxidation number. Many important biological processes involve redox reactions. Cellular respiration, for instance, is the oxidation of glucose (C6H12O6) to CO2 and the reduction of oxygen to water. The summary equation for cell respiration is: C6H12O6 + 6 O2 → 6 CO2 + 6 H20 The process of cell respiration also depends heavily on the reduction of NAD+ to NADH and the reverse reaction (the oxidation of NADH to NAD+). Photosynthesis and cellular respiration are complementary, but photosynthesis is not the reverse of the redox reaction in cell respiration: 6 CO2 + 6 H2O + light energy → C6H12O6 + 6 O2 Biological energy is frequently stored and released by means of redox reactions. Photosynthesis involves the reduction of carbon dioxide into sugars and the oxidation of water into molecular oxygen. The reverse reaction, respiration, oxidizes sugars to produce carbon dioxide and water. As intermediate steps, the reduced carbon compounds are used to reduce nicotinamide adenine dinucleotide (NAD+) to NADH, which then contributes to the creation of a proton gradient, which drives the synthesis of adenosine triphosphate (ATP) and is maintained by the reduction of oxygen. In animal cells, mitochondria perform similar functions. See the Membrane potential article. Free radical reactions are redox reactions that occur as a part of homeostasis and killing microorganisms, where an electron detaches from a molecule and then reattaches almost instantaneously. Free radicals are a part of redox molecules and can become harmful to the human body if they do not reattach to the redox molecule or an antioxidant. Unsatisfied free radicals can spur the mutation of cells they encounter and are, thus, causes of cancer. The term redox state is often used to describe the balance of GSH/GSSG, NAD+/NADH and NADP+/NADPH in a biological system such as a cell or organ. The redox state is reflected in the balance of several sets of metabolites (e.g., lactate and pyruvate, beta-hydroxybutyrate, and acetoacetate), whose interconversion is dependent on these ratios. An abnormal redox state can develop in a variety of deleterious situations, such as hypoxia, shock, and sepsis. Redox mechanism also control some cellular processes. Redox proteins and their genes must be co-located for redox regulation according to the CoRR hypothesis for the function of DNA in mitochondria and chloroplasts. 2.12 The Chemistry Of Water Water is an inorganic, transparent, tasteless, odorless, and nearly colorless chemical substance, which is the main constituent of Earth’s hydrosphere and the fluids of all known living organisms. It is vital for all known forms of life, even though it provides no calories or organic nutrients. Its chemical formula is H2O, meaning that each of its molecules contains one oxygen and two hydrogen atoms, connected by covalent bonds. From a biological standpoint, water has many distinct properties that are critical for the proliferation of life. It carries out this role by allowing organic compounds to react in ways that ultimately allow replication. All known forms of life depend on water. Water is vital both as a solvent in which many of the body’s solutes dissolve and as an essential part of many metabolic processes within the body. Metabolism is the sum total of anabolism and catabolism. In anabolism, water is removed from molecules (through energy requiring enzymatic chemical reactions) in order to grow larger molecules (e.g., starches, triglycerides and proteins for storage of fuels and information). In catabolism, water is used to break bonds in order to generate smaller molecules (e.g., glucose, fatty acids and amino acids to be used for fuels for energy use or other purposes). Without water, these particular metabolic processes could not exist. Water is fundamental to photosynthesis and respiration. Photosynthetic cells use the sun’s energy to split off water’s hydrogen from oxygen. Hydrogen is combined with CO2 (absorbed from air or water) to form glucose and release oxygen. All living cells use such fuels and oxidize the hydrogen and carbon to capture the sun’s energy and reform water and CO2 in the process (cellular respiration). Water is also central to acid-base neutrality and enzyme function. An acid, a hydrogen ion (H+, that is, a proton) donor, can be neutralized by a base, a proton acceptor such as a hydroxide ion (OH−) to form water. Water is considered to be neutral, with a pH of 7. Acids have pH values less than 7 while bases have values greater than 7. Earth surface waters are filled with life. The earliest life forms appeared in water; nearly all fish live exclusively in water, and there are many types of marine mammals, such as dolphins and whales. Some kinds of animals, such as amphibians, spend portions of their lives in water and portions on land. Plants such as kelp and algae grow in the water and are the basis for some underwater ecosystems. Plankton is generally the foundation of the ocean food chain. Aquatic vertebrates must obtain oxygen to survive, and they do so in various ways. Fish have gills instead of lungs, although some species of fish, such as the lungfish, have both. Marine mammals, such as dolphins, whales, and seals need to surface periodically to breathe air. Some amphibians are able to absorb oxygen through their skin. Invertebrates exhibit a wide range of modifications to survive in poorly oxygenated waters including breathing tubes (see insect and mollusc siphons) and gills (Carcinus). However as invertebrate life evolved in an aquatic habitat most have little or no specialization for respiration in water. “Water” is the name of the liquid state of H2O at standard ambient temperature and pressure. It forms precipitation in the form of rain and aerosols in the form of fog. Clouds are formed from suspended droplets of water and ice, its solid state. When finely divided, crystalline ice may precipitate in the form of snow. The gaseous state of water is steam or water vapor. Water moves continually through the water cycle of evaporation, transpiration (evapotranspiration), condensation, precipitation, and runoff, usually reaching the sea. Water covers 71% of the Earth’s surface, mostly in seas and oceans. Small portions of water occur as groundwater (1.7%), in the glaciers and the ice caps of Antarctica and Greenland (1.7%), and in the air as vapor, clouds (formed of ice and liquid water suspended in air), and precipitation (0.001%). Water plays an important role in the world economy. Approximately 70% of the freshwater used by humans goes to agriculture. Fishing in salt and fresh water bodies is a major source of food for many parts of the world. Much of the long-distance trade of commodities (such as oil, natural gas, and manufactured products) is transported by boats through seas, rivers, lakes, and canals. Large quantities of water, ice, and steam are used for cooling and heating, in industry and homes. Water is an excellent solvent for a wide variety of substances both mineral and organic; as such it is widely used in industrial processes, and in cooking and washing. Water (H2O) is a polar inorganic compound that is at room temperature a tasteless and odorless liquid, nearly colorless with a hint of blue. This simplest hydrogen chalcogenide is by far the most studied chemical compound and is described as the “universal solvent” for its ability to dissolve many substances. This allows it to be the “solvent of life”: indeed, water as found in nature almost always includes various dissolved substances, and special steps are required to obtain chemically pure water. Water is the only common substance to exist as a solid, liquid, and gas in normal terrestrial conditions. Water is one of the two official names for the chemical compound H2O; it is also the liquid phase of H2O. The other two common states of matter of water are the solid phase, ice, and the gaseous phase, water vapor or steam. The addition or removal of heat can cause phase transitions: freezing (water to ice), melting (ice to water), vaporization (water to vapor), condensation (vapor to water), sublimation (ice to vapor) and deposition (vapor to ice). Water differs from most liquids in that it becomes less dense as it freezes. In 1 atm pressure, it reaches its maximum density of 1,000 kg/m3 (62.43 lb/cu ft) at 3.98 °C (39.16 °F). The density of ice is 917 kg/m3 (57.25 lb/cu ft), an expansion of 9%. This expansion can exert enormous pressure, bursting pipes and cracking rocks. In a lake or ocean, water at 4 °C sinks to the bottom and ice forms on the surface, floating on the liquid water. This ice insulates the water below, preventing it from freezing solid. Without this protection, most aquatic organisms would perish during the winter. At a pressure of one atmosphere (atm), ice melts or water freezes at 0 °C (32 °F) and water boils or vapor condenses at 100 °C (212 °F). In a water molecule, the hydrogen atoms form a 104.5° angle with the oxygen atom. The hydrogen atoms are close to two corners of a tetrahedron centered on the oxygen. At the other two corners are lone pairs of valence electrons that do not participate in the bonding. In a perfect tetrahedron, the atoms would form a 109.5° angle, but the repulsion between the lone pairs is greater than the repulsion between the hydrogen atoms. Other substances have a tetrahedral molecular structure, for example, methane (CH4) and hydrogen sulfide (H2S). However, oxygen is more electronegative (holds on to its electrons more tightly) than most other elements, so the oxygen atom retains a negative charge while the hydrogen atoms are positively charged. Along with the bent structure, this gives the molecule an electrical dipole moment and it is classified as a polar molecule. Water is a good polar solvent, that dissolves many salts and hydrophilic organic molecules such as sugars and simple alcohols such as ethanol. Water also dissolves many gases, such as oxygen and carbon dioxide—the latter giving the fizz of carbonated beverages, sparkling wines and beers. In addition, many substances in living organisms, such as proteins, DNA and polysaccharides, are dissolved in water. The interactions between water and the subunits of these biomacromolecules shape protein folding, DNA base pairing, and other phenomena crucial to life (hydrophobic effect). Many organic substances (such as fats and oils and alkanes) are hydrophobic, that is, insoluble in water. Many inorganic substances are insoluble too, including most metal oxides, sulfides, and silicates. Because of its polarity, a molecule of water in the liquid or solid state can form up to four hydrogen bonds with neighboring molecules. Hydrogen bonds are about ten times as strong as the Van der Waals force that attracts molecules to each other in most liquids. This is the reason why the melting and boiling points of water are much higher than those of other analogous compounds like hydrogen sulfide. They also explain its exceptionally high specific heat capacity (about 4.2 J/g/K), heat of fusion (about 333 J/g), heat of vaporization (2257 J/g), and thermal conductivity (between 0.561 and 0.679 W/m/K). These properties make water more effective at moderating Earth’s climate, by storing heat and transporting it between the oceans and the atmosphere. The hydrogen bonds of water are around 23 kJ/mol (compared to a covalent O-H bond at 492 kJ/mol). Of this, it is estimated that 90% is attributable to electrostatics, while the remaining 10% is partially covalent. Figure 2.13: Model of hydrogen bonds (1) between molecules of water. These bonds are the cause of water’s high surface tension and capillary forces. The capillary action refers to the tendency of water to move up a narrow tube against the force of gravity. This property is relied upon by all vascular plants, such as trees. Water is a weak solution of hydronium hydroxide - there is an equilibrium 2H2O ⇆ H3O+ + OH- to form water. Water is considered to be neutral, with a pH of 7. Acids have pH values less than 7 while bases have values greater than 7. Pure water has a low electrical conductivity, which increases with the dissolution of a small amount of ionic material such as common salt. Liquid water can be split into the elements hydrogen and oxygen by passing an electric current through it—a process called electrolysis. The decomposition requires more energy input than the heat released by the inverse process (285.8 kJ/mol, or 15.9 MJ/kg). 2.13 Basic Organic Chemistry For Biology Organic chemistry is a branch of chemistry that studies the structure, properties and reactions of organic compounds, which contain carbon in covalent bonding. Study of structure determines their chemical composition and formula. Study of properties includes physical and chemical properties, and evaluation of chemical reactivity to understand their behavior. The study of organic reactions includes the chemical synthesis of natural products, drugs, and polymers, and study of individual organic molecules in the laboratory and via theoretical (in silico) study. Organic compounds form the basis of all earthly life and constitute the majority of known chemicals. The bonding patterns of carbon, with its valence of four—formal single, double, and triple bonds, plus structures with delocalized electrons—make the array of organic compounds structurally diverse, and their range of applications enormous. They form the basis of, or are constituents of, many commercial products including pharmaceuticals; petrochemicals and agrichemicals, and products made from them including lubricants, solvents; plastics; fuels and explosives. The study of organic chemistry overlaps organometallic chemistry and biochemistry, but also with medicinal chemistry, polymer chemistry, and materials science. The range of chemicals studied in organic chemistry includes hydrocarbons (compounds containing only carbon and hydrogen) as well as compounds based on carbon, but also containing other elements, especially oxygen, nitrogen, sulfur, phosphorus (included in many biochemicals) and the halogens. Before the nineteenth century, chemists generally believed that compounds obtained from living organisms were endowed with a vital force that distinguished them from inorganic compounds. According to the concept of vitalism (vital force theory), organic matter was endowed with a “vital force”. During the first half of the nineteenth century, some of the first systematic studies of organic compounds were reported. Around 1816 Michel Chevreul started a study of soaps made from various fats and alkalis. He separated the acids that, in combination with the alkali, produced the soap. Since these were all individual compounds, he demonstrated that it was possible to make a chemical change in various fats (which traditionally come from organic sources), producing new compounds, without “vital force”. In 1828 Friedrich Wöhler produced the organic chemical urea (carbamide), a constituent of urine, from inorganic starting materials (the salts potassium cyanate and ammonium sulfate), in what is now called the Wöhler synthesis. Although Wöhler himself was cautious about claiming he had disproved vitalism, this was the first time a substance thought to be organic was synthesized in the laboratory without biological (organic) starting materials. The event is now generally accepted as indeed disproving the doctrine of vitalism. A crucial breakthrough for organic chemistry was the concept of chemical structure, developed independently in 1858 by both Friedrich August Kekulé and Archibald Scott Couper. Both researchers suggested that tetravalent carbon atoms could link to each other to form a carbon lattice, and that the detailed patterns of atomic bonding could be discerned by skillful interpretations of appropriate chemical reactions. Organic molecules are described commonly by drawings or structural formulas, combinations of drawings and chemical symbols. The line-angle formula is simple and unambiguous. In this system, the endpoints and intersections of each line represent one carbon, and hydrogen atoms can either be notated explicitly or assumed to be present as implied by tetravalent carbon. Figure 2.14: This diagramshows 5 different structural representations of the organic compound butane. The left-most structure is a bond-line drawing where the hydrogen atoms are removed. The 2nd structure has the hydrogens added depicted-the dark wedged bonds indicate the hydrogen atoms are coming toward the reader, the hashed bonds indicate the atoms are oriented away from the reader, and the solid (plain) ponds indicate the bonds are in the plane of the screen/paper. The middle structure shows the four carbon atoms. The 4th structure is a representation just showing the atoms and bonds without 3-dimensions. The right-most structure is a condensed structure representation of butane. The era of the pharmaceutical industry began in the last decade of the 19th century when the manufacturing of acetylsalicylic acid—more commonly referred to as aspirin—in Germany was started by Bayer. By 1910 Paul Ehrlich and his laboratory group began developing arsenic-based arsphenamine, (Salvarsan), as the first effective medicinal treatment of syphilis, and thereby initiated the medical practice of chemotherapy. Ehrlich popularized the concepts of “magic bullet” drugs and of systematically improving drug therapies. His laboratory made decisive contributions to developing antiserum for diphtheria and standardizing therapeutic serums. In the early part of the 20th century, polymers and enzymes were shown to be large organic molecules, and petroleum was shown to be of biological origin. The majority of chemical compounds occurring in biological organisms are carbon compounds, so the association between organic chemistry and biochemistry is so close that biochemistry might be regarded as in essence a branch of organic chemistry. Although the history of biochemistry might be taken to span some four centuries, fundamental understanding of the field only began to develop in the late 19th century and the actual term biochemistry was coined around the start of 20th century. 2.13.1 Functional Groups The concept of functional groups is central in organic chemistry, both as a means to classify structures and for predicting properties. A functional group is a molecular module, and the reactivity of that functional group is assumed, within limits, to be the same in a variety of molecules. Functional groups can have a decisive influence on the chemical and physical properties of organic compounds. Molecules are classified based on their functional groups. Alcohols, for example, all have the subunit C-O-H. All alcohols tend to be somewhat hydrophilic, usually form esters, and usually can be converted to the corresponding halides. Most functional groups feature heteroatoms (atoms other than C and H). Organic compounds are classified according to functional groups, alcohols, carboxylic acids, amines, etc. Figure 2.15: Biologically important functional groups. Combining the names of functional groups with the names of the parent alkanes generates what is termed a systematic nomenclature for naming organic compounds. In traditional nomenclature, the first carbon atom after the carbon that attaches to the functional group is called the alpha carbon; the second, beta carbon, the third, gamma carbon, etc. If there is another functional group at a carbon, it may be named with the Greek letter, e.g., the gamma-amine in gamma-aminobutyric acid is on the third carbon of the carbon chain attached to the carboxylic acid group. IUPAC conventions call for numeric labeling of the position, e.g. 4-aminobutanoic acid. In traditional names various qualifiers are used to label isomers, for example, isopropanol (IUPAC name: propan-2-ol) is an isomer of n-propanol (propan-1-ol). The term moiety has some overlap with the term “functional group”. However, a moiety is an entire “half” of a molecule, which can be not only a single functional group, but also a larger unit consisting of multiple functional groups. For example, an “aryl moiety” may be any group containing an aromatic ring, regardless of how many functional groups the said aryl has. Table 2.3: Some biologically important functional groups containing oxygen or nitrogen Chemical class Group Formula Prefix Example Alcohol Hydroxyl ROH hydroxy- Methanol Ketone Carbonyl RCOR’ -oyl- (-COR’)oroxo- (=O) Butanone(Methyl ethyl ketone) Aldehyde Aldehyde RCHO formyl- (-COH)oroxo- (=O) Acetaldehyde(Ethanal) Carboxylate Carboxylate RCOO- carboxy- Sodium acetate(Sodium ethanoate) Carboxylic acid Carboxyl RCOOH carboxy- Acetic acid(Ethanoic acid) Ester Carboalkoxy RCOOR’ alkanoyloxy-oralkoxycarbonyl Ethyl butyrate(Ethyl butanoate) Amide Carboxamide RCONR’R\" carboxamido-orcarbamoyl- Acetamide(Ethanamide) Amines Primary amine RNH2 amino- Methylamine(Methanamine) Amines Secondary amine R’R\"NH amino- Dimethylamine Amines Tertiary amine R3N amino- Trimethylamine Amines Quaternary ammonium ion R4N+ ammonio- Choline 2.13.2 Biomolecules A biomolecule or biological molecule is a loosely used term for molecules present in organisms that are essential to one or more typically biological processes, such as cell division, morphogenesis, or development. Biomolecules include large macromolecules (or polyanions) such as proteins, carbohydrates, lipids, and nucleic acids, as well as small molecules such as primary metabolites, secondary metabolites and natural products. A more general name for this class of material is biological materials. Biomolecules are usually endogenous, produced within the organism but organisms usually need exogenous biomolecules, for example certain nutrients, to survive. Biology and its subfields of biochemistry and molecular biology study biomolecules and their reactions. Most biomolecules are organic compounds, and just four elements—oxygen, carbon, hydrogen, and nitrogen—make up 96% of the human body’s mass. But many other elements, such as the various biometals, are present in small amounts. The uniformity of both specific types of molecules (the biomolecules) and of certain metabolic pathways are invariant features among the wide diversity of life forms; thus these biomolecules and metabolic pathways are referred to as “biochemical universals” or “theory of material unity of the living beings”, a unifying concept in biology, along with cell theory and evolution theory. A macromolecule is a very large molecule, such as protein, commonly composed of the polymerization of smaller subunits called monomers. They are typically composed of thousands of atoms or more. A substance that is composed of macromolecules is called a polymer. The most common macromolecules in biochemistry are biopolymers (nucleic acids, proteins, and carbohydrates) and large non-polymeric molecules (such as lipids and macrocycles), synthetic fibers as well as experimental materials such as carbon nanotubes. Macromolecules are large molecules composed of thousands of covalently connected atoms. Carbohydrates, lipids, proteins, and nucleic acids are all macromolecules. Macromolecules are formed by many monomers linking together, forming a polymer. Carbohydrates are composed of carbon, oxygen, and hydrogen. The monomer of carbohydrates are monosaccharides. There are three forms of carbohydrates: energy, storage, and structural molecules. A disaccharide is formed when a dehydration reaction joins two monosaccharides. Another type of macromolecules are lipids. Lipids are hydrocarbons that do not form polymers. Fats are constructed from glycerol and fatty acids. Phospholipids are commonly found in the phospholipid bilayer of membranes. They have hydrophilic heads and hydrophopic tails. A protein is another type of macromolecules. Amino acids are the monomers of proteins. Proteins have many different functions. There are proteins that are used for structural support, storage, transport, cellular communication, movement, defense against foreign substances, and more. Nucleic acids transmit and help express hereditary information. They are made up of monomers called nucleotides. Two types of nucleic acids are DNA and RNA. All living organisms are dependent on three essential biopolymers for their biological functions: DNA, RNA and proteins. Each of these molecules is required for life since each plays a distinct, indispensable role in the cell. The simple summary is that DNA makes RNA, and then RNA makes proteins. DNA, RNA, and proteins all consist of a repeating structure of related building blocks (nucleotides in the case of DNA and RNA, amino acids in the case of proteins). In general, they are all unbranched polymers, and so can be represented in the form of a string. Indeed, they can be viewed as a string of beads, with each bead representing a single nucleotide or amino acid monomer linked together through covalent chemical bonds into a very long chain. In most cases, the monomers within the chain have a strong propensity to interact with other amino acids or nucleotides. In DNA and RNA, this can take the form of Watson-Crick base pairs (G-C and A-T or A-U), although many more complicated interactions can and do occur. Table 2.4: Comparison of the main classes of biological macromolecules. Macromolecule (Polymer) Building Block (Monomer) Joining Bond Proteins Amino acids Peptide DNA Nucleotides (a phoshate, ribose, and a base- adenine, guanine, thymine, or cytosine) Phoshodiester RNA Nucleotides (a phoshate, ribose, and a base- adenine, guanine, Uracil, or cytosine) Phoshodiester Polysaccharides (carbohydrates) Monosaccharides Glycosidic Lipids unlike the other macromolecules, lipids are not defined by chemical Structure. Lipids are any organic nonpolar molecule. Some lipids are held together by ester bonds; some are huge aggregates of small molecules held together by hydrophobic interactions. 2.13.3 Proteins Proteins are large biomolecules, or macromolecules, consisting of one or more long chains of amino acid residues. Proteins perform a vast array of functions within organisms, including catalysing metabolic reactions, DNA replication, responding to stimuli, providing structure to cells, and organisms, and transporting molecules from one location to another. Proteins differ from one another primarily in their sequence of amino acids, which is dictated by the nucleotide sequence of their genes, and which usually results in protein folding into a specific 3D structure that determines its activity. A linear chain of amino acid residues is called a polypeptide. A protein contains at least one long polypeptide. Short polypeptides, containing less than 20–30 residues, are rarely considered to be proteins and are commonly called peptides, or sometimes oligopeptides. The individual amino acid residues are bonded together by peptide bonds and adjacent amino acid residues. The sequence of amino acid residues in a protein is defined by the sequence of a gene, which is encoded in the genetic code. In general, the genetic code specifies 20 standard amino acids; but in certain organisms the genetic code can include selenocysteine and—in certain archaea—pyrrolysine. Shortly after or even during synthesis, the residues in a protein are often chemically modified by post-translational modification, which alters the physical and chemical properties, folding, stability, activity, and ultimately, the function of the proteins. Some proteins have non-peptide groups attached, which can be called prosthetic groups or cofactors. Proteins can also work together to achieve a particular function, and they often associate to form stable protein complexes. Figure 2.16: Chemical structure of the peptide bond (bottom) and the three-dimensional structure of a peptide bond between an alanine and an adjacent amino acid (top/inset). The bond itself is made of the CHON elements. Once formed, proteins only exist for a certain period and are then degraded and recycled by the cell’s machinery through the process of protein turnover. A protein’s lifespan is measured in terms of its half-life and covers a wide range. They can exist for minutes or years with an average lifespan of 1–2 days in mammalian cells. Abnormal or misfolded proteins are degraded more rapidly either due to being targeted for destruction or due to being unstable. Like other biological macromolecules such as polysaccharides and nucleic acids, proteins are essential parts of organisms and participate in virtually every process within cells. Many proteins are enzymes that catalyse biochemical reactions and are vital to metabolism. Proteins also have structural or mechanical functions, such as actin and myosin in muscle and the proteins in the cytoskeleton, which form a system of scaffolding that maintains cell shape. Other proteins are important in cell signaling, immune responses, cell adhesion, and the cell cycle. In animals, proteins are needed in the diet to provide the essential amino acids that cannot be synthesized. Digestion breaks the proteins down for use in the metabolism. Proteins may be purified from other cellular components using a variety of techniques such as ultracentrifugation, precipitation, electrophoresis, and chromatography; the advent of genetic engineering has made possible a number of methods to facilitate purification. Methods commonly used to study protein structure and function include immunohistochemistry, site-directed mutagenesis, X-ray crystallography, nuclear magnetic resonance and mass spectrometry. Proteins were recognized as a distinct class of biological molecules in the eighteenth century by Antoine Fourcroy and others, distinguished by the molecules’ ability to coagulate or flocculate under treatments with heat or acid. Noted examples at the time included albumin from egg whites, blood serum albumin, fibrin, and wheat gluten. Proteins were first described by the Dutch chemist Gerardus Johannes Mulder and named by the Swedish chemist Jöns Jacob Berzelius in 1838. Mulder carried out elemental analysis of common proteins and found that nearly all proteins had the same empirical formula, C400H620N100O120P1S1. He came to the erroneous conclusion that they might be composed of a single type of (very large) molecule. The term “protein” to describe these molecules was proposed by Mulder’s associate Berzelius; protein is derived from the Greek word πρώτειος (proteios), meaning “primary”, “in the lead”, or “standing in front”, + -in. Mulder went on to identify the products of protein degradation such as the amino acid leucine for which he found a (nearly correct) molecular weight of 131 Da. Prior to “protein”, other names were used, like “albumins” or “albuminous materials” (Eiweisskörper, in German). Early nutritional scientists such as the German Carl von Voit believed that protein was the most important nutrient for maintaining the structure of the body, because it was generally believed that “flesh makes flesh.” Karl Heinrich Ritthausen extended known protein forms with the identification of glutamic acid. At the Connecticut Agricultural Experiment Station a detailed review of the vegetable proteins was compiled by Thomas Burr Osborne. Working with Lafayette Mendel and applying Justus von Liebig’s law of the minimum in feeding laboratory rats, the nutritionally essential amino acids were established. The work was continued and communicated by William Cumming Rose. The understanding of proteins as polypeptides came through the work of Franz Hofmeister and Hermann Emil Fischer in 1902. The central role of proteins as enzymes in living organisms was not fully appreciated until 1926, when James B. Sumner showed that the enzyme urease was in fact a protein. The difficulty in purifying proteins in large quantities made them very difficult for early protein biochemists to study. Hence, early studies focused on proteins that could be purified in large quantities, e.g., those of blood, egg white, various toxins, and digestive/metabolic enzymes obtained from slaughterhouses. In the 1950s, the Armour Hot Dog Co. purified 1 kg of pure bovine pancreatic ribonuclease A and made it freely available to scientists; this gesture helped ribonuclease A become a major target for biochemical study for the following decades. Linus Pauling is credited with the successful prediction of regular protein secondary structures based on hydrogen bonding, an idea first put forth by William Astbury in 1933. Later work by Walter Kauzmann on denaturation, based partly on previous studies by Kaj Linderstrøm-Lang, contributed an understanding of protein folding and structure mediated by hydrophobic interactions. The first protein to be sequenced was insulin, by Frederick Sanger, in 1949. Sanger correctly determined the amino acid sequence of insulin, thus conclusively demonstrating that proteins consisted of linear polymers of amino acids rather than branched chains, colloids, or cyclols. He won the Nobel Prize for this achievement in 1958. The first protein structures to be solved were hemoglobin and myoglobin, by Max Perutz and Sir John Cowdery Kendrew, respectively, in 1958. As of 2017, the Protein Data Bank has over 126,060 atomic-resolution structures of proteins. In more recent times, cryo-electron microscopy of large macromolecular assemblies and computational protein structure prediction of small protein domains are two methods approaching atomic resolution. Most proteins consist of linear polymers built from series of up to 20 different L-α- amino acids. All proteinogenic amino acids possess common structural features, including an α-carbon to which an amino group, a carboxyl group, and a variable side chain are bonded. Only proline differs from this basic structure as it contains an unusual ring to the N-end amine group, which forces the CO–NH amide moiety into a fixed conformation. The side chains of the standard amino acids, detailed in the list of standard amino acids, have a great variety of chemical structures and properties; it is the combined effect of all of the amino acid side chains in a protein that ultimately determines its three-dimensional structure and its chemical reactivity. The amino acids in a polypeptide chain are linked by peptide bonds. Once linked in the protein chain, an individual amino acid is called a residue, and the linked series of carbon, nitrogen, and oxygen atoms are known as the main chain or protein backbone. The peptide bond has two resonance forms that contribute some double-bond character and inhibit rotation around its axis, so that the alpha carbons are roughly coplanar. The other two dihedral angles in the peptide bond determine the local shape assumed by the protein backbone. The end with a free amino group is known as the N-terminus or amino terminus, whereas the end of the protein with a free carboxyl group is known as the C-terminus or carboxy terminus (the sequence of the protein is written from N-terminus to C-terminus, from left to right). The words protein, polypeptide, and peptide are a little ambiguous and can overlap in meaning. Protein is generally used to refer to the complete biological molecule in a stable conformation, whereas peptide is generally reserved for a short amino acid oligomers often lacking a stable 3D structure. But the boundary between the two is not well defined and usually lies near 20–30 residues. Polypeptide can refer to any single linear chain of amino acids, usually regardless of length, but often implies an absence of a defined conformation. Proteins can interact with many types of molecules, including with other proteins, with lipids, with carboyhydrates, and with DNA. It has been estimated that average-sized bacteria contain about 2 million proteins per cell (e.g. E. coli and Staphylococcus aureus). Smaller bacteria, such as Mycoplasma or spirochetes contain fewer molecules, on the order of 50,000 to 1 million. By contrast, eukaryotic cells are larger and thus contain much more protein. For instance, yeast cells have been estimated to contain about 50 million proteins and human cells on the order of 1 to 3 billion. The concentration of individual protein copies ranges from a few molecules per cell up to 20 million. Not all genes coding proteins are expressed in most cells and their number depends on, for example, cell type and external stimuli. For instance, of the 20,000 or so proteins encoded by the human genome, only 6,000 are detected in lymphoblastoid cells. Moreover, the number of proteins the genome encodes correlates well with the organism complexity. Eukaryotes have 15,000, bacteria have 3,200, archaea have 2,400, and viruses have 42 proteins on average coded in their respective genomes. Proteins are assembled from amino acids using information encoded in genes. Each protein has its own unique amino acid sequence that is specified by the nucleotide sequence of the gene encoding this protein. The genetic code is a set of three-nucleotide sets called codons and each three-nucleotide combination designates an amino acid, for example AUG (adenine–uracil–guanine) is the code for methionine. Because DNA contains four nucleotides, the total number of possible codons is 64; hence, there is some redundancy in the genetic code, with some amino acids specified by more than one codon. Genes encoded in DNA are first transcribed into pre-messenger RNA (mRNA) by proteins such as RNA polymerase. Most organisms then process the pre-mRNA (also known as a primary transcript) using various forms of Post-transcriptional modification to form the mature mRNA, which is then used as a template for protein synthesis by the ribosome. In prokaryotes the mRNA may either be used as soon as it is produced, or be bound by a ribosome after having moved away from the nucleoid. In contrast, eukaryotes make mRNA in the cell nucleus and then translocate it across the nuclear membrane into the cytoplasm, where protein synthesis then takes place. The rate of protein synthesis is higher in prokaryotes than eukaryotes and can reach up to 20 amino acids per second. The process of synthesizing a protein from an mRNA template is known as translation. The mRNA is loaded onto the ribosome and is read three nucleotides at a time by matching each codon to its base pairing anticodon located on a transfer RNA molecule, which carries the amino acid corresponding to the codon it recognizes. The enzyme aminoacyl tRNA synthetase “charges” the tRNA molecules with the correct amino acids. The growing polypeptide is often termed the nascent chain. Proteins are always biosynthesized from N-terminus to C-terminus. The size of a synthesized protein can be measured by the number of amino acids it contains and by its total molecular mass, which is normally reported in units of daltons (synonymous with atomic mass units), or the derivative unit kilodalton (kDa). The average size of a protein increases from Archaea to Bacteria to Eukaryote (283, 311, 438 residues and 31, 34, 49 kDa respectively) due to a bigger number of protein domains constituting proteins in higher organisms. For instance, yeast proteins are on average 466 amino acids long and 53 kDa in mass. The largest known proteins are the titins, a component of the muscle sarcomere, with a molecular mass of almost 3,000 kDa and a total length of almost 27,000 amino acids. 2.13.4 Structure Most proteins fold into unique 3D structures. The shape into which a protein naturally folds is known as its native conformation. Although many proteins can fold unassisted, simply through the chemical properties of their amino acids, others require the aid of molecular chaperones to fold into their native states. Biochemists often refer to four distinct aspects of a protein’s structure: Primary structure: the amino acid sequence. A protein is a polyamide. Secondary structure: regularly repeating local structures stabilized by hydrogen bonds. The most common examples are the α-helix, β-sheet and turns. Because secondary structures are local, many regions of different secondary structure can be present in the same protein molecule. Tertiary structure: the overall shape of a single protein molecule; the spatial relationship of the secondary structures to one another. Tertiary structure is generally stabilized by nonlocal interactions, most commonly the formation of a hydrophobic core, but also through salt bridges, hydrogen bonds, disulfide bonds, and even posttranslational modifications. The term “tertiary structure” is often used as synonymous with the term fold. The tertiary structure is what controls the basic function of the protein. Quaternary structure: the structure formed by several protein molecules (polypeptide chains), usually called protein subunits in this context, which function as a single protein complex. Quinary structure: the signatures of protein surface that organize the crowded cellular interior. Quinary structure is dependent on transient, yet essential, macromolecular interactions that occur inside living cells. Figure 2.17: The amino-acid sequence, the primary structure of a protein, determines the secondary (α-helix and β-sheet), tertiary and quaternary protein structures Proteins are not entirely rigid molecules. In addition to these levels of structure, proteins may shift between several related structures while they perform their functions. In the context of these functional rearrangements, these tertiary or quaternary structures are usually referred to as “conformations”, and transitions between them are called conformational changes. Such changes are often induced by the binding of a substrate molecule to an enzyme’s active site, or the physical region of the protein that participates in chemical catalysis. In solution proteins also undergo variation in structure through thermal vibration and the collision with other molecules. Proteins can be informally divided into three main classes, which correlate with typical tertiary structures: globular proteins, fibrous proteins, and membrane proteins. Almost all globular proteins are soluble and many are enzymes. Fibrous proteins are often structural, such as collagen, the major component of connective tissue, or keratin, the protein component of hair and nails. Membrane proteins often serve as receptors or provide channels for polar or charged molecules to pass through the cell membrane. A special case of intramolecular hydrogen bonds within proteins, poorly shielded from water attack and hence promoting their own dehydration, are called dehydrons. Many proteins are composed of several protein domains, i.e. segments of a protein that fold into distinct structural units. Domains usually also have specific functions, such as enzymatic activities (e.g. kinase) or they serve as binding modules (e.g. the SH3 domain binds to proline-rich sequences in other proteins). Short amino acid sequences within proteins often act as recognition sites for other proteins. For instance, SH3 domains typically bind to short PxxP motifs (i.e. 2 prolines [P], separated by two unspecified amino acids [x], although the surrounding amino acids may determine the exact binding specificity). Many such motifs has been collected in the Eukaryotic Linear Motif (ELM) database. 2.13.5 Cellular Functions of Proteins Proteins are the chief actors within the cell, said to be carrying out the duties specified by the information encoded in genes. With the exception of certain types of RNA, most other biological molecules are relatively inert elements upon which proteins act. Proteins make up half the dry weight of an Escherichia coli cell, whereas other macromolecules such as DNA and RNA make up only 3% and 20%, respectively. The set of proteins expressed in a particular cell or cell type is known as its proteome. The chief characteristic of proteins that also allows their diverse set of functions is their ability to bind other molecules specifically and tightly. The region of the protein responsible for binding another molecule is known as the binding site and is often a depression or “pocket” on the molecular surface. This binding ability is mediated by the tertiary structure of the protein, which defines the binding site pocket, and by the chemical properties of the surrounding amino acids’ side chains. Protein binding can be extraordinarily tight and specific; for example, the ribonuclease inhibitor protein binds to human angiogenin with a sub-femtomolar dissociation constant (&lt;10−15 M) but does not bind at all to its amphibian homolog onconase (&gt;1 M). Extremely minor chemical changes such as the addition of a single methyl group to a binding partner can sometimes suffice to nearly eliminate binding; for example, the aminoacyl tRNA synthetase specific to the amino acid valine discriminates against the very similar side chain of the amino acid isoleucine. Proteins can bind to other proteins as well as to small-molecule substrates. When proteins bind specifically to other copies of the same molecule, they can oligomerize to form fibrils; this process occurs often in structural proteins that consist of globular monomers that self-associate to form rigid fibers. Protein–protein interactions also regulate enzymatic activity, control progression through the cell cycle, and allow the assembly of large protein complexes that carry out many closely related reactions with a common biological function. Proteins can also bind to, or even be integrated into, cell membranes. The ability of binding partners to induce conformational changes in proteins allows the construction of enormously complex signaling networks. As interactions between proteins are reversible, and depend heavily on the availability of different groups of partner proteins to form aggregates that are capable to carry out discrete sets of function, study of the interactions between specific proteins is a key to understand important aspects of cellular function, and ultimately the properties that distinguish particular cell types. The best-known role of proteins in the cell is as enzymes, which catalyse chemical reactions. Enzymes are usually highly specific and accelerate only one or a few chemical reactions. Enzymes carry out most of the reactions involved in metabolism, as well as manipulating DNA in processes such as DNA replication, DNA repair, and transcription. Some enzymes act on other proteins to add or remove chemical groups in a process known as posttranslational modification. About 4,000 reactions are known to be catalysed by enzymes. The rate acceleration conferred by enzymatic catalysis is often enormous—as much as 1017-fold increase in rate over the uncatalysed reaction in the case of orotate decarboxylase (78 million years without the enzyme, 18 milliseconds with the enzyme). The molecules bound and acted upon by enzymes are called substrates. Although enzymes can consist of hundreds of amino acids, it is usually only a small fraction of the residues that come in contact with the substrate, and an even smaller fraction—three to four residues on average—that are directly involved in catalysis. The region of the enzyme that binds the substrate and contains the catalytic residues is known as the active site. Dirigent proteins are members of a class of proteins that dictate the stereochemistry of a compound synthesized by other enzymes. 2.13.6 Cell Signaling And Ligand Binding Many proteins are involved in the process of cell signaling and signal transduction. Some proteins, such as insulin, are extracellular proteins that transmit a signal from the cell in which they were synthesized to other cells in distant tissues. Others are membrane proteins that act as receptors whose main function is to bind a signaling molecule and induce a biochemical response in the cell. Many receptors have a binding site exposed on the cell surface and an effector domain within the cell, which may have enzymatic activity or may undergo a conformational change detected by other proteins within the cell. Antibodies are protein components of an adaptive immune system whose main function is to bind antigens, or foreign substances in the body, and target them for destruction. Antibodies can be secreted into the extracellular environment or anchored in the membranes of specialized B cells known as plasma cells. Whereas enzymes are limited in their binding affinity for their substrates by the necessity of conducting their reaction, antibodies have no such constraints. An antibody’s binding affinity to its target is extraordinarily high. Many ligand transport proteins bind particular small biomolecules and transport them to other locations in the body of a multicellular organism. These proteins must have a high binding affinity when their ligand is present in high concentrations, but must also release the ligand when it is present at low concentrations in the target tissues. The canonical example of a ligand-binding protein is haemoglobin, which transports oxygen from the lungs to other organs and tissues in all vertebrates and has close homologs in every biological kingdom. Lectins are sugar-binding proteins which are highly specific for their sugar moieties. Lectins typically play a role in biological recognition phenomena involving cells and proteins. Receptors and hormones are highly specific binding proteins. Transmembrane proteins can also serve as ligand transport proteins that alter the permeability of the cell membrane to small molecules and ions. The membrane alone has a hydrophobic core through which polar or charged molecules cannot diffuse. Membrane proteins contain internal channels that allow such molecules to enter and exit the cell. Many ion channel proteins are specialized to select for only a particular ion; for example, potassium and sodium channels often discriminate for only one of the two ions. 2.13.7 Structural Proteins Structural proteins confer stiffness and rigidity to otherwise-fluid biological components. Most structural proteins are fibrous proteins; for example, collagen and elastin are critical components of connective tissue such as cartilage, and keratin is found in hard or filamentous structures such as hair, nails, feathers, hooves, and some animal shells. Some globular proteins can also play structural functions, for example, actin and tubulin are globular and soluble as monomers, but polymerize to form long, stiff fibers that make up the cytoskeleton, which allows the cell to maintain its shape and size. Other proteins that serve structural functions are motor proteins such as myosin, kinesin, and dynein, which are capable of generating mechanical forces. These proteins are crucial for cellular motility of single celled organisms and the sperm of many multicellular organisms which reproduce sexually. They also generate the forces exerted by contracting muscles and play essential roles in intracellular transport. 2.13.8 Carbohydrates A carbohydrate is a biomolecule consisting of carbon (C), hydrogen (H) and oxygen (O) atoms, usually with a hydrogen–oxygen atom ratio of 2:1 (as in water) and thus with the empirical formula Cm(H2O)n (where m may be different from n). This formula holds true for monosaccharides. Some exceptions exist; for example, deoxyribose, a sugar component of DNA, has the empirical formula C5H10O4. The carbohydrates are technically hydrates of carbon; structurally it is more accurate to view them asaldoses and ketoses. The term is most common in biochemistry, where it is a synonym of saccharide, a group that includes sugars, starch, and cellulose. The saccharides are divided into four chemical groups: monosaccharides, disaccharides, oligosaccharides, and polysaccharides. Monosaccharides and disaccharides, the smallest (lower molecular weight) carbohydrates, are commonly referred to as sugars. The word saccharide comes from the Greek word σάκχαρον (sákkharon), meaning “sugar”. While the scientific nomenclature of carbohydrates is complex, the names of the monosaccharides and disaccharides very often end in the suffix -ose, as in the monosaccharides fructose (fruit sugar) and glucose (starch sugar) and the disaccharides sucrose (cane or beet sugar) and lactose (milk sugar). Figure 2.18: The disaccharide sucrose Carbohydrates perform numerous roles in living organisms. Polysaccharides serve for the storage of energy (e.g. starch and glycogen) and as structural components (e.g. cellulose in plants and chitin in arthropods). The 5-carbon monosaccharide ribose is an important component of coenzymes (e.g. ATP, FAD and NAD) and the backbone of the genetic molecule known as RNA. The related deoxyribose is a component of DNA. Saccharides and their derivatives include many other important biomolecules that play key roles in the immune system, fertilization, preventing pathogenesis, blood clotting, and development. They are found in a wide variety of natural and processed foods. Starch is a polysaccharide. It is abundant in cereals (wheat, maize, rice), potatoes, and processed food based on cereal flour, such as bread, pizza or pasta. Sugars appear in human diet mainly as table sugar (sucrose, extracted from sugarcane or sugar beets), lactose (abundant in milk), glucose and fructose, both of which occur naturally in honey, many fruits, and some vegetables. Table sugar, milk, or honey are often added to drinks and many prepared foods such as jam, biscuits and cakes. Cellulose, a polysaccharide found in the cell walls of all plants, is one of the main components of insoluble dietary fiber. Although it is not digestible, insoluble dietary fiber helps to maintain a healthy digestive system by easing defecation. Other polysaccharides contained in dietary fiber include resistant starch and inulin, which feed some bacteria in the microbiota of the large intestine, and are metabolized by these bacteria to yield short-chain fatty acids. In scientific literature, the term “carbohydrate” has many synonyms, like “sugar” (in the broad sense), “saccharide”, “ose”, “glucide”, “hydrate of carbon” or “polyhydroxy compounds with aldehyde or ketone”. Some of these terms, specially “carbohydrate” and “sugar”, are also used with other meanings. Formerly the name “carbohydrate” was used in chemistry for any compound with the formula Cm (H2O)n. Following this definition, some chemists considered formaldehyde (CH2O) to be the simplest carbohydrate, while others claimed that title for glycolaldehyde. Today, the term is generally understood in the biochemistry sense, which excludes compounds with only one or two carbons and includes many biological carbohydrates which deviate from this formula. For example, while the above representative formulas would seem to capture the commonly known carbohydrates, ubiquitous and abundant carbohydrates often deviate from this. For example, carbohydrates often display chemical groups such as: N-acetyl (e.g. chitin), sulphate (e.g. glycosaminoglycans), carboxylic acid (e.g. sialic acid) and deoxy modifications (e.g. fucose and sialic acid). Natural saccharides are generally built of simple carbohydrates called monosaccharides with general formula (CH2O)n where n is three or more. A typical monosaccharide has the structure H–(CHOH)x(C=O)–(CHOH)y–H, that is, an aldehyde or ketone with many hydroxyl groups added, usually one on each carbon atom that is not part of the aldehyde or ketone functional group. Examples of monosaccharides are glucose, fructose, and glyceraldehydes. However, some biological substances commonly called “monosaccharides” do not conform to this formula (e.g. uronic acids and deoxy-sugars such as fucose) and there are many chemicals that do conform to this formula but are not considered to be monosaccharides (e.g. formaldehyde CH2O and inositol (CH2O)6). The open-chain form of a monosaccharide often coexists with a closed ring form where the aldehyde/ketone carbonyl group carbon (C=O) and hydroxyl group (–OH) react forming a hemiacetal with a new C–O–C bridge. Monosaccharides can be linked together into what are called polysaccharides (or oligosaccharides) in a large variety of ways. Many carbohydrates contain one or more modified monosaccharide units that have had one or more groups replaced or removed. For example, deoxyribose, a component of DNA, is a modified version of ribose; chitin is composed of repeating units of N-acetyl glucosamine, a nitrogen-containing form of glucose. Monosaccharides are the simplest carbohydrates in that they cannot be hydrolyzed to smaller carbohydrates. They are aldehydes or ketones with two or more hydroxyl groups. The general chemical formula of an unmodified monosaccharide is (CH2O)n, literally a “carbon hydrate”. Monosaccharides are important fuel molecules as well as building blocks for nucleic acids. The smallest monosaccharides, for which n=3, are dihydroxyacetone and D- and L-glyceraldehydes. Monosaccharides are the major fuel source for metabolism, being used both as an energy source (glucose being the most important in nature) and in biosynthesis. When monosaccharides are not immediately needed by many cells, they are often converted to more space-efficient forms, often polysaccharides. In many animals, including humans, this storage form is glycogen, especially in liver and muscle cells. In plants, starch is used for the same purpose. The most abundant carbohydrate, cellulose, is a structural component of the cell wall of plants and many forms of algae. Ribose is a component of RNA. Deoxyribose is a component of DNA. Lyxose is a component of lyxoflavin found in the human heart. Ribulose and xylulose occur in the pentose phosphate pahway. Galactose, a component of milk sugar lactose, is found in galactolipids in plant cell membranes and in glycoproteins in many tissues. Mannose occurs in human metabolism, especially in the glycosylation of certain proteins. Fructose, or fruit sugar, is found in many plants and humans, it is metabolized in the liver, absorbed directly into the intestines during digestion, and found in semen. Trehalose, a major sugar of insects, is rapidly hydrolyzed into two glucose molecules to support continuous flight. Two joined monosaccharides are called a disaccharide and these are the simplest polysaccharides. Examples include sucrose and lactose. They are composed of two monosaccharide units bound together by a covalent bond known as a glycosidic linkage formed via a dehydration reaction, resulting in the loss of a hydrogen atom from one monosaccharide and a hydroxyl group from the other. The formula of unmodified disaccharides is C12H22O~11. Although there are numerous kinds of disaccharides, a handful of disaccharides are particularly notable. Its monosaccharides: glucose and fructose Their ring types: glucose is a pyranose and fructose is a furanose How they are linked together: the oxygen on carbon number 1 (C1) of α-D-glucose is linked to the C2 of D-fructose. The -oside suffix indicates that the anomeric carbon of both monosaccharides participates in the glycosidic bond. Lactose, a disaccharide composed of one D-galactose molecule and one D-glucose molecule, occurs naturally in mammalian milk. The systematic name for lactose is O-β-D-galactopyranosyl-(1→4)-D-glucopyranose. Other notable disaccharides include maltose (two D-glucoses linked α-1,4) and cellulobiose (two D-glucoses linked β-1,4). Disaccharides can be classified into two types: reducing and non-reducing disaccharides. If the functional group is present in bonding with another sugar unit, it is called a reducing disaccharide or biose. Figure 2.19: The disaccharide lactose 2.13.9 Lipids In biology and biochemistry, a lipid is a macrobiomolecule that is soluble in nonpolar solvents. Non-polar solvents are typically hydrocarbons used to dissolve other naturally occurring hydrocarbon lipid molecules that do not (or do not easily) dissolve in water, including fatty acids, waxes, sterols, fat-soluble vitamins (such as vitamins A, D, E, and K), monoglycerides, diglycerides, triglycerides, and phospholipids. Figure 2.20: Structures of some common lipids. At the top are cholesterol and oleic acid. The middle structure is a triglyceride composed of oleoyl, stearoyl, and palmitoyl chains attached to a glycerol backbone. At the bottom is the common phospholipid phosphatidylcholine. The functions of lipids include storing energy, signaling, and acting as structural components of cell membranes. Lipids have applications in the cosmetic and food industries as well as in nanotechnology. Scientists sometimes define lipids as hydrophobic or amphiphilic small molecules; the amphiphilic nature of some lipids allows them to form structures such as vesicles, multilamellar/unilamellar liposomes, or membranes in an aqueous environment. Biological lipids originate entirely or in part from two distinct types of biochemical subunits or “building-blocks”: ketoacyl and isoprene groups. Using this approach, lipids may be divided into eight categories: fatty acids, glycerolipids, glycerophospholipids, sphingolipids, saccharolipids, and polyketides (derived from condensation of ketoacyl subunits); and sterol lipids and prenol lipids (derived from condensation of isoprene subunits). Although the term “lipid” is sometimes used as a synonym for fats, fats are a subgroup of lipids called triglycerides. Lipids also encompass molecules such as fatty acids and their derivatives (including tri-, di-, monoglycerides, and phospholipids), as well as other sterol-containing metabolites such as cholesterol. Although humans and other mammals use various biosynthetic pathways both to break down and to synthesize lipids, some essential lipids can’t be made this way and must be obtained from the diet. Lipid may be regarded as organic substances relatively insoluble in water, soluble in organic solvents(alcohol, ether etc.) actually or potentially related to fatty acid and utilized by the living cells. In 1815, Henri Braconnot classified lipids (graisses) in two categories, suifs (solid greases or tallow) and huiles (fluid oils). In 1823, Michel Eugène Chevreul developed a more detailed classification, including oils, greases, tallow, waxes, resins, balsams and volatile oils (or essential oils). In 1827, William Prout recognized fat (“oily” alimentary matters), along with protein (“albuminous”) and carbohydrate (“saccharine”), as an important nutrient for humans and animals. The word “lipide” , which stems etymologically from the Greek lipos (fat), was introduced in 1923 by the french pharmacologist Gabriel Bertrand. Bertrands included in the concept not only the traditional fats (glycerides), but also the “lipoids”, with a complex constitution. Despite the word “lipide” was unanimously approved by the international commission of Société de Chimie Biologique during the plenary session on the 3rd of July 1923. The word “lipide” has been later anglicized as “lipid” because of its pronunciation (‘lɪpɪd). In the french language, the suffixe “-ide”, from the ancient greek “-ίδης” (meaning ’son of’ or ‘descendant of’), is always pronounced (ɪd). In 1947, T. P. Hilditch divided lipids into “simple lipids”, with greases and waxes (true waxes, sterols, alcohols). Fatty acids, or fatty acid residues when they are part of a lipid, are a diverse group of molecules synthesized by chain-elongation of an acetyl-CoA primer with malonyl-CoA or methylmalonyl-CoA groups in a process called fatty acid synthesis. They are made of a hydrocarbon chain that terminates with a carboxylic acid group; this arrangement confers the molecule with a polar, hydrophilic end, and a nonpolar, hydrophobic end that is insoluble in water. The fatty acid structure is one of the most fundamental categories of biological lipids and is commonly used as a building-block of more structurally complex lipids. The carbon chain, typically between four and 24 carbons long, may be saturated or unsaturated, and may be attached to functionalgroups containing oxygen, halogens, nitrogen, and sulfur. If a fatty acid contains a double bond, there is the possibility of either a cis or trans geometric isomerism, which significantly affects the molecule’s configuration. Cis-double bonds cause the fatty acid chain to bend, an effect that is compounded with more double bonds in the chain. Three double bonds in 18-carbon linolenic acid, the most abundant fatty-acyl chains of plant thylakoid membranes, render these membranes highly fluid despite environmental low-temperatures, and also makes linolenic acid give dominating sharp peaks in high resolution 13-C NMR spectra of chloroplasts. This in turn plays an important role in the structure and function of cell membranes. Most naturally occurring fatty acids are of the cis configuration, although the trans form does exist in some natural and partially hydrogenated fats and oils. Examples of biologically important fatty acids include the eicosanoids, derived primarily from arachidonic acid and eicosapentaenoic acid, that include prostaglandins, leukotrienes, and thromboxanes. Docosahexaenoic acid is also important in biological systems, particularly with respect to sight. Other major lipid classes in the fatty acid category are the fatty esters and fatty amides. Fatty esters include important biochemical intermediates such as wax esters, fatty acid thioester coenzyme A derivatives, fatty acid thioester ACP derivatives and fatty acid carnitines. The fatty amides include N-acyl ethanolamines, such as the cannabinoid neurotransmitter anandamide. Sterols, such as cholesterol and its derivatives, are an important component of membrane lipids, along with the glycerophospholipids and sphingomyelins. Other examples of sterols are the bile acids and their conjugates, which in mammals are oxidized derivatives of cholesterol and are synthesized in the liver. The plant equivalents are the phytosterols, such as β-sitosterol, stigmasterol, and brassicasterol; the latter compound is also used as a biomarker for algal growth. The predominant sterol in fungal cell membranes is ergosterol. Sterols are steroids in which one of the hydrogen atoms is substituted with a hydroxyl group, at position 3 in the carbon chain. They have in common with steroids the same fused four-ring core structure. teroids have different biological roles as hormones and signaling molecules. The eighteen-carbon (C18) steroids include the estrogen family whereas the C19 steroids comprise the androgens such as testosterone and androsterone. The C21 subclass includes the progestogens as well as the glucocorticoids and mineralocorticoids. The secosteroids, comprising various forms of vitamin D, are characterized by cleavage of the B ring of the core structure. Eukaryotic cells feature the compartmentalized membrane-bound organelles that carry out different biological functions. The glycerophospholipids are the main structural component of biological membranes, as the cellular plasma membrane and the intracellular membranes of organelles; in animal cells, the plasma membrane physically separates the intracellular components from the extracellular environment. The glycerophospholipids are amphipathic molecules (containing both hydrophobic and hydrophilic regions) that contain a glycerol core linked to two fatty acid-derived “tails” by ester linkages and to one “head” group by a phosphate ester linkage. While glycerophospholipids are he major component of biological membranes, other non-glyceride lipid components such as sphingomyelin and sterols (mainly cholesterol in animal cell membranes) are also found in biological membranes. In plants and algae, the galactosyldiacylglycerols, and sulfoquinovosyldiacylglycerol, which lack a phosphate group, are important components of membranes of chloroplasts and related organelles and are the most abundant lipids in photosynthetic tissues, including those of higher plants, algae and certain bacteria. Plant thylakoid membranes have the largest lipid component of a non-bilayer forming monogalactosyl diglyceride (MGDG), and little phospholipids; despite this unique lipid composition, chloroplast thylakoid membranes have been shown to contain a dynamic lipid-bilayer matrix as revealed by magnetic resonance and electron microscope studies. A biological membrane is a form of lamellar phase lipid bilayer. The formation of lipid bilayers is an energetically preferred process when the glycerophospholipids described above are in an aqueous environment. This is known as the hydrophobic effect. In an aqueous system, the polar heads of lipids align towards the polar, aqueous environment, while the hydrophobic tails minimize their contact with water and tend to cluster together, forming a vesicle; depending on the concentration of the lipid, this biophysical interaction may result in the formation of micelles, liposomes, or lipid bilayers. Other aggregations are also observed and form part of the polymorphism of amphiphile (lipid) behavior. Micelles and bilayers form in the polar medium by a process known as the hydrophobic effect. When dissolving a lipophilic or amphiphilic substance in a polar environment, the polar molecules (i.e., water in an aqueous solution) become more ordered around the dissolved lipophilic substance, since the polar molecules cannot form hydrogen bonds to the lipophilic areas of the amphiphile. So in an aqueous environment, the water molecules form an ordered “clathrate” cage around the dissolved lipophilic molecule. The formation of lipids into protocell membranes represents a key step in models of abiogenesis, the origin of life. Triglycerides, stored in adipose tissue, are a major form of energy storage both in animals and plants. They are a major source of energy because carbohydrates are fully reduced structures. In comparison to glycogen which would contribute only half of the energy per its pure mass, triglyceride carbons are all bonded to hydrogens, unlike in carbohydrates. The adipocyte, or fat cell, is designed for continuous synthesis and breakdown of triglycerides in animals, with breakdown controlled mainly by the activation of hormone-sensitive enzyme lipase. The complete oxidation of fatty acids provides high caloric content, about 38 kJ/g (9 kcal/g), compared with 17 kJ/g (4 kcal/g) for the breakdown of carbohydrates and proteins. Migratory birds that must fly long distances without eating use stored energy of triglycerides to fuel their flights. Figure 2.21: Example of an unsaturated fat triglyceride (C55H98O6). Left part: glycerol; right part, from top to bottom: palmitic acid, oleic acid, alpha-linolenic acid. In recent years, evidence has emerged showing that lipid signaling is a vital part of the cell signaling. Lipid signaling may occur via activation of G protein-coupled or nuclear receptors, and members of several different lipid categories have been identified as signaling molecules and cellular messengers. These include sphingosine-1-phosphate, a sphingolipid derived from ceramide that is a potent messenger molecule involved in regulating calcium mobilization, cell growth, and apoptosis; diacylglycerol (DAG) and the phosphatidylinositol phosphates (PIPs), involved in calcium-mediated activation of protein kinase C; the prostaglandins, which are one type of fatty-acid derived eicosanoid involved in inflammation and immunity; the steroid hormones such as estrogen, testosterone and cortisol, which modulate a host of functions such as reproduction, metabolism and blood pressure; and the oxysterols such as 25-hydroxy-cholesterol that are liver X receptor agonists. Phosphatidylserine lipids are known to be involved in signaling for the phagocytosis of apoptotic cells or pieces of cells. They accomplish this by being exposed to the extracellular face of the cell membrane after the inactivation of flippases which place them exclusively on the cytosolic side and the activation of scramblases, which scramble the orientation of the phospholipids. After this occurs, other cells recognize the phosphatidylserines and phagocytosize the cells or cell fragments exposing them. The “fat-soluble” vitamins (A, D, E and K) – which are isoprene-based lipids – are essential nutrients stored in the liver and fatty tissues, with a diverse range of functions. Acyl-carnitines are involved in the transport and metabolism of fatty acids in and out of mitochondria, where they undergo beta oxidation. Polyprenols and their phosphorylated derivatives also play important transport roles, in this case the transport of oligosaccharides across membranes. Polyprenol phosphate sugars and polyprenol diphosphate sugars function in extra-cytoplasmic glycosylation reactions, in extracellular polysaccharide biosynthesis (for instance, peptidoglycan polymerization in bacteria), and in eukaryotic protein N-glycosylation. Cardiolipins are a subclass of glycerophospholipids containing four acyl chains and three glycerol groups that are particularly abundant in the inner mitochondrial membrane. They are believed to activate enzymes involved with oxidative phosphorylation. Lipids also form the basis of steroid hormones. 2.13.10 Nucleic Acids Nucleic acids are the biopolymers, or large biomolecules, essential to all known forms of life. The term nucleic acid is the overall name for DNA and RNA. They are composed of nucleotides, which are the monomers made of three components: a 5-carbon sugar, a phosphate group and a nitrogenous base. If the sugar is a compound ribose, the polymer is RNA (ribonucleic acid); if the sugar is derived from ribose as deoxyribose, the polymer is DNA (deoxyribonucleic acid). Nucleic acids are the most important of all biomolecules. These are found in abundance in all living things, where they function to create and encode and then store information of every living cell of every life-form organism on Earth. In turn, they function to transmit and express that information inside and outside the cell nucleus—to the interior operations of the cell and ultimately to the next generation of each living organism. The encoded information is contained and conveyed via the nucleic acid sequence, which provides the ‘ladder-step’ ordering of nucleotides within the molecules of RNA and DNA. Strings of nucleotides are bonded to form helical backbones—typically, one for RNA, two for DNA—and assembled into chains of base-pairs selected from the five primary, or canonical, nucleobases, which are: adenine, cytosine, guanine, thymine, and uracil. Thymine occurs only in DNA and uracil only in RNA. Using amino acids and the process known as protein synthesis, the specific sequencing in DNA of these nucleobase-pairs enables storing and transmitting coded instructions as genes. In RNA, base-pair sequencing provides for manufacturing new proteins that determine the frames and parts and most chemical processes of all life forms The term nucleic acid is the overall name for DNA and RNA, members of a family of biopolymers, and is synonymous with polynucleotide. Nucleic acids were named for their initial discovery within the nucleus, and for the presence of phosphate groups (related to phosphoric acid). Although first discovered within the nucleus of eukaryotic cells, nucleic acids are now known to be found in all life forms including within bacteria, archaea, mitochondria, chloroplasts, and viruses. All living cells contain both DNA and RNA (except some cells such as mature red blood cells), while viruses contain either DNA or RNA, but usually not both. The basic component of biological nucleic acids is the nucleotide, each of which contains a pentose sugar (ribose or deoxyribose), a phosphate group, and a nucleobase. Nucleic acids are also generated within the laboratory, through the use of enzymes (DNA and RNA polymerases) and by solid-phase chemical synthesis. The chemical methods also enable the generation of altered nucleic acids that are not found in nature, for example peptide nucleic acids. Nucleic acids are generally very large molecules. Indeed, DNA molecules are probably the largest individual molecules known. Well-studied biological nucleic acid molecules range in size from 21 nucleotides (small interfering RNA) to large chromosomes (human chromosome 1 is a single molecule that contains 247 million base pairs). In most cases, naturally occurring DNA molecules are double-stranded and RNA molecules are single-stranded. There are numerous exceptions, however—some viruses have genomes made of double-stranded RNA and other viruses have single-stranded DNA genomes, and, in some circumstances, nucleic acid structures with three or four strands can form. Nucleic acids are linear polymers (chains) of nucleotides. Each nucleotide consists of three components: a purine or pyrimidine nucleobase (sometimes termed nitrogenous base or simply base), a pentose sugar, and a phosphate group. The substructure consisting of a nucleobase plus sugar is termed a nucleoside. Nucleic acid types differ in the structure of the sugar in their nucleotides–DNA contains 2’-deoxyribose while RNA contains ribose (where the only difference is the presence of a hydroxyl group). Also, the nucleobases found in the two nucleic acid types are different: adenine, cytosine, and guanine are found in both RNA and DNA, while thymine occurs in DNA and uracil occurs in RNA. The sugars and phosphates in nucleic acids are connected to each other in an alternating chain (sugar-phosphate backbone) through phosphodiester linkages. In conventional nomenclature, the carbons to which the phosphate groups attach are the 3’-end and the 5’-end carbons of the sugar. This gives nucleic acids directionality, and the ends of nucleic acid molecules are referred to as 5’-end and 3’-end. The nucleobases are joined to the sugars via an N-glycosidic linkage involving a nucleobase ring nitrogen (N-1 for pyrimidines and N-9 for purines) and the 1’ carbon of the pentose sugar ring. 2.13.11 Deoxyribonucleic Acid (DNA) Deoxyribonucleic acid (DNA) is a nucleic acid containing the genetic instructions used in the development and functioning of all known living organisms. The DNA segments carrying this genetic information are called genes. Likewise, other DNA sequences have structural purposes or are involved in regulating the use of this genetic information. Along with RNA and proteins, DNA is one of the three major macromolecules that are essential for all known forms of life. Figure 2.22: The structure of the DNA double helix. A section of DNA. The bases lie horizontally between the two spiraling strands. The atoms in the structure are colour-coded by element (based on atomic coordinates of PDB 1bna rendered with open source molecular visualization tool PyMol.) DNA consists of two long polymers of simple units called nucleotides, with backbones made of sugars and phosphate groups joined by ester bonds. These two strands run in opposite directions to each other and are, therefore, anti-parallel. Attached to each sugar is one of four types of molecules called nucleobases (informally, bases). It is the sequence of these four nucleobases along the backbone that encodes information. This information is read using the genetic code, which specifies the sequence of the amino acids within proteins. The code is read by copying stretches of DNA into the related nucleic acid RNA in a process called transcription. Within cells, DNA is organized into long structures called chromosomes. During cell division these chromosomes are duplicated in the process of DNA replication, providing each cell its own complete set of chromosomes. Eukaryotic organisms (animals, plants, fungi, and protists) store most of their DNA inside the cell nucleus and some of their DNA in organelles, such as mitochondria or chloroplasts. In contrast, prokaryotes (bacteria and archaea) store their DNA only in the cytoplasm. Within the chromosomes, chromatin proteins such as histones compact and organize DNA. These compact structures guide the interactions between DNA and other proteins, helping control which parts of the DNA are transcribed. Figure 2.23: Structural elements of three nucleotides—where one-, two- or three-phosphates are attached to the nucleoside (in yellow, blue, green) at center: 1st, the nucleotide termed as a nucleoside monophosphate is formed by adding a phosphate (in red); 2nd, adding a second phosphate forms a nucleoside diphosphate; 3rd, adding a third phosphate results in a nucleoside triphosphate. + The nitrogenous base (nucleobase) is indicated by “Base” and “glycosidic bond” (sugar bond). All five primary, or canonical, bases—the purines and pyrimidines—are sketched at right (in blue). 2.13.12 Ribonucleic Acid (RNA) Ribonucleic acid (RNA) functions in converting genetic information from genes into the amino acid sequences of proteins. The three universal types of RNA include transfer RNA (tRNA), messenger RNA (mRNA), and ribosomal RNA (rRNA). Messenger RNA acts to carry genetic sequence information between DNA and ribosomes, directing protein synthesis. Ribosomal RNA is a major component of the ribosome, and catalyzes peptide bond formation. Transfer RNA serves as the carrier molecule for amino acids to be used in protein synthesis, and is responsible for decoding the mRNA. In addition, many other classes of RNA are now known. "],["an-introduction-to-methods-of-studying-microorganisms.html", "3 An Introduction To Methods Of Studying Microorganisms 3.1 Microscopy 3.2 The Gram Stain 3.3 Electron Microscopy 3.4 Microbiological Culture 3.5 Culture Collections 3.6 Growth Medium", " 3 An Introduction To Methods Of Studying Microorganisms 3.1 Microscopy Microscopy is the technical field of using microscopes to view objects and areas of objects that cannot be seen with the naked eye (objects that are not within the resolution range of the normal eye). There are three well-known branches of microscopy: optical, electron, and scanning probe microscopy, along with the emerging field of X-ray microscopy. Optical microscopy and electron microscopy involve the diffraction, reflection, or refraction of electromagnetic radiation/electron beams interacting with the specimen, and the collection of the scattered radiation or another signal in order to create an image. This process may be carried out by wide-field irradiation of the sample (for example standard light microscopy and transmission electron microscopy) or by scanning a fine beam over the sample (for example confocal laser scanning microscopy and scanning electron microscopy). Scanning probe microscopy involves the interaction of a scanning probe with the surface of the object of interest. The development of microscopy revolutionized biology, gave rise to the field of histology and so remains an essential technique in the life and physical sciences. X-ray microscopy is three-dimensional and non-destructive, allowing for repeated imaging of the same sample for in situ or 4D studies, and providing the ability to “see inside” the sample being studied before sacrificing it to higher resolution techniques. A 3D X-ray microscope uses the technique of computed tomography (microCT), rotating the sample 360 degrees and reconstructing the images. CT is typically carried out with a flat panel display. A 3D X-ray microscope employs a range of objectives, e.g., from 4X to 40X, and can also include a flat panel. The field of microscopy (optical microscopy) dates back to at least the 17th-century. Earlier microscopes, single lens magnifying glasses with limited magnification, date at least as far back as the wide spread use of lenses in eyeglasses in the 13th century but more advanced compound microscopes first appeared in Europe around 1620 The earliest practitioners of microscopy include Galileo Galilei, who found in 1610 that he could close focus his telescope to view small objects close up and Cornelis Drebbel, who may have invented the compound microscope around 1620 Antonie van Leeuwenhoek developed a very high magnification simple microscope in the 1670s and is often considered to be the first acknowledged microscopist and microbiologist. 3.1.1 Light Microscopy Optical or light microscopy involves passing visible light transmitted through or reflected from the sample through a single lens or multiple lenses to allow a magnified view of the sample. The resulting image can be detected directly by the eye, imaged on a photographic plate, or captured digitally. The single lens with its attachments, or the system of lenses and imaging equipment, along with the appropriate lighting equipment, sample stage, and support, makes up the basic light microscope. The most recent development is the digital microscope, which uses a CCD camera to focus on the exhibit of interest. The image is shown on a computer screen, so eye-pieces are unnecessary. 3.1.2 The Optical (Light) Microscope The optical microscope, also referred to as a light microscope, is a type of microscope that commonly uses visible light and a system of lenses to generate magnified images of small objects. Optical microscopes are the oldest design of microscope and were possibly invented in their present compound form in the 17th century. Basic optical microscopes can be very simple, although many complex designs aim to improve resolution and sample contrast. The object is placed on a stage and may be directly viewed through one or two eyepieces on the microscope. In high-power microscopes, both eyepieces typically show the same image, but with a stereo microscope, slightly different images are used to create a 3-D effect. A camera is typically used to capture the image (micrograph). The sample can be lit in a variety of ways. Transparent objects can be lit from below and solid objects can be lit with light coming through (bright field) or around (dark field) the objective lens. Polarised light may be used to determine crystal orientation of metallic objects. Phase-contrast imaging can be used to increase image contrast by highlighting small details of differing refractive index. A range of objective lenses with different magnification are usually provided mounted on a turret, allowing them to be rotated into place and providing an ability to zoom-in. The maximum magnification power of optical microscopes is typically limited to around 1000x because of the limited resolving power of visible light. The magnification of a compound optical microscope is the product of the magnification of the eyepiece (say 10x) and the objective lens (say 100x), to give a total magnification of 1,000×. Modified environments such as the use of oil or ultraviolet light can increase the magnification. Alternatives to optical microscopy which do not use visible light include scanning electron microscopy and transmission electron microscopy and scanning probe microscopy and as a result, can achieve much greater magnifications. There are two basic types of optical microscopes: simple microscopes and compound microscopes. A simple microscope uses the optical power of single lens or group of lenses for magnification. A compound microscope uses a system of lenses (one set enlarging the image produced by another) to achieve much higher magnification of an object. The vast majority of modern research microscopes are compound microscopes while some cheaper commercial digital microscopes are simple single lens microscopes. Compound microscopes can be further divided into a variety of other types of microscopes which differ in their optical configurations, cost, and intended purposes. 3.1.3 Simple Microscope A simple microscope uses a lens or set of lenses to enlarge an object through angular magnification alone, giving the viewer an erect enlarged virtual image. The use of a single convex lens or groups of lenses are found in simple magnification devices such as the magnifying glass, loupes, and eyepieces for telescopes and microscopes. 3.1.4 Compound Microscope A compound microscope uses a lens close to the object being viewed to collect light (called the objective lens) which focuses a real image of the object inside the microscope (image 1). That image is then magnified by a second lens or group of lenses (called the eyepiece) that gives the viewer an enlarged inverted virtual image of the object (image 2). The use of a compound objective/eyepiece combination allows for much higher magnification. Common compound microscopes often feature exchangeable objective lenses, allowing the user to quickly adjust the magnification. A compound microscope also enables more advanced illumination setups, such as phase contrast. 3.1.5 The Main Components Of The Light Microscope All modern optical microscopes designed for viewing samples by transmitted light share the same basic components of the light path. In addition, the vast majority of microscopes have the same ‘structural’ components (numbered below according to the image on the right): Eyepiece (ocular lens) (1) Objective turret, revolver, or revolving nose piece (to hold multiple objective lenses) (2) Objective lenses (3) Focus knobs (to move the stage) Coarse adjustment (4) Fine adjustment (5) Stage (to hold the specimen) (6) Light source (a light or a mirror) (7) Diaphragm and condenser (8) Mechanical stage (9) 3.1.6 Eyepiece (Ocular Lens) The eyepiece, or ocular lens, is a cylinder containing two or more lenses; its function is to bring the image into focus for the eye. The eyepiece is inserted into the top end of the body tube. Eyepieces are interchangeable and many different eyepieces can be inserted with different degrees of magnification. Typical magnification values for eyepieces include 5×, 10× (the most common), 15× and 20×. In some high performance microscopes, the optical configuration of the objective lens and eyepiece are matched to give the best possible optical performance. This occurs most commonly with apochromatic objectives. Objective turret (revolver or revolving nose piece) Objective turret, revolver, or revolving nose piece is the part that holds the set of objective lenses. It allows the user to switch between objective lenses. 3.1.7 Objective Lens At the lower end of a typical compound optical microscope, there are one or more objective lenses that collect light from the sample. The objective is usually in a cylinder housing containing a glass single or multi-element compound lens. Typically there will be around three objective lenses screwed into a circular nose piece which may be rotated to select the required objective lens. These arrangements are designed to be parfocal, which means that when one changes from one lens to another on a microscope, the sample stays in focus. Microscope objectives are characterized by two parameters, namely, magnification and numerical aperture. The former typically ranges from 5× to 100× while the latter ranges from 0.14 to 0.7, corresponding to focal lengths of about 40 to 2 mm, respectively. Objective lenses with higher magnifications normally have a higher numerical aperture and a shorter depth of field in the resulting image. Some high performance objective lenses may require matched eyepieces to deliver the best optical performance. 3.1.8 Oil Immersion Objective Some microscopes make use of oil-immersion objectives or water-immersion objectives for greater resolution at high magnification. These are used with index-matching material such as immersion oil or water and a matched cover slip between the objective lens and the sample. The refractive index of the index-matching material is higher than air allowing the objective lens to have a larger numerical aperture (greater than 1) so that the light is transmitted from the specimen to the outer face of the objective lens with minimal refraction. Numerical apertures as high as 1.6 can be achieved. The larger numerical aperture allows collection of more light making detailed observation of smaller details possible. An oil immersion lens usually has a magnification of 40 to 100×. 3.1.9 Focus Knobs Adjustment knobs move the stage up and down with separate adjustment for coarse and fine focusing. The same controls enable the microscope to adjust to specimens of different thickness. In older designs of microscopes, the focus adjustment wheels move the microscope tube up or down relative to the stand and had a fixed stage. 3.1.10 The Frame The whole of the optical assembly is traditionally attached to a rigid arm, which in turn is attached to a robust U-shaped foot to provide the necessary rigidity. The arm angle may be adjustable to allow the viewing angle to be adjusted. The frame provides a mounting point for various microscope controls. Normally this will include controls for focusing, typically a large knurled wheel to adjust coarse focus, together with a smaller knurled wheel to control fine focus. Other features may be lamp controls and/or controls for adjusting the condenser. 3.1.11 The Stage The stage is a platform below the objective lens which supports the specimen being viewed. In the center of the stage is a hole through which light passes to illuminate the specimen. The stage usually has arms to hold slides (rectangular glass plates with typical dimensions of 25×75 mm, on which the specimen is mounted). At magnifications higher than 100× moving a slide by hand is not practical. A mechanical stage, typical of medium and higher priced microscopes, allows tiny movements of the slide via control knobs that reposition the sample/slide as desired. If a microscope did not originally have a mechanical stage it may be possible to add one. All stages move up and down for focus. With a mechanical stage slides move on two horizontal axes for positioning the specimen to examine specimen details. Focusing starts at lower magnification in order to center the specimen by the user on the stage. Moving to a higher magnification requires the stage to be moved higher vertically for re-focus at the higher magnification and may also require slight horizontal specimen position adjustment. Horizontal specimen position adjustments are the reason for having a mechanical stage. Due to the difficulty in preparing specimens and mounting them on slides, for children it’s best to begin with prepared slides that are centered and focus easily regardless of the focus level used. 3.1.12 The Light Source Many sources of light can be used. At its simplest, daylight is directed via a mirror. Most microscopes, however, have their own adjustable and controllable light source – often a halogen lamp, although illumination using LEDs and lasers are becoming a more common provision. Köhler illumination is often provided on more expensive instruments. 3.1.13 The Condenser The condenser is a lens designed to focus light from the illumination source onto the sample. The condenser may also include other features, such as a diaphragm and/or filters, to manage the quality and intensity of the illumination. For illumination techniques like dark field, phase contrast and differential interference contrast microscopy additional optical components must be precisely aligned in the light path. 3.1.14 Magnification The actual power or magnification of a compound optical microscope is the product of the powers of the ocular (eyepiece) and the objective lens. The maximum normal magnifications of the ocular and objective are 10× and 100× respectively, giving a final magnification of 1,000×. When using a camera to capture a micrograph the effective magnification of the image must take into account the size of the image. This is independent of whether it is on a print from a film negative or displayed digitally on a computer screen. In the case of photographic film cameras the calculation is simple; the final magnification is the product of: the objective lens magnification, the camera optics magnification and the enlargement factor of the film print relative to the negative. A typical value of the enlargement factor is around 5× (for the case of 35 mm film and a 15 × 10 cm (6 × 4 inch) print). In the case of digital cameras the size of the pixels in the CMOS or CCD detector and the size of the pixels on the screen have to be known. The enlargement factor from the detector to the pixels on screen can then be calculated. As with a film camera the final magnification is the product of: the objective lens magnification, the camera optics magnification and the enlargement factor At very high magnifications with transmitted light, point objects are seen as fuzzy discs surrounded by diffraction rings. These are called Airy disks. The resolving power of a microscope is taken as the ability to distinguish between two closely spaced Airy disks (or, in other words the ability of the microscope to reveal adjacent structural detail as distinct and separate). It is these impacts of diffraction that limit the ability to resolve fine details. The extent and magnitude of the diffraction patterns are affected by both the wavelength of light (λ), the refractive materials used to manufacture the objective lens and the numerical aperture (NA) of the objective lens. There is therefore a finite limit beyond which it is impossible to resolve separate points in the objective field, known as the diffraction limit. Assuming that optical aberrations in the whole optical set-up are negligible, the resolution d, can be stated as: \\[ d={\\frac {\\lambda }{2NA}}\\] Usually a wavelength of 550 nm is assumed, which corresponds to green light. With air as the external medium, the highest practical NA is 0.95, and with oil, up to 1.5. In practice the lowest value of d obtainable with conventional lenses is about 200 nm. A new type of lens using multiple scattering of light allowed to improve the resolution to below 100 nm. 3.1.15 The Microscope Slide A microscope slide is a thin flat piece of glass, typically 75 by 26 mm (3 by 1 inches) and about 1 mm thick, used to hold objects for examination under a microscope. Typically the object is mounted (secured) on the slide, and then both are inserted together in the microscope for viewing. This arrangement allows several slide-mounted objects to be quickly inserted and removed from the microscope, labeled, transported, and stored in appropriate slide cases or folders etc. Microscope slides are often used together with a cover slip or cover glass, a smaller and thinner sheet of glass that is placed over the specimen. Slides are held in place on the microscope’s stage by slide clips, slide clamps or a cross-table which is used to achieve precise, remote movement of the slide upon the microscope’s stage (such as in an automated/computer operated system, or where touching the slide with fingers is inappropriate either due to the risk of contamination or lack of precision). The mounting of specimens on microscope slides is often critical for successful viewing. The problem has been given much attention in the last two centuries and is a well-developed area with many specialized and sometimes quite sophisticated techniques. Specimens are often held into place using the smaller glass cover slips. The main function of the cover slip is to keep solid specimens pressed flat, and liquid samples shaped into a flat layer of even thickness. This is necessary because high-resolution microscopes have a very narrow region within which they focus. The cover glass often has several other functions. It holds the specimen in place (either by the weight of the cover slip or, in the case of a wet mount, by surface tension) and protects the specimen from dust and accidental contact. It protects the microscope’s objective lens from contacting the specimen and vice versa; in oil immersion microscopy or water immersion microscopy the cover slip prevents contact between the immersion liquid and the specimen. The cover slip can be glued to the slide so as to seal off the specimen, retarding dehydration and oxidation of the specimen and also preventing contamination. A number of sealants are in use, including commercial sealants, laboratory preparations, or even regular clear nail polish, depending on the sample. A solvent-free sealant that can be used for live cell samples is “valap”, a mixture of vaseline, lanolin and paraffin in equal parts. Microbial and cell cultures can be grown directly on the cover slip before it is placed on the slide, and specimens may be permanently mounted on the slip instead of on the slide. Cover slips are available in a range of sizes and thicknesses. Using the wrong thickness can result in spherical aberration and a reduction in resolution and image intensity. Specialty objectives may used to image specimens without coverslips, or may have correction collars that permit a user to accommodate for alternative coverslip thickness. 3.1.16 Dry Mount In a dry mount, the simplest kind of mounting, the object is merely placed on the slide. A cover slip may be placed on top to protect the specimen and the microscope’s objective and to keep the specimen still and pressed flat. This mounting can be successfully used for viewing specimens like pollen, feathers, hairs, etc. It is also used to examine particles caught in transparent membrane filters (e.g., in analysis of airborne dust). 3.1.17 Wet Mount Or Temporary Mount In a wet mount, the specimen is placed in a drop of water or other liquid held between the slide and the cover slip by surface tension. This method is commonly used, for example, to view microscopic organisms that grow in pond water or other liquid media, especially when studying their movement and behavior. Care must be taken to exclude air bubbles that would interfere with the viewing and hamper the organisms’ movements. An example of a temporary wet mount is a lactofuchsin mount, which provides both a sample mounting, as well as a fuchsine staining. 3.1.18 Prepared Mount Or Permanent Mount For pathological and biological research, the specimen usually undergoes a complex histological preparation that involves fixing it to prevent decay, removing any water contained in it, replacing the water with paraffin, cutting it into very thin sections using a microtome, placing the sections on a microscope slide, staining the tissue using various stains to reveal specific tissue components, clearing the tissue to render it transparent and covering it with a coverslip and mounting medium. 3.1.19 Techniques Of Optical Microscopy Optical or light microscopy involves passing visible light transmitted through or reflected from the sample through a single lens or multiple lenses to allow a magnified view of the sample.[11] The resulting image can be detected directly by the eye, imaged on a photographic plate, or captured digitally. The single lens with its attachments, or the system of lenses and imaging equipment, along with the appropriate lighting equipment, sample stage, and support, makes up the basic light microscope. The most recent development is the digital microscope, which uses a CCD camera to focus on the exhibit of interest. The image is shown on a computer screen, so eye-pieces are unnecessary. Limitations of standard optical microscopy (bright field microscopy) lie in three areas; This technique can only image dark or strongly refracting objects effectively. There is a diffraction-limited resolution depending on incident wavelength; in visible range, the resolution of optical microscopy is limited to approximately 0.2 micrometres (see: microscope) and the practical magnification limit to ~1500x. Out-of-focus light from points outside the focal plane reduces image clarity. Live cells in particular generally lack sufficient contrast to be studied successfully, since the internal structures of the cell are colorless and transparent. The most common way to increase contrast is to stain the different structures with selective dyes, but this often involves killing and fixing the sample. Staining may also introduce artifacts, which are apparent structural details that are caused by the processing of the specimen and are thus not legitimate features of the specimen. In general, these techniques make use of differences in the refractive index of cell structures. Bright-field microscopy is comparable to looking through a glass window: one sees not the glass but merely the dirt on the glass. There is a difference, as glass is a denser material, and this creates a difference in phase of the light passing through. The human eye is not sensitive to this difference in phase, but clever optical solutions have been devised to change this difference in phase into a difference in amplitude (light intensity). In order to improve specimen contrast or highlight certain structures in a sample, special techniques must be used. A huge selection of microscopy techniques are available to increase contrast or label a sample. 3.1.20 Bright Field Bright field microscopy is the simplest of all the light microscopy techniques. Sample illumination is via transmitted white light, i.e. illuminated from below and observed from above. Limitations include low contrast of most biological samples and low apparent resolution due to the blur of out-of-focus material. The simplicity of the technique and the minimal sample preparation required are significant advantages. 3.1.21 Oblique Illumination The use of oblique (from the side) illumination gives the image a three-dimensional (3D) appearance and can highlight otherwise invisible features. A more recent technique based on this method is Hoffmann’s modulation contrast, a system found on inverted microscopes for use in cell culture. Oblique illumination suffers from the same limitations as bright field microscopy (low contrast of many biological samples; low apparent resolution due to out of focus objects). 3.1.22 Dark Field Dark field microscopy is a technique for improving the contrast of unstained, transparent specimens. Dark field illumination uses a carefully aligned light source to minimize the quantity of directly transmitted (unscattered) light entering the image plane, collecting only the light scattered by the sample. Dark field can dramatically improve image contrast – especially of transparent objects – while requiring little equipment setup or sample preparation. However, the technique suffers from low light intensity in final image of many biological samples and continues to be affected by low apparent resolution. Rheinberg illumination is a special variant of dark field illumination in which transparent, colored filters are inserted just before the condenser so that light rays at high aperture are differently colored than those at low aperture (i.e., the background to the specimen may be blue while the object appears self-luminous red). Other color combinations are possible, but their effectiveness is quite variable. 3.1.23 Dispersion Staining Dispersion staining is an optical technique that results in a colored image of a colorless object. This is an optical staining technique and requires no stains or dyes to produce a color effect. There are five different microscope configurations used in the broader technique of dispersion staining. They include brightfield Becke line, oblique, darkfield, phase contrast, and objective stop dispersion staining. 3.1.24 Phase Contrast More sophisticated techniques will show proportional differences in optical density. Phase contrast is a widely used technique that shows differences in refractive index as difference in contrast. It was developed by the Dutch physicist Frits Zernike in the 1930s (for which he was awarded the Nobel Prize in 1953). The nucleus in a cell for example will show up darkly against the surrounding cytoplasm. Contrast is excellent; however it is not for use with thick objects. Frequently, a halo is formed even around small objects, which obscures detail. The system consists of a circular annulus in the condenser, which produces a cone of light. This cone is superimposed on a similar sized ring within the phase-objective. Every objective has a different size ring, so for every objective another condenser setting has to be chosen. The ring in the objective has special optical properties: it, first of all, reduces the direct light in intensity, but more importantly, it creates an artificial phase difference of about a quarter wavelength. As the physical properties of this direct light have changed, interference with the diffracted light occurs, resulting in the phase contrast image. One disadvantage of phase-contrast microscopy is halo formation (halo-light ring). 3.1.25 Differential Interference Contrast Superior and much more expensive is the use of interference contrast. Differences in optical density will show up as differences in relief. A nucleus within a cell will actually show up as a globule in the most often used differential interference contrast system according to Georges Nomarski. However, it has to be kept in mind that this is an optical effect, and the relief does not necessarily resemble the true shape. Contrast is very good and the condenser aperture can be used fully open, thereby reducing the depth of field and maximizing resolution. The system consists of a special prism (Nomarski prism, Wollaston prism) in the condenser that splits light in an ordinary and an extraordinary beam. The spatial difference between the two beams is minimal (less than the maximum resolution of the objective). After passage through the specimen, the beams are reunited by a similar prism in the objective. In a homogeneous specimen, there is no difference between the two beams, and no contrast is being generated. However, near a refractive boundary (say a nucleus within the cytoplasm), the difference between the ordinary and the extraordinary beam will generate a relief in the image. Differential interference contrast requires a polarized light source to function; two polarizing filters have to be fitted in the light path, one below the condenser (the polarizer), and the other above the objective (the analyzer). Note: In cases where the optical design of a microscope produces an appreciable lateral separation of the two beams we have the case of classical interference microscopy, which does not result in relief images, but can nevertheless be used for the quantitative determination of mass-thicknesses of microscopic objects. 3.1.26 Interference Reflection An additional technique using interference is interference reflection microscopy (also known as reflected interference contrast, or RIC). It relies on cell adhesion to the slide to produce an interference signal. If there is no cell attached to the glass, there will be no interference. Interference reflection microscopy can be obtained by using the same elements used by DIC, but without the prisms. Also, the light that is being detected is reflected and not transmitted as it is when DIC is employed. 3.1.27 Fluorescence Microscopy When certain compounds are illuminated with high energy light, they emit light of a lower frequency. This effect is known as fluorescence. Often specimens show their characteristic autofluorescence image, based on their chemical makeup. This method is of critical importance in the modern life sciences, as it can be extremely sensitive, allowing the detection of single molecules. Many different fluorescent dyes can be used to stain different structures or chemical compounds. One particularly powerful method is the combination of antibodies coupled to a fluorophore as in immunostaining. Examples of commonly used fluorophores are fluorescein or rhodamine. The antibodies can be tailor-made for a chemical compound. For example, one strategy often in use is the artificial production of proteins, based on the genetic code (DNA). These proteins can then be used to immunize rabbits, forming antibodies which bind to the protein. The antibodies are then coupled chemically to a fluorophore and used to trace the proteins in the cells under study. Highly efficient fluorescent proteins such as the green fluorescent protein (GFP) have been developed using the molecular biology technique of gene fusion, a process that links the expression of the fluorescent compound to that of the target protein. This combined fluorescent protein is, in general, non-toxic to the organism and rarely interferes with the function of the protein under study. Genetically modified cells or organisms directly express the fluorescently tagged proteins, which enables the study of the function of the original protein in vivo. Growth of protein crystals results in both protein and salt crystals. Both are colorless and microscopic. Recovery of the protein crystals requires imaging which can be done by the intrinsic fluorescence of the protein or by using transmission microscopy. Both methods require an ultraviolet microscope as protein absorbs light at 280 nm. Protein will also fluorescence at approximately 353 nm when excited with 280 nm light. Since fluorescence emission differs in wavelength (color) from the excitation light, an ideal fluorescent image shows only the structure of interest that was labeled with the fluorescent dye. This high specificity led to the widespread use of fluorescence light microscopy in biomedical research. Different fluorescent dyes can be used to stain different biological structures, which can then be detected simultaneously, while still being specific due to the individual color of the dye. To block the excitation light from reaching the observer or the detector, filter sets of high quality are needed. These typically consist of an excitation filter selecting the range of excitation wavelengths, a dichroic mirror, and an emission filter blocking the excitation light. Most fluorescence microscopes are operated in the Epi-illumination mode (illumination and detection from one side of the sample) to further decrease the amount of excitation light entering the detector. 3.1.28 Confoca Microscopy Confocal laser scanning microscopy uses a focused laser beam (e.g. 488 nm) that is scanned across the sample to excite fluorescence in a point-by-point fashion. The emitted light is directed through a pinhole to prevent out-of-focus light from reaching the detector, typically a photomultiplier tube. The image is constructed in a computer, plotting the measured fluorescence intensities according to the position of the excitation laser. Compared to full sample illumination, confocal microscopy gives slightly higher lateral resolution and significantly improves optical sectioning (axial resolution). Confocal microscopy is, therefore, commonly used where 3D structure is important. A subclass of confocal microscopes are spinning disc microscopes which are able to scan multiple points simultaneously across the sample. A corresponding disc with pinholes rejects out-of-focus light. The light detector in a spinning disc microscope is a digital camera, typically EM-CCD or sCMOS. 3.1.29 Two-Photon Microscopy A two-photon microscope is also a laser-scanning microscope, but instead of UV, blue or green laser light, a pulsed infrared laser is used for excitation. Only in the tiny focus of the laser is the intensity high enough to generate fluorescence by two-photon excitation, which means that no out-of-focus fluorescence is generated, and no pinhole is necessary to clean up the image. This allows imaging deep in scattering tissue, where a confocal microscope would not be able to collect photons efficiently. Two-photon microscopes with wide-field detection are frequently used for functional imaging, e.g. calcium imaging, in brain tissue. They are marketed as Multiphoton microscopes by several companies, although the gains of using 3-photon instead of 2-photon excitation are marginal. 3.2 The Gram Stain Gram stain or Gram staining, also called Gram’s method, is a method of staining used to distinguish and classify bacterial species into two large groups: gram-positive bacteria and gram-negative bacteria. The name comes from the Danish bacteriologist Hans Christian Gram, who developed the technique. Gram staining differentiates bacteria by the chemical and physical properties of their cell walls. Gram-positive cells have a thick layer of peptidoglycan in the cell wall that retains the primary stain, crystal violet. Gram-negative cells have a thinner peptidoglycan layer that allows the crystal violet to wash out on addition of ethanol. They are stained pink or red by the counterstain, commonly safranin or fuchsine. Lugol’s iodine solution is always added after addition of crystal violet to strengthen the bonds of the stain with the cell membrane. Gram staining is almost always the first step in the preliminary identification of a bacterial organism. While Gram staining is a valuable diagnostic tool in both clinical and research settings, not all bacteria can be definitively classified by this technique. This gives rise to gram-variable and gram-indeterminate groups. The method is named after its inventor, the Danish scientist Hans Christian Gram (1853–1938), who developed the technique while working with Carl Friedländer in the morgue of the city hospital in Berlin in 1884. Gram devised his technique not for the purpose of distinguishing one type of bacterium from another but to make bacteria more visible in stained sections of lung tissue. He published his method in 1884, and included in his short report the observation that the typhus bacillus did not retain the stain. Gram staining is a bacteriological laboratory technique used to differentiate bacterial species into two large groups (gram-positive and gram-negative) based on the physical properties of their cell walls.[page needed] Gram staining is not used to classify archaea, formerly archaeabacteria, since these microorganisms yield widely varying responses that do not follow their phylogenetic groups. Some organisms are gram-variable (meaning they may stain either negative or positive); some are not stained with either dye used in the Gram technique and are not seen. In a modern environmental or molecular microbiology lab, most identification is done using genetic sequences and other molecular techniques, which are far more specific and informative than differential staining. Gram staining has been suggested to be as effective a diagnostic tool as PCR in one primary research report regarding gonorrhea. Gram stains are performed on body fluid or biopsy when infection is suspected. Gram stains yield results much more quickly than culturing, and are especially important when infection would make an important difference in the patient’s treatment and prognosis; examples are cerebrospinal fluid for meningitis and synovial fluid for septic arthritis. Gram-positive bacteria have a thick mesh-like cell wall made of peptidoglycan (50–90% of cell envelope), and as a result are stained purple by crystal violet, whereas gram-negative bacteria have a thinner layer (10% of cell envelope), so do not retain the purple stain and are counter-stained pink by safranin. There are four basic steps of the Gram stain: Applying a primary stain (crystal violet) to a heat-fixed smear of a bacterial culture. Heat fixation kills some bacteria but is mostly used to affix the bacteria to the slide so that they don’t rinse out during the staining procedure. The addition of iodine, which binds to crystal violet and traps it in the cell Rapid decolorization with ethanol or acetone Counterstaining with safranin. Carbol fuchsin is sometimes substituted for safranin since it more intensely stains anaerobic bacteria, but it is less commonly used as a counterstain. Crystal violet (CV) dissociates in aqueous solutions into CV+ and chloride (Cl− ) ions. These ions penetrate the cell wall of both gram-positive and gram-negative cells. The CV+ ion interacts with negatively charged components of bacterial cells and stains the cells purple. Iodide (I− or I− 3) interacts with CV+ and forms large complexes of crystal violet and iodine (CV–I) within the inner and outer layers of the cell. Iodine is often referred to as a mordant, but is a trapping agent that prevents the removal of the CV–I complex and, therefore, colors the cell. When a decolorizer such as alcohol or acetone is added, it interacts with the lipids of the cell membrane. A gram-negative cell loses its outer lipopolysaccharide membrane, and the inner peptidoglycan layer is left exposed. The CV–I complexes are washed from the gram-negative cell along with the outer membrane. In contrast, a gram-positive cell becomes dehydrated from an ethanol treatment. The large CV–I complexes become trapped within the gram-positive cell due to the multilayered nature of its peptidoglycan. The decolorization step is critical and must be timed correctly; the crystal violet stain is removed from both gram-positive and negative cells if the decolorizing agent is left on too long (a matter of seconds). After decolorization, the gram-positive cell remains purple and the gram-negative cell loses its purple color. Counterstain, which is usually positively charged safranin or basic fuchsine, is applied last to give decolorized gram-negative bacteria a pink or red color. Both gram-positive bacteria and gram-negative bacteria pick up the counterstain. The counterstain, however, is unseen on gram-positive bacteria because of the darker crystal violet stain. 3.2.1 Gram-Positive Bacteria Gram-positive bacteria generally have a single membrane (monoderm) surrounded by a thick peptidoglycan. This rule is followed by two phyla: Firmicutes (except for the classes Mollicutes and Negativicutes) and the Actinobacteria. In contrast, members of the Chloroflexi (green non-sulfur bacteria) are monoderms but possess a thin or absent (class Dehalococcoidetes) peptidoglycan and can stain negative, positive or indeterminate; members of the Deinococcus–Thermus group stain positive but are diderms with a thick peptidoglycan.[page needed] Historically, the gram-positive forms made up the phylum Firmicutes, a name now used for the largest group. It includes many well-known genera such as Lactobacillus, Bacillus, Listeria, Staphylococcus, Streptococcus, Enterococcus, and Clostridium. It has also been expanded to include the Mollicutes, bacteria such as Mycoplasma and Thermoplasma that lack cell walls and so cannot be Gram-stained, but are derived from such forms. Some bacteria have cell walls which are particularly adept at retaining stains. These will appear positive by Gram stain even though they are not closely related to other gram-positive bacteria. These are called acid-fast bacteria, and can only be differentiated from other gram-positive bacteria by special staining procedures. 3.2.2 Gram-Negative Bacteria Gram-negative bacteria generally possess a thin layer of peptidoglycan between two membranes (diderm). Lipopolysaccharide (LPS) is the most abundant antigen on the cell surface of most Gram-negative bacteria, contributing up to 80% of the outer membrane of E. coli and Salmonella. Most bacterial phyla are gram-negative, including the cyanobacteria, green sulfur bacteria, and most Proteobacteria (exceptions being some members of the Rickettsiales and the insect-endosymbionts of the Enterobacteriales).[page needed] 3.2.3 Gram-Variable and Gram-Indeterminate Bacteria Some bacteria, after staining with the Gram stain, yield a gram-variable pattern: a mix of pink and purple cells are seen. In cultures of Bacillus, Butyrivibrio, and Clostridium, a decrease in peptidoglycan thickness during growth coincides with an increase in the number of cells that stain gram-negative. In addition, in all bacteria stained using the Gram stain, the age of the culture may influence the results of the stain. Gram-indeterminate bacteria do not respond predictably to Gram staining and, therefore, cannot be determined as either gram-positive or gram-negative. Examples include many species of Mycobacterium, including Mycobacterium bovis, Mycobactrium leprae and Mycobacterium tuberculosis, the latter two of which are the causative agents of leprosy and tuberculosis, respectively. Bacteria of the genus Mycoplasma lack a cell wall around their cell membranes, which means they do not stain by Gram’s method and are resistant to the antibiotics that target cell wall synthesis. 3.3 Electron Microscopy Until the invention of sub-diffraction microscopy, the wavelength of the light limited the resolution of traditional microscopy to around 0.2 micrometers. In order to gain higher resolution, the use of an electron beam with a far smaller wavelength is used in electron microscopes. 3.3.1 The Transmission Electron Microscope (TEM) The original form of the electron microscope, the transmission electron microscope (TEM), uses a high voltage electron beam to illuminate the specimen and create an image. The electron beam is produced by an electron gun, commonly fitted with a tungsten filament cathode as the electron source. The electron beam is accelerated by an anode typically at +100 keV (40 to 400 keV) with respect to the cathode, focused by electrostatic and electromagnetic lenses, and transmitted through the specimen that is in part transparent to electrons and in part scatters them out of the beam. When it emerges from the specimen, the electron beam carries information about the structure of the specimen that is magnified by the objective lens system of the microscope. The spatial variation in this information (the “image”) may be viewed by projecting the magnified electron image onto a fluorescent viewing screen coated with a phosphor or scintillator material such as zinc sulfide. Alternatively, the image can be photographically recorded by exposing a photographic film or plate directly to the electron beam, or a high-resolution phosphor may be coupled by means of a lens optical system or a fibre optic light-guide to the sensor of a digital camera. The image detected by the digital camera may be displayed on a monitor or computer. The resolution of TEMs is limited primarily by spherical aberration, but a new generation of hardware correctors can reduce spherical aberration to increase the resolution in high-resolution transmission electron microscopy (HRTEM) to below 0.5 angstrom (50 picometres), enabling magnifications above 50 million times. The ability of HRTEM to determine the positions of atoms within materials is useful for nano-technologies research and development. Transmission electron microscopes are often used in electron diffraction mode. The advantages of electron diffraction over X-ray crystallography are that the specimen need not be a single crystal or even a polycrystalline powder, and also that the Fourier transform reconstruction of the object’s magnified structure occurs physically and thus avoids the need for solving the phase problem faced by the X-ray crystallographers after obtaining their X-ray diffraction patterns. One major disadvantage of the transmission electron microscope is the need for extremely thin sections of the specimens, typically about 100 nanometers. Creating these thin sections for biological and materials specimens is technically very challenging. Semiconductor thin sections can be made using a focused ion beam. Biological tissue specimens are chemically fixed, dehydrated and embedded in a polymer resin to stabilize them sufficiently to allow ultrathin sectioning. Sections of biological specimens, organic polymers, and similar materials may require staining with heavy atom labels in order to achieve the required image contrast. 3.3.2 The Scanning Electron Microscope (SEM) The SEM produces images by probing the specimen with a focused electron beam that is scanned across a rectangular area of the specimen (raster scanning). When the electron beam interacts with the specimen, it loses energy by a variety of mechanisms. The lost energy is converted into alternative forms such as heat, emission of low-energy secondary electrons and high-energy backscattered electrons, light emission (cathodoluminescence) or X-ray emission, all of which provide signals carrying information about the properties of the specimen surface, such as its topography and composition. The image displayed by an SEM maps the varying intensity of any of these signals into the image in a position corresponding to the position of the beam on the specimen when the signal was generated. In the SEM image of an ant shown below and to the right, the image was constructed from signals produced by a secondary electron detector, the normal or conventional imaging mode in most SEMs. Generally, the image resolution of an SEM is lower than that of a TEM. However, because the SEM images the surface of a sample rather than its interior, the electrons do not have to travel through the sample. This reduces the need for extensive sample preparation to thin the specimen to electron transparency. The SEM is able to image bulk samples that can fit on its stage and still be maneuvered, including a height less than the working distance being used, often 4 millimeters for high-resolution images. The SEM also has a great depth of field, and so can produce images that are good representations of the three-dimensional surface shape of the sample. Another advantage of SEMs comes with environmental scanning electron microscopes (ESEM) that can produce images of good quality and resolution with hydrated samples or in low, rather than high, vacuum or under chamber gases. This facilitates imaging unfixed biological samples that are unstable in the high vacuum of conventional electron microscopes. Electron microscopes are expensive to build and maintain, but the capital and running costs of confocal light microscope systems now overlaps with those of basic electron microscopes. Microscopes designed to achieve high resolutions must be housed in stable buildings (sometimes underground) with special services such as magnetic field canceling systems. The samples largely have to be viewed in vacuum, as the molecules that make up air would scatter the electrons. An exception is liquid-phase electron microscopy using either a closed liquid cell or an environmental chamber, for example, in the environmental scanning electron microscope, which allows hydrated samples to be viewed in a low-pressure (up to 20 Torr or 2.7 kPa) wet environment. Various techniques for in situ electron microscopy of gaseous samples have been developed as well. Scanning electron microscopes operating in conventional high-vacuum mode usually image conductive specimens; therefore non-conductive materials require conductive coating (gold/palladium alloy, carbon, osmium, etc.). The low-voltage mode of modern microscopes makes possible the observation of non-conductive specimens without coating. Non-conductive materials can be imaged also by a variable pressure (or environmental) scanning electron microscope. Small, stable specimens such as carbon nanotubes, diatom frustules and small mineral crystals (asbestos fibres, for example) require no special treatment before being examined in the electron microscope. Samples of hydrated materials, including almost all biological specimens have to be prepared in various ways to stabilize them, reduce their thickness (ultrathin sectioning) and increase their electron optical contrast (staining). These processes may result in artifacts, but these can usually be identified by comparing the results obtained by using radically different specimen preparation methods. Since the 1980s, analysis of cryofixed, vitrified specimens has also become increasingly used by scientists, further confirming the validity of this technique. 3.4 Microbiological Culture A microbiological culture, or microbial culture, is a method of multiplying microbial organisms by letting them reproduce in predetermined culture medium under controlled laboratory conditions. Microbial cultures are foundational and basic diagnostic methods used as a research tool in molecular biology. Microbial cultures are used to determine the type of organism, its abundance in the sample being tested, or both. It is one of the primary diagnostic methods of microbiology and used as a tool to determine the cause of infectious disease by letting the agent multiply in a predetermined medium. For example, a throat culture is taken by scraping the lining of tissue in the back of the throat and blotting the sample into a medium to be able to screen for harmful microorganisms, such as Streptococcus pyogenes, the causative agent of strep throat. Furthermore, the term culture is more generally used informally to refer to “selectively growing” a specific kind of microorganism in the lab. It is often essential to isolate a pure culture of microorganisms. A pure (or axenic) culture is a population of cells or multicellular organisms growing in the absence of other species or types. A pure culture may originate from a single cell or single organism, in which case the cells are genetic clones of one another. For the purpose of gelling the microbial culture, the medium of agarose gel (agar) is used. Agar is a gelatinous substance derived from seaweed. A cheap substitute for agar is guar gum, which can be used for the isolation and maintenance of thermophiles. There are several types of bacterial culture methods that are selected based on the agent being cultured and the downstream use. 3.4.1 Broth cultures One method of bacterial culture is liquid culture, in which the desired bacteria are suspended in a liquid nutrient medium, such as Luria Broth, in an upright flask. This allows a scientist to grow up large amounts of bacteria for a variety of downstream applications. Liquid cultures are ideal for preparation of an antimicrobial assay in which the experimenter inoculates liquid broth with bacteria and lets it grow overnight (they may use a shaker for uniform growth). Then they would take aliquots of the sample to test for the antimicrobial activity of a specific drug or protein (antimicrobial peptides). As an alternative, the microbiologist may decide to use static liquid cultures. These cultures are not shaken and they provide the microbes with an oxygen gradient. 3.4.2 Agar Plates Microbiological cultures can be grown in petri dishes of differing sizes that have a thin layer of agar-based growth medium. Once the growth medium in the petri dish is inoculated with the desired bacteria, the plates are incubated at the optimal temperature for the growing of the selected bacteria (for example, usually at 37 degrees Celsius, or the human body temperature, for cultures from humans or animals, or lower for environmental cultures). After the desired level of growth is achieved, agar plates can be stored upside down in a refrigerator for an extended period of time to keep bacteria for future experiments. There are a variety of additives that can be added to agar before it is poured into a plate and allowed to solidify. Some types of bacteria can only grow in the presence of certain additives. This can also be used when creating engineered strains of bacteria that contain an antibiotic-resistance gene. When the selected antibiotic is added to the agar, only bacterial cells containing the gene insert conferring resistance will be able to grow. This allows the researcher to select only the colonies that were successfully transformed. Miniaturised version of agar plates implemented to dipstick formats, eg. Dip Slide, Digital Dipstick show potential to be used at the point-of-care for diagnosis purposes. They have advantages over agar plates since they are cost effective and their operation does not require expertise or laboratory environment, which enable them to be used at the point-of-care. 3.4.3 Stab Cultures Stab cultures are similar to agar plates, but are formed by solid agar in a test tube. Bacteria is introduced via an inoculation needle or a pipette tip being stabbed into the center of the agar. Bacteria grow in the punctured area. Stab cultures are most commonly used for short-term storage or shipment of cultures. 3.5 Culture Collections Microbial culture collections focus on the acquisition, authentication, production, preservation, catalogueing and distribution of viable cultures of standard reference microorganisms, cell lines and other materials for research in microbial systematics. Culture collection are also repositories of type strains. 3.6 Growth Medium A growth medium or culture medium is a solid, liquid, or semi-solid designed to support the growth of a population of microorganisms or cells via the process of cell proliferation or small plants like the moss Physcomitrella patens. Different types of media are used for growing different types of cells. The two major types of growth media are those used for cell culture, which use specific cell types derived from plants or animals, and those used for microbiological culture, which are used for growing microorganisms such as bacteria or fungi. The most common growth media for microorganisms are nutrient broths and agar plates; specialized media are sometimes required for microorganism and cell culture growth. Some organisms, termed fastidious organisms, require specialized environments due to complex nutritional requirements. Viruses, for example, are obligate intracellular parasites and require a growth medium containing living cells. he most common growth media for microorganisms are nutrient broths (liquid nutrient medium) or lysogeny broth medium. Liquid media are often mixed with agar and poured via a sterile media dispenser into Petri dishes to solidify. These agar plates provide a solid medium on which microbes may be cultured. They remain solid, as very few bacteria are able to decompose agar (the exception being some species in the genera: Cytophaga, Flavobacterium, Bacillus, Pseudomonas, and Alcaligenes). Bacteria grown in liquid cultures often form colloidal suspensions. The difference between growth media used for cell culture and those used for microbiological culture is that cells derived from whole organisms and grown in culture often cannot grow without the addition of, for instance, hormones or growth factors which usually occur in vivo. In the case of animal cells, this difficulty is often addressed by the addition of blood serum or a synthetic serum replacement to the medium. In the case of microorganisms, no such limitations exist, as they are often unicellular organisms. One other major difference is that animal cells in culture are often grown on a flat surface to which they attach, and the medium is provided in a liquid form, which covers the cells. In contrast, bacteria such as Escherichia coli may be grown on solid or in liquid media. An important distinction between growth media types is that of defined versus undefined media. A defined medium will have known quantities of all ingredients. For microorganisms, they consist of providing trace elements and vitamins required by the microbe and especially defined carbon and nitrogen sources. Glucose or glycerol are often used as carbon sources, and ammonium salts or nitrates as inorganic nitrogen sources. An undefined medium has some complex ingredients, such as yeast extract or casein hydrolysate, which consist of a mixture of many chemical species in unknown proportions. Undefined media are sometimes chosen based on price and sometimes by necessity – some microorganisms have never been cultured on defined media. A good example of a growth medium is the wort used to make beer. The wort contains all the nutrients required for yeast growth, and under anaerobic conditions, alcohol is produced. When the fermentation process is complete, the combination of medium and dormant microbes, now beer, is ready for consumption. The main types are cultural media minimal media selective media differential media transport media indicator media 3.6.1 Culture Media Culture media contain all the elements that most bacteria need for growth and are not selective, so they are used for the general cultivation and maintenance of bacteria kept in laboratory culture collections. An undefined medium (also known as a basal or complex medium) contains: a carbon source such as glucose water various salts a source of amino acids and nitrogen (e.g. beef, yeast extract) This is an undefined medium because the amino-acid source contains a variety of compounds; the exact composition is unknown. A defined medium (also known as chemically defined medium or synthetic medium) is a medium in which all the chemicals used are known no yeast, animal, or plant tissue is present Examples of nutrient media: nutrient agar plate count agar trypticase soy agar 3.6.2 Minimal Media A defined medium that has just enough ingredients to support growth is called a “minimal medium”. The number of ingredients that must be added to a minimal medium varies enormously depending on which microorganism is being grown. Minimal media are those that contain the minimum nutrients possible for colony growth, generally without the presence of amino acids, and are often used by microbiologists and geneticists to grow “wild-type” microorganisms. Minimal media can also be used to select for or against recombinants or exconjugants. Minimal medium typically contains: a carbon source, which may be a sugar such as glucose, or a less energy-rich source such as succinate various salts, which may vary among bacteria species and growing conditions; these generally provide essential elements such as magnesium, nitrogen, phosphorus, and sulfur to allow the bacteria to synthesize protein and nucleic acids water Supplementary minimal media are minimal media that also contains a single selected agent, usually an amino acid or a sugar. This supplementation allows for the culturing of specific lines of auxotrophic recombinants. 3.6.3 Selective Media Selective media are used for the growth of only selected microorganisms. For example, if a microorganism is resistant to a certain antibiotic, such as ampicillin or tetracycline, then that antibiotic can be added to the medium to prevent other cells, which do not possess the resistance, from growing. Media lacking an amino acid such as proline in conjunction with E. coli unable to synthesize it were commonly used by geneticists before the emergence of genomics to map bacterial chromosomes. Selective growth media are also used in cell culture to ensure the survival or proliferation of cells with certain properties, such as antibiotic resistance or the ability to synthesize a certain metabolite. Normally, the presence of a specific gene or an allele of a gene confers upon the cell the ability to grow in the selective medium. In such cases, the gene is termed a marker. Selective growth media for eukaryotic cells commonly contain neomycin to select cells that have been successfully transfected with a plasmid carrying the neomycin resistance gene as a marker. Gancyclovir is an exception to the rule, as it is used to specifically kill cells that carry its respective marker, the Herpes simplex virus thymidine kinase. Examples of selective media: Eosin methylene blue contains dyes that are toxic for Gram-positive bacteria. It is the selective and differential medium for coliforms. YM (yeast extract, malt extract agar) has a low pH, deterring bacterial growth. MacConkey agar is for Gram-negative bacteria. Hektoen enteric agar is selective for Gram-negative bacteria. HIS-selective medium is a type cell culture medium that lacks the amino acid histidine. Mannitol salt agar is selective for gram-positive bacteria and differential for mannitol. Xylose lysine deoxycholate is selective for Gram-negative bacteria. Buffered charcoal yeast extract agar is selective for certain gram-negative bacteria, especially Legionella pneumophila. Baird–Parker agar is for gram-positive staphylococci. Sabouraud’s agar is selective to certain fungi due to its low pH (5.6) and high glucose concentration (3–4%). DRBC (dichloran rose bengal chloramphenicol agar) is a selective medium for the enumeration of moulds and yeasts in foods. Dichloran and rose bengal restrict the growth of mould colonies, preventing overgrowth of luxuriant species and assisting accurate counting of colonies. 3.6.4 Differential Media Differential or indicator media distinguish one microorganism type from another growing on the same medium. This type of media uses the biochemical characteristics of a microorganism growing in the presence of specific nutrients or indicators (such as neutral red, phenol red, eosin y, or methylene blue) added to the medium to visibly indicate the defining characteristics of a microorganism. These media are used for the detection of microorganisms and by molecular biologists to detect recombinant strains of bacteria. Examples of differential media: Blood agar (used in strep tests) contains bovine heart blood that becomes transparent in the presence of β-hemolytic organisms such as Streptococcus pyogenes and Staphylococcus aureus. Eosin methylene blue is differential for lactose fermentation. Granada medium is selective and differential for Streptococcus agalactiae (group B streptococcus) which grows as distinctive red colonies in this medium. MacConkey agar is differential for lactose fermentation. Mannitol salt agar is differential for mannitol fermentation. X-gal plates are differential for lac operon mutants. 3.6.5 Transport Media Transport media should fulfill these criteria: Temporary storage of specimens being transported to the laboratory for cultivation Maintain the viability of all organisms in the specimen without altering their concentration Contain only buffers and salt Lack of carbon, nitrogen, and organic growth factors so as to prevent microbial multiplication Transport media used in the isolation of anaerobes must be free of molecular oxygen. Examples of transport media: Thioglycolate broth is for strict anaerobes. Stuart transport medium is a non-nutrient soft agar gel containing a reducing agent to prevent oxidation, and charcoal to neutralize. Certain bacterial inhibitors are used for gonococci, and buffered glycerol saline for enteric bacilli. Venkataraman Ramakrishna (VR) medium is used for V. cholerae.dd 3.6.6 Enriched Media Enriched media contain the nutrients required to support the growth of a wide variety of organisms, including some of the more fastidious ones. They are commonly used to harvest as many different types of microbes as are present in the specimen. Blood agar is an enriched medium in which nutritionally rich whole blood supplements the basic nutrients. Chocolate agar is enriched with heat-treated blood (40–45 °C or 104–113 °F), which turns brown and gives the medium the color for which it is named. 3.6.7 Agar Plate An agar plate is a Petri dish that contains a growth medium solidified with agar, used to culture microorganisms. Sometimes selective compounds are added to influence growth, such as antibiotics. 96 pinner used to perform spot assays with yeast, fungal or bacterial cells Individual microorganisms placed on the plate will grow into individual colonies, each a clone genetically identical to the individual ancestor organism (except for the low, unavoidable rate of mutation). Thus, the plate can be used either to estimate the concentration of organisms in a liquid culture or a suitable dilution of that culture using a colony counter, or to generate genetically pure cultures from a mixed culture of genetically different organisms. Several methods are available to plate out cells. One technique is known as “streaking”. In this technique, a drop of the culture on the end of a thin, sterile loop of wire, sometimes known as an inoculator, is streaked across the surface of the agar leaving organisms behind, a higher number at the beginning of the streak and a lower number at the end. At some point during a successful “streak”, the number of organisms deposited will be such that distinct individual colonies will grow in that area which may be removed for further culturing, using another sterile loop. It is crucial to work sterile to prevent contamination on the plates. Another way of plating organisms, next to streaking, on agar plates is the spot analysis. This type of analysis is often used to check the viability of cells and performed with pinners (often also called froggers). A third used technique is the use of sterile glass beads to plate out cells. In this technique cells are grown in a liquid culture of which a small volume is pipetted on the agar plate and then spread out with the beads. Replica plating is another technique in order to plate out cells on agar plates. These four techniques are the most common, but others are also possible. It is crucial to work in a sterile manner in order to prevent contamination on the agar plates. Plating is thus often done in a laminar flow cabinet or on the working bench next to a bunsen burner. In 1881, Fanny Hesse, who was working as a technician for her husband Walther Hesse in the laboratory of Robert Koch, suggested agar as an effective setting agent, since it had been commonplace in jam making for some time. Like other growth media, the formulations of agar used in plates may be classified as either “defined” or “undefined”; a defined medium is synthesized from individual chemicals required by the organism so the exact molecular composition is known, whereas an undefined medium is made from natural products such as yeast extract, where the precise composition is unknown. Agar plates may be formulated as either permissive, with the intent of allowing the growth of whatever organisms are present, or restrictive or selective, with the intent of only allowing growth a particular subset of those organisms. This may take the form of a nutritional requirement, for instance providing a particular compound such as lactose as the only source of carbon and thereby selecting only organisms which can metabolize that compound, or by including a particular antibiotic or other substance to select only organisms which are resistant to that substance. This correlates to some degree with defined and undefined media; undefined media, made from natural products and containing an unknown combination of very many organic molecules, is typically more permissive in terms of supplying the needs of a wider variety of organisms, while defined media can be precisely tailored to select organisms with specific properties. Agar plates may also be indicator plates, in which the organisms are not selected on the basis of growth, but are instead distinguished by a color change in some colonies, typically caused by the action of an enzyme on some compound added to the medium. The plates are incubated for 12 hours up to several days depending on the test that is performed. Some commonly used agar plate types are: 3.6.8 Blood Agar Plate Blood agar plates (BAPs) contain mammalian blood (usually sheep or horse), typically at a concentration of 5–10%. BAPs are enriched, differential media used to isolate fastidious organisms and detect hemolytic activity. β-Hemolytic activity will show lysis and complete digestion of red blood cell contents surrounding a colony. Examples include Streptococcus haemolyticus. α-Hemolysis will only cause partial lysis of the red blood cells (the cell membrane is left intact) and will appear green or brown, due to the conversion of hemoglobin to methemoglobin. An example of this would be Streptococcus viridans. γ-Hemolysis (or nonhemolytic) is the term referring to a lack of hemolytic activity. BAPs also contain meat extract, tryptone, sodium chloride, and agar. 3.6.9 Chocolate Agar Chocolate agar a type of blood agar plate in which the blood cells have been lysed by heating the cells to 80 °C. It is used for growing fastidious respiratory bacteria, such as Haemophilus influenzae. No chocolate is actually contained in the plate; it is named for the coloration only. "],["an-introduction-to-prokaryotic-cells-and-microorganisms.html", "4 An Introduction To Prokaryotic Cells And Microorganisms 4.1 Basic Characteristics Of Life 4.2 Origin Of Life 4.3 The Foundations Of Modern Biology 4.4 Basic Characteristics Of Cells 4.5 Prokaryotic Cells 4.6 Bacteria 4.7 Archaea", " 4 An Introduction To Prokaryotic Cells And Microorganisms 4.1 Basic Characteristics Of Life In the past, there have been many attempts to define what is meant by “life” through obsolete concepts such as odic force, hylomorphism, spontaneous generation and vitalism, that have now been disproved by biological discoveries. Aristotle is considered to be the first person to classify organisms. Later, Carl Linnaeus introduced his system of binomial nomenclature for the classification of species. Eventually new groups and categories of life were discovered, such as cells and microorganisms, forcing dramatic revisions of the structure of relationships between living organisms. Though currently only known on Earth, life need not be restricted to it, and many scientists speculate in the existence of extraterrestrial life. Artificial life is a computer simulation or human-made reconstruction of any aspect of life, which is often used to examine systems related to natural life. Death is the permanent termination of all biological functions which sustain an organism, and as such, is the end of its life. Extinction is the term describing the dying out of a group or taxon, usually a species. Fossils are the preserved remains or traces of organisms. The definition of life has long been a challenge for scientists and philosophers, with many varied definitions put forward. This is partially because life is a process, not a substance. This is complicated by a lack of knowledge of the characteristics of living entities, if any, that may have developed outside of Earth. Philosophical definitions of life have also been put forward, with similar difficulties on how to distinguish living things from the non-living. Legal definitions of life have also been described and debated, though these generally focus on the decision to declare a human dead, and the legal ramifications of this decision. Since there is no unequivocal definition of life, most current definitions in biology are descriptive. Life is considered a characteristic of something that preserves, furthers or reinforces its existence in the given environment. This characteristic exhibits all or most of the following traits: Homeostasis: regulation of the internal environment to maintain a constant state; for example, sweating to reduce temperature Organization: being structurally composed of one or more cells – the basic units of life Metabolism: transformation of energy by converting chemicals and energy into cellular components (anabolism) and decomposing organic matter (catabolism). Living things require energy to maintain internal organization (homeostasis) and to produce the other phenomena associated with life. Growth: maintenance of a higher rate of anabolism than catabolism. A growing organism increases in size in all of its parts, rather than simply accumulating matter. Adaptation: the ability to change over time in response to the environment. This ability is fundamental to the process of evolution and is determined by the organism’s heredity, diet, and external factors. Response to stimuli: a response can take many forms, from the contraction of a unicellular organism to external chemicals, to complex reactions involving all the senses of multicellular organisms. A response is often expressed by motion; for example, the leaves of a plant turning toward the sun (phototropism), and chemotaxis. Reproduction: the ability to produce new individual organisms, either asexually from a single parent organism or sexually from two parent organisms. These complex processes, called physiological functions, have underlying physical and chemical bases, as well as signaling and control mechanisms that are essential to maintaining life. More than 99% of all species of life forms, amounting to over five billion species, that ever lived on Earth are estimated to be extinct. Although the number of Earth’s catalogued species of lifeforms is between 1.2 million and 2 million, the total number of species in the planet is uncertain. Estimates range from 8 million to 100 million, with a more narrow range between 10 and 14 million, but it may be as high as 1 trillion (with only one-thousandth of one percent of the species described) according to studies realized in May 2016. The total number of related DNA base pairs on Earth is estimated at 5.0 x 1037 and weighs 50 billion tonnes. In comparison, the total mass of the biosphere has been estimated to be as much as 4 TtC (trillion tons of carbon). In July 2016, scientists reported identifying a set of 355 genes from the Last Universal Common Ancestor (LUCA) of all organisms living on Earth. 4.2 Origin Of Life The Ancient Greeks believed that living things could spontaneously come into being from nonliving matter, and that the goddess Gaia could make life arise spontaneously from stones – a process known as Generatio spontanea. Aristotle disagreed, but he still believed that creatures could arise from dissimilar organisms or from soil. Variations of this concept of spontaneous generation still existed as late as the 17th century, but towards the end of the 17th century, a series of observations and arguments began that eventually discredited such ideas. This advance in scientific understanding was met with much opposition, with personal beliefs and individual prejudices often obscuring the facts. William Harvey (1578–1657) was an early proponent of all life beginning from an egg, omne vivum ex ovo. Francesco Redi, an Italian physician, proved as early as 1668 that higher forms of life did not originate spontaneously by demonstrating that maggots come from eggs of flies. But proponents of spontaneous generation claimed that this did not apply to microbes and continued to hold that these could arise spontaneously. Attempts to disprove the spontaneous generation of life from non-life continued in the early 19th century with observations and experiments by Franz Schulze and Theodor Schwann. In 1745, John Needham added chicken broth to a flask and boiled it. He then let it cool and waited. Microbes grew, and he proposed it as an example of spontaneous generation. In 1768, Lazzaro Spallanzani repeated Needham’s experiment but removed all the air from the flask. No growth occurred. In 1854, Heinrich G. F. Schröder (1810–1885) and Theodor von Dusch, and in 1859, Schröder alone, repeated the Helmholtz filtration experiment and showed that living particles can be removed from air by filtering it through cotton-wool. In 1864, Louis Pasteur finally announced the results of his scientific experiments. In a series of experiments similar to those performed earlier by Needham and Spallanzani, Pasteur demonstrated that life does not arise in areas that have not been contaminated by existing life. Pasteur’s empirical results were summarized in the phrase Omne vivum ex vivo, Latin for “all life [is] from life”. All known life forms share fundamental molecular mechanisms, reflecting their common descent; based on these observations, hypotheses on the origin of life attempt to find a mechanism explaining the formation of a universal common ancestor, from simple organic molecules via pre-cellular life to protocells and metabolism. Models have been divided into “genes-first” and “metabolism-first” categories, but a recent trend is the emergence of hybrid models that combine both categories. Life on Earth is based on carbon and water. Carbon provides stable frameworks for complex chemicals and can be easily extracted from the environment, especially from carbon dioxide. There is no other chemical element whose properties are similar enough to carbon’s to be called an analogue; silicon, the element directly below carbon on the periodic table, does not form very many complex stable molecules, and because most of its compounds are water-insoluble and because silicon dioxide is a hard and abrasive solid in contrast to carbon dioxide at temperatures associated with living things, it would be more difficult for organisms to extract. The elements boron and phosphorus have more complex chemistries, but suffer from other limitations relative to carbon. Water is an excellent solvent and has two other useful properties: the fact that ice floats enables aquatic organisms to survive beneath it in winter; and its molecules have electrically negative and positive ends, which enables it to form a wider range of compounds than other solvents can. Other good solvents, such as ammonia, are liquid only at such low temperatures that chemical reactions may be too slow to sustain life, and lack water’s other advantages. Organisms based on alternative biochemistry may, however, be possible on other planets. Abiogenesis, or informally the origin of life, is the natural process of life arising from non-living matter, such as simple organic compounds. The prevailing scientific hypothesis is that the transition from non-living to living entities was not a single event, but a gradual process of increasing complexity. Although the occurrence of abiogenesis is uncontroversial among scientists, its possible mechanisms are poorly understood. There are several principles and hypotheses for how abiogenesis could have occurred. Life on Earth first appeared as early as 4.28 billion years ago, soon after ocean formation 4.41 billion years ago, and not long after the formation of the Earth 4.54 billion years ago. The earliest known life forms are microfossils of bacteria. There is no current scientific consensus as to how life originated. However, many accepted scientific models build on the Miller–Urey experiment and the work of Sidney Fox, which show that conditions on the primitive Earth favored chemical reactions that synthesize amino acids and other organic compounds from inorganic precursors, and phospholipids spontaneously form lipid bilayers, the basic structure of a cell membrane. The classic 1952 Miller–Urey experiment (Figure 4.1) demonstrated that most amino acids, the chemical constituents of the proteins used in all living organisms, can be synthesized from inorganic compounds under conditions intended to replicate those of the early Earth. The experiment used water (H2O), methane (CH4), ammonia (NH3), and hydrogen (H2). The chemicals were all sealed inside a sterile 5-liter glass flask connected to a 500 ml flask half-full of water. The water in the smaller flask was heated to induce evaporation, and the water vapour was allowed to enter the larger flask. Continuous electrical sparks were fired between the electrodes to simulate lightning in the water vapour and gaseous mixture, and then the simulated atmosphere was cooled again so that the water condensed and trickled into a U-shaped trap at the bottom of the apparatus. After a day, the solution collected at the trap had turned pink in colour, and after a week of continuous operation the solution was deep red and turbid. The boiling flask was then removed, and mercuric chloride was added to prevent microbial contamination. The reaction was stopped by adding barium hydroxide and sulfuric acid, and evaporated to remove impurities. Using paper chromatography, Miller identified five amino acids present in the solution: glycine, α-alanine and β-alanine were positively identified, while aspartic acid and α-aminobutyric acid (AABA) were less certain, due to the spots being faint.Complex organic molecules occur in the Solar System and in interstellar space, and these molecules may have provided starting material for the development of life on Earth. Figure 4.1: The Miller–Urey experiment was a chemical experiment that simulated the conditions thought at the time (1952) to be present on the early Earth and tested the chemical origin of life under those conditions. The experiment at the time supported Alexander Oparin’s and J. B. S. Haldane’s hypothesis that putative conditions on the primitive Earth favoured chemical reactions that synthesized more complex organic compounds from simpler inorganic precursors. Considered to be the classic experiment investigating abiogenesis, it was conducted in 1952 by Stanley Miller, with assistance from Harold Urey, at the University of Chicago and later the University of California, San Diego and published the following year. Living organisms synthesize proteins, which are polymers of amino acids using instructions encoded by deoxyribonucleic acid (DNA). Protein synthesis entails intermediary ribonucleic acid (RNA) polymers. One possibility for how life began is that genes originated first, followed by proteins; the alternative being that proteins came first and then genes. However, because genes and proteins are both required to produce the other, the problem of considering which came first is like that of the chicken or the egg. Most scientists have adopted the hypothesis that because of this, it is unlikely that genes and proteins arose independently. Therefore, a possibility, first suggested by Francis Crick, is that the first life was based on RNA, which has the DNA-like properties of information storage and the catalytic properties of some proteins. This is called the RNA world hypothesis, and it is supported by the observation that many of the most critical components of cells (those that evolve the slowest) are composed mostly or entirely of RNA. Also, many critical cofactors (ATP, Acetyl-CoA, NADH, etc.) are either nucleotides or substances clearly related to them. The catalytic properties of RNA had not yet been demonstrated when the hypothesis was first proposed, but they were confirmed by Thomas Cech in 1986. One issue with the RNA world hypothesis is that synthesis of RNA from simple inorganic precursors is more difficult than for other organic molecules. One reason for this is that RNA precursors are very stable and react with each other very slowly under ambient conditions, and it has also been proposed that living organisms consisted of other molecules before RNA. However, the successful synthesis of certain RNA molecules under the conditions that existed prior to life on Earth has been achieved by adding alternative precursors in a specified order with the precursor phosphate present throughout the reaction. This study makes the RNA world hypothesis more plausible. Geological findings in 2013 showed that reactive phosphorus species (like phosphite) were in abundance in the ocean before 3.5 Ga, and that Schreibersite easily reacts with aqueous glycerol to generate phosphite and glycerol 3-phosphate. It is hypothesized that Schreibersite-containing meteorites from the Late Heavy Bombardment could have provided early reduced phosphorus, which could react with prebiotic organic molecules to form phosphorylated biomolecules, like RNA. In 2009, experiments demonstrated Darwinian evolution of a two-component system of RNA enzymes (ribozymes) in vitro. The work was performed in the laboratory of Gerald Joyce, who stated “This is the first example, outside of biology, of evolutionary adaptation in a molecular genetic system.” Prebiotic compounds may have originated extraterrestrially. NASA findings in 2011, based on studies with meteorites found on Earth, suggest DNA and RNA components (adenine, guanine and related organic molecules) may be formed in outer space. In March 2015, NASA scientists reported that, for the first time, complex DNA and RNA organic compounds of life, including uracil, cytosine and thymine, have been formed in the laboratory under outer space conditions, using starting chemicals, such as pyrimidine, found in meteorites. Pyrimidine, like polycyclic aromatic hydrocarbons (PAHs), the most carbon-rich chemical found in the universe, may have been formed in red giants or in interstellar dust and gas clouds, according to the scientists. According to the panspermia hypothesis, microscopic life—distributed by meteoroids, asteroids and other small Solar System bodies—may exist throughout the universe. Since its primordial beginnings, life on Earth has changed its environment on a geologic time scale, but it has also adapted to survive in most ecosystems and conditions. Some microorganisms, called extremophiles, thrive in physically or geochemically extreme environments that are detrimental to most other life on Earth. The cell is considered the structural and functional unit of life. There are two kinds of cells, prokaryotic and eukaryotic, both of which consist of cytoplasm enclosed within a membrane and contain many biomolecules such as proteins and nucleic acids. Cells reproduce through a process of cell division, in which the parent cell divides into two or more daughter cells. Figure 4.2: Cartoons of a eukaryotic and prokaryotic cell. 4.3 The Foundations Of Modern Biology 4.3.1 The Cell Theory Cell theory states that the cell is the fundamental unit of life, that all living things are composed of one or more cells, and that all cells arise from pre-existing cells through cell division. In multicellular organisms, every cell in the organism’s body derives ultimately from a single cell in a fertilized egg. The cell is also considered to be the basic unit in many pathological processes. In addition, the phenomenon of energy flow occurs in cells in processes that are part of the function known as metabolism. Finally, cells contain hereditary information (DNA), which is passed from cell to cell during cell division. Research into the origin of life, abiogenesis, amounts to an attempt to discover the origin of the first cells. Cells are the basic unit of structure in every living thing, and all cells arise from pre-existing cells by division. Cell theory was formulated by Henri Dutrochet, Theodor Schwann, Matthias Jakob Schleiden, Rudolf Virchow and others during the early nineteenth century, and subsequently became widely accepted. The activity of an organism depends on the total activity of its cells, with energy flow occurring within and between them. Cells contain hereditary information that is carried forward as a genetic code during cell division. There are two primary types of cells. Prokaryotes lack a nucleus and other membrane-bound organelles, although they have circular DNA and ribosomes. Bacteria and Archaea are two domains of prokaryotes. The other primary type of cells are the eukaryotes, which have distinct nuclei bound by a nuclear membrane and membrane-bound organelles, including mitochondria, chloroplasts, lysosomes, rough and smooth endoplasmic reticulum, and vacuoles. In addition, they possess organized chromosomes that store genetic material. All species of large complex organisms are eukaryotes, including animals, plants and fungi, though most species of eukaryote are protist microorganisms. The conventional model is that eukaryotes evolved from prokaryotes, with the main organelles of the eukaryotes forming through endosymbiosis between bacteria and the progenitor eukaryotic cell. Figure 4.3: Tree diagram illustrating the evolutionary relationship of living organisms. A virus is a submicroscopic infectious agent that replicates only inside the living cells of an organism. Scientific opinions differ on whether viruses are a form of life, or organic structures that interact with living organisms. They have been described as “organisms at the edge of life”, since they resemble organisms in that they possess genes, evolve by natural selection, and reproduce by creating multiple copies of themselves through self-assembly. Although they have genes, they do not have a cellular structure, which is seen as the basic unit of life. Viruses do not have their own metabolism, and require a host cell to make new products. They therefore cannot naturally reproduce outside a host cell—although bacterial species such as rickettsia and chlamydia are considered living organisms despite the same limitation. Accepted forms of life use cell division to reproduce, whereas viruses spontaneously assemble within cells. They differ from autonomous growth of crystals as they inherit genetic mutations while being subject to natural selection. Virus self-assembly within host cells has implications for the study of the origin of life, as it lends further credence to the hypothesis that life could have started as self-assembling organic molecules. The molecular mechanisms of cell biology are based on proteins which are synthesized by the ribosomes through an enzyme-catalyzed process called protein biosynthesis. A sequence of amino acids is assembled and joined together based upon gene expression of the cell’s nucleic acid. In eukaryotic cells, these proteins may then be transported and processed through the Golgi apparatus in preparation for dispatch to their destination. Cells reproduce through a process of cell division in which the parent cell divides into two or more daughter cells. For prokaryotes, cell division occurs through a process of fission in which the DNA is replicated, then the two copies are attached to parts of the cell membrane. In eukaryotes, a more complex process of mitosis is followed. However, the end result is the same; the resulting cell copies are identical to each other and to the original cell (except for mutations), and both are capable of further division following an interphase period. Multicellular organisms may have first evolved through the formation of colonies of identical cells. These cells can form group organisms through cell adhesion. The individual members of a colony are capable of surviving on their own, whereas the members of a true multi-cellular organism have developed specializations, making them dependent on the remainder of the organism for survival. Such organisms are formed clonally or from a single germ cell that is capable of forming the various specialized cells that form the adult organism. This specialization allows multicellular organisms to exploit resources more efficiently than single cells. In January 2016, scientists reported that, about 800 million years ago, a minor genetic change in a single molecule, called GK-PID, may have allowed organisms to go from a single cell organism to one of many cells. Cells have evolved methods to perceive and respond to their microenvironment, thereby enhancing their adaptability. Cell signaling coordinates cellular activities, and hence governs the basic functions of multicellular organisms. Signaling between cells can occur through direct cell contact using juxtacrine signalling, or indirectly through the exchange of agents as in the endocrine system. In more complex organisms, coordination of activities can occur through a dedicated nervous system. 4.3.2 The Theory Of Evolution A central organizing concept in biology is that life changes and develops through evolution, and that all life-forms known have a common origin. The theory of evolution postulates that all organisms on the Earth, both living and extinct, have descended from a common ancestor or an ancestral gene pool. This universal common ancestor of all organisms is believed to have appeared about 3.5 billion years ago. Biologists regard the ubiquity of the genetic code as definitive evidence in favor of the theory of universal common descent for all bacteria, archaea, and eukaryotes. The term “evolution” was introduced into the scientific lexicon by Jean-Baptiste de Lamarck in 1809, and fifty years later Charles Darwin posited a scientific model of natural selection as evolution’s driving force. Alfred Russel Wallace independently reached the same conclusions and is recognized as the co-discoverer of this concept. Evolution is now used to explain the great variations of life found on Earth. Darwin theorized that species flourish or die when subjected to the processes of natural selection or selective breeding. Genetic drift was embraced as an additional mechanism of evolutionary development in the modern synthesis of the theory. The evolutionary history of the species—which describes the characteristics of the various species from which it descended—together with its genealogical relationship to every other species is known as its phylogeny. Widely varied approaches to biology generate information about phylogeny. These include the comparisons of DNA sequences, a product of molecular biology (more particularly genomics), and comparisons of fossils or other records of ancient organisms, a product of paleontology. Biologists organize and analyze evolutionary relationships through various methods, including phylogenetics, phenetics, and cladistics Evolution is relevant to the understanding of the natural history of life forms and to the understanding of the organization of current life forms. But, those organizations can only be understood in light of how they came to be by way of the process of evolution. Consequently, evolution is central to all fields of biology. The evolutionary history of life on Earth traces the processes by which living and fossil organisms evolved, from the earliest emergence of life to the present. Earth formed about 4.5 billion years (Ga) ago and evidence suggests life emerged prior to 3.7 Ga. (Although there is some evidence of life as early as 4.1 to 4.28 Ga, it remains controversial due to the possible non-biological formation of the purported fossils.) The similarities among all known present-day species indicate that they have diverged through the process of evolution from a common ancestor. Approximately 1 trillion species currently live on Earth of which only 1.75–1.8 million have been named and 1.6 million documented in a central database. These currently living species represent less than one percent of all species that have ever lived on earth. The earliest evidence of life comes from biogenic carbon signatures and stromatolite fossils discovered in 3.7 billion-year-old metasedimentary rocks from western Greenland. In 2015, possible “remains of biotic life” were found in 4.1 billion-year-old rocks in Western Australia. In March 2017, putative evidence of possibly the oldest forms of life on Earth was reported in the form of fossilized microorganisms discovered in hydrothermal vent precipitates in the Nuvvuagittuq Belt of Quebec, Canada, that may have lived as early as 4.28 billion years ago, not long after the oceans formed 4.4 billion years ago, and not long after the formation of the Earth 4.54 billion years ago. Figure 4.4: Modern stromatolites in Shark Bay, Western Australia Microbial mats of coexisting bacteria and archaea were the dominant form of life in the early Archean Epoch and many of the major steps in early evolution are thought to have taken place in this environment. The evolution of photosynthesis, around 3.5 Ga, eventually led to a buildup of its waste product, oxygen, in the atmosphere, leading to the great oxygenation event, beginning around 2.4 Ga. The earliest evidence of eukaryotes (complex cells with organelles) dates from 1.85 Ga, and while they may have been present earlier, their diversification accelerated when they started using oxygen in their metabolism. Later, around 1.7 Ga, multicellular organisms began to appear, with differentiated cells performing specialised functions. Sexual reproduction, which involves the fusion of male and female reproductive cells (gametes) to create a zygote in a process called fertilization is, in contrast to asexual reproduction, the primary method of reproduction for the vast majority of macroscopic organisms, including almost all eukaryotes (which includes animals and plants). However the origin and evolution of sexual reproduction remain a puzzle for biologists though it did evolve from a common ancestor that was a single celled eukaryotic species. Bilateria, animals having a left and a right side that are mirror images of each other, appeared by 555 Ma (million years ago). The earliest plants on land date back to around 850 million years ago (Ma), from carbon isotopes in Precambrian rocks, while algae-like multicellular land plants are dated back even to about 1 billion years ago, although evidence suggests that microorganisms formed the earliest terrestrial ecosystems, at least 2.7 billion years ago (Ga). Microorganisms are thought to have paved the way for the inception of land plants in the Ordovician. Land plants were so successful that they are thought to have contributed to the Late Devonian extinction event. (The long causal chain implied seems to involve the success of early tree archaeopteris (1) drew down CO2 levels, leading to global cooling and lowered sea levels, (2) roots of archeopteris fostered soil development which increased rock weathering, and the subsequent nutrient run-off may have triggered algal blooms resulting in anoxic events which caused marine-life die-offs. Marine species were the primary victims of the Late Devonian extinction.) Ediacara biota appear during the Ediacaran period, while vertebrates, along with most other modern phyla originated about 525 Ma during the Cambrian explosion. During the Permian period, synapsids, including the ancestors of mammals, dominated the land, but most of this group became extinct in the Permian–Triassic extinction event 252 Ma. During the recovery from this catastrophe, archosaurs became the most abundant land vertebrates; one archosaur group, the dinosaurs, dominated the Jurassic and Cretaceous periods. After the Cretaceous–Paleogene extinction event 65 Ma killed off the non-avian dinosaurs, mammals increased rapidly in size and diversity. Such mass extinctions may have accelerated evolution by providing opportunities for new groups of organisms to diversify. 4.3.3 Genetics Genes are the primary units of inheritance in all organisms. A gene is a unit of heredity and corresponds to a region of DNA that influences the form or function of an organism in specific ways. All organisms, from bacteria to animals, share the same basic machinery that copies and translates DNA into proteins. Cells transcribe a DNA gene into an RNA version of the gene, and a ribosome then translates the RNA into a sequence of amino acids known as a protein. The translation code from RNA codon to amino acid is the same for most organisms. For example, a sequence of DNA that codes for insulin in humans also codes for insulin when inserted into other organisms, such as plants. DNA is found as linear chromosomes in eukaryotes, and circular chromosomes in prokaryotes. A chromosome is an organized structure consisting of DNA and histones. The set of chromosomes in a cell and any other hereditary information found in the mitochondria, chloroplasts, or other locations is collectively known as a cell’s genome. In eukaryotes, genomic DNA is localized in the cell nucleus, or with small amounts in mitochondria and chloroplasts. In prokaryotes, the DNA is held within an irregularly shaped body in the cytoplasm called the nucleoid. The genetic information in a genome is held within genes, and the complete assemblage of this information in an organism is called its genotype. 4.3.4 Homeostasis Homeostasis is the ability of an open system to regulate its internal environment to maintain stable conditions by means of multiple dynamic equilibrium adjustments that are controlled by interrelated regulation mechanisms. All living organisms, whether unicellular or multicellular, exhibit homeostasis. To maintain dynamic equilibrium and effectively carry out certain functions, a system must detect and respond to perturbations. After the detection of a perturbation, a biological system normally responds through negative feedback that stabilize conditions by reducing or increasing the activity of an organ or system. One example is the release of glucagon when sugar levels are too low. 4.3.5 Energy The survival of a living organism depends on the continuous input of energy. Chemical reactions that are responsible for its structure and function are tuned to extract energy from substances that act as its food and transform them to help form new cells and sustain them. In this process, molecules of chemical substances that constitute food play two roles; first, they contain energy that can be transformed and reused in that organism’s biological, chemical reactions; second, food can be transformed into new molecular structures (biomolecules) that are of use to that organism. The organisms responsible for the introduction of energy into an ecosystem are known as producers or autotrophs. Nearly all such organisms originally draw their energy from the sun. Plants and other phototrophs use solar energy via a process known as photosynthesis to convert raw materials into organic molecules, such as ATP, whose bonds can be broken to release energy. A few ecosystems, however, depend entirely on energy extracted by chemotrophs from methane, sulfides, or other non-luminal energy sources. Some of the energy thus captured produces biomass and energy that is available for growth and development of other life forms. The majority of the rest of this biomass and energy are lost as waste molecules and heat. The most important processes for converting the energy trapped in chemical substances into energy useful to sustain life are metabolism and cellular respiration. Bacteria (singular bacterium) and Archaea (singular archaeon) constitute two domains of single-celled organisms. These microorganisms lack cell nuclei and are therefore prokaryotes. Figure 4.5: Scanning electron micrograph of Escherichia coli bacteria. For much of the 20th century, prokaryotes were regarded as a single group of organisms and classified based on their biochemistry, morphology and metabolism. Microbiologists tried to classify microorganisms based on the structures of their cell walls, their shapes, and the substances they consume. In 1965, Emile Zuckerkandl and Linus Pauling instead proposed using the sequences of the genes in different prokaryotes to work out how they are related to each other. This phylogenetic approach is the main method used today. Archaea – at that time only the methanogens were known – were first classified separately from bacteria in 1977 by Carl Woese and George E. Fox based on their ribosomal RNA (rRNA) genes. They called these groups the Urkingdoms of Archaebacteria and Eubacteria, though other researchers treated them as kingdoms or subkingdoms. Woese and Fox gave the first evidence for Archaebacteria as a separate “line of descent”: 1. lack of peptidoglycan in their cell walls, 2. two unusual coenzymes, 3. results of 16S ribosomal RNA gene sequencing. To emphasize this difference, Woese, Otto Kandler and Mark Wheelis later proposed reclassifying organisms into three natural domains known as the three-domain system: the Eukarya, the Bacteria and the Archaea, in what is now known as “The Woesian Revolution”. Figure 4.6: Halobacterium sp. strain NRC-1, each cell about 5 μm long 4.4 Basic Characteristics Of Cells The cell (from Latin cella, meaning “small room”) is the basic structural, functional, and biological unit of all known organisms. A cell is the smallest unit of life. Cells are often called the “building blocks of life”. The study of cells is called cell biology, cellular biology, or cytology. Cells consist of cytoplasm enclosed within a membrane, which contains many biomolecules such as proteins and nucleic acids. Most plant and animal cells are only visible under a microscope, with dimensions between 1 and 100 micrometres. Organisms can be classified as unicellular (consisting of a single cell such as bacteria) or multicellular (including plants and animals). Most unicellular organisms are classed as microorganisms. The number of cell in plants and animals varies from species to species; it has been estimated that humans contain somewhere around 40 trillion (4×1013) cells. The human brain accounts for around 80 billion of these cells. In biology, cell theory is the historic scientific theory, now universally accepted, that living organisms are made up of cells, that they are the basic structural/organizational unit of all organisms, and that all cells come from pre-existing cells. Cells are the basic unit of structure in all organisms and also the basic unit of reproduction. Credit for developing cell theory is usually given to two scientists: Theodor Schwann and Matthias Jakob Schleiden. While Rudolf Virchow contributed to the theory, he is not as credited for his attributions toward it. In 1839, Schleiden suggested that every structural part of a plant was made up of cells or the result of cells. He also suggested that cells were made by a crystallization process either within other cells or from the outside. However, this was not an original idea of Schleiden. He claimed this theory as his own, though Barthelemy Dumortier had stated it years before him. This crystallization process is no longer accepted with modern cell theory. In 1839, Theodor Schwann states that along with plants, animals are composed of cells or the product of cells in their structures. This was a major advancement in the field of biology since little was known about animal structure up to this point compared to plants. From these conclusions about plants and animals, two of the three tenets of cell theory were postulated. All living organisms are composed of one or more cells The cell is the most basic unit of life Schleiden’s theory of free cell formation through crystallization was refuted in the 1850s by Robert Remak, Rudolf Virchow, and Albert von Kölliker. In 1855, Rudolf Virchow added the third tenet to cell theory. In Latin, this tenet states Omnis cellula e cellula. This translated to: All cells arise only from pre-existing cells However, the idea that all cells come from pre-existing cells had in fact already been proposed by Robert Remak; it has been suggested that Virchow plagiarized Remak and did not give him credit. Remak published observations in 1852 on cell division, claiming Schleiden and Schawnn were incorrect about generation schemes. He instead said that binary fission, which was first introduced by Dumortier, was how reproduction of new animal cells were made. Once this tenet was added, the classical cell theory was complete. The generally accepted parts of modern cell theory include: All living cells arise from pre-existing cells by division. The cell is the fundamental unit of structure and function in all living organisms. The activity of an organism depends on the total activity of independent cells. Energy flow (metabolism and biochemistry) occurs within cells. Cells contain DNA which is found specifically in the chromosome and RNA found in the cell nucleus and cytoplasm. All cells are basically the same in chemical composition in organisms of similar species. The discovery of the cell was made possible through the invention of the microscope. In the first century BC, Romans were able to make glass, discovering that objects appeared to be larger under the glass. In Italy during the 12th century, Salvino D’Armate made a piece of glass fit over one eye, allowing for a magnification effect to that eye. The expanded use of lenses in eyeglasses in the 13th century probably led to wider spread use of simple microscopes (magnifying glasses) with limited magnification. Compound microscopes, which combine an objective lens with an eyepiece to view a real image achieving much higher magnification, first appeared in Europe around 1620. In 1665, Robert Hooke used a microscope about six inches long with two convex lenses inside and examined specimens under reflected light for the observations in his book Micrographia. Hooke also used a simpler microscope with a single lens for examining specimens with directly transmitted light, because this allowed for a clearer image. Figure 4.7: Title page of “MICROGRAPHIA or some physiological descriptions of minute bodies made by magnifying glasses with observations and inquiries thereupon”. Figure 4.8: Hooke’s microscope, from an engraving in Micrographia Figure 4.9: Hooke was the first to apply the word “cell”to biological objects. Cell structure of cork by Hooke. Extensive microscopic study was done by Anton van Leeuwenhoek, a draper who took the interest in microscopes after seeing one while on an apprenticeship in Amsterdam in 1648. At some point in his life before 1668, he was able to learn how to grind lenses. This eventually led to Leeuwenhoek making his own unique microscope. His was a single lens simple microscope, rather than a compound microscope. This was because he was able to use a single lens that was a small glass sphere but allowed for a magnification of 270x. This was a large progression since the magnification before was only a maximum of 50x. After Leeuwenhoek, there was not much progress in microscope technology until the 1850s, two hundred years later. Carl Zeiss, a German engineer who manufactured microscopes, began to make changes to the lenses used. But the optical quality did not improve until the 1880s when he hired Otto Schott and eventually Ernst Abbe. Optical microscopes can focus on objects the size of a wavelength or larger, giving restrictions still to advancement in discoveries with objects smaller than the wavelengths of visible light. The development of the electron microscope in the 1920s made it possible to view objects that are smaller than optical wavelengths, once again opening up new possibilities in science. The cell was first discovered by Robert Hooke in 1665, which can be found to be described in his book Micrographia. In this book, he gave 60 ‘observations’ in detail of various objects under a coarse, compound microscope. One observation was from very thin slices of bottle cork. Hooke discovered a multitude of tiny pores that he named “cells”. This came from the Latin word Cella, meaning ‘a small room’ like monks lived in and also Cellulae, which meant the six sided cell of a honeycomb. However, Hooke did not know their real structure or function. What Hooke had thought were cells, were actually empty cell walls of plant tissues. With microscopes during this time having a low magnification, Hooke was unable to see that there were other internal components to the cells he was observing. Therefore, he did not think the “cellulae” were alive. His cell observations gave no indication of the nucleus and other organelles found in most living cells. In Micrographia, Hooke also observed mould, bluish in color, found on leather. After studying it under his microscope, he was unable to observe “seeds” that would have indicated how the mould was multiplying in quantity. This led to Hooke suggesting that spontaneous generation, from either natural or artificial heat, was the cause. Since this was an old Aristotelian theory still accepted at the time, others did not reject it and was not disproved until Leeuwenhoek later discovered that generation was achieved otherwise. Anton van Leeuwenhoek is another scientist who saw these cells soon after Hooke did. He made use of a microscope containing improved lenses that could magnify objects almost 300-fold, or 270x. Under these microscopes, Leeuwenhoek found motile objects. In a letter to The Royal Society on October 9, 1676, he states that motility is a quality of life therefore these were living organisms. Over time, he wrote many more papers in which described many specific forms of microorganisms. Leeuwenhoek named these “animalcules,” which included protozoa and other unicellular organisms, like bacteria. Though he did not have much formal education, he was able to identify the first accurate description of red blood cells and discovered bacteria after gaining interest in the sense of taste that resulted in Leeuwenhoek to observe the tongue of an ox, then leading him to study “pepper water” in 1676. He also found for the first time the sperm cells of animals and humans. Once discovering these types of cells, Leeuwenhoek saw that the fertilization process requires the sperm cell to enter the egg cell. This put an end to the previous theory of spontaneous generation. After reading letters by Leeuwenhoek, Hooke was the first to confirm his observations that were thought to be unlikely by other contemporaries. The cells in animal tissues were observed after plants were because the tissues were so fragile and susceptible to tearing, it was difficult for such thin slices to be prepared for studying. Biologists believed that there was a fundamental unit to life, but were unsure what this was. It would not be until over a hundred years later that this fundamental unit was connected to cellular structure and existence of cells in animals or plants. This conclusion was not made until Henri Dutrochet. Besides stating “the cell is the fundamental element of organization”, Dutrochet also claimed that cells were not just a structural unit, but also a physiological unit. In 1804, Karl Rudolphi and Johann Heinrich Friedrich Link were awarded the prize for “solving the problem of the nature of cells”, meaning they were the first to prove that cells had independent cell walls by the Königliche Societät der Wissenschaft (Royal Society of Science), Göttingen. Before, it had been thought that cells shared walls and the fluid passed between them this way. Cells can be subdivided into the following subcategories: Prokaryotes: Prokaryotes are relatively small cells surrounded by the plasma membrane, with a characteristic cell wall that may differ in composition depending on the particular organism. Prokaryotes lack a nucleus (although they do have circular or linear DNA) and other membrane-bound organelles (though they do contain ribosomes). The protoplasm of a prokaryote contains the chromosomal region that appears as fibrous deposits under the microscope, and the cytoplasm. Bacteria and Archaea are the two domains of prokaryotes. Eukaryotes: Eukaryotic cells are also surrounded by the plasma membrane, but on the other hand, they have distinct nuclei bound by a nuclear membrane or envelope. Eukaryotic cells also contain membrane-bound organelles, such as (mitochondria, chloroplasts, lysosomes, rough and smooth endoplasmic reticulum, vacuoles). In addition, they possess organized chromosomes which store genetic material. Animals have evolved a greater diversity of cell types in a multicellular body (100–150 different cell types), compared with 10–20 in plants, fungi, and protoctista. The distinction between prokaryotes and eukaryotes was firmly established by the microbiologists Roger Stanier and C. B. van Niel in their 1962 paper The concept of a bacterium (though spelled procaryote and eucaryote there). That paper cites Édouard Chatton’s 1937 book Titres et Travaux Scientifiques for using those terms and recognizing the distinction. One reason for this classification was so that what was then often called blue-green algae (now called cyanobacteria) would not be classified as plants but grouped with bacteria. 4.5 Prokaryotic Cells A prokaryote is a cellular organism that lacks an envelope-enclosed nucleus. The word prokaryote comes from the Greek πρό (pro, ‘before’) and κάρυον (karyon, ‘nut’ or ‘kernel’). In the two-empire system arising from the work of Édouard Chatton, prokaryotes were classified within the empire Prokaryota. But in the three-domain system, based upon molecular analysis, prokaryotes are divided into two domains: Bacteria (formerly Eubacteria) and Archaea (formerly Archaebacteria). Organisms with nuclei are placed in a third domain, Eukaryota. In the study of the origins of life, prokaryotes are thought to have arisen before eukaryotes. Prokaryotes lack mitochondria, or any other eukaryotic membrane-bound organelles; and it was once thought that prokayotes lacked cellular compartments, and therefore all cellular components within the cytoplasm were unenclosed, except for an outer cell membrane. But bacterial microcompartments, which are thought to be primitive organelles enclosed in protein shells, have been discovered; and there is also evidence of prokayotic membrane-bound organelles. While typically being unicellular, some prokaryotes, such as cyanobacteria, may form large colonies. Others, such as myxobacteria, have multicellular stages in their life cycles. Prokaryotes are asexual, reproducing without fusion of gametes, although horizontal gene transfer also takes place. Figure 4.10: Structure of a typical prokaryotic cell Molecular studies have provided insight into the evolution and interrelationships of the three domains of life. The division between prokaryotes and eukaryotes reflects the existence of two very different levels of cellular organization; only eukaryotic cells have a enveloped nucleus that contains its chromosomal DNA, and other characteristic membrane-bound organelles including mitochondria. Distinctive types of prokaryotes include extremophiles and methanogens; these are common in some extreme environments. Prokaryotes include bacteria and archaea, two of the three domains of life. Prokaryotic cells were the first form of life on Earth, characterized by having vital biological processes including cell signaling. They are simpler and smaller than eukaryotic cells, and lack a nucleus, and other membrane-bound organelles. The DNA of a prokaryotic cell consists of a single circular chromosome that is in direct contact with the cytoplasm. The nuclear region in the cytoplas is called the nucleoid. Most prokaryotes are the smallest of all organisms ranging from 0.5 to 2.0 µm in diameter. A prokaryotic cell has three regions: Enclosing the cell is the cell envelope – generally consisting of a plasma membrane covered by a cell wall which, for some bacteria, may be further covered by a third layer called a capsule. Though most prokaryotes have both a cell membrane and a cell wall, there are exceptions such as Mycoplasma (bacteria) and Thermoplasma (archaea) which only possess the cell membrane layer. The envelope gives rigidity to the cell and separates the interior of the cell from its environment, serving as a protective filter. The cell wall consists of peptidoglycan in bacteria, and acts as an additional barrier against exterior forces. It also prevents the cell from expanding and bursting (cytolysis) from osmotic pressure due to a hypotonic environment. Some eukaryotic cells (plant cells and fungal cells) also have a cell wall. Inside the cell is the cytoplasmic region that contains the genome (DNA), ribosomes and various sorts of inclusions. The genetic material is freely found in the cytoplasm. Prokaryotes can carry extrachromosomal DNA elements called plasmids, which are usually circular. Linear bacterial plasmids have been identified in several species of spirochete bacteria, including members of the genus Borrelia notably Borrelia burgdorferi, which causes Lyme disease. Though not forming a nucleus, the DNA is condensed in a nucleoid. Plasmids encode additional genes, such as antibiotic resistance genes. On the outside, flagella and pili project from the cell’s surface. These are structures (not present in all prokaryotes) made of proteins that facilitate movement and communication between cells. 4.6 Bacteria Bacteria (plural of the New Latin bacterium, which is the latinisation of the Greek βακτήριον (bakterion), the diminutive of βακτηρία (bakteria), meaning “staff, cane”, because the first ones to be discovered were rod-shaped) constitute a large domain of prokaryotic microorganisms. Typically a few micrometres in length, bacteria have a number of shapes, ranging from spheres to rods and spirals. Bacteria were among the first life forms to appear on Earth, and are present in most of its habitats. Bacteria inhabit soil, water, acidic hot springs, radioactive waste, and the deep biosphere of the earth’s crust. Bacteria also live in symbiotic and parasitic relationships with plants and animals. Most bacteria have not been characterised, and only about 27 percent of the bacterial phyla have species that can be grown in the laboratory. The study of bacteria is known as bacteriology, a branch of microbiology. Nearly all animal life is dependent on bacteria for survival as only bacteria and some archaea possess the genes and enzymes necessary to synthesize vitamin B12, also known as cobalamin, and provide it through the food chain. Vitamin B12 is a water-soluble vitamin that is involved in the metabolism of every cell of the human body. It is a cofactor in DNA synthesis, and in both fatty acid and amino acid metabolism. It is particularly important in the normal functioning of the nervous system via its role in the synthesis of myelin. There are typically 40 million bacterial cells in a gram of soil and a million bacterial cells in a millilitre of fresh water. There are approximately 5×1030 bacteria on Earth, forming a biomass which exceeds that of all plants and animals. Bacteria are vital in many stages of the nutrient cycle by recycling nutrients such as the fixation of nitrogen from the atmosphere. The nutrient cycle includes the decomposition of dead bodies; bacteria are responsible for the putrefaction stage in this process. In the biological communities surrounding hydrothermal vents and cold seeps, extremophile bacteria provide the nutrients needed to sustain life by converting dissolved compounds, such as hydrogen sulphide and methane, to energy. In humans and most animals the largest number of bacteria exist in the gut, and a large number on the skin. The vast majority of the bacteria in the body are rendered harmless by the protective effects of the immune system, though many are beneficial, particularly in the gut flora. However, several species of bacteria are pathogenic and cause infectious diseases, including cholera, syphilis, anthrax, leprosy, and bubonic plague. The most common fatal bacterial diseases are respiratory infections. Tuberculosis alone kills about 2 million people per year, mostly in sub-Saharan Africa. Antibiotics are used to treat bacterial infections and are also used in farming, making antibiotic resistance a growing problem. In industry, bacteria are important in sewage treatment and the breakdown of oil spills, the production of cheese and yogurt through fermentation, the recovery of gold, palladium, copper and other metals in the mining sector, as well as in biotechnology, and the manufacture of antibiotics and other chemicals. Once regarded as plants constituting the class Schizomycetes (“fission fungi”), bacteria are now classified as prokaryotes. Unlike cells of animals and other eukaryotes, bacterial cells do not contain a nucleus and rarely harbour membrane-bound organelles. Although the term bacteria traditionally included all prokaryotes, the scientific classification changed after the discovery in the 1990s that prokaryotes consist of two very different groups of organisms that evolved from an ancient common ancestor. These evolutionary domains are called Bacteria and Archaea. The ancestors of modern bacteria were unicellular microorganisms that were the first forms of life to appear on Earth, about 4 billion years ago. For about 3 billion years, most organisms were microscopic, and bacteria and archaea were the dominant forms of life. Although bacterial fossils exist, such as stromatolites, their lack of distinctive morphology prevents them from being used to examine the history of bacterial evolution, or to date the time of origin of a particular bacterial species. However, gene sequences can be used to reconstruct the bacterial phylogeny, and these studies indicate that bacteria diverged first from the archaeal/eukaryotic lineage. The most recent common ancestor of bacteria and archaea was probably a hyperthermophile that lived about 2.5 billion–3.2 billion years ago. The earliest life on land may have been bacteria some 3.22 billion years ago. Bacteria were also involved in the second great evolutionary divergence, that of the archaea and eukaryotes. Here, eukaryotes resulted from the entering of ancient bacteria into endosymbiotic associations with the ancestors of eukaryotic cells, which were themselves possibly related to the Archaea. This involved the engulfment by proto-eukaryotic cells of alphaproteobacterial symbionts to form either mitochondria or hydrogenosomes, which are still found in all known Eukarya (sometimes in highly reduced form, e.g. in ancient “amitochondrial” protozoa). Later, some eukaryotes that already contained mitochondria also engulfed cyanobacteria-like organisms, leading to the formation of chloroplasts in algae and plants. This is known as primary endosymbiosis. Bacteria display a wide diversity of shapes and sizes, called morphologies. Bacterial cells are about one-tenth the size of eukaryotic cells and are typically 0.5–5.0 micrometres in length. However, a few species are visible to the unaided eye—for example, Thiomargarita namibiensis is up to half a millimetre long and Epulopiscium fishelsoni reaches 0.7 mm. Among the smallest bacteria are members of the genus Mycoplasma, which measure only 0.3 micrometres, as small as the largest viruses. Some bacteria may be even smaller, but these ultramicrobacteria are not well-studied. Figure 4.11: Bacteria display various cell morphologies and arrangements Most bacterial species are either spherical, called cocci (singular coccus, from Greek kókkos, grain, seed), or rod-shaped, called bacilli (sing. bacillus, from Latin baculus, stick). Some bacteria, called vibrio, are shaped like slightly curved rods or comma-shaped; others can be spiral-shaped, called spirilla, or tightly coiled, called spirochaetes. A small number of other unusual shapes have been described, such as star-shaped bacteria. This wide variety of shapes is determined by the bacterial cell wall and cytoskeleton, and is important because it can influence the ability of bacteria to acquire nutrients, attach to surfaces, swim through liquids and escape predators. Many bacterial species exist simply as single cells, others associate in characteristic patterns: Neisseria form diploids (pairs), Streptococcus form chains, and Staphylococcus group together in “bunch of grapes” clusters. Bacteria can also group to form larger multicellular structures, such as the elongated filaments of Actinobacteria, the aggregates of Myxobacteria, and the complex hyphae of Streptomyces. These multicellular structures are often only seen in certain conditions. For example, when starved of amino acids, Myxobacteria detect surrounding cells in a process known as quorum sensing, migrate towards each other, and aggregate to form fruiting bodies up to 500 micrometres long and containing approximately 100,000 bacterial cells. In these fruiting bodies, the bacteria perform separate tasks; for example, about one in ten cells migrate to the top of a fruiting body and differentiate into a specialised dormant state called a myxospore, which is more resistant to drying and other adverse environmental conditions. Bacteria often attach to surfaces and form dense aggregations called biofilms, and larger formations known as microbial mats. These biofilms and mats can range from a few micrometres in thickness to up to half a metre in depth, and may contain multiple species of bacteria, protists and archaea. Bacteria living in biofilms display a complex arrangement of cells and extracellular components, forming secondary structures, such as microcolonies, through which there are networks of channels to enable better diffusion of nutrients. In natural environments, such as soil or the surfaces of plants, the majority of bacteria are bound to surfaces in biofilms. Biofilms are also important in medicine, as these structures are often present during chronic bacterial infections or in infections of implanted medical devices, and bacteria protected within biofilms are much harder to kill than individual isolated bacteria. 4.6.1 Intracellular Structure The bacterial cell is surrounded by a cell membrane, which is made primarily of phospholipids. This membrane encloses the contents of the cell and acts as a barrier to hold nutrients, proteins and other essential components of the cytoplasm within the cell. Unlike eukaryotic cells, bacteria usually lack large membrane-bound structures in their cytoplasm such as a nucleus, mitochondria, chloroplasts and the other organelles present in eukaryotic cells. However, some bacteria have protein-bound organelles in the cytoplasm which compartmentalize aspects of bacterial metabolism, such as the carboxysome. Additionally, bacteria have a multi-component cytoskeleton to control the localisation of proteins and nucleic acids within the cell, and to manage the process of cell division. Many important biochemical reactions, such as energy generation, occur due to concentration gradients across membranes, creating a potential difference analogous to a battery. The general lack of internal membranes in bacteria means these reactions, such as electron transport, occur across the cell membrane between the cytoplasm and the outside of the cell or periplasm. However, in many photosynthetic bacteria the plasma membrane is highly folded and fills most of the cell with layers of light-gathering membrane. These light-gathering complexes may even form lipid-enclosed structures called chlorosomes in green sulfur bacteria. Bacteria do not have a membrane-bound nucleus, and their genetic material is typically a single circular bacterial chromosome of DNA located in the cytoplasm in an irregularly shaped body called the nucleoid. The nucleoid contains the chromosome with its associated proteins and RNA. Like all other organisms, bacteria contain ribosomes for the production of proteins, but the structure of the bacterial ribosome is different from that of eukaryotes and Archaea. Some bacteria produce intracellular nutrient storage granules, such as glycogen, polyphosphate, sulfur or polyhydroxyalkanoates. Bacteria such as the photosynthetic cyanobacteria, produce internal gas vacuoles, which they use to regulate their buoyancy, allowing them to move up or down into water layers with different light intensities and nutrient levels. 4.6.2 Extracellular Structures Around the outside of the cell membrane is the cell wall. Bacterial cell walls are made of peptidoglycan (also called murein), which is made from polysaccharide chains cross-linked by peptides containing D-amino acids. Bacterial cell walls are different from the cell walls of plants and fungi, which are made of cellulose and chitin, respectively. The cell wall of bacteria is also distinct from that of Archaea, which do not contain peptidoglycan. The cell wall is essential to the survival of many bacteria, and the antibiotic penicillin (produced by a fungus called Penicillium) is able to kill bacteria by inhibiting a step in the synthesis of peptidoglycan. There are broadly speaking two different types of cell wall in bacteria, that classify bacteria into Gram-positive bacteria and Gram-negative bacteria. The names originate from the reaction of cells to the Gram stain, a long-standing test for the classification of bacterial species. Gram-positive bacteria possess a thick cell wall containing many layers of peptidoglycan and teichoic acids. In contrast, Gram-negative bacteria have a relatively thin cell wall consisting of a few layers of peptidoglycan surrounded by a second lipid membrane containing lipopolysaccharides and lipoproteins. Most bacteria have the Gram-negative cell wall, and only the Firmicutes and Actinobacteria (previously known as the low G+C and high G+C Gram-positive bacteria, respectively) have the alternative Gram-positive arrangement. These differences in structure can produce differences in antibiotic susceptibility; for instance, vancomycin can kill only Gram-positive bacteria and is ineffective against Gram-negative pathogens, such as Haemophilus influenzae or Pseudomonas aeruginosa. Some bacteria have cell wall structures that are neither classically Gram-positive or Gram-negative. This includes clinically important bacteria such as Mycobacteria which have a thick peptidoglycan cell wall like a Gram-positive bacterium, but also a second outer layer of lipids. In many bacteria, an S-layer of rigidly arrayed protein molecules covers the outside of the cell. This layer provides chemical and physical protection for the cell surface and can act as a macromolecular diffusion barrier. S-layers have diverse but mostly poorly understood functions, but are known to act as virulence factors in Campylobacter and contain surface enzymes in Bacillus stearothermophilus. Figure 4.12: Helicobacter pylori electron micrograph, showing multiple flagella on the cell surface Flagella are rigid protein structures, about 20 nanometres in diameter and up to 20 micrometres in length, that are used for motility. Flagella are driven by the energy released by the transfer of ions down an electrochemical gradient across the cell membrane. The bacterial flagellum is made up of the protein flagellin. Its shape is a 20-nanometer-thick hollow tube. It is helical and has a sharp bend just outside the outer membrane; this “hook” allows the axis of the helix to point directly away from the cell. A shaft runs between the hook and the basal body, passing through protein rings in the cell’s membrane that act as bearings. Gram-positive organisms have two of these basal body rings, one in the peptidoglycan layer and one in the plasma membrane. Gram-negative organisms have four such rings: the L ring associates with the lipopolysaccharides, the P ring associates with peptidoglycan layer, the M ring is embedded in the plasma membrane, and the S ring is directly attached to the plasma membrane. The filament ends with a capping protein. Figure 4.13: Gram-negative bacterial flagellum. A flagellum is a long, slender projection from the cell body, whose function is to propel a unicellular or small multicellular organism. The depicted type of flagellum is found in bacteria such as E. coli and Salmonella, and rotates like a propeller when the bacterium swims. The bacterial movement can be divided into 2 kinds: run, resulting from a counterclockwise rotation of the flagellum, and tumbling, from a clockwise rotation of the flagellum. The flagellar filament is the long, helical screw that propels the bacterium when rotated by the motor, through the hook. In most bacteria that have been studied, including the Gram-negative Escherichia coli, Salmonella typhimurium, Caulobacter crescentus, and Vibrio alginolyticus, the filament is made up of 11 protofilaments approximately parallel to the filament axis. Each protofilament is a series of tandem protein chains. However, Campylobacter jejuni has seven protofilaments. The basal body has several traits in common with some types of secretory pores, such as the hollow, rod-like “plug” in their centers extending out through the plasma membrane. The similarities between bacterial flagella and bacterial secretory system structures and proteins provide scientific evidence supporting the theory that bacterial flagella evolved from the type-three secretion system. The bacterial flagellum is driven by a rotary engine (Mot complex) made up of protein, located at the flagellum’s anchor point on the inner cell membrane. The engine is powered by proton motive force, i.e., by the flow of protons (hydrogen ions) across the bacterial cell membrane due to a concentration gradient set up by the cell’s metabolism (Vibrio species have two kinds of flagella, lateral and polar, and some are driven by a sodium ion pump rather than a proton pump). The rotor transports protons across the membrane, and is turned in the process. The rotor alone can operate at 6,000 to 17,000 rpm, but with the flagellar filament attached usually only reaches 200 to 1000 rpm. The direction of rotation can be changed by the flagellar motor switch almost instantaneously, caused by a slight change in the position of a protein, FliG, in the rotor. The flagellum is highly energy efficient and uses very little energy.[unreliable source?] The exact mechanism for torque generation is still poorly understood. Because the flagellar motor has no on-off switch, the protein epsE is used as a mechanical clutch to disengage the motor from the rotor, thus stopping the flagellum and allowing the bacterium to remain in one place. The cylindrical shape of flagella is suited to locomotion of microscopic organisms; these organisms operate at a low Reynolds number, where the viscosity of the surrounding water is much more important than its mass or inertia. The rotational speed of flagella varies in response to the intensity of the proton motive force, thereby permitting certain forms of speed control, and also permitting some types of bacteria to attain remarkable speeds in proportion to their size; some achieve roughly 60 cell lengths per second. At such a speed, a bacterium would take about 245 days to cover 1 km; although that may seem slow, the perspective changes when the concept of scale is introduced. In comparison to macroscopic life forms, it is very fast indeed when expressed in terms of number of body lengths per second. A cheetah, for example, only achieves about 25 body lengths per second. Through use of their flagella, E. coli is able to move rapidly towards attractants and away from repellents, by means of a biased random walk, with ‘runs’ and ‘tumbles’ brought about by rotating its flagellum counterclockwise and clockwise, respectively. The two directions of rotation are not identical (with respect to flagellum movement) and are selected by a molecular switch. During flagellar assembly, components of the flagellum pass through the hollow cores of the basal body and the nascent filament. During assembly, protein components are added at the flagellar tip rather than at the base. In vitro, flagellar filaments assemble spontaneously in a solution containing purified flagellin as the sole protein. At least 10 protein components of the bacterial flagellum share homologous proteins with the type three secretion system (T3SS) found in many gram-negative bacteria, hence one likely evolved from the other. Because the T3SS has a similar number of components as a flagellar apparatus (about 25 proteins), which one evolved first is difficult to determine. However, the flagellar system appears to involve more proteins overall, including various regulators and chaperones, hence it has been argued that flagella evolved from a T3SS. However, it has also been suggested that the flagellum may have evolved first or the two structures evolved in parallel. Early single-cell organisms’ need for motility (mobility) support that the more mobile flagella would be selected by evolution first, but the T3SS evolving from the flagellum can be seen as ‘reductive evolution’, and receives no topological support from the phylogenetic trees. The hypothesis that the two structures evolved separately from a common ancestor accounts for the protein similarities between the two structures, as well as their functional diversity. Different species of bacteria have different numbers and arrangements of flagella. Monotrichous bacteria have a single flagellum (e.g., Vibrio cholerae). Lophotrichous bacteria have multiple flagella located at the same spot on the bacterial surfaces which act in concert to drive the bacteria in a single direction. In many cases, the bases of multiple flagella are surrounded by a specialized region of the cell membrane, called the polar organelle.[citation needed] Amphitrichous bacteria have a single flagellum on each of two opposite ends (only one flagellum operates at a time, allowing the bacterium to reverse course rapidly by switching which flagellum is active). Peritrichous bacteria have flagella projecting in all directions (e.g., E. coli). In certain large forms of Selenomonas, more than 30 individual flagella are organized outside the cell body, helically twining about each other to form a thick structure (easily visible with the light microscope) called a “fascicle”. Spirochetes, in contrast, have flagella called endoflagella arising from opposite poles of the cell, and are located within the periplasmic space as shown by breaking the outer-membrane and also by electron cryotomography microscopy. The rotation of the filaments relative to the cell body causes the entire bacterium to move forward in a corkscrew-like motion, even through material viscous enough to prevent the passage of normally flagellated bacteria. Counterclockwise rotation of a monotrichous polar flagellum pushes the cell forward with the flagellum trailing behind, much like a corkscrew moving inside cork. Indeed, water on the microscopic scale is highly viscous, very different from our daily experience of water. Flagella are left-handed helices, and bundle and rotate together only when rotating counterclockwise. When some of the rotors reverse direction, the flagella unwind and the cell starts “tumbling”. Even if all flagella would rotate clockwise, they likely will not form a bundle, due to geometrical, as well as hydrodynamic reasons. Such “tumbling” may happen occasionally, leading to the cell seemingly thrashing about in place, resulting in the reorientation of the cell. The clockwise rotation of a flagellum is suppressed by chemical compounds favorable to the cell (e.g. food), but the motor is highly adaptive to this. Therefore, when moving in a favorable direction, the concentration of the chemical attractant increases and “tumbles” are continually suppressed; however, when the cell’s direction of motion is unfavorable (e.g., away from a chemical attractant), tumbles are no longer suppressed and occur much more often, with the chance that the cell will be thus reoriented in the correct direction. In some Vibrio spp. (particularly Vibrio parahaemolyticus) and related proteobacteria such as Aeromonas, two flagellar systems co-exist, using different sets of genes and different ion gradients for energy. The polar flagella are constitutively expressed and provide motility in bulk fluid, while the lateral flagella are expressed when the polar flagella meet too much resistance to turn. These provide swarming motility on surfaces or in viscous fluids. Fimbriae (sometimes called “attachment pili”) are fine filaments of protein, usually 2–10 nanometres in diameter and up to several micrometres in length. They are distributed over the surface of the cell, and resemble fine hairs when seen under the electron microscope. Fimbriae are believed to be involved in attachment to solid surfaces or to other cells, and are essential for the virulence of some bacterial pathogens. Pili (sing. pilus) are cellular appendages, slightly larger than fimbriae, that can transfer genetic material between bacterial cells in a process called conjugation where they are called conjugation pili or sex pili (see bacterial genetics, below). They can also generate movement where they are called type IV pili. Glycocalyx is produced by many bacteria to surround their cells, and varies in structural complexity: ranging from a disorganised slime layer of extracellular polymeric substances to a highly structured capsule. These structures can protect cells from engulfment by eukaryotic cells such as macrophages (part of the human immune system). They can also act as antigens and be involved in cell recognition, as well as aiding attachment to surfaces and the formation of biofilms. The assembly of these extracellular structures is dependent on bacterial secretion systems. These transfer proteins from the cytoplasm into the periplasm or into the environment around the cell. Many types of secretion systems are known and these structures are often essential for the virulence of pathogens, so are intensively studied. 4.6.3 Endospores Certain genera of Gram-positive bacteria, such as Bacillus, Clostridium, Sporohalobacter, Anaerobacter, and Heliobacterium, can form highly resistant, dormant structures called endospores. Endospores develop within the cytoplasm of the cell; generally a single endospore develops in each cell. Each endospore contains a core of DNA and ribosomes surrounded by a cortex layer and protected by a multilayer rigid coat composed of peptidoglycan and a variety of proteins. Figure 4.14: A stained preparation of the cell Bacillus subtilis showing endospores as green and the vegetative cell as red. Endospores show no detectable metabolism and can survive extreme physical and chemical stresses, such as high levels of UV light, gamma radiation, detergents, disinfectants, heat, freezing, pressure, and desiccation. In this dormant state, these organisms may remain viable for millions of years, and endospores even allow bacteria to survive exposure to the vacuum and radiation in space, possibly bacteria could be distributed throughout the Universe by space dust, meteoroids, asteroids, comets, planetoids or via directed panspermia. Endospore-forming bacteria can also cause disease: for example, anthrax can be contracted by the inhalation of Bacillus anthracis endospores, and contamination of deep puncture wounds with Clostridium tetani endospores causes tetanus. Figure 4.15: Formation of an endospore through the process of sporulation. 4.6.4 Metabolism Bacteria exhibit an extremely wide variety of metabolic types. The distribution of metabolic traits within a group of bacteria has traditionally been used to define their taxonomy, but these traits often do not correspond with modern genetic classifications. Bacterial metabolism is classified into nutritional groups on the basis of three major criteria: the source of energy, the electron donors used, and the source of carbon used for growth. Bacteria either derive energy from light using photosynthesis (called phototrophy), or by breaking down chemical compounds using oxidation (called chemotrophy). Chemotrophs use chemical compounds as a source of energy by transferring electrons from a given electron donor to a terminal electron acceptor in a redox reaction. This reaction releases energy that can be used to drive metabolism. Chemotrophs are further divided by the types of compounds they use to transfer electrons. Bacteria that use inorganic compounds such as hydrogen, carbon monoxide, or ammonia as sources of electrons are called lithotrophs, while those that use organic compounds are called organotrophs. The compounds used to receive electrons are also used to classify bacteria: aerobic organisms use oxygen as the terminal electron acceptor, while anaerobic organisms use other compounds such as nitrate, sulfate, or carbon dioxide. Many bacteria get their carbon from other organic carbon, called heterotrophy. Others such as cyanobacteria and some purple bacteria are autotrophic, meaning that they obtain cellular carbon by fixing carbon dioxide. In unusual circumstances, the gas methane can be used by methanotrophic bacteria as both a source of electrons and a substrate for carbon anabolism. Table 4.1: Nutritional types in bacterial metabolism Nutritional Type Source of Energy Source of Carbon Examples  Phototrophs  Sunlight  Organic compounds (photoheterotrophs) or carbon fixation (photoautotrophs)  Cyanobacteria, Green sulfur bacteria, Chloroflexi, or Purple bacteria   Lithotrophs Inorganic compounds  Organic compounds (lithoheterotrophs) or carbon fixation (lithoautotrophs)  Thermodesulfobacteria, Hydrogenophilaceae, or Nitrospirae   Organotrophs Organic compounds  Organic compounds (chemoheterotrophs) or carbon fixation (chemoautotrophs)    Bacillus, Clostridium or Enterobacteriaceae  In many ways, bacterial metabolism provides traits that are useful for ecological stability and for human society. One example is that some bacteria have the ability to fix nitrogen gas using the enzyme nitrogenase. This environmentally important trait can be found in bacteria of most metabolic types listed above. This leads to the ecologically important processes of denitrification, sulfate reduction, and acetogenesis, respectively. Bacterial metabolic processes are also important in biological responses to pollution; for example, sulfate-reducing bacteria are largely responsible for the production of the highly toxic forms of mercury (methyl- and dimethylmercury) in the environment. Non-respiratory anaerobes use fermentation to generate energy and reducing power, secreting metabolic by-products (such as ethanol in brewing) as waste. Facultative anaerobes can switch between fermentation and different terminal electron acceptors depending on the environmental conditions in which they find themselves. 4.6.5 Growth And Reproduction Many bacteria reproduce through binary fission, which is compared to mitosis and meiosis in this image. Unlike in multicellular organisms, increases in cell size (cell growth) and reproduction by cell division are tightly linked in unicellular organisms. Bacteria grow to a fixed size and then reproduce through binary fission, a form of asexual reproduction. Under optimal conditions, bacteria can grow and divide extremely rapidly, and bacterial populations can double as quickly as every 9.8 minutes. In cell division, two identical clone daughter cells are produced. Some bacteria, while still reproducing asexually, form more complex reproductive structures that help disperse the newly formed daughter cells. Examples include fruiting body formation by Myxobacteria and aerial hyphae formation by Streptomyces, or budding. Budding involves a cell forming a protrusion that breaks away and produces a daughter cell. In the laboratory, bacteria are usually grown using solid or liquid media. Solid growth media, such as agar plates, are used to isolate pure cultures of a bacterial strain. However, liquid growth media are used when the measurement of growth or large volumes of cells are required. Growth in stirred liquid media occurs as an even cell suspension, making the cultures easy to divide and transfer, although isolating single bacteria from liquid media is difficult. The use of selective media (media with specific nutrients added or deficient, or with antibiotics added) can help identify specific organisms. Most laboratory techniques for growing bacteria use high levels of nutrients to produce large amounts of cells cheaply and quickly. However, in natural environments, nutrients are limited, meaning that bacteria cannot continue to reproduce indefinitely. This nutrient limitation has led the evolution of different growth strategies (see r/K selection theory). Some organisms can grow extremely rapidly when nutrients become available, such as the formation of algal (and cyanobacterial) blooms that often occur in lakes during the summer. Other organisms have adaptations to harsh environments, such as the production of multiple antibiotics by Streptomyces that inhibit the growth of competing microorganisms. In nature, many organisms live in communities (e.g., biofilms) that may allow for increased supply of nutrients and protection from environmental stresses. These relationships can be essential for growth of a particular organism or group of organisms (syntrophy). Bacterial growth follows four phases. When a population of bacteria first enter a high-nutrient environment that allows growth, the cells need to adapt to their new environment. The first phase of growth is the lag phase, a period of slow growth when the cells are adapting to the high-nutrient environment and preparing for fast growth. The lag phase has high biosynthesis rates, as proteins necessary for rapid growth are produced. The second phase of growth is the logarithmic phase, also known as the exponential phase. The log phase is marked by rapid exponential growth. The rate at which cells grow during this phase is known as the growth rate (k), and the time it takes the cells to double is known as the generation time (g). During log phase, nutrients are metabolised at maximum speed until one of the nutrients is depleted and starts limiting growth. The third phase of growth is the stationary phase and is caused by depleted nutrients. The cells reduce their metabolic activity and consume non-essential cellular proteins. The stationary phase is a transition from rapid growth to a stress response state and there is increased expression of genes involved in DNA repair, antioxidant metabolism and nutrient transport. The final phase is the death phase where the bacteria run out of nutrients and die. 4.6.6 Bacterial Genetics Most bacteria have a single circular chromosome that can range in size from only 160,000 base pairs in the endosymbiotic bacteria Carsonella ruddii, to 12,200,000 base pairs (12.2 Mbp) in the soil-dwelling bacteria Sorangium cellulosum. There are many exceptions to this, for example some Streptomyces and Borrelia species contain a single linear chromosome, while some Vibrio species contain more than one chromosome. Bacteria can also contain plasmids, small extra-chromosomal molecules of DNA that may contain genes for various useful functions such as antibiotic resistance, metabolic capabilities, or various virulence factors. Bacteria genomes usually encode a few hundred to a few thousand genes. The genes in bacterial genomes are usually a single continuous stretch of DNA and although several different types of introns do exist in bacteria, these are much rarer than in eukaryotes. Bacteria, as asexual organisms, inherit an identical copy of the parent’s genomes and are clonal. However, all bacteria can evolve by selection on changes to their genetic material DNA caused by genetic recombination or mutations. Mutations come from errors made during the replication of DNA or from exposure to mutagens. Mutation rates vary widely among different species of bacteria and even among different clones of a single species of bacteria. Genetic changes in bacterial genomes come from either random mutation during replication or “stress-directed mutation”, where genes involved in a particular growth-limiting process have an increased mutation rate. Some bacteria also transfer genetic material between cells. This can occur in three main ways. First, bacteria can take up exogenous DNA from their environment, in a process called transformation. Many bacteria can naturally take up DNA from the environment, while others must be chemically altered in order to induce them to take up DNA. The development of competence in nature is usually associated with stressful environmental conditions, and seems to be an adaptation for facilitating repair of DNA damage in recipient cells. The second way bacteria transfer genetic material is by transduction, when the integration of a bacteriophage introduces foreign DNA into the chromosome. Many types of bacteriophage exist, some simply infect and lyse their host bacteria, while others insert into the bacterial chromosome. Bacteria resist phage infection through restriction modification systems that degrade foreign DNA, and a system that uses CRISPR sequences to retain fragments of the genomes of phage that the bacteria have come into contact with in the past, which allows them to block virus replication through a form of RNA interference. The third method of gene transfer is conjugation, whereby DNA is transferred through direct cell contact. In ordinary circumstances, transduction, conjugation, and transformation involve transfer of DNA between individual bacteria of the same species, but occasionally transfer may occur between individuals of different bacterial species and this may have significant consequences, such as the transfer of antibiotic resistance. In such cases, gene acquisition from other bacteria or the environment is called horizontal gene transfer and may be common under natural conditions. 4.6.7 Movement Of Bacteria Many bacteria are motile (able to move themselves) and do so using a variety of mechanisms. The best studied of these are flagella, long filaments that are turned by a motor at the base to generate propeller-like movement. The bacterial flagellum is made of about 20 proteins, with approximately another 30 proteins required for its regulation and assembly. The flagellum is a rotating structure driven by a reversible motor at the base that uses the electrochemical gradient across the membrane for power. Bacteria can use flagella in different ways to generate different kinds of movement. Many bacteria (such as E. coli) have two distinct modes of movement: forward movement (swimming) and tumbling. The tumbling allows them to reorient and makes their movement a three-dimensional random walk. Bacterial species differ in the number and arrangement of flagella on their surface; some have a single flagellum (monotrichous), a flagellum at each end (amphitrichous), clusters of flagella at the poles of the cell (lophotrichous), while others have flagella distributed over the entire surface of the cell (peritrichous). The flagella of a unique group of bacteria, the spirochaetes, are found between two membranes in the periplasmic space. They have a distinctive helical body that twists about as it moves. Two other types of bacterial motion are called twitching motility that relies on a structure called the type IV pilus, and gliding motility, that uses other mechanisms. In twitching motility, the rod-like pilus extends out from the cell, binds some substrate, and then retracts, pulling the cell forward. Motile bacteria are attracted or repelled by certain stimuli in behaviours called taxes: these include chemotaxis, phototaxis, energy taxis, and magnetotaxis. In one peculiar group, the myxobacteria, individual bacteria move together to form waves of cells that then differentiate to form fruiting bodies containing spores. The myxobacteria move only when on solid surfaces, unlike E. coli, which is motile in liquid or solid media. Several Listeria and Shigella species move inside host cells by usurping the cytoskeleton, which is normally used to move organelles inside the cell. By promoting actin polymerisation at one pole of their cells, they can form a kind of tail that pushes them through the host cell’s cytoplasm. 4.6.8 Bacterial Communication Bacteria often function as multicellular aggregates known as biofilms, exchanging a variety of molecular signals for inter-cell communication, and engaging in coordinated multicellular behaviour. The communal benefits of multicellular cooperation include a cellular division of labour, accessing resources that cannot effectively be used by single cells, collectively defending against antagonists, and optimising population survival by differentiating into distinct cell types. For example, bacteria in biofilms can have more than 500 times increased resistance to antibacterial agents than individual “planktonic” bacteria of the same species. One type of inter-cellular communication by a molecular signal is called quorum sensing, which serves the purpose of determining whether there is a local population density that is sufficiently high that it is productive to invest in processes that are only successful if large numbers of similar organisms behave similarly, as in excreting digestive enzymes or emitting light. Quorum sensing allows bacteria to coordinate gene expression, and enables them to produce, release and detect autoinducers or pheromones which accumulate with the growth in cell population. 4.6.9 Classification And identification Classification seeks to describe the diversity of bacterial species by naming and grouping organisms based on similarities. Bacteria can be classified on the basis of cell structure, cellular metabolism or on differences in cell components, such as DNA, fatty acids, pigments, antigens and quinones. While these schemes allowed the identification and classification of bacterial strains, it was unclear whether these differences represented variation between distinct species or between strains of the same species. This uncertainty was due to the lack of distinctive structures in most bacteria, as well as lateral gene transfer between unrelated species. Due to lateral gene transfer, some closely related bacteria can have very different morphologies and metabolisms. To overcome this uncertainty, modern bacterial classification emphasises molecular systematics, using genetic techniques such as guanine cytosine ratio determination, genome-genome hybridisation, as well as sequencing genes that have not undergone extensive lateral gene transfer, such as the rRNA gene. Classification of bacteria is determined by publication in the International Journal of Systematic Bacteriology, and Bergey’s Manual of Systematic Bacteriology. The International Committee on Systematic Bacteriology (ICSB) maintains international rules for the naming of bacteria and taxonomic categories and for the ranking of them in the International Code of Nomenclature of Bacteria. The term “bacteria” was traditionally applied to all microscopic, single-cell prokaryotes. However, molecular systematics showed prokaryotic life to consist of two separate domains, originally called Eubacteria and Archaebacteria, but now called Bacteria and Archaea that evolved independently from an ancient common ancestor. The archaea and eukaryotes are more closely related to each other than either is to the bacteria. These two domains, along with Eukarya, are the basis of the three-domain system, which is currently the most widely used classification system in microbiology. However, due to the relatively recent introduction of molecular systematics and a rapid increase in the number of genome sequences that are available, bacterial classification remains a changing and expanding field. For example, Cavalier-Smith argued that the Archaea and Eukaryotes evolved from Gram-positive bacteria. The identification of bacteria in the laboratory is particularly relevant in medicine, where the correct treatment is determined by the bacterial species causing an infection. Consequently, the need to identify human pathogens was a major impetus for the development of techniques to identify bacteria. The Gram stain, developed in 1884 by Hans Christian Gram, characterises bacteria based on the structural characteristics of their cell walls. The thick layers of peptidoglycan in the “Gram-positive” cell wall stain purple, while the thin “Gram-negative” cell wall appears pink. By combining morphology and Gram-staining, most bacteria can be classified as belonging to one of four groups (Gram-positive cocci, Gram-positive bacilli, Gram-negative cocci and Gram-negative bacilli). Some organisms are best identified by stains other than the Gram stain, particularly mycobacteria or Nocardia, which show acid-fastness on Ziehl–Neelsen or similar stains. Other organisms may need to be identified by their growth in special media, or by other techniques, such as serology. Culture techniques are designed to promote the growth and identify particular bacteria, while restricting the growth of the other bacteria in the sample. Often these techniques are designed for specific specimens; for example, a sputum sample will be treated to identify organisms that cause pneumonia, while stool specimens are cultured on selective media to identify organisms that cause diarrhoea, while preventing growth of non-pathogenic bacteria. Specimens that are normally sterile, such as blood, urine or spinal fluid, are cultured under conditions designed to grow all possible organisms. Once a pathogenic organism has been isolated, it can be further characterised by its morphology, growth patterns (such as aerobic or anaerobic growth), patterns of hemolysis, and staining. As with bacterial classification, identification of bacteria is increasingly using molecular methods. Diagnostics using DNA-based tools, such as polymerase chain reaction, are increasingly popular due to their specificity and speed, compared to culture-based methods. These methods also allow the detection and identification of “viable but nonculturable” cells that are metabolically active but non-dividing. However, even using these improved methods, the total number of bacterial species is not known and cannot even be estimated with any certainty. Following present classification, there are a little less than 9,300 known species of prokaryotes, which includes bacteria and archaea; but attempts to estimate the true number of bacterial diversity have ranged from 107 to 109 total species—and even these diverse estimates may be off by many orders of magnitude. 4.6.10 Interactions With Other Organisms Despite their apparent simplicity, bacteria can form complex associations with other organisms. These symbiotic associations can be divided into parasitism, mutualism and commensalism. Due to their small size, commensal bacteria are ubiquitous and grow on animals and plants exactly as they will grow on any other surface. However, their growth can be increased by warmth and sweat, and large populations of these organisms in humans are the cause of body odour. Some species of bacteria kill and then consume other microorganisms, these species are called predatory bacteria. These include organisms such as Myxococcus xanthus, which forms swarms of cells that kill and digest any bacteria they encounter. Other bacterial predators either attach to their prey in order to digest them and absorb nutrients, such as Vampirovibrio chlorellavorus, or invade another cell and multiply inside the cytosol, such as Daptobacter. These predatory bacteria are thought to have evolved from saprophages that consumed dead microorganisms, through adaptations that allowed them to entrap and kill other organisms. Certain bacteria form close spatial associations that are essential for their survival. One such mutualistic association, called interspecies hydrogen transfer, occurs between clusters of anaerobic bacteria that consume organic acids, such as butyric acid or propionic acid, and produce hydrogen, and methanogenic Archaea that consume hydrogen. The bacteria in this association are unable to consume the organic acids as this reaction produces hydrogen that accumulates in their surroundings. Only the intimate association with the hydrogen-consuming Archaea keeps the hydrogen concentration low enough to allow the bacteria to grow. In soil, microorganisms that reside in the rhizosphere (a zone that includes the root surface and the soil that adheres to the root after gentle shaking) carry out nitrogen fixation, converting nitrogen gas to nitrogenous compounds. This serves to provide an easily absorbable form of nitrogen for many plants, which cannot fix nitrogen themselves. Many other bacteria are found as symbionts in humans and other organisms. For example, the presence of over 1,000 bacterial species in the normal human gut flora of the intestines can contribute to gut immunity, synthesise vitamins, such as folic acid, vitamin K and biotin, convert sugars to lactic acid (see Lactobacillus), as well as fermenting complex undigestible carbohydrates. The presence of this gut flora also inhibits the growth of potentially pathogenic bacteria (usually through competitive exclusion) and these beneficial bacteria are consequently sold as probiotic dietary supplements. 4.6.11 Bacteria As Pathogens If bacteria form a parasitic association with other organisms, they are classed as pathogens. Pathogenic bacteria are a major cause of human death and disease and cause infections such as tetanus (Caused by Clostridium tetani), typhoid fever, diphtheria, syphilis, cholera, foodborne illness, leprosy (caused by Micobacterium leprae) and tuberculosis (Caused by Mycobacterium tuberculosis). A pathogenic cause for a known medical disease may only be discovered many years after, as was the case with Helicobacter pylori and peptic ulcer disease. Bacterial diseases are also important in agriculture, with bacteria causing leaf spot, fire blight and wilts in plants, as well as Johne’s disease, mastitis, salmonella and anthrax in farm animals. Each species of pathogen has a characteristic spectrum of interactions with its human hosts. Some organisms, such as Staphylococcus or Streptococcus, can cause skin infections, pneumonia, meningitis and even overwhelming sepsis, a systemic inflammatory response producing shock, massive vasodilation and death. Yet these organisms are also part of the normal human flora and usually exist on the skin or in the nose without causing any disease at all. Other organisms invariably cause disease in humans, such as the Rickettsia, which are obligate intracellular parasites able to grow and reproduce only within the cells of other organisms. One species of Rickettsia causes typhus, while another causes Rocky Mountain spotted fever. Chlamydia, another phylum of obligate intracellular parasites, contains species that can cause pneumonia, or urinary tract infection and may be involved in coronary heart disease. Finally, some species, such as Pseudomonas aeruginosa, Burkholderia cenocepacia, and Mycobacterium avium, are opportunistic pathogens and cause disease mainly in people suffering from immunosuppression or cystic fibrosis. Bacterial infections may be treated with antibiotics, which are classified as bacteriocidal if they kill bacteria, or bacteriostatic if they just prevent bacterial growth. There are many types of antibiotics and each class inhibits a process that is different in the pathogen from that found in the host. An example of how antibiotics produce selective toxicity are chloramphenicol and puromycin, which inhibit the bacterial ribosome, but not the structurally different eukaryotic ribosome. Antibiotics are used both in treating human disease and in intensive farming to promote animal growth, where they may be contributing to the rapid development of antibiotic resistance in bacterial populations. Infections can be prevented by antiseptic measures such as sterilising the skin prior to piercing it with the needle of a syringe, and by proper care of indwelling catheters. Surgical and dental instruments are also sterilised to prevent contamination by bacteria. Disinfectants such as bleach are used to kill bacteria or other pathogens on surfaces to prevent contamination and further reduce the risk of infection. 4.6.12 Significance In Technology And Industry Bacteria, often lactic acid bacteria, such as Lactobacillus and Lactococcus, in combination with yeasts and moulds, have been used for thousands of years in the preparation of fermented foods, such as cheese, pickles, soy sauce, sauerkraut, vinegar, wine and yogurt. The ability of bacteria to degrade a variety of organic compounds is remarkable and has been used in waste processing and bioremediation. Bacteria capable of digesting the hydrocarbons in petroleum are often used to clean up oil spills. Fertiliser was added to some of the beaches in Prince William Sound in an attempt to promote the growth of these naturally occurring bacteria after the 1989 Exxon Valdez oil spill. These efforts were effective on beaches that were not too thickly covered in oil. Bacteria are also used for the bioremediation of industrial toxic wastes. In the chemical industry, bacteria are most important in the production of enantiomerically pure chemicals for use as pharmaceuticals or agrichemicals. Bacteria can also be used in the place of pesticides in the biological pest control. This commonly involves Bacillus thuringiensis (also called BT), a Gram-positive, soil dwelling bacterium. Subspecies of this bacteria are used as a Lepidopteran-specific insecticides under trade names such as Dipel and Thuricide. Because of their specificity, these pesticides are regarded as environmentally friendly, with little or no effect on humans, wildlife, pollinators and most other beneficial insects. Because of their ability to quickly grow and the relative ease with which they can be manipulated, bacteria are the workhorses for the fields of molecular biology, genetics and biochemistry. By making mutations in bacterial DNA and examining the resulting phenotypes, scientists can determine the function of genes, enzymes and metabolic pathways in bacteria, then apply this knowledge to more complex organisms. This aim of understanding the biochemistry of a cell reaches its most complex expression in the synthesis of huge amounts of enzyme kinetic and gene expression data into mathematical models of entire organisms. This is achievable in some well-studied bacteria, with models of Escherichia coli metabolism now being produced and tested. This understanding of bacterial metabolism and genetics allows the use of biotechnology to bioengineer bacteria for the production of therapeutic proteins, such as insulin, growth factors, or antibodies. Because of their importance for research in general, samples of bacterial strains are isolated and preserved in Biological Resource Centers. This ensures the availability of the strain to scientists worldwide. 4.7 Archaea The word archaea comes from the Ancient Greek ἀρχαῖα, meaning “ancient things”, as the first representatives of the domain Archaea were methanogens and it was assumed that their metabolism reflected Earth’s primitive atmosphere and the organisms’ antiquity, but as new habitats were studied, more organisms were discovered. Extreme halophilic and hyperthermophilic microbes were also included in Archaea. For a long time, archaea were seen as extremophiles that exist only in extreme habitats such as hot springs and salt lakes, but by the end of the 20th century, archaea had been identified in non-extreme environments as well. Today, they are known to be a large and diverse group of organisms abundantly distributed throughout nature. This new appreciation of the importance and ubiquity of archaea came from using polymerase chain reaction (PCR) to detect prokaryotes from environmental samples (such as water or soil) by multiplying their ribosomal genes. This allows the detection and identification of organisms that have not been cultured in the laboratory. Archaeal cells have unique properties separating them from the other two domains, Bacteria and Eukaryota. Archaea are further divided into multiple recognized phyla. Classification is difficult because most have not been isolated in the laboratory and have been detected only by analysis of their nucleic acids in samples from their environment. Archaea and bacteria are generally similar in size and shape, although a few archaea have very different shapes, such as the flat and square cells of Haloquadratum walsbyi. Despite this morphological similarity to bacteria, archaea possess genes and several metabolic pathways that are more closely related to those of eukaryotes, notably for the enzymes involved in transcription and translation. Other aspects of archaeal biochemistry are unique, such as their reliance on ether lipids in their cell membranes, including archaeols. Archaea use more energy sources than eukaryotes: these range from organic compounds, such as sugars, to ammonia, metal ions or even hydrogen gas. Salt-tolerant archaea (the Haloarchaea) use sunlight as an energy source, and other species of archaea fix carbon, but unlike plants and cyanobacteria, no known species of archaea does both. Archaea reproduce asexually by binary fission, fragmentation, or budding; unlike bacteria, no known species of Archaea form endospores. The first observed archaea were extremophiles, living in extreme environments, such as hot springs and salt lakes with no other organisms. Improved detection tools led to the discovery of archaea in almost every habitat, including soil, oceans, and marshlands. Archaea are particularly numerous in the oceans, and the archaea in plankton may be one of the most abundant groups of organisms on the planet. Archaea are a major part of Earth’s life. They are part of the microbiota of all organisms. In the human microbiota, they are important in the gut, mouth, and on the skin. Their morphological, metabolic, and geographical diversity permits them to play multiple ecological roles: carbon fixation; nitrogen cycling; organic compound turnover; and maintaining microbial symbiotic and syntrophic communities, for example. No clear examples of archaeal pathogens or parasites are known. Instead they are often mutualists or commensals, such as the methanogens (methane-producing strains) that inhabit the gastrointestinal tract in humans and ruminants, where their vast numbers aid digestion. Methanogens are also used in biogas production and sewage treatment, and biotechnology exploits enzymes from extremophile archaea that can endure high temperatures and organic solvents. 4.7.1 Origin And evolution The age of the Earth is about 4.54 billion years. Scientific evidence suggests that life began on Earth at least 3.5 billion years ago. The earliest evidence for life on Earth is graphite found to be biogenic in 3.7-billion-year-old metasedimentary rocks discovered in Western Greenland and microbial mat fossils found in 3.48-billion-year-old sandstone discovered in Western Australia. In 2015, possible remains of biotic matter were found in 4.1-billion-year-old rocks in Western Australia. Although probable prokaryotic cell fossils date to almost 3.5 billion years ago, most prokaryotes do not have distinctive morphologies, and fossil shapes cannot be used to identify them as archaea. Instead, chemical fossils of unique lipids are more informative because such compounds do not occur in other organisms. Some publications suggest that archaeal or eukaryotic lipid remains are present in shales dating from 2.7 billion years ago; though such data have since been questioned. These lipids have also been detected in even older rocks from west Greenland. The oldest such traces come from the Isua district, which includes Earth’s oldest known sediments, formed 3.8 billion years ago. The archaeal lineage may be the most ancient that exists on Earth. Woese argued that the Bacteria, Archaea, and Eukaryotes represent separate lines of descent that diverged early on from an ancestral colony of organisms. One possibility is that this occurred before the evolution of cells, when the lack of a typical cell membrane allowed unrestricted lateral gene transfer, and that the common ancestors of the three domains arose by fixation of specific subsets of genes. It is possible that the last common ancestor of bacteria and archaea was a thermophile, which raises the possibility that lower temperatures are “extreme environments” for archaea, and organisms that live in cooler environments appeared only later. Since archaea and bacteria are no more related to each other than they are to eukaryotes, the term prokaryote may suggest a false similarity between them. However, structural and functional similarities between lineages often occur because of shared ancestral traits or evolutionary convergence. These similarities are known as a grade, and prokaryotes are best thought of a grade of life, characterized by such features as an absence of membrane-bound organelles. The following table (4.2 compares some major characteristics of the three domains, to illustrate their similarities and differences. Table 4.2: A comparison of major characterisitcs of the domains of Bacteria, Archaea and Eukaryia Property Bacteria Archaea Eukarya Cell membrane Ether-linked lipids Ester-linked lipids Ester-linked lipids Cell wall Pseudopeptidoglycan, glycoprotein, or S-layer Peptidoglycan, S-layer, or no cell wall Various structures Gene structure Circular chromosomes, similar translation and transcription to Eukarya Circular chromosomes, unique translation and transcription Multiple, linear chromosomes, but translation and transcription similar to Archaea Internal cell structure No membrane-bound organelles (?[62]) or nucleus No membrane-bound organelles or nucleus Membrane-bound organelles and nucleus Metabolism[63] Various, including diazotrophy, with methanogenesis unique to Archaea Various, including photosynthesis, aerobic and anaerobic respiration, fermentation, diazotrophy, and autotrophy Photosynthesis, cellular respiration, and fermentation; no diazotrophy Reproduction Asexual reproduction, horizontal gene transfer Asexual reproduction, horizontal gene transfer Sexual and asexual reproduction Protein synthesis initiation Methionine Formylmethionine Methionine RNA polymerase Many One Many Toxin Sensitive to diphtheria toxin Resistant to diphtheria toxin Sensitive to diphtheria toxin Archaea were split off as a third domain because of the large differences in their ribosomal RNA structure. The particular molecule 16S rRNA is key to the production of proteins in all organisms. Because this function is so central to life, organisms with mutations in their 16S rRNA are unlikely to survive, leading to great (but not absolute) stability in the structure of this nucleotide over generations. 16S rRNA is large enough to show organism-specific variations, but still small enough to be compared quickly. In 1977, Carl Woese, a microbiologist studying the genetic sequences of organisms, developed a new comparison method that involved splitting the RNA into fragments that could be sorted and compared with other fragments from other organisms. The more similar the patterns between species, the more closely they are related. Woese used his new rRNA comparison method to categorize and contrast different organisms. He compared a variety of species and happened upon a group of methanogens with rRNA vastly different from any known prokaryotes or eukaryotes. These methanogens were much more similar to each other than to other organisms, leading Woese to propose the new domain of Archaea. His experiments showed that the archaea were genetically more similar to eukaryotes than prokaryotes, even though they were more similar to prokaryotes in structure. This led to the conclusion that Archaea and Eukarya shared a common ancestor more recent than Eukarya and Bacteria. The development of the nucleus occurred after the split between Bacteria and this common ancestor. One property unique to archaea is the abundant use of ether-linked lipids in their cell membranes. Ether linkages are more chemically stable than the ester linkages found in bacteria and eukarya, which may be a contributing factor to the ability of many archaea to survive in extreme environments that place heavy stress on cell membranes, such as extreme heat and salinity. Comparative analysis of archaeal genomes has also identified several molecular conserved signature indels and signature proteins uniquely present in either all archaea or different main groups within archaea. Another unique feature of archaea, found in no other organisms, is methanogenesis (the metabolic production of methane). Methanogenic archaea play a pivotal role in ecosystems with organisms that derive energy from oxidation of methane, many of which are bacteria, as they are often a major source of methane in such environments and can play a role as primary producers. Methanogens also play a critical role in the carbon cycle, breaking down organic carbon into methane, which is also a major greenhouse gas. 4.7.2 Relationship To Bacteria The relationships among the three domains are of central importance for understanding the origin of life. Most of the metabolic pathways, which are the object of the majority of an organism’s genes, are common between Archaea and Bacteria, while most genes involved in genome expression are common between Archaea and Eukarya. Within prokaryotes, archaeal cell structure is most similar to that of gram-positive bacteria, largely because both have a single lipid bilayer and usually contain a thick sacculus (exoskeleton) of varying chemical composition. In some phylogenetic trees based upon different gene/protein sequences of prokaryotic homologs, the archaeal homologs are more closely related to those of gram-positive bacteria. Archaea and gram-positive bacteria also share conserved indels in a number of important proteins, such as Hsp70 and glutamine synthetase I; but the phylogeny of these genes was interpreted to reveal interdomain gene transfer, and might not reflect the organismal relationship(s). It has been proposed that the archaea evolved from gram-positive bacteria in response to antibiotic selection pressure. This is suggested by the observation that archaea are resistant to a wide variety of antibiotics that are produced primarily by gram-positive bacteria, and that these antibiotics act primarily on the genes that distinguish archaea from bacteria. The proposal is that the selective pressure towards resistance generated by the gram-positive antibiotics was eventually sufficient to cause extensive changes in many of the antibiotics’ target genes, and that these strains represented the common ancestors of present-day Archaea. The evolution of Archaea in response to antibiotic selection, or any other competitive selective pressure, could also explain their adaptation to extreme environments (such as high temperature or acidity) as the result of a search for unoccupied niches to escape from antibiotic-producing organisms; Cavalier-Smith has made a similar suggestion. This proposal is also supported by other work investigating protein structural relationships and studies that suggest that gram-positive bacteria may constitute the earliest branching lineages within the prokaryotes. 4.7.3 Relation To Eukaryotes The evolutionary relationship between archaea and eukaryotes remains unclear. Aside from the similarities in cell structure and function that are discussed below, many genetic trees group the two. Complicating factors include claims that the relationship between eukaryotes and the archaeal phylum Crenarchaeota is closer than the relationship between the Euryarchaeota and the phylum Crenarchaeota and the presence of archaea-like genes in certain bacteria, such as Thermotoga maritima, from horizontal gene transfer. The standard hypothesis states that the ancestor of the eukaryotes diverged early from the Archaea, and that eukaryotes arose through fusion of an archaean and eubacterium, which became the nucleus and cytoplasm; this hypothesis explains various genetic similarities but runs into difficulties explaining cell structure. An alternative hypothesis, the eocyte hypothesis, posits that Eukaryota emerged relatively late from the Archaea. A lineage of archaea discovered in 2015, Lokiarchaeum (of proposed new Phylum “Lokiarchaeota”), named for a hydrothermal vent called Loki’s Castle in the Arctic Ocean, was found to be the most closely related to eukaryotes known at that time. It has been called a transitional organism between prokaryotes and eukaryotes. Several sister phyla of “Lokiarchaeota” have since been found (“Thorarchaeota”, “Odinarchaeota”, “Heimdallarchaeota”), all together comprising a newly proposed supergroup Asgard, which may appear as a sister taxon to Proteoarchaeota. Details of the relation of Asgard members and eukaryotes are still under consideration, although, in January 2020, scientists reported that Candidatus Prometheoarchaeum syntrophicum, a type of Asgard archaea, may be a possible link between simple prokaryotic and complex eukaryotic microorganisms about two billion years ago. 4.7.4 Morphology Individual archaea range from 0.1 micrometers (μm) to over 15 μm in diameter, and occur in various shapes, commonly as spheres, rods, spirals or plates. Other morphologies in the Crenarchaeota include irregularly shaped lobed cells in Sulfolobus, needle-like filaments that are less than half a micrometer in diameter in Thermofilum, and almost perfectly rectangular rods in Thermoproteus and Pyrobaculum. Archaea in the genus Haloquadratum such as Haloquadratum walsbyi are flat, square specimens that live in hypersaline pools. These unusual shapes are probably maintained by both their cell walls and a prokaryotic cytoskeleton. Proteins related to the cytoskeleton components of other organisms exist in archaea, and filaments form within their cells, but in contrast with other organisms, these cellular structures are poorly understood. In Thermoplasma and Ferroplasma the lack of a cell wall means that the cells have irregular shapes, and can resemble amoebae. Some species form aggregates or filaments of cells up to 200 μm long. These organisms can be prominent in biofilms. Notably, aggregates of Thermococcus coalescens cells fuse together in culture, forming single giant cells. Archaea in the genus Pyrodictium produce an elaborate multicell colony involving arrays of long, thin hollow tubes called cannulae that stick out from the cells’ surfaces and connect them into a dense bush-like agglomeration. The function of these cannulae is not settled, but they may allow communication or nutrient exchange with neighbors. Multi-species colonies exist, such as the “string-of-pearls” community that was discovered in 2001 in a German swamp. Round whitish colonies of a novel Euryarchaeota species are spaced along thin filaments that can range up to 15 centimetres (5.9 in) long; these filaments are made of a particular bacteria species. 4.7.5 Structure, Composition Development, And Operation Archaea and bacteria have generally similar cell structure, but cell composition and organization set the archaea apart. Like bacteria, archaea lack interior membranes and organelles. Like bacteria, the cell membranes of archaea are usually bounded by a cell wall and they swim using one or more flagella. Structurally, archaea are most similar to gram-positive bacteria. Most have a single plasma membrane and cell wall, and lack a periplasmic space; the exception to this general rule is Ignicoccus, which possess a particularly large periplasm that contains membrane-bound vesicles and is enclosed by an outer membrane. 4.7.6 Cell Wall And Flagella Most archaea (but not Thermoplasma and Ferroplasma) possess a cell wall. In most archaea the wall is assembled from surface-layer proteins, which form an S-layer. An S-layer is a rigid array of protein molecules that cover the outside of the cell (like chain mail). This layer provides both chemical and physical protection, and can prevent macromolecules from contacting the cell membrane. Unlike bacteria, archaea lack peptidoglycan in their cell walls. Methanobacteriales do have cell walls containing pseudopeptidoglycan, which resembles eubacterial peptidoglycan in morphology, function, and physical structure, but pseudopeptidoglycan is distinct in chemical structure; it lacks D-amino acids and N-acetylmuramic acid, substituting the latter with N-Acetyltalosaminuronic acid. Archaeal flagella are known as archaella, that operate like bacterial flagella – their long stalks are driven by rotatory motors at the base. These motors are powered by a proton gradient across the membrane, but archaella are notably different in composition and development. The two types of flagella evolved from different ancestors. The bacterial flagellum shares a common ancestor with the type III secretion system, while archaeal flagella appear to have evolved from bacterial type IV pili. In contrast with the bacterial flagellum, which is hollow and assembled by subunits moving up the central pore to the tip of the flagella, archaeal flagella are synthesized by adding subunits at the base. 4.7.7 Membranes Archaeal membranes are made of molecules that are distinctly different from those in all other life forms, showing that archaea are related only distantly to bacteria and eukaryotes. In all organisms, cell membranes are made of molecules known as phospholipids. These molecules possess both a polar part that dissolves in water (the phosphate “head”), and a “greasy” non-polar part that does not (the lipid tail). These dissimilar parts are connected by a glycerol moiety. In water, phospholipids cluster, with the heads facing the water and the tails facing away from it. The major structure in cell membranes is a double layer of these phospholipids, which is called a lipid bilayer. The phospholipids of archaea are unusual in four ways: They have membranes composed of glycerol-ether lipids, whereas bacteria and eukaryotes have membranes composed mainly of glycerol-ester lipids. The difference is the type of bond that joins the lipids to the glycerol moiety; the two types are shown in yellow in the figure at the right. In ester lipids this is an ester bond, whereas in ether lipids this is an ether bond. The stereochemistry of the archaeal glycerol moiety is the mirror image of that found in other organisms. The glycerol moiety can occur in two forms that are mirror images of one another, called enantiomers. Just as a right hand does not fit easily into a left-handed glove, enantiomers of one type generally cannot be used or made by enzymes adapted for the other. The archaeal phospholipids are built on a backbone of sn-glycerol-1-phosphate, which is an enantiomer of sn-glycerol-3-phosphate, the phospholipid backbone found in bacteria and eukaryotes. This suggests that archaea use entirely different enzymes for synthesizing phospholipids as compared to bacteria and eukaryotes. Such enzymes developed very early in life’s history, indicating an early split from the other two domains. Archaeal lipid tails differ from those of other organisms in that they are based upon long isoprenoid chains with multiple side-branches, sometimes with cyclopropane or cyclohexane rings. By contrast, the fatty acids in the membranes of other organisms have straight chains without side branches or rings. Although isoprenoids play an important role in the biochemistry of many organisms, only the archaea use them to make phospholipids. These branched chains may help prevent archaeal membranes from leaking at high temperatures. In some archaea, the lipid bilayer is replaced by a monolayer. In effect, the archaea fuse the tails of two phospholipid molecules into a single molecule with two polar heads (a bolaamphiphile); this fusion may make their membranes more rigid and better able to resist harsh environments. For example, the lipids in Ferroplasma are of this type, which is thought to aid this organism’s survival in its highly acidic habitat. Figure 4.16: A comparison of the membrane structures of Archaea, Bacteria and Eukarya. Top, an archaeal phospholipid: 1, isoprene chains; 2, ether linkages; 3, L-glycerol moiety; 4, phosphate group. Middle, a bacterial or eukaryotic phospholipid: 5, fatty acid chains; 6, ester linkages; 7, D-glycerol moiety; 8, phosphate group. Bottom: 9, lipid bilayer of bacteria and eukaryotes; 10, lipid monolayer of some archaea. 4.7.8 Archaeal Metabolism Archaea exhibit a great variety of chemical reactions in their metabolism and use many sources of energy. These reactions are classified into nutritional groups, depending on energy and carbon sources. Some archaea obtain energy from inorganic compounds such as sulfur or ammonia (they are chemotrophs). These include nitrifiers, methanogens and anaerobic methane oxidisers. In these reactions one compound passes electrons to another (in a redox reaction), releasing energy to fuel the cell’s activities. One compound acts as an electron donor and one as an electron acceptor. The energy released is used to generate adenosine triphosphate (ATP) through chemiosmosis, the same basic process that happens in the mitochondrion of eukaryotic cells. Other groups of archaea use sunlight as a source of energy (they are phototrophs), but oxygen–generating photosynthesis does not occur in any of these organisms. Many basic metabolic pathways are shared among all forms of life; for example, archaea use a modified form of glycolysis (the Entner–Doudoroff pathway) and either a complete or partial citric acid cycle. These similarities to other organisms probably reflect both early origins in the history of life and their high level of efficiency. Table 4.3: Nutritional types in archaeal metabolism Nutritional Type Source of Energy Source of Carbon Examples  Phototrophs   Sunlight   Organic compounds   Halobacterium   Lithotrophs  Inorganic compounds  Organic compounds or carbon fixation  Ferroglobus, Methanobacteria or Pyrolobus   Organotrophs  Organic compounds   Organic compounds or carbon fixation   Pyrococcus, Sulfolobus or Methanosarcinales  Some Euryarchaeota are methanogens (archaea that produce methane as a result of metabolism) living in anaerobic environments, such as swamps. This form of metabolism evolved early, and it is even possible that the first free-living organism was a methanogen. A common reaction involves the use of carbon dioxide as an electron acceptor to oxidize hydrogen. Methanogenesis involves a range of coenzymes that are unique to these archaea, such as coenzyme M and methanofuran. Other organic compounds such as alcohols, acetic acid or formic acid are used as alternative electron acceptors by methanogens. These reactions are common in gut-dwelling archaea. Acetic acid is also broken down into methane and carbon dioxide directly, by acetotrophic archaea. These acetotrophs are archaea in the order Methanosarcinales, and are a major part of the communities of microorganisms that produce biogas. Other archaea use CO2 in the atmosphere as a source of carbon, in a process called carbon fixation (they are autotrophs). This process involves either a highly modified form of the Calvin cycle or another metabolic pathway called the 3-hydroxypropionate/ 4-hydroxybutyrate cycle. The Crenarchaeota also use the reverse Krebs cycle while the Euryarchaeota also use the reductive acetyl-CoA pathway. Carbon fixation is powered by inorganic energy sources. No known archaea carry out photosynthesis. Archaeal energy sources are extremely diverse, and range from the oxidation of ammonia by the Nitrosopumilales to the oxidation of hydrogen sulfide or elemental sulfur by species of Sulfolobus, using either oxygen or metal ions as electron acceptors. Phototrophic archaea use light to produce chemical energy in the form of ATP. In the Halobacteria, light-activated ion pumps like bacteriorhodopsin and halorhodopsin generate ion gradients by pumping ions out of and into the cell across the plasma membrane. The energy stored in these electrochemical gradients is then converted into ATP by ATP synthase. This process is a form of photophosphorylation. The ability of these light-driven pumps to move ions across membranes depends on light-driven changes in the structure of a retinol cofactor buried in the center of the protein. 4.7.9 Archaeal Genetics Archaea usually have a single circular chromosome, with as many as 5,751,492 base pairs in Methanosarcina acetivorans, the largest known archaeal genome. The tiny 490,885 base-pair genome of Nanoarchaeum equitans is one-tenth of this size and the smallest archaeal genome known; it is estimated to contain only 537 protein-encoding genes. Smaller independent pieces of DNA, called plasmids, are also found in archaea. Plasmids may be transferred between cells by physical contact, in a process that may be similar to bacterial conjugation. Archaea are genetically distinct from bacteria and eukaryotes, with up to 15% of the proteins encoded by any one archaeal genome being unique to the domain, although most of these unique genes have no known function. Of the remainder of the unique proteins that have an identified function, most belong to the Euryarchaea and are involved in methanogenesis. The proteins that archaea, bacteria and eukaryotes share form a common core of cell function, relating mostly to transcription, translation, and nucleotide metabolism. Other characteristic archaeal features are the organization of genes of related function – such as enzymes that catalyze steps in the same metabolic pathway into novel operons, and large differences in tRNA genes and their aminoacyl tRNA synthetases. Transcription in archaea more closely resembles eukaryotic than bacterial transcription, with the archaeal RNA polymerase being very close to its equivalent in eukaryotes, while archaeal translation shows signs of both bacterial and eukaryotic equivalents. Although archaea have only one type of RNA polymerase, its structure and function in transcription seems to be close to that of the eukaryotic RNA polymerase II, with similar protein assemblies (the general transcription factors) directing the binding of the RNA polymerase to a gene’s promoter, but other archaeal transcription factors are closer to those found in bacteria. Post-transcriptional modification is simpler than in eukaryotes, since most archaeal genes lack introns, although there are many introns in their transfer RNA and ribosomal RNA genes, and introns may occur in a few protein-encoding genes. 4.7.10 Archaeal Ecology Archaea exist in a broad range of habitats, and are now recognized as a major part of global ecosystems, and may represent about 20% of microbial cells in the oceans. However, the first-discovered archaeans were extremophiles. Indeed, some archaea survive high temperatures, often above 100 °C (212 °F), as found in geysers, black smokers, and oil wells. Other common habitats include very cold habitats and highly saline, acidic, or alkaline water, but archaea include mesophiles that grow in mild conditions, in swamps and marshland, sewage, the oceans, the intestinal tract of animals, and soils. Extremophile archaea are members of four main physiological groups. These are the halophiles, thermophiles, alkaliphiles, and acidophiles. These groups are not comprehensive or phylum-specific, nor are they mutually exclusive, since some archaea belong to several groups. Nonetheless, they are a useful starting point for classification. Halophiles, including the genus Halobacterium, live in extremely saline environments such as salt lakes and outnumber their bacterial counterparts at salinities greater than 20–25%. Thermophiles grow best at temperatures above 45 °C (113 °F), in places such as hot springs; hyperthermophilic archaea grow optimally at temperatures greater than 80 °C (176 °F). The archaeal Methanopyrus kandleri Strain 116 can even reproduce at 122 °C (252 °F), the highest recorded temperature of any organism. Other archaea exist in very acidic or alkaline conditions. For example, one of the most extreme archaean acidophiles is Picrophilus torridus, which grows at pH 0, which is equivalent to thriving in 1.2 molar sulfuric acid. This resistance to extreme environments has made archaea the focus of speculation about the possible properties of extraterrestrial life. Some extremophile habitats are not dissimilar to those on Mars, leading to the suggestion that viable microbes could be transferred between planets in meteorites. Recently, several studies have shown that archaea exist not only in mesophilic and thermophilic environments but are also present, sometimes in high numbers, at low temperatures as well. For example, archaea are common in cold oceanic environments such as polar seas. Even more significant are the large numbers of archaea found throughout the world’s oceans in non-extreme habitats among the plankton community (as part of the picoplankton). Although these archaea can be present in extremely high numbers (up to 40% of the microbial biomass), almost none of these species have been isolated and studied in pure culture. Consequently, our understanding of the role of archaea in ocean ecology is rudimentary, so their full influence on global biogeochemical cycles remains largely unexplored. Some marine Crenarchaeota are capable of nitrification, suggesting these organisms may affect the oceanic nitrogen cycle, although these oceanic Crenarchaeota may also use other sources of energy. Vast numbers of archaea are also found in the sediments that cover the sea floor, with these organisms making up the majority of living cells at depths over 1 meter below the ocean bottom. It has been demonstrated that in all oceanic surface sediments (from 1000- to 10,000-m water depth), the impact of viral infection is higher on archaea than on bacteria and virus-induced lysis of archaea accounts for up to one-third of the total microbial biomass killed, resulting in the release of ~0.3 to 0.5 gigatons of carbon per year globally. 4.7.11 Significance In Technology And Industry Extremophile archaea, particularly those resistant either to heat or to extremes of acidity and alkalinity, are a source of enzymes that function under these harsh conditions. These enzymes have found many uses. For example, thermostable DNA polymerases, such as the Pfu DNA polymerase from Pyrococcus furiosus, revolutionized molecular biology by allowing the polymerase chain reaction to be used in research as a simple and rapid technique for cloning DNA. In industry, amylases, galactosidases and pullulanases in other species of Pyrococcus that function at over 100 °C (212 °F) allow food processing at high temperatures, such as the production of low lactose milk and whey. Enzymes from these thermophilic archaea also tend to be very stable in organic solvents, allowing their use in environmentally friendly processes in green chemistry that synthesize organic compounds. This stability makes them easier to use in structural biology. Consequently, the counterparts of bacterial or eukaryotic enzymes from extremophile archaea are often used in structural studies. In contrast with the range of applications of archaean enzymes, the use of the organisms themselves in biotechnology is less developed. Methanogenic archaea are a vital part of sewage treatment, since they are part of the community of microorganisms that carry out anaerobic digestion and produce biogas. In mineral processing, acidophilic archaea display promise for the extraction of metals from ores, including gold, cobalt and copper. Archaea host a new class of potentially useful antibiotics. A few of these archaeocins have been characterized, but hundreds more are believed to exist, especially within Haloarchaea and Sulfolobus. These compounds differ in structure from bacterial antibiotics, so they may have novel modes of action. In addition, they may allow the creation of new selectable markers for use in archaeal molecular biology. "],["an-introduction-to-eukaryotic-cells-and-microorganisms.html", "5 An Introduction To Eukaryotic Cells And Microorganisms 5.1 Characteristic Features Of Eukaryotic Cells 5.2 Origin Of Eukaryotic Cells 5.3 Protists 5.4 Protozoa 5.5 Flagellates 5.6 Ciliates 5.7 Amoebozoa 5.8 Algae 5.9 Slime Molds", " 5 An Introduction To Eukaryotic Cells And Microorganisms Most living things that are visible to the naked eye in their adult form are eukaryotes, including humans. Eukaryotes belong to the domain Eukaryota or Eukarya; their name comes from the Greek εὖ (eu, “well” or “good”) and κάρυον (karyon, “nut” or “kernel”). The domain Eukaryota makes up one of the domains of life in the three-domain system; the two other domains are Bacteria and Archaea (together known as prokaryotes). Eukaryotes represent a tiny minority of the number of living organisms; however, due to their generally much larger size, their collective worldwide biomass is estimated to be about equal to that of prokaryotes. Eukaryotes evolved approximately 1.6–2.1 billion years ago, during the Proterozoic eon. However, many eukaryotes are also microorganisms. Unlike bacteria and archaea, eukaryotes contain organelles such as the cell nucleus, the Golgi apparatus and mitochondria in their cells. The nucleus is an organelle that houses the DNA that makes up a cell’s genome. DNA (Deoxyribonucleic acid) itself is arranged in complex chromosomes. Mitochondria are organelles vital in metabolism as they are the site of the citric acid cycle and oxidative phosphorylation. They evolved from symbiotic bacteria and retain a remnant genome. Like bacteria, plant cells have cell walls, and contain organelles such as chloroplasts in addition to the organelles in other eukaryotes. Chloroplasts produce energy from light by photosynthesis, and were also originally symbiotic bacteria. Animals, plants, and fungi are the most familiar eukaryotes; other eukaryotes are sometimes called protists. Unicellular eukaryotes consist of a single cell throughout their life cycle. This qualification is significant since most multicellular eukaryotes consist of a single cell called a zygote only at the beginning of their life cycles. Microbial eukaryotes can be either haploid or diploid, and some organisms have multiple cell nuclei. Unicellular eukaryotes usually reproduce asexually by mitosis under favorable conditions. However, under stressful conditions such as nutrient limitations and other conditions associated with DNA damage, they tend to reproduce sexually by meiosis and syngamy. Figure 5.1: Cartoon of the structure of a typical animal cell Figure 5.2: Cartoon of the structure of a typical plant cell Eukaryotes can reproduce both asexually through mitosis and sexually through meiosis and gamete fusion. In mitosis, one cell divides to produce two genetically identical cells. In meiosis, DNA replication is followed by two rounds of cell division to produce four haploid daughter cells. These act as sex cells (gametes). Each gamete has just one set of chromosomes, each a unique mix of the corresponding pair of parental chromosomes resulting from genetic recombination during meiosis. Plants, animals, fungi, and protists are all eukaryotic. These cells are about fifteen times wider than a typical prokaryote and can be as much as a thousand times greater in volume. The main distinguishing feature of eukaryotes as compared to prokaryotes is compartmentalization: the presence of membrane-bound organelles (compartments) in which specific activities take place. Most important among these is a cell nucleus, an organelle that houses the cell’s DNA. This nucleus gives the eukaryote its name, which means “true kernel (nucleus)”. Other differences include: The eukaryotic DNA is organized in one or more linear molecules, called chromosomes, which are associated with histone proteins. All chromosomal DNA is stored in the cell nucleus, separated from the cytoplasm by a membrane. Some eukaryotic organelles such as mitochondria also contain some DNA. Many eukaryotic cells are ciliated with primary cilia. Primary cilia play important roles in chemosensation, mechanosensation, and thermosensation. Each cilium may thus be “viewed as a sensory cellular antennae that coordinates a large number of cellular signaling pathways, sometimes coupling the signaling to ciliary motility or alternatively to cell division and differentiation.” Motile eukaryotes can move using motile cilia or flagella. Motile cells are absent in conifers and flowering plants. Eukaryotic flagella are more complex than those of prokaryotes. Table 5.1: Comparison of the main features of prokaryotes and eukaryotes. Prokaryotes Eukaryotes Typical organisms bacteria, archaea protists; fungi; plants; animals Typical size ~1–5 µm ~10–100 µm Type of nucleus nucleoid region; no true nucleus true nucleus with double membrane DNA circular (usually) linear molecules (chromosomes) with histone proteins RNA/protein synthesis coupled in the cytoplasm RNA synthesis in the nucleus; protein synthesis in the cytoplasm Ribosomes 50S and 30S 60S and 40S Cytoplasmic structure very few structures highly structured by endomembranes and a cytoskeleton Cell movement flagella made of flagellin flagella and cilia containing microtubules; lamellipodia and filopodia containing actin Mitochondria none one to several thousand Chloroplasts none in algae and plants Organization usually single cells single cells, colonies, higher multicellular organisms with specialized cells Cell division binary fission (simple division) mitosis (fission or budding); meiosis Chromosomes single chromosome more than one chromosome Membranes cell membrane Cell membrane and membrane-bound organelles 5.1 Characteristic Features Of Eukaryotic Cells All cells, whether prokaryotic or eukaryotic, have a membrane that envelops the cell, regulates what moves in and out (selectively permeable), and maintains the electric potential of the cell. Inside the membrane, the cytoplasm takes up most of the cell’s volume. All cells (except red blood cells which lack a cell nucleus and most organelles to accommodate maximum space for hemoglobin) possess DNA, the hereditary material of genes, and RNA, containing the information necessary to build various proteins such as enzymes, the cell’s primary machinery. There are also other kinds of biomolecules in cells. This article lists these primary cellular components, then briefly describes their function. 5.1.1 The Cell Membrane The cell membrane, or plasma membrane, is a biological membrane that surrounds the cytoplasm of a cell. In animals, the plasma membrane is the outer boundary of the cell, while in plants and prokaryotes it is usually covered by a cell wall. This membrane serves to separate and protect a cell from its surrounding environment and is made mostly from a double layer of phospholipids, which are amphiphilic (partly hydrophobic and partly hydrophilic). Hence, the layer is called a phospholipid bilayer, or sometimes a fluid mosaic membrane. Embedded within this membrane is a macromolecular structure called the porosome the universal secretory portal in cells and a variety of protein molecules that act as channels andpumps that move different molecules into and out of the cell. The membrane is semi-permeable, and selectively permeable, in that it can either let a substance (molecule or ion) pass through freely, pass through to a limited extent or not pass through at all. Cell surface membranes also contain receptor proteins that allow cells to detect external signaling molecules such as hormones. Figure 5.3: Detailed diagram of lipid bilayer cell membrane 5.1.2 The Cytoskeleton The cytoskeleton is a complex, dynamic network of interlinking protein filaments present in the cytoplasm of all cells, including bacteria and archaea. It extends from the cell nucleus to the cell membrane and is composed of similar proteins in the various organisms. In eukaryotes, it is composed of three main components, microfilaments, intermediate filaments and microtubules, and these are all capable of rapid growth or disassembly dependent on the cell’s requirements. A multitude of functions can be performed by the cytoskeleton. Its primary function is to give the cell its shape and mechanical resistance to deformation, and through association with extracellular connective tissue and other cells it stabilizes entire tissues. The cytoskeleton can also contract, thereby deforming the cell and the cell’s environment and allowing cells to migrate. Moreover, it is involved in many cell signaling pathways and in the uptake of extracellular material (endocytosis), the segregation of chromosomes during cellular division, the cytokinesis stage of cell division, as scaffolding to organize the contents of the cell in space and in intracellular transport (for example, the movement of vesicles and organelles within the cell) and can be a template for the construction of a cell wall. Furthermore, it can form specialized structures, such as flagella, cilia, lamellipodia and podosomes. The structure, function and dynamic behavior of the cytoskeleton can be very different, depending on organism and cell type. Even within one cell, the cytoskeleton can change through association with other proteins and the previous history of the network. A large-scale example of an action performed by the cytoskeleton is muscle contraction. This is carried out by groups of highly specialized cells working together. A main component in the cytoskeleton that helps show the true function of this muscle contraction is the microfilament. Microfilaments are composed of the most abundant cellular protein known as actin. During contraction of a muscle, within each muscle cell, myosin molecular motors collectively exert forces on parallel actin filaments. Muscle contraction starts from nerve impulses which then causes increased amounts of calcium to be released from the sarcoplasmic reticulum. Increases in calcium in the cytosol allows muscle contraction to begin with the help of two proteins, tropomyosin and troponin. Tropomyosin inhibits the interaction between actin and myosin, while troponin senses the increase in calcium and releases the inhibition. This action contracts the muscle cell, and through the synchronous process in many muscle cells, the entire muscle. Eukaryotic cells contain three main kinds of cytoskeletal filaments: microfilaments, microtubules, and intermediate filaments. Each type is formed by the polymerization of a distinct type of protein subunit and has its own characteristic shape and intracellular distribution. Microfilaments are polymers of the protein actin and are 7 nm in diameter. Microtubules are composed of tubulin and are 25 nm in diameter. Intermediate filaments are composed of various proteins, depending on the type of cell in which they are found; they are normally 8-12 nm in diameter. The cytoskeleton provides the cell with structure and shape, and by excluding macromolecules from some of the cytosol, it adds to the level of macromolecular crowding in this compartment. Cytoskeletal elements interact extensively and intimately with cellular membranes. Figure 5.4: The eukaryotic cytoskeleton. Actin filaments are shown in red, and microtubules composed of beta tubulin are in green. Microfilaments, also known as actin filaments, are composed of linear polymers of G-actin proteins, and generate force when the growing (plus) end of the filament pushes against a barrier, such as the cell membrane. They also act as tracks for the movement of myosin molecules that affix to the microfilament and “walk” along them. In general, the major component or protein of microfilaments are actin. The G-actin monomer combines to form a polymer which continues to form the microfilament (actin filament). These subunits then assemble into two chains that intertwine into what are called F-actin chains. Myosin motoring along F-actin filaments generates contractile forces in so-called actomyosin fibers, both in muscle as well as most non-muscle cell types. Figure 5.5: Cartoon of the structure of a microfilament, which creates the structure in the cytoskeleton of an eukaryotic cell. Intermediate filaments are a part of the cytoskeleton of many eukaryotic cells. These filaments, averaging 10 nanometers in diameter, are more stable (strongly bound) than microfilaments, and heterogeneous constituents of the cytoskeleton. Like actin filaments, they function in the maintenance of cell-shape by bearing tension (microtubules, by contrast, resist compression but can also bear tension during mitosis and during the positioning of the centrosome). Intermediate filaments organize the internal tridimensional structure of the cell, anchoring organelles and serving as structural components of the nuclear lamina. They also participate in some cell-cell and cell-matrix junctions. Nuclear lamina exist in all animals and all tissues. Some animals like the fruit fly do not have any cytoplasmic intermediate filaments. In those animals that express cytoplasmic intermediate filaments, these are tissue specific. Keratin intermediate filaments in epithelial cells provide protection for different mechanical stresses the skin may endure. They also provide protection for organs against metabolic, oxidative, and chemical stresses. Strengthening of epithelial cells with these intermediate filaments may prevent onset of apoptosis, or cell death, by reducing the probability of stress. Figure 5.6: Cartoon of the the structure of an intermediate filament. Microtubules are hollow cylinders about 23 nm in diameter (lumen diameter of approximately 15 nm), most commonly comprising 13 protofilaments that, in turn, are polymers of alpha and beta tubulin. They have a very dynamic behavior, binding GTP for polymerization. They are commonly organized by the centrosome. Figure 5.7: Cartoon of the the structure of a microtubule. In nine triplet sets (star-shaped), they form the centrioles, and in nine doublets oriented about two additional microtubules (wheel-shaped), they form cilia and flagella. The latter formation is commonly referred to as a “9+2” arrangement, wherein each doublet is connected to another by the protein dynein. As both flagella and cilia are structural components of the cell, and are maintained by microtubules, they can be considered part of the cytoskeleton. There are two types of cilia: motile and non-motile cilia. Cilia are short and more numerous than flagella. The motile cilia have a rhythmic waving or beating motion compared to the non-motile cilia which receive sensory information for the cell; processing signals from the other cells or the fluids surrounding it. Additionally, the microtubules control the beating (movement) of the cilia and flagella. Also, the dynein arms attached to the microtubules function as the molecular motors. The motion of the cilia and flagella is created by the microtubules sliding past one another, which requires ATP. Cytoplasmic streaming, also known as cyclosis, is the active movement of a cell’s contents along the components of the cytoskeleton. While mainly seen in plants, all cell types use this process for transportation of waste, nutrients, and organelles to other parts of the cell. Plant and algae cells are generally larger than many other cells; so cytoplasmic streaming is important in these types of cells. This is because the cell’s extra volume requires cytoplasmic streaming in order to move organelles throughout the entire cell. Organelles move along microfilaments in the cytoskeleton driven by myosin motors binding and pushing along actin filament bundles. 5.1.3 The Genetic Material Two different kinds of genetic material exist: deoxyribonucleic acid (DNA) and ribonucleic acid (RNA). Cells use DNA for their long-term information storage. The biological information contained in an organism is encoded in its DNA sequence. RNA is used for information transport (e.g., mRNA) and enzymatic functions (e.g., ribosomal RNA). Transfer RNA (tRNA) molecules are used to add amino acids during protein translation. Prokaryotic genetic material is organized in a simple circular bacterial chromosome in the nucleoid region of the cytoplasm. Eukaryotic genetic material is divided into different, linear molecules called chromosomes inside a discrete nucleus, usually with additional genetic material in some organelles like mitochondria and chloroplasts (see endosymbiotic theory). A human cell has genetic material contained in the cell nucleus (the nuclear genome) and in the mitochondria (the mitochondrial genome). In humans the nuclear genome is divided into 46 linear DNA molecules called chromosomes, including 22 homologous chromosome pairs and a pair of sex chromosomes. The mitochondrial genome is a circular DNA molecule distinct from the nuclear DNA. Although the mitochondrial DNA is very small compared to nuclear chromosomes, it codes for 13 proteins involved in mitochondrial energy production and specific tRNAs. Foreign genetic material (most commonly DNA) can also be artificially introduced into the cell by a process called transfection. This can be transient, if the DNA is not inserted into the cell’s genome, or stable, if it is. Certain viruses also insert their genetic material into the genome. 5.1.4 Organelles of Eukaryotic Cells Organelles are parts of the cell which are adapted and/or specialized for carrying out one or more vital functions, analogous to the organs of the human body (such as the heart, lung, and kidney, with each organ performing a different function). Both eukaryotic and prokaryotic cells have organelles, but prokaryotic organelles are generally simpler and are not membrane-bound. There are several types of organelles in a cell. Some (such as the nucleus and golgi apparatus) are typically solitary, while others (such as mitochondria, chloroplasts, peroxisomes and lysosomes) can be numerous (hundreds to thousands). The cytosol is the gelatinous fluid that fills the cell and surrounds the organelles. Cell nucleus: A cell’s information center, the cell nucleus is the most conspicuous organelle found in a eukaryotic cell. It houses the cell’s chromosomes, and is the place where almost all DNA replication and RNA synthesis (transcription) occur. The nucleus is spherical and separated from the cytoplasm by a double membrane called the nuclear envelope. The nuclear envelope isolates and protects a cell’s DNA from various molecules that could accidentally damage its structure or interfere with its processing. During processing, DNA is transcribed, or copied into a special RNA, called messenger RNA (mRNA). This mRNA is then transported out of the nucleus, where it is translated into a specific protein molecule. The nucleolus is a specialized region within the nucleus where ribosome subunits are assembled. In prokaryotes, DNA processing takes place in the cytoplasm. Mitochondria and Chloroplasts: generate energy for the cell.Mitochondria are self-replicating organelles that occur in various numbers, shapes, and sizes in the cytoplasm of all eukaryotic cells. Respiration occurs in the cell mitochondria, which generate the cell’s energy by oxidative phosphorylation, using oxygen to release energy stored in cellular nutrients (typically pertaining to glucose) to generate ATP. Mitochondria multiply by binary fission, like prokaryotes. Chloroplasts can only be found in plants and algae, and they capture the sun’s energy to make carbohydrates through photosynthesis. Endoplasmic reticulum: The endoplasmic reticulum (ER) is a transport network for molecules targeted for certain modifications and specific destinations, as compared to molecules that float freely in the cytoplasm. The ER has two forms: the rough ER, which has ribosomes on its surface that secrete proteins into the ER, and the smooth ER, which lacks ribosomes. The smooth ER plays a role in calcium sequestration and release. Golgi apparatus: The primary function of the Golgi apparatus is to process and package the macromolecules such as proteins and lipids that are synthesized by the cell. Lysosomes and Peroxisomes: Lysosomes contain digestive enzymes (acid hydrolases). They digest excess or worn-out organelles, food particles, and engulfed viruses or bacteria. Peroxisomes have enzymes that rid the cell of toxic peroxides. The cell could not house these destructive enzymes if they were not contained in a membrane-bound system. Centrosome: the cytoskeleton organiser: The centrosome produces the microtubules of a cell – a key component of the cytoskeleton. It directs the transport through the ER and the Golgi apparatus. Centrosomes are composed of two centrioles, which separate during cell division and help in the formation of the mitotic spindle. A single centrosome is present in the animal cells. They are also found in some fungi and algae cells. Vacuoles: Vacuoles sequester waste products and in plant cells store water. They are often described as liquid filled space and are surrounded by a membrane. Some cells, most notably Amoeba, have contractile vacuoles, which can pump water out of the cell if there is too much water. The vacuoles of plant cells and fungal cells are usually larger than those of animal cells. 5.1.5 The Cell Nucleus In cell biology, the nucleus (pl. nuclei; from Latin nucleus or nuculeus, meaning kernel or seed) is a membrane-bound organelle found in eukaryotic cells. Eukaryotes usually have a single nucleus, but a few cell types, such as mammalian red blood cells, have no nuclei, and a few others including osteoclasts have many. Inside its fully enclosed nuclear membrane, it contains the majority of the cell’s genetic material. This material is organized as DNA molecules, along with a variety of proteins, to form chromosomes. Figure 5.8: HeLa cells stained for nuclear DNA with the blue fluorescent Hoechst dye. The central and rightmost cell are in interphase, thus their entire nuclei are labeled. On the left, a cell is going through mitosis and its DNA has condensed. HeLa is an immortal cell line used in scientific research. It is the oldest and most commonly used human cell line. The line is derived from cervical cancer cells taken on February 8, 1951, from Henrietta Lacks, a 31-year-old African-American mother of five, who died of cancer on October 4, 1951. The cell line was found to be remarkably durable and prolific, which allows it to be used extensively in scientific study. The cells from Lacks’ cancerous cervical tumor were taken without her knowledge or consent, which was common practice at the time. Cell biologist George Otto Gey found that they could be kept alive, and developed a cell line. Previously, cells cultured from other human cells would only survive for a few days. Cells from Lacks’ tumor behaved differently. As was custom for Gey’s lab assistant, she labeled the culture ‘HeLa’, the first two letters of the patient’s first and last name; this became the name of the cell line. HeLa was the subject of a 2010 book by Rebecca Skloot, The Immortal Life of Henrietta Lacks, investigating the historical context of the cell line and how the Lacks family was involved its use. The nucleus was the first organelle to be discovered. What is most likely the oldest preserved drawing dates back to the early microscopist Antonie van Leeuwenhoek (1632–1723). He observed a “lumen”, the nucleus, in the red blood cells of salmon (Figure 5.9). Unlike mammalian red blood cells, those of other vertebrates still contain nuclei. Figure 5.9: Oldest known depiction of cells and their nuclei by Antonie van Leeuwenhoek, 1719 The cell nucleus contains all of the cell’s genome, except for a small fraction of mitochondrial DNA, organized as multiple long linear DNA molecules in a complex with a large variety of proteins, such as histones, to form chromosomes. The genes within these chromosomes are structured in such a way to promote cell function. The nucleus maintains the integrity of genes and controls the activities of the cell by regulating gene expression—the nucleus is, therefore, the control center of the cell. The main structures making up the nucleus are the nuclear envelope, a double membrane that encloses the entire organelle and isolates its contents from the cellular cytoplasm, and the nuclear matrix (which includes the nuclear lamina), a network within the nucleus that adds mechanical support, much like the cytoskeleton, which supports the cell as a whole. Figure 5.10: An electron micrograph of a cell nucleus, showing the darkly stained nucleolus Figure 5.11: The eukaryotic cell nucleus. Visible in this diagram are the ribosome-studded double membranes of the nuclear envelope, the DNA (complexed as chromatin), and the nucleolus. Within the cell nucleus is a viscous liquid called nucleoplasm, similar to the cytoplasm found outside the nucleus. Because the nuclear envelope is impermeable to large molecules, nuclear pores are required to regulate nuclear transport of molecules across the envelope. The pores cross both nuclear membranes, providing a channel through which larger molecules must be actively transported by carrier proteins while allowing free movement of small molecules and ions. Movement of large molecules such as proteins and RNA through the pores is required for both gene expression and the maintenance of chromosomes. Although the interior of the nucleus does not contain any membrane-bound subcompartments, its contents are not uniform, and a number of nuclear bodies exist, made up of unique proteins, RNA molecules, and particular parts of the chromosomes. The best-known of these is the nucleolus, which is mainly involved in the assembly of ribosomes. After being produced in the nucleolus, ribosomes are exported to the cytoplasm where they translate mRNA. Figure 5.12: A cross section of a nuclear pore on the surface of the nuclear envelope (1). Other diagram labels show (2) the outer ring, (3) spokes, (4) basket, and (5) filaments. The nuclear envelope, otherwise known as nuclear membrane, consists of two cellular membranes, an inner and an outer membrane, arranged parallel to one another and separated by 10 to 50 nanometres (nm). The nuclear envelope completely encloses the nucleus and separates the cell’s genetic material from the surrounding cytoplasm, serving as a barrier to prevent macromolecules from diffusing freely between the nucleoplasm and the cytoplasm. The outer nuclear membrane is continuous with the membrane of the rough endoplasmic reticulum (RER), and is similarly studded with ribosomes. The space between the membranes is called the perinuclear space and is continuous with the RER lumen. Nuclear pores, which provide aqueous channels through the envelope, are composed of multiple proteins, collectively referred to as nucleoporins. The pores are about 125 million daltons in molecular weight and consist of around 50 (in yeast) to several hundred proteins (in vertebrates). The pores are 100 nm in total diameter; however, the gap through which molecules freely diffuse is only about 9 nm wide, due to the presence of regulatory systems within the center of the pore. This size selectively allows the passage of small water-soluble molecules while preventing larger molecules, such as nucleic acids and larger proteins, from inappropriately entering or exiting the nucleus. These large molecules must be actively transported into the nucleus instead. The nucleus of a typical mammalian cell will have about 3000 to 4000 pores throughout its envelope, each of which contains an eightfold-symmetric ring-shaped structure at a position where the inner and outer membranes fuse. Attached to the ring is a structure called the nuclear basket that extends into the nucleoplasm, and a series of filamentous extensions that reach into the cytoplasm. Both structures serve to mediate binding to nuclear transport proteins. Most proteins, ribosomal subunits, and some DNAs are transported through the pore complexes in a process mediated by a family of transport factors known as karyopherins. Those karyopherins that mediate movement into the nucleus are also called importins, whereas those that mediate movement out of the nucleus are called exportins. Most karyopherins interact directly with their cargo, although some use adaptor proteins. Steroid hormones such as cortisol and aldosterone, as well as other small lipid-soluble molecules involved in intercellular signaling, can diffuse through the cell membrane and into the cytoplasm, where they bind nuclear receptor proteins that are trafficked into the nucleus. There they serve as transcription factors when bound to their ligand; in the absence of a ligand, many such receptors function as histone deacetylases that repress gene expression The cell nucleus contains the majority of the cell’s genetic material in the form of multiple linear DNA molecules organized into structures called chromosomes. Each human cell contains roughly two meters of DNA. During most of the cell cycle these are organized in a DNA-protein complex known as chromatin, and during cell division the chromatin can be seen to form the well-defined chromosomes familiar from a karyotype. A small fraction of the cell’s genes are located instead in the mitochondria. There are two types of chromatin. Euchromatin is the less compact DNA form, and contains genes that are frequently expressed by the cell. The other type, heterochromatin, is the more compact form, and contains DNA that is infrequently transcribed. This structure is further categorized into facultative heterochromatin, consisting of genes that are organized as heterochromatin only in certain cell types or at certain stages of development, and constitutive heterochromatin that consists of chromosome structural components such as telomeres and centromeres. During interphase the chromatin organizes itself into discrete individual patches, called chromosome territories. Active genes, which are generally found in the euchromatic region of the chromosome, tend to be located towards the chromosome’s territory boundary. The nucleolus is the largest of the discrete densely stained, membraneless structures known as nuclear bodies found in the nucleus. It forms around tandem repeats of rDNA, DNA coding for ribosomal RNA (rRNA). These regions are called nucleolar organizer regions (NOR). The main roles of the nucleolus are to synthesize rRNA and assemble ribosomes. The structural cohesion of the nucleolus depends on its activity, as ribosomal assembly in the nucleolus results in the transient association of nucleolar components, facilitating further ribosomal assembly, and hence further association. This model is supported by observations that inactivation of rDNA results in intermingling of nucleolar structures. In the first step of ribosome assembly, a protein called RNA polymerase I transcribes rDNA, which forms a large pre-rRNA precursor. This is cleaved into the subunits 5.8S, 18S, and 28S rRNA. The transcription, post-transcriptional processing, and assembly of rRNA occurs in the nucleolus, aided by small nucleolar RNA (snoRNA) molecules, some of which are derived from spliced introns from messenger RNAs encoding genes related to ribosomal function. The assembled ribosomal subunits are the largest structures passed through the nuclear pores. When observed under the electron microscope, the nucleolus can be seen to consist of three distinguishable regions: the innermost fibrillar centers (FCs), surrounded by the dense fibrillar component (DFC) (that contains fibrillarin and nucleolin), which in turn is bordered by the granular component (GC) (that contains the protein nucleophosmin). Transcription of the rDNA occurs either in the FC or at the FC-DFC boundary, and, therefore, when rDNA transcription in the cell is increased, more FCs are detected. Most of the cleavage and modification of rRNAs occurs in the DFC, while the latter steps involving protein assembly onto the ribosomal subunits occur in the GC. 5.1.6 The Mitochondria The mitochondrion (plural mitochondria) is a semi autonomous double-membrane-bound organelle found in most eukaryotic organisms. Some cells in some multicellular organisms may, however, lack mitochondria (for example, mature mammalian red blood cells). Figure 5.13: Two mitochondria from mammalian lung tissue displaying their matrix and membranes as shown by electron microscopy. The word mitochondrion comes from the Greek μίτος, mitos, “thread”, and χονδρίον, chondrion, “granule” or “grain-like”. Mitochondria generate most of the cell’s supply of adenosine triphosphate (ATP), used as a source of chemical energy. A mitochondrion is thus termed the powerhouse of the cell. In addition to supplying cellular energy, mitochondria are involved in other tasks, such as signaling, cellular differentiation, and cell death, as well as maintaining control of the cell cycle and cell growth. The organelle is composed of compartments that carry out specialized functions. These compartments or regions include the outer membrane, the intermembrane space, the inner membrane, and the cristae and matrix. Figure 5.14: Cartoon of the structure of a mitochondrion. Components of a typical mitochondrion 1 Outer membrane 1.1 Porin 2 Intermembrane space 2.1 Intracristal space 2.2 Peripheral space 3 Lamella 3.1 Inner membrane 3.11 Inner boundary membrane 3.12 Cristal membrane 3.2 Matrix 3.3 Cristæ 4 Mitochondrial DNA 5 Matrix granule 6 Ribosome 7 ATP synthase Although most of a cell’s DNA is contained in the cell nucleus, the mitochondrion has its own independent genome (“mitogenome”) that shows substantial similarity to bacterial genomes. Mitochondrial proteins (proteins transcribed from mitochondrial DNA) vary depending on the tissue and the species. The endosymbiotic hypothesis suggests that mitochondria were originally prokaryotic cells, capable of implementing oxidative mechanisms that were not possible for eukaryotic cells; they became endosymbionts living inside the eukaryote. The endosymbiotic hypothesis suggests that mitochondria descended from bacteria that somehow survived endocytosis by another cell, and became incorporated into the cytoplasm. The ability of these bacteria to conduct respiration in host cells that had relied on glycolysis and fermentation would have provided a considerable evolutionary advantage. This symbiotic relationship probably developed 1.7 to 2 billion years ago. A mitochondrion contains outer and inner membranes composed of phospholipid bilayers and proteins. The two membranes have different properties. Because of this double-membraned organization, there are five distinct parts to a mitochondrion. They are: the outer mitochondrial membrane, the intermembrane space (the space between the outer and inner membranes), the inner mitochondrial membrane, the cristae space (formed by infoldings of the inner membrane), and the matrix (space within the inner membrane). The inner mitochondrial membrane contains proteins with three types of functions: Those that perform the electron transport chain redox reactions ATP synthase, which generates ATP in the matrix Specific transport proteins that regulate metabolite passage into and out of the mitochondrial matrix The most prominent roles of mitochondria are to produce the energy currency of the cell, ATP (i.e., phosphorylation of ADP), through respiration, and to regulate cellular metabolism. The central set of reactions involved in ATP production are collectively known as the citric acid cycle, or the Krebs cycle. However, the mitochondrion has many other functions in addition to the production of ATP. Figure 5.15: A fluorescent image of an endothelial cell. Nuclei are stained blue, mitochondria are stained red, and microfilaments are stained green. 5.1.7 The Chloroplasts Chloroplasts are organelles that conduct photosynthesis, where the photosynthetic pigment chlorophyll captures the energy from sunlight, converts it, and stores it in the energy-storage molecules ATP and NADPH while freeing oxygen from water in plant and algal cells. They then use the ATP and NADPH to make organic molecules from carbon dioxide in a process known as the Calvin cycle. Chloroplasts carry out a number of other functions, including fatty acid synthesis, much amino acid synthesis, and the immune response in plants. The number of chloroplasts per cell varies from one, in unicellular algae, up to 100 in plants like Arabidopsis and wheat. A chloroplast is a type of organelle known as a plastid, characterized by its two membranes and a high concentration of chlorophyll. Other plastid types, such as the leucoplast and the chromoplast, contain little chlorophyll and do not carry out photosynthesis. Figure 5.16: Cartoon of the structure of a chloroplast. Components of a typical chloroplast 1 Granum 2 Chloroplast envelope 2.1 Outer membrane 2.2 Intermembrane space 2.3 Inner membrane 3 Thylakoid ◄ You are here 3.1 Thylakoid space (lumen) 3.2 Thylakoid membrane 4 Stromal thylakoid 5 Stroma 6 Nucleoid (DNA ring) 7 Ribosome 8 Plastoglobulus 9 Starch granule Chloroplasts are highly dynamic—they circulate and are moved around within plant cells, and occasionally pinch in two to reproduce. Their behavior is strongly influenced by environmental factors like light color and intensity. Chloroplasts, like mitochondria, contain their own DNA, which is thought to be inherited from their ancestor—a photosynthetic cyanobacterium that was engulfed by an early eukaryotic cell. Chloroplasts cannot be made by the plant cell and must be inherited by each daughter cell during cell division. Chloroplasts are considered endosymbiotic Cyanobacteria. Cyanobacteria are sometimes called blue-green algae even though they are prokaryotes. Chloroplasts can probably be traced back to a single endosymbiotic event, when a cyanobacterium was engulfed by the eukaryote. Despite this, chloroplasts can be found in an extremely wide set of organisms, some not even directly related to each other—a consequence of many secondary and even tertiary endosymbiotic events. The word chloroplast is derived from the Greek words chloros (χλωρός), which means green, and plastes (πλάστης), which means “the one who forms”. In land plants, chloroplasts are generally lens-shaped, 3–10 μm in diameter and 1–3 μm thick. All chloroplasts have at least three membrane systems—the outer chloroplast membrane, the inner chloroplast membrane, and the thylakoid system. Inside the outer and inner chloroplast membranes is the chloroplast stroma, a semi-gel-like fluid that makes up much of a chloroplast’s volume, and in which the thylakoid system floats. The chloroplast stroma contains many proteins, though the most common and important is RuBisCO, which is probably also the most abundant protein on the planet. RuBisCO is the enzyme that fixes CO2 into sugar molecules. In C3 plants, RuBisCO is abundant in all chloroplasts, though in C4 plants, it is confined to the bundle sheath chloroplasts, where the Calvin cycle is carried out in C4 plants. Suspended within the chloroplast stroma is the thylakoid system, a highly dynamic collection of membranous sacks called thylakoids where chlorophyll is found and the light reactions of photosynthesis happen. In most vascular plant chloroplasts, the thylakoids are arranged in stacks called grana, though in certain C4 plant chloroplasts and some algal chloroplasts, the thylakoids are free floating. Thylakoids (sometimes spelled thylakoïds), are small interconnected sacks which contain the membranes that the light reactions of photosynthesis take place on. The word thylakoid comes from the Greek word thylakos which means “sack”. Embedded in the thylakoid membranes are important protein complexes which carry out the light reactions of photosynthesis. Photosystem II and photosystem I contain light-harvesting complexes with chlorophyll and carotenoids that absorb light energy and use it to energize electrons. Molecules in the thylakoid membrane use the energized electrons to pump hydrogen ions into the thylakoid space, decreasing the pH and turning it acidic. ATP synthase is a large protein complex that harnesses the concentration gradient of the hydrogen ions in the thylakoid space to generate ATP energy as the hydrogen ions flow back out into the stroma—much like a dam turbine. There are two types of thylakoids—granal thylakoids, which are arranged in grana, and stromal thylakoids, which are in contact with the stroma. Granal thylakoids are pancake-shaped circular disks about 300–600 nanometers in diameter. Stromal thylakoids are helicoid sheets that spiral around grana. The flat tops and bottoms of granal thylakoids contain only the relatively flat photosystem II protein complex. This allows them to stack tightly, forming grana with many layers of tightly appressed membrane, called granal membrane, increasing stability and surface area for light capture. In contrast, photosystem I and ATP synthase are large protein complexes which jut out into the stroma. They can’t fit in the appressed granal membranes, and so are found in the stromal thylakoid membrane—the edges of the granal thylakoid disks and the stromal thylakoids. These large protein complexes may act as spacers between the sheets of stromal thylakoids. The number of thylakoids and the total thylakoid area of a chloroplast is influenced by light exposure. Shaded chloroplasts contain larger and more grana with more thylakoid membrane area than chloroplasts exposed to bright light, which have smaller and fewer grana and less thylakoid area. Thylakoid extent can change within minutes of light exposure or removal. Inside the photosystems embedded in chloroplast thylakoid membranes are various photosynthetic pigments, which absorb and transfer light energy. The types of pigments found are different in various groups of chloroplasts, and are responsible for a wide variety of chloroplast colorations. Chlorophyll a is found in all chloroplasts, as well as their cyanobacterial ancestors. Chlorophyll a is a blue-green pigment partially responsible for giving most cyanobacteria and chloroplasts their color. Chlorophyll b is an olive green pigment found only in the chloroplasts of plants, green algae, any secondary chloroplasts obtained through the secondary endosymbiosis of a green alga, and a few cyanobacteria. It is the chlorophylls a and b together that make most plant and green algal chloroplasts green. In addition to chlorophylls, another group of yellow–orange pigments called carotenoids are also found in the photosystems. There are about thirty photosynthetic carotenoids. They help transfer and dissipate excess energy, and their bright colors sometimes override the chlorophyll green, like during the fall, when the leaves of some land plants change color. β-carotene is a bright red-orange carotenoid found in nearly all chloroplasts, like chlorophyll a. Xanthophylls, especially the orange-red zeaxanthin, are also common. Many other forms of carotenoids exist that are only found in certain groups of chloroplasts. The chloroplasts of plant and algal cells can orient themselves to best suit the available light. In low-light conditions, they will spread out in a sheet—maximizing the surface area to absorb light. Under intense light, they will seek shelter by aligning in vertical columns along the plant cell’s cell wall or turning sideways so that light strikes them edge-on. This reduces exposure and protects them from photooxidative damage. This ability to distribute chloroplasts so that they can take shelter behind each other or spread out may be the reason why land plants evolved to have many small chloroplasts instead of a few big ones. Chloroplast movement is considered one of the most closely regulated stimulus-response systems that can be found in plants. One of the main functions of the chloroplast is its role in photosynthesis, the process by which light is transformed into chemical energy, to subsequently produce food in the form of sugars. Water (H2O) and carbon dioxide (CO2) are used in photosynthesis, and sugar and oxygen (O2) is made, using light energy. Photosynthesis is divided into two stages—the light reactions, where water is split to produce oxygen, and the dark reactions, or Calvin cycle, which builds sugar molecules from carbon dioxide. The two phases are linked by the energy carriers adenosine triphosphate (ATP) and nicotinamide adenine dinucleotide phosphate (NADP+). 5.1.8 The Endoplasmic Reticulum The endoplasmic reticulum (ER) is a type of organelle made up of two subunits – rough endoplasmic reticulum (RER), and smooth endoplasmic reticulum (SER). The endoplasmic reticulum is found in most eukaryotic cells and forms an interconnected network of flattened, membrane-enclosed sacs known as cisternae (in the RER), and tubular structures in the SER. The membranes of the ER are continuous with the outer nuclear membrane. The endoplasmic reticulum is not found in red blood cells, or spermatozoa. The two types of ER share many of the same proteins and engage in certain common activities such as the synthesis of certain lipids and cholesterol. Different types of cells contain different ratios of the two types of ER depending on the activities of the cell. The outer (cytosolic) face of the rough endoplasmic reticulum is studded with ribosomes that are the sites of protein synthesis. The rough endoplasmic reticulum is especially prominent in cells such as hepatocytes. The smooth endoplasmic reticulum lacks ribosomes and functions in lipid synthesis but not metabolism, the production of steroid hormones, and detoxification. The smooth endoplasmic reticulum is especially abundant in mammalian liver and gonad cells. The general structure of the endoplasmic reticulum is a network of membranes called cisternae. These sac-like structures are held together by the cytoskeleton. The phospholipid membrane encloses the cisternal space (or lumen), which is continuous with the perinuclear space but separate from the cytosol. The functions of the endoplasmic reticulum can be summarized as the synthesis and export of proteins and membrane lipids, but varies between ER and cell type and cell function. The quantity of both rough and smooth endoplasmic reticulum in a cell can slowly interchange from one type to the other, depending on the changing metabolic activities of the cell. Transformation can include embedding of new proteins in membrane as well as structural changes. Changes in protein content may occur without noticeable structural changes. The surface of the rough endoplasmic reticulum (often abbreviated RER or rough ER; also called granular endoplasmic reticulum) is studded with protein-manufacturing ribosomes giving it a “rough” appearance (hence its name). The binding site of the ribosome on the rough endoplasmic reticulum is the translocon. However, the ribosomes are not a stable part of this organelle’s structure as they are constantly being bound and released from the membrane. A ribosome only binds to the RER once a specific protein-nucleic acid complex forms in the cytosol. This special complex forms when a free ribosome begins translating the mRNA of a protein destined for the secretory pathway. The first 5–30 amino acids polymerized encode a signal peptide, a molecular message that is recognized and bound by a signal recognition particle (SRP). Translation pauses and the ribosome complex binds to the RER translocon where translation continues with the nascent (new) protein forming into the RER lumen and/or membrane. The protein is processed in the ER lumen by an enzyme (a signal peptidase), which removes the signal peptide. Ribosomes at this point may be released back into the cytosol; however, non-translating ribosomes are also known to stay associated with translocons. In most cells the smooth endoplasmic reticulum (abbreviated SER) is scarce. Instead there are areas where the ER is partly smooth and partly rough, this area is called the transitional ER. The transitional ER gets its name because it contains ER exit sites. These are areas where the transport vesicles that contain lipids and proteins made in the ER, detach from the ER and start moving to the Golgi apparatus. Specialized cells can have a lot of smooth endoplasmic reticulum and in these cells the smooth ER has many functions. It synthesizes lipids, phospholipids, and steroids. Cells which secrete these products, such as those in the testes, ovaries, and sebaceous glands have an abundance of smooth endoplasmic reticulum. It also carries out the metabolism of carbohydrates, detoxification of natural metabolism products and of alcohol and drugs, attachment of receptors on cell membrane proteins, and steroid metabolism. In muscle cells, it regulates calcium ion concentration. 5.1.9 The Golgi Apparatus The Golgi apparatus, also known as the Golgi complex, Golgi body, or simply the Golgi, is an organelle found in most eukaryotic cells. Part of the endomembrane system in the cytoplasm, it packages proteins into membrane-bound vesicles inside the cell before the vesicles are sent to their destination. It resides at the intersection of the secretory, lysosomal, and endocytic pathways. It is of particular importance in processing proteins for secretion, containing a set of glycosylation enzymes that attach various sugar monomers to proteins as the proteins move through the apparatus. It was identified in 1897 by the Italian scientist Camillo Golgi and was named after him in 1898. In most eukaryotes, the Golgi apparatus is made up of a series of compartments and is a collection of fused, flattened membrane-enclosed disks known as cisternae (singular: cisterna, also called “dictyosomes”), originating from vesicular clusters that bud off the endoplasmic reticulum. A mammalian cell typically contains 40 to 100 stacks of cisternae. Between four and eight cisternae are usually present in a stack; however, in some protists as many as sixty cisternae have been observed. This collection of cisternae is broken down into cis, medial, and trans compartments, making up two main networks: the cis Golgi network (CGN) and the trans Golgi network (TGN). The CGN is the first cisternal structure, and the TGN is the final, from which proteins are packaged into vesicles destined to lysosomes, secretory vesicles, or the cell surface. The TGN is usually positioned adjacent to the stack, but can also be separate from it. The TGN may act as an early endosome in yeast and plants. The Golgi apparatus is a major collection and dispatch station of protein products received from the endoplasmic reticulum (ER). Proteins synthesized in the ER are packaged into vesicles, which then fuse with the Golgi apparatus. These cargo proteins are modified and destined for secretion via exocytosis or for use in the cell. In this respect, the Golgi can be thought of as similar to a post office: it packages and labels items which it then sends to different parts of the cell or to the extracellular space. The Golgi apparatus is also involved in lipid transport and lysosome formation. Figure 5.17: Diagram of the endomembrane system 5.1.10 The Ribosomes The ribosome is a large complex of RNA and protein molecules. They each consist of two subunits, and act as an assembly line where RNA from the nucleus is used to synthesise proteins from amino acids. Ribosomes can be found either floating freely or bound to a membrane (the rough endoplasmatic reticulum in eukaryotes, or the cell membrane in prokaryotes). Figure 5.18: Crystal structure of the human 80S ribosome (based on atomic coordinates of PDB 4V6X rendered with open source molecular visualization tool PyMol). The 40S (small) ribosomal subunit proteins are shown in lightblue, the 60S (large) subunit proteins in palegreen, the ribosomal RNA in orange. 5.1.11 Structures Outside The Cell Membrane Many cells also have structures which exist wholly or partially outside the cell membrane. These structures are notable because they are not protected from the external environment by the semipermeable cell membrane. In order to assemble these structures, their components must be carried across the cell membrane by export processes. Many types of prokaryotic and eukaryotic cells have a cell wall. The cell wall acts to protect the cell mechanically and chemically from its environment, and is an additional layer of protection to the cell membrane. Different types of cell have cell walls made up of different materials; plant cell walls are primarily made up of cellulose, fungi cell walls are made up of chitin and bacteria cell walls are made up of peptidoglycan. A gelatinous capsule is present in some bacteria outside the cell membrane and cell wall. The capsule may be polysaccharide as in pneumococci, meningococci or polypeptide as Bacillus anthracis or hyaluronic acid as in streptococci. Capsules are not marked by normal staining protocols and can be detected by India ink or methyl blue; which allows for higher contrast between the cells for observation.:87 Flagella are organelles for cellular mobility. The bacterial flagellum stretches from cytoplasm through the cell membrane(s) and extrudes through the cell wall. They are long and thick thread-like appendages, protein in nature. A different type of flagellum is found in archaea and a different type is found in eukaryotes. A fimbria (plural fimbriae also known as a pilus, plural pili) is a short, thin, hair-like filament found on the surface of bacteria. Fimbriae are formed of a protein called pilin (antigenic) and are responsible for the attachment of bacteria to specific receptors on human cells (cell adhesion). There are special types of pili involved in bacterial conjugation. 5.1.12 Cellular Replication Cell division involves a single cell (called a mother cell) dividing into two daughter cells. This leads to growth in multicellular organisms (the growth of tissue) and to procreation (vegetative reproduction) in unicellular organisms. Prokaryotic cells divide by binary fission, while eukaryotic cells usually undergo a process of nuclear division, called mitosis, followed by division of the cell, called cytokinesis. A diploid cell may also undergo meiosis to produce haploid cells, usually four. Haploid cells serve as gametes in multicellular organisms, fusing to form new diploid cells. DNA replication, or the process of duplicating a cell’s genome, always happens when a cell divides through mitosis or binary fission. This occurs during the S phase of the cell cycle. In meiosis, the DNA is replicated only once, while the cell divides twice. DNA replication only occurs before meiosis I. DNA replication does not occur when the cells divide the second time, in meiosis II. Replication, like all cellular activities, requires specialized proteins for carrying out the job. 5.1.13 DNA Repair In general, cells of all organisms contain enzyme systems that scan their DNA for damages and carry out repair processes when damages are detected. Diverse repair processes have evolved in organisms ranging from bacteria to humans. The widespread prevalence of these repair processes indicates the importance of maintaining cellular DNA in an undamaged state in order to avoid cell death or errors of replication due to damages that could lead to mutation. E. coli bacteria are a well-studied example of a cellular organism with diverse well-defined DNA repair processes. These include: (1) nucleotide excision repair, (2) DNA mismatch repair, (3) non-homologous end joining of double-strand breaks, (4) recombinational repair and (5) light-dependent repair (photoreactivation). 5.1.14 Cellular Growth And Metabolism Between successive cell divisions, cells grow through the functioning of cellular metabolism. Cell metabolism is the process by which individual cells process nutrient molecules. Metabolism has two distinct divisions: catabolism, in which the cell breaks down complex molecules to produce energy and reducing power, and anabolism, in which the cell uses energy and reducing power to construct complex molecules and perform other biological functions. Complex sugars consumed by the organism can be broken down into simpler sugar molecules called monosaccharides such as glucose. Once inside the cell, glucose is broken down to make adenosine triphosphate (ATP), a molecule that possesses readily available energy, through two different pathways. 5.1.15 Protein Synthesis Cells are capable of synthesizing new proteins, which are essential for the modulation and maintenance of cellular activities. This process involves the formation of new protein molecules from amino acid building blocks based on information encoded in DNA/RNA. Protein synthesis generally consists of two major steps: transcription and translation. Transcription is the process where genetic information in DNA is used to produce a complementary RNA strand. This RNA strand is then processed to give messenger RNA (mRNA), which is free to migrate through the cell. mRNA molecules bind to protein-RNA complexes called ribosomes located in the cytosol, where they are translated into polypeptide sequences. The ribosome mediates the formation of a polypeptide sequence based on the mRNA sequence. The mRNA sequence directly relates to the polypeptide sequence by binding to transfer RNA (tRNA) adapter molecules in binding pockets within the ribosome. The new polypeptide then folds into a functional three-dimensional protein molecule. 5.1.16 Cell Motility Unicellular organisms can move in order to find food or escape predators. Common mechanisms of motion include flagella and cilia. In multicellular organisms, cells can move during processes such as wound healing, the immune response and cancer metastasis. For example, in wound healing in animals, white blood cells move to the wound site to kill the microorganisms that cause infection. Cell motility involves many receptors, crosslinking, bundling, binding, adhesion, motor and other proteins. The process is divided into three steps – protrusion of the leading edge of the cell, adhesion of the leading edge and de-adhesion at the cell body and rear, and cytoskeletal contraction to pull the cell forward. Each step is driven by physical forces generated by unique segments of the cytoskeleton. Multicellular organisms are organisms that consist of more than one cell, in contrast to single-celled organisms. In complex multicellular organisms, cells specialize into different cell types that are adapted to particular functions. In mammals, major cell types include skin cells, muscle cells, neurons, blood cells, fibroblasts, stem cells, and others. Cell types differ both in appearance and function, yet are genetically identical. Cells are able to be of the same genotype but of different cell type due to the differential expression of the genes they contain. Most distinct cell types arise from a single totipotent cell, called a zygote, that differentiates into hundreds of different cell types during the course of development. Differentiatio of cells is driven by different environmental cues (such as cell–cell interaction) and intrinsic differences (such as those caused by the uneven distribution of molecules during division). 5.2 Origin Of Eukaryotic Cells There are several theories about the origin of small molecules that led to life on the early Earth. They may have been carried to Earth on meteorites (see Murchison meteorite), created at deep-sea vents, or synthesized by lightning in a reducing atmosphere (see Miller–Urey experiment). There is little experimental data defining what the first self-replicating forms were. RNA is thought to be the earliest self-replicating molecule, as it is capable of both storng genetic information and catalyzing chemical reactions (see RNA world hypothesis), but some other entity with the potential to self-replicate could have preceded RNA, such as clay or peptide nucleic acid. Cells emerged at least 3.5 billion years ago. The current belief is that these cells were heterotrophs. The early cell membranes were probably more simple and permeable than modern ones, with only a single fatty acid chain per lipid. Lipids are known to spontaneously form bilayered vesicles in water, and could have preceded RNA, but the first cell membranes could also have been produced by catalytic RNA, or even have required structural proteins before they could form. The eukaryotic cell seems to have evolved from a symbiotic community of prokaryotic cells. DNA-bearing organelles like the mitochondria and the chloroplasts are descended from ancient symbiotic oxygen-breathing proteobacteria and cyanobacteria, respectively, which were endosymbiosed by an ancestral archaean prokaryote. 5.3 Protists A protist is any eukaryotic organism (one with cells containing a nucleus) that is not an animal, plant, or fungus. While it is likely that protists share a common ancestor (the last eukaryotic common ancestor), the exclusion of other eukaryotes means that protists do not form a natural group, or clade. So some protists may be more closely related to animals, plants, or fungi than they are to other protists; however, like algae, invertebrates, or protozoans, the grouping is used for convenience. Figure 5.19: A sampling of protists: red algae (Chondrus crispus); brown algae (Giant Kelp); ciliate (Frontonia); golden algae (Dinobryon); Foraminifera (Radiolaria); parasitic flagellate (Giardia muris); pathogenic amoeba (Acanthamoeba); amoebozoan slime mold (Fuligo septica) In antiquity, the two lineages of animals and plants were recognized. They were given the taxonomic rank of Kingdom by the Swedish botanist Carl Linnaeus. Though he included the fungi with plants with some reservations, it was later realized that they are quite distinct and warrant a separate kingdom, the composition of which was not entirely clear until the 1980s. The various single-cell eukaryotes were originally placed with plants or animals when they became known. In 1818, the German biologist Georg A. Goldfuss coined the word protozoa to refer to organisms such as ciliates, and this group was expanded until it encompassed all single-celled eukaryotes, and given their own kingdom, the Protista, by Ernst Haeckel in 1866. Figure 5.20: “Monophyletischer Stambaum der Organismen” from Generelle Morphologie der Organismen (1866) with the three branches Plantae, Protista, Animalia. The eukaryotes thus came to be composed of four kingdoms: Kingdom Protista Kingdom Plantae Kingdom Fungi Kingdom Animalia The protists were understood to be “primitive forms”, and thus an evolutionary grade, united by their primitive unicellular nature. The disentanglement of the deep splits in the tree of life only really started with DNA sequencing, leading to a system of domains rather than kingdoms as top level rank being put forward by Carl Woese, uniting all the eukaryote kingdoms under the eukaryote domain. At the same time, work on the protist tree intensified, and is still actively going on today. Several alternative classifications have been forwarded, though there is no consensus in the field. A revised classification in 2012 recognizes five supergroups of eukaryotes as shown in Table 5.2. Table 5.2: A recent (2012) classification of protists. Supergroup Name Organisms Archaeplastida (or Primoplantae) Land plants, green algae, red algae, and glaucophytes SAR supergroup Stramenopiles (brown algae, diatoms, etcetera), Alveolata, and Rhizaria (Foraminifera, Radiolaria, and various other amoeboid protozoa) Excavata Various flagellate protozoa Amoebozoa Most lobose amoeboids and slime molds Opisthokonta Animals, fungi, choanoflagellates, etcetera The classification of a separate kingdom to the animals and plants was first proposed by John Hogg in 1860 as the kingdom Protoctista; in 1866 Ernst Haeckel also proposed a third kingdom Protista as “the kingdom of primitive forms”. Originally these also included prokaryotes, but with time these would be removed to a fourth kingdom Monera. In the popular five-kingdom scheme proposed by Robert Whittaker in 1969, the Protista was defined as eukaryotic “organisms which are unicellular or unicellular-colonial and which form no tissues”, and the fifth kingdom Fungi was established. In the five-kingdom system of Lynn Margulis, the term protist is reserved for microscopic organisms, while the more inclusive kingdom Protoctista (or protoctists) included certain large multicellular eukaryotes, such as kelp, red algae and slime molds. Others use the term protist interchangeably with Margulis’s protoctist, to encompass both single-celled and multicellular eukaryotes, including those that form specialized tissues but do not fit into any of the other traditional kingdoms. Besides their relatively simple levels of organization, protists do not necessarily have much in common. When used, the term “protists” is now considered to mean a paraphyletic assemblage of similar-appearing but diverse taxa (biological groups); these taxa do not have an exclusive common ancestor beyond being composed of eukaryotes, and have different life cycles, trophic levels, modes of locomotion and cellular structures. Examples of protists include: amoebas (including nucleariids and Foraminifera); choanaflagellates; ciliates; diatoms; dinoflagellates; Giardia; Plasmodium (which causes malaria); oomycetes (including Phytophthora, the cause of the Great Famine of Ireland); and slime molds. These examples are unicellular, although oomycetes can form filaments, and slime molds can aggregate. In cladistic systems (classifications based on common ancestry), there are no equivalents to the taxa Protista or Protoctista, as both terms refer to a paraphyletic group that spans the entire eukaryotic tree of life. In cladistic classification, the contents of Protista are mostly distributed among various supergroups: examples include the SAR supergroup (of stramenopiles or heterokonts, alveolates, and Rhizaria); Archaeplastida (or Plantae sensu lato); Excavata (which is mostly unicellular flagellates); and Opisthokonta (which commonly includes unicellular flagellates, but also animals and fungi). “Protista”, “Protoctista”, and “Protozoa” are therefore considered obsolete. However, the term “protist” continues to be used informally as a catch-all term for eukayotic organisms that aren’t within other traditional kingdoms. For example, the word “protist pathogen” may be used to denote any disease-causing organism that is not plant, animal, fungal, prokaryotic, viral, or subviral. The term protista was first used by Ernst Haeckel in 1866. Protists were traditionally subdivided into several groups based on similarities to the “higher” kingdoms such as: Protozoa: unicellular “animal-like” (heterotrophic, and sometimes parasitic) organisms that are further sub-divided based on characteristics such as motility, such as the (flagellated) Flagellata, the (ciliated) Ciliophora, the (phagocytic) amoeba, and the (spore-forming) Sporozoa. Protophyta: plant-like\" (autotrophic) organisms that are composed mostly of unicellular algae. The dinoflagelates, diatoms and Euglena-like flagellates are photosynthetic protists. Molds: “Mold” generally refer to fungi; but slime molds and water molds are fungus-like\" (saprophytic) protists, although some are pathogens. Some protists, sometimes called ambiregnal protists, have been considered to be both protozoa and algae or fungi (e.g., slime molds and flagellated algae). Conflicts, such as these – for example the dual-classification of Euglenids and Dinobryons, which are mixotrophic – is an example of why the kingdom Protista was adopted. These traditional subdivisions, largely based on superficial commonalities, have been replaced by classifications based on phylogenetics (evolutionary relatedness among organisms). Molecular analyses in modern taxonomy have been used to redistribute former members of this group into diverse and sometimes distantly related phyla. For instance, the water molds are now considered to be closely related to photosynthetic organisms such as Brown algae and Diatoms, the slime molds are grouped mainly under Amoebozoa, and the Amoebozoa itself includes only a subset of the “Amoeba” group, and significant number of erstwhile “Amoeboid” genera are distributed among Rhizarians and other Phyla. However, the older terms are still used as informal names to describe the morphology and ecology of various protists. For example, the term protozoa is used to refer to heterotrophic species of protists that do not form filaments. Systematists today do not treat Protista as a formal taxon, but the term “protist” is still commonly used for convenience in two ways. The most popular contemporary definition is a phylogenetic one, that identifies a paraphyletic group: a protist is any eukaryote that is not an animal, (land) plant, or (true) fungus; this definition excludes many unicellular groups, like the Microsporidia (fungi), many Chytridiomycetes (fungi), and yeasts (fungi), and also a non-unicellular group included in Protista in the past, the Myxozoa (animal). The taxonomy of protists is still changing. Newer classifications attempt to present monophyletic groups based on morphological (especially ultrastructural), biochemical (chemotaxonomy) and DNA sequence (molecular research) information. Because the protists as a whole are paraphyletic, new systems often split up or abandon the kingdom, instead treating the protist groups as separate lines of eukaryotes. Table 5.3: Nutritional types in protist metabolism Nutritional Type Source of Energy Source of Carbon Examples  Photoautotrophs   Sunlight   Organic compounds or carbon fixation  Most algae   Chemoheterotrophs  Organic compounds   Organic compounds   Apicomplexa, Trypanosomes or Amoebae  5.4 Protozoa Protozoa (also protozoan, plural protozoans) is an informal term for a group of single-celled eukaryotes, either free-living or parasitic, which feed on organic matter such as other microorganisms or organic tissues and debris. Historically, protozoans were regarded as “one-celled animals”, because they often possess animal-like behaviours, such as motility and predation, and lack a cell wall, as found in plants and many algae. Although the traditional practice of grouping protozoa with animals is no longer considered valid, the term continues to be used in a loose way to describe single-celled protists (that is, eukaryotes that aren’t animals, plants, or fungi) that feed by heterotrophy. In some systems of biological classification, Protozoa remains a high-level taxonomic group. When first introduced by Georg Goldfuss in 1818, Protozoa was erected as a class within the animals, and its etymology is literally “first animals”. In later classification schemes it was elevated to a variety of higher ranks, including phylum, subkingdom and kingdom, and sometimes included within Protoctista or Protista. With the advent of techniques such as molecular phylogenetics, it was realized that Protozoa did not represent a natural group; but while it is not an accepted taxon in cladistic analyses, some systematists continue to use it as a formal taxon. In a series of classifications proposed by Thomas Cavalier-Smith and his collaborators since 1981, Protozoa has been ranked as a kingdom. The seven-kingdom scheme presented by Ruggiero et al. in 2015, places eight phyla under Kingdom Protozoa: Euglenozoa, Amoebozoa, Metamonada, Choanozoa sensu Cavalier-Smith, Loukozoa, Percolozoa, Microsporidia and Sulcozoa. Notably, this kingdom excludes several major groups of organisms traditionally placed among the protozoa, including the ciliates, dinoflagellates, foraminifera, and the parasitic apicomplexans, all of which are classified under Kingdom Chromista. Kingdom Protozoa, as defined in this scheme, does not form a natural group or clade, but a paraphyletic group or evolutionary grade, within which the members of Fungi, Animalia and Chromista are thought to have evolved. The word “protozoa” (singular protozoon or protozoan) was coined in 1818 by zoologist Georg August Goldfuss, as the Greek equivalent of the German Urthiere, meaning “primitive, or original animals” (ur- ‘proto-’ + Thier ‘animal’). Goldfuss created Protozoa as a class containing what he believed to be the simplest animals. Originally, the group included not only single-celled microorganisms but also some “lower” multicellular animals, such as rotifers, corals, sponges, jellyfish, bryozoa and polychaete worms. The term Protozoa is formed from the Greek words πρῶτος (prôtos), meaning “first”, and ζῶα (zôa), plural of ζῶον (zôon), meaning “animal”. The use of Protozoa as a formal taxon has been discouraged by some researchers, mainly because the term implies kinship with animals (Metazoa) and promotes an arbitrary separation of “animal-like” from “plant-like” organisms. In 1848, as a result of advancements in cell theory pioneered by Theodor Schwann and Matthias Schleiden, the anatomist and zoologist C. T. von Siebold proposed that the bodies of protozoans such as ciliates and amoebae consisted of single cells, similar to those from which the multicellular tissues of plants and animals were constructed. Von Siebold redefined Protozoa to include only such unicellular forms, to the exclusion of all metazoa (animals). At the same time, he raised the group to the level of a phylum containing two broad classes of microorganisms: Infusoria (mostly ciliates and flagellated algae), and Rhizopoda (amoeboid organisms). The definition of Protozoa as a phylum or sub-kingdom composed of “unicellular animals” was adopted by the zoologist Otto Bütschli—celebrated at his centenary as the “architect of protozoology”—and the term came into wide use. As a phylum under Animalia, the Protozoa were firmly rooted in the old “two-kingdom” classification of life, according to which all living beings were classified as either animals or plants. As long as this scheme remained dominant, the protozoa were understood to be animals and studied in departments of Zoology, while photosynthetic microorganisms and microscopic fungi—the so-called Protophyta—were assigned to the Plants, and studied in departments of Botany. Criticism of this system began in the latter half of the 19th century, with the realization that many organisms met the criteria for inclusion among both plants and animals. For example, the algae Euglena and Dinobryon have chloroplasts for photosynthesis, but can also feed on organic matter and are motile. In 1860, John Hogg argued against the use of “protozoa”, on the grounds that “naturalists are divided in opinion—and probably some will ever continue so—whether many of these organisms, or living beings, are animals or plants.” As an alternative, he proposed a new kingdom called Primigenum, consisting of both the protozoa and unicellular algae (protophyta), which he combined together under the name “Protoctista”. In Hoggs’s conception, the animal and plant kingdoms were likened to two great “pyramids” blending at their bases in the Kingdom Primigenum. Six years later, Ernst Haeckel also proposed a third kingdom of life, which he named Protista. At first, Haeckel included a few multicellular organisms in this kingdom, but in later work he restricted the Protista to single-celled organisms, or simple colonies whose individual cells are not differentiated into different kinds of tissues. Despite these proposals, Protozoa emerged as the preferred taxonomic placement for heterotrophic microorganisms such as amoebae and ciliates, and remained so for more than a century. In the course of the 20th century, however, the old “two kingdom” system began to weaken, with the growing awareness that fungi did not belong among the plants, and that most of the unicellular protozoa were no more closely related to the animals than they were to the plants. By mid-century, some biologists, such as Herbert Copeland, Robert H. Whittaker and Lynn Margulis, advocated the revival of Haeckel’s Protista or Hogg’s Protoctista as a kingdom-level eukaryotic group, alongside Plants, Animals and Fungi. A variety of multi-kingdom systems were proposed, and Kingdoms Protista and Protoctista became well established in biology texts and curricula. While many taxonomists have abandoned Protozoa as a high-level group, Thomas Cavalier-Smith has retained it as a kingdom in the various classifications he has proposed. As of 2015, Cavalier-Smith’s Protozoa excludes several major groups of organisms traditionally placed among the protozoa, including the ciliates, dinoflagellates and foraminifera (all members of the SAR supergroup). In its current form, his kingdom Protozoa is a paraphyletic group which includes a common ancestor and most of its descendants, but excludes two important clades that branch within it: the animals and fungi. Since the protozoa, as traditionally defined, can no longer be regarded as “primitive animals” the terms “protists”, “Protista” or “Protoctista” are sometimes preferred. In 2005, members of the Society of Protozoologists voted to change its name to the International Society of Protistologists. Free-living protozoans are common and often abundant in fresh, brackish and salt water, as well as other moist environments, such as soils and mosses. Some species thrive in extreme environments such as hot springs and hypersaline lakes and lagoons. All protozoa require a moist habitat; however, some can survive for long periods of time in dry environments, by forming resting cysts which enable them to remain dormant until conditions improve. Parasitic and symbiotic protozoa live on or within other organisms, including vertebrates and invertebrates, as well as plants and other single-celled organisms. Some are harmless or beneficial to their host organisms; others may be significant causes of diseases, such as babesia, malaria and toxoplasmosis. Association between protozoan symbionts and their host organisms can be mutually beneficial. Flagellated protozoans such as Trichonympha and Pyrsonympha inhabit the guts of termites, where they enable their insect host to digest wood by helping to break down complex sugars into smaller, more easily digested molecules. A wide range of protozoans live commensally in the rumens of ruminant animals, such as cattle and sheep. These include flagellates, such as Trichomonas, and ciliated protozoa, such as Isotricha and Entodinium. The ciliate subclass Astomatia is composed entirely of mouthless symbionts adapted for life in the guts of annelid worms. All protozoans are heterotrophic, deriving nutrients from other organisms, either by ingesting them whole or consuming their organic remains and waste-products. Some protozoans take in food by phagocytosis, engulfing organic particles with pseudopodia (as amoebae do), or taking in food through a specialized mouth-like aperture called a cytostome. Others take in food by osmotrophy, absorbing dissolved nutrients through their cell membranes. Parasitic protozoans use a wide variety of feeding strategies, and some may change methods of feeding in different phases of their life cycle. For instance, the malaria parasite Plasmodium feeds by pinocytosis during its immature trophozoite stage of life (ring phase), but develops a dedicated feeding organelle (cytostome) as it matures within a host’s red blood cell. Protozoa may also live as mixotrophs, supplementing a heterotrophic diet with some form of autotrophy. Some protozoa form close associations with symbiotic photosynthetic algae, which live and grow within the membranes of the larger cell and provide nutrients to the host. Others practice kleptoplasty, stealing chloroplasts from prey organisms and maintaining them within their own cell bodies as they continue to produce nutrients through photosynthesis. The ciliate Mesodinium rubrum retains functioning plastids from the cryptophyte algae on which it feeds, using them to nourish themselves by autotrophy. These, in turn, may be passed along to dinoflagellates of the genus Dinophysis, which prey on Mesodinium rubrum but keep the enslaved plastids for themselves. Within Dinophysis, these plastids can continue to function for months. Organisms traditionally classified as protozoa are abundant in aqueous environments and soil, occupying a range of trophic levels. The group includes flagellates (which move with the help of whip-like structures called flagella), ciliates (which move by using hair-like structures called cilia) and amoebae (which move by the use of foot-like structures called pseudopodia). Some protozoa are sessile, and do not move at all. Unlike plants, fungi and most types of algae, protozoans do not typically have a rigid cell wall, but are usually enveloped by elastic structures of membranes that permit movement of the cell. In some protozoans, such as the ciliates and euglenozoans, the cell is supported by a composite membranous envelope called the “pellicle”. The pellicle gives some shape to the cell, especially during locomotion. Pellicles of protozoan organisms vary from flexible and elastic to fairly rigid. In ciliates and Apicomplexa, the pellicle is supported by closely packed vesicles called alveoli. In euglenids, it is formed from protein strips arranged spirally along the length of the body. Familiar examples of protists with a pellicle are the euglenoids and the ciliate Paramecium. In some protozoa, the pellicle hosts epibiotic bacteria that adhere to the surface by their fimbriae (attachment pili). Some protozoa have two-phase life cycles, alternating between proliferative stages (e.g., trophozoites) and dormant cysts. As cysts, protozoa can survive harsh conditions, such as exposure to extreme temperatures or harmful chemicals, or long periods without access to nutrients, water, or oxygen for periods of time. Being a cyst enables parasitic species to survive outside of a host, and allows their transmission from one host to another. When protozoa are in the form of trophozoites (Greek tropho = to nourish), they actively feed. The conversion of a trophozoite to cyst form is known as encystation, while the process of transforming back into a trophozoite is known as excystation. Protozoans reproduce asexually by binary fission or multiple fission. Many protozoan species also exchange genetic material by sexual means (typically, through conjugation), but this is generally decoupled from the process of reproduction, and does not immediately result in increased population. Although meiotic sex is widespread among present day eukaryotes, it has, until recently, been unclear whether or not eukaryotes were sexual early in their evolution. Due to recent advances in gene detection and other techniques, evidence has been found for some form of meiotic sex in an increasing number of protozoans of ancient lineage that diverged early in eukaryotic evolution. (See eukaryote reproduction.) Thus, such findings suggest that meiotic sex arose early in eukaryotic evolution. Examples of protozoan meiotic sexuality are described in the articles Amoebozoa, Giardia lamblia, Leishmania, Plasmodium falciparum biology, Paramecium, Toxoplasma gondii, Trichomonas vaginalis and Trypanosoma brucei. Historically, the Protozoa were classified as “unicellular animals”, as distinct from the Protophyta, single-celled photosynthetic organisms (algae) which were considered primitive plants. Both groups were commonly given the rank of phylum, under the kingdom Protista. In older systems of classification, the phylum Protozoa was commonly divided into several sub-groups, reflecting the means of locomotion. Classification schemes differed, but throughout much of the 20th century the major groups of Protozoa included: Flagellates, or Mastigophora (motile cells equipped with whiplike organelles of locomotion, e.g., Giardia lamblia) Amoebae or Sarcodina (cells that move by extending pseudopodia or lamellipodia, e.g., Entamoeba histolytica) Sporozoans, or Sporozoa (parasitic, spore-producing cells, whose adult form lacks organs of motility, e.g., Plasmodium knowlesi) Apicomplexa (now in Alveolata) Microsporidia (now in Fungi) Ascetosporea (now in Rhizaria) Myxosporidia (now in Cnidaria) Ciliates, or Ciliophora (cells equipped with large numbers of short hairlike organs of locomotion, e.g. Balantidium coli) Figure 5.21: Composite image of various Apicomplexan parasites showing Babesia microti in red blood cells (top left), toxoplasma gondii (top right), a septate eugregarine (bottom left), Lankesteria cystodytae (bottom middle), and Plasmodium falciparum in red blood cells (bottom right). With the emergence of molecular phylogenetics and tools enabling researchers to directly compare the DNA of different organisms, it became evident that, of the main sub-groups of Protozoa, only the ciliates (Ciliophora) formed a natural group, or monophyletic clade (that is, a distinct lineage of organisms sharing common ancestry). The other classes or subphyla of Protozoa were all polyphyletic groups composed of organisms that, despite similarities of appearance or way of life, were not necessarily closely related to one another. In the system of eukaryote classification currently endorsed by the International Society of Protistologists, members of the old phylum Protozoa have been distributed among a variety of supergroups. A number of protozoan pathogens are human parasites, causing diseases such as malaria (by Plasmodium), amoebiasis, giardiasis, toxoplasmosis, cryptosporidiosis, trichomoniasis, Chagas disease, leishmaniasis, African trypanosomiasis (sleeping sickness), Acanthamoeba keratitis, and primary amoebic meningoencephalitis (naegleriasis). The protozoan Ophryocystis elektroscirrha is a parasite of butterfly larvae, passed from female to caterpillar. Severely infected individuals are weak, unable to expand their wings, or unable to eclose, and have shortened lifespans, but parasite levels vary in populations. Infection creates a culling effect, whereby infected migrating animals are less likely to complete the migration. This results in populations with lower parasite loads at the end of the migration. This is not the case in laboratory or commercial rearing, where after a few generations, all individuals can be infected 5.5 Flagellates In older classifications, flagellated protozoa were grouped in Flagellata (= Mastigophora), sometimes divided in Phytoflagellata (= Phytomastigina, mostly autotrophic) and Zooflagellata (= Zoomastigina, heterotrophic). They were sometimes grouped with Sarcodina (ameboids) in the group Sarcomastigophora. Excavata is a major supergroup of unicellular organisms eukayotes that are classified based on their flagellar structures, and they are considered to be the most basal Flagellate lineage. It contains a variety of free-living and symbiotic forms, and also includes some important parasites of humans, including Giardia and Trichomonas. Except for Euglenozoa, they are all non-photosynthetic. Euglena is a genus of single cell flagellate eukaryotes. It is the best known and most widely studied member of the class Euglenoidea, a diverse group containing some 54 genera and at least 800 species. Species of Euglena are found in freshwater and salt water. They are often abundant in quiet inland waters where they may bloom in numbers sufficient to color the surface of ponds and ditches green (E. viridis) or red (E. sanguinea). Figure 5.22: Euglena. The species Euglena gracilis has been used extensively in the laboratory as a model organism. Most species of Euglena have photosynthesizing chloroplasts within the body of the cell, which enable them to feed by autotrophy, like plants. However, they can also take nourishment heterotrophically, like animals. Since Euglena have features of both animals and plants, early taxonomists, working within the Linnaean two-kingdom system of biological classification, found them difficult to classify. It was the question of where to put such “unclassifiable” creatures that prompted Ernst Haeckel to add a third living kingdom (a fourth kingdom in toto) to the Animale, Vegetabile (and Lapideum meaning Mineral) of Linnaeus: the Kingdom Protista. When feeding as a heterotroph, Euglena takes in nutrients by osmotrophy, and can survive without light on a diet of organic matter, such as beef extract, peptone, acetate, ethanol or carbohydrates. When there is sufficient sunlight for it to feed by phototrophy, it uses chloroplasts containing the pigments chlorophyll a and chlorophyll b to produce sugars by photosynthesis. Euglena’s chloroplasts are surrounded by three membranes, while those of plants and the green algae (among which earlier taxonomists often placed Euglena) have only two membranes. This fact has been taken as morphological evidence that Euglena’s chloroplasts evolved from a eukaryotic green alga. Thus, the similarities between Euglena and plants would have arisen not because of kinship but because of a secondary endosymbiosis. Molecular phylogenetic analysis has lent support to this hypothesis, and it is now generally accepted. Euglena chloroplasts contain pyrenoids, used in the synthesis of paramylon, a form of starch energy storage enabling Euglena to survive periods of light deprivation. The presence of pyrenoids is used as an identifying feature of the genus, separating it from other euglenoids, such as Lepocinclis and Phacus. Euglena have two flagella rooted in basal bodies located in a small reservoir at the front of the cell. Typically, one flagellum is very short, and does not protrude from the cell, while the other is long enough to be seen with light microscopy. In some species, such as Euglena mutabilis, both flagella are “non-emergent”–entirely confined to the interior of the cell’s reservoir–and consequently cannot be seen in the light microscope. In species that possess a long, emergent flagellum, it may be used to help the organism swim. The surface of the flagellum is coated with about 30,000 extremely fine filaments called mastigonemes. Like other euglenoids, Euglena possess a red eyespot, an organelle composed of carotenoid pigment granules. The red spot itself is not thought to be photosensitive. Rather, it filters the sunlight that falls on a light-detecting structure at the base of the flagellum (a swelling, known as the paraflagellar body), allowing only certain wavelengths of light to reach it. As the cell rotates with respect to the light source, the eyespot partially blocks the source, permitting the Euglena to find the light and move toward it (a process known as phototaxis). Euglena lacks a cell wall. Instead, it has a pellicle made up of a protein layer supported by a substructure of microtubules, arranged in strips spiraling around the cell. The action of these pellicle strips sliding over one another, known as metaboly, gives Euglena its exceptional flexibility and contractility. The mechanism of this euglenoid movement is not understood, but its molecular basis may be similar to that of amoeboid movement. In low moisture conditions, or when food is scarce, Euglena forms a protective wall around itself and lies dormant as a resting cyst until environmental Euglena reproduce asexually through binary fission, a form of cell division. Reproduction begins with the mitosis of the cell nucleus, followed by the division of the cell itself. Euglena divide longitudinally, beginning at the front end of the cell, with the duplication of flagellar processes, gullet and stigma. Presently, a cleavage forms in the anterior, and a V-shaped bifurcation gradually moves toward the posterior, until the two halves are entirely separated 5.6 Ciliates The ciliates are a group of protozoans characterized by the presence of hair-like organelles called cilia, which are identical in structure to eukaryotic flagella, but are in general shorter and present in much larger numbers, with a different undulating pattern than flagella. Cilia occur in all members of the group (although the peculiar Suctoria only have them for part of their life-cycle) and are variously used in swimming, crawling, attachment, feeding, and sensation. Figure 5.23: Composite image of various ciliates: Lacrymaria olor, Paramecium bursaria, Coleps, Dileptus, Stentor coeruleus. Ciliates are an important group of protists, common almost anywhere there is water — in lakes, ponds, oceans, rivers, and soils. About 4,500 unique free-living species have been described, and the potential number of extant species is estimated at 27,000–40,000. Included in this number are many ectosymbiotic and endosymbiotic species, as well as some obligate and opportunistic parasites. Ciliate species range in size from as little as 10 µm in some colpodeans to as much as 4 mm in length in some geleiids, and include some of the most morphologically complex protozoans. Unlike most other eukaryotes, ciliates have two different sorts of nuclei: a tiny, diploid micronucleus (the “generative nucleus,” which carries the germline of the cell), and a large, polyploid macronucleus (the “vegetative nucleus,” which takes care of general cell regulation, expressing the phenotype of the organism). The latter is generated from the micronucleus by amplification of the genome and heavy editing. The micronucleus passes its genetic material to offspring, but does not express its genes. The macronucleus provides the small nuclear RNA for vegetative growth. Division of the macronucleus occurs by amitosis, and the segregation of the chromosomes occurs by a process whose mechanism is unknown. This process is not perfect, and after about 200 generations the cell shows signs of aging. Periodically the macronuclei must be regenerated from the micronuclei. In most, this occurs during conjugation. Here two cells line up, the micronuclei undergo meiosis, some of the haploid daughters are exchanged and then fuse to form new micronuclei and macronuclei. Food vacuoles are formed through phagocytosis and typically follow a particular path through the cell as their contents are digested and broken down by lysosomes so the substances the vacuole contains are then small enough to diffuse through the membrane of the food vacuole into the cell. Anything left in the food vacuole by the time it reaches the cytoproct (anal pore) is discharged by exocytosis. Most ciliates also have one or more prominent contractile vacuoles, which collect water and expel it from the cell to maintain osmotic pressure, or in some function to maintain ionic balance. In some genera, such as Paramecium, these have a distinctive star shape, with each point being a collecting tube. Figure 5.24: Diagram of the ciliate Paramecium Most ciliates are heterotrophs, feeding on smaller organisms, such as bacteria and algae, and detritus swept into the oral groove (mouth) by modified oral cilia. This usually includes a series of membranelles to the left of the mouth and a paroral membrane to its right, both of which arise from polykinetids, groups of many cilia together with associated structures. The food is moved by the cilia through the mouth pore into the gullet, which forms food vacuoles. Feeding techniques vary considerably, however. Some ciliates are mouthless and feed by absorption (osmotrophy), while others are predatory and feed on other protozoa and in particular on other ciliates. Some ciliates parasitize animals, although only one species, Balantidium coli, is known to cause disease in humans. Ciliates reproduce asexually, by various kinds of fission. During fission, the micronucleus undergoes mitosis and the macronucleus elongates and undergoes amitosis (except among the Karyorelictean ciliates, whose macronuclei do not divide). The cell then divides in two, and each new cell obtains a copy of the micronucleus and the macronucleus. Typically, the cell is divided transversally, with the anterior half of the ciliate (the proter) forming one new organism, and the posterior half (the opisthe) forming another. However, other types of fission occur in some ciliate groups. These include budding (the emergence of small ciliated offspring, or “swarmers”, from the body of a mature parent); strobilation (multiple divisions along the cell body, producing a chain of new organisms); and palintomy (multiple fissions, usually within a cyst). Fission may occur spontaneously, as part of the vegetative cell cycle. Alternatively, it may proceed as a result of self-fertilization (autogamy), or it may follow conjugation, a sexual phenomenon in which ciliates of compatible mating types exchange genetic material. While conjugation is sometimes described as a form of reproduction, it is not directly connected with reproductive processes, and does not directly result in an increase in the number of individual ciliates or their progeny. Ciliate conjugation is a sexual phenomenon that results in genetic recombination and nuclear reorganization within the cell. During conjugation, two ciliates of a compatible mating type form a bridge between their cytoplasms. The micronuclei undergo meiosis, the macronuclei disappear, and haploid micronuclei are exchanged over the bridge. In some ciliates (peritrichs, chonotrichs and some suctorians), conjugating cells become permanently fused, and one conjugant is absorbed by the other. In most ciliate groups, however, the cells separate after conjugation, and both form new macronuclei from their micronuclei. Conjugation and autogamy are always followed by fission. Figure 5.25: Stages of conjugation in Paramecium caudatum In many ciliates, such as Paramecium, conjugating partners (gamonts) are similar or indistinguishable in size and shape. This is referred to as “isogamontic” conjugation. In some groups, partners are different in size and shape. This is referred to as “anisogamontic” conjugation. In sessile peritrichs, for instance, one sexual partner (the microconjugant) is small and mobile, while the other (macroconjugant) is large and sessile In Paramecium caudatum, the stages of conjugation are as follows (see diagram at right): Compatible mating strains meet and partly fuse The micronuclei undergo meiosis, producing four haploid micronuclei per cell. Three of these micronuclei disintegrate. The fourth undergoes mitosis. The two cells exchange a micronucleus. The cells then separate. The micronuclei in each cell fuse, forming a diploid micronucleus. Mitosis occurs three times, giving rise to eight micronuclei. Four of the new micronuclei transform into macronuclei, and the old macronucleus disintegrates. Binary fission occurs twice, yielding four identical daughter cells. Ciliates contain two types of nuclei: somatic “macronucleus” and the germline “micronucleus”. Only the DNA in the micronucleus is passed on during sexual reproduction (conjugation). On the other hand, only the DNA in the macronucleus is actively expressed and results in the phenotype of the organism. Macronuclear DNA is derived from micronuclear DNA by amazingly extensive DNA rearrangement and amplification. The macronucleus begins as a copy of the micronucleus. The micronuclear chromosomes are fragmented into many smaller pieces and amplified to give many copies. The resulting macronuclear chromosomes often contain only a single gene. In Tetrahymena, the micronucleus has 10 chromosomes (five per haploid genome), while the macronucleus has over 20,000 chromosomes. In addition, the micronuclear genes are interrupted by numerous “internal eliminated sequences” (IESs). During development of the macronucleus, IESs are deleted and the remaining gene segments, macronuclear destined sequences (MDSs), are spliced together to give the operational gene. Tetrahymena has about 6,000 IESs and about 15% of micronuclear DNA is eliminated during this process. The process is guided by small RNAs and epigenetic chromatin marks. In spirotrich ciliates (such as Oxytricha), the process is even more complex due to “gene scrambling”: the MDSs in the micronucleus are often in different order and orientation from that in the macronuclear gene, and so in addition to deletion, DNA inversion and translocation are required for “unscrambling”. This process is guided by long RNAs derived from the parental macronucleus. More than 95% of micronuclear DNA is eliminated during spirotrich macronuclear development. 5.7 Amoebozoa Amoebozoa is a major taxonomic group containing about 2,400 described species of amoeboid protists, often possessing blunt, fingerlike, lobose pseudopods and tubular mitochondrial cristae. In most classification schemes, Amoebozoa is ranked as a phylum within either the kingdom Protista or the kingdom Protozoa. In the classification favored by the International Society of Protistologists, it is retained as an unranked “supergroup” within Eukaryota. Molecular genetic analysis supports Amoebozoa as a monophyletic clade. Most phylogenetic trees identify it as the sister group to Opisthokonta, another major clade which contains both fungi and animals as well as some 300 species of unicellular protists. Amoebozoa and Opisthokonta are sometimes grouped together in a high-level taxon, variously named Unikonta, Amorphea or Opimoda. Amoebozoa includes many of the best-known amoeboid organisms, such as Chaos, Entamoeba, Pelomyxa and the genus Amoeba itself. Species of Amoebozoa may be either shelled (testate), or naked, and cells may possess flagella. Free-living species are common in both salt and freshwater as well as soil, moss and leaf litter. Some live as parasites or symbiotes of other organisms, and some are known to cause disease in humans and other organisms. While the majority of amoebozoan species are unicellular, the group also includes several varieties of slime molds, which have a macroscopic, multicellular stage of life during which individual amoeboid cells aggregate to produce spores. Amoebozoa vary greatly in size. Some are only 10–20 μm in diameter, while others are among the largest protozoa. The well-known species Amoeba proteus, which may reach 800 μm in length, is often studied in schools and laboratories as a representative cell or model organism, partly because of its convenient size. Multinucleate amoebae like Chaos and Pelomyxa may be several millimetres in length, and some multicellular amoebozoa, such as the “dog vomit” slime mold Fuligo septica, can cover an area of several square meters. Amoebozoa is a large and diverse group, but certain features are common to many of its members. The amoebozoan cell is typically divided into a granular central mass, called endoplasm, and a clear outer layer, called ectoplasm. During locomotion, the endoplasm flows forwards and the ectoplasm runs backwards along the outside of the cell. In motion, many amoebozoans have a clearly defined anterior and posterior and may assume a “monopodial” form, with the entire cell functioning as a single pseudopod. Large pseudopods may produce numerous clear projections called subpseudopodia (or determinate pseudopodia), which are extended to a certain length and then retracted, either for the purpose of locomotion or food intake. A cell may also form multiple indeterminate pseudopodia, through which the entire contents of the cell flow in the direction of locomotion. These are more or less tubular and are mostly filled with granular endoplasm. The cell mass flows into a leading pseudopod, and the others ultimately retract, unless the organism changes direction. While most amoebozoans are “naked,” like the familiar Amoeba and Chaos, or covered with a loose coat of minute scales, like Cochliopodium and Korotnevella, members of the order Arcellinida form rigid shells, or tests, equipped with a single aperture through which the pseudopods emerge. Arcellinid tests may be secreted from organic materials, as in Arcella, or built up from collected particles cemented together, as in Difflugia. In all amoebozoa, the primary mode of nutrition is phagocytosis, in which the cell surrounds potential food particles with its pseudopods, sealing them into vacuoles within which they may be digested and absorbed. Some amoebozoans have a posterior bulb called a uroid, which may serve to accumulate waste, periodically detaching from the rest of the cell. When food is scarce, most species can form cysts, which may be carried aerially and introduce them to new environments. In slime moulds, these structures are called spores, and form on stalked structures called fruiting bodies or sporangia. The majority of Amoebozoa lack flagella and more generally do not form microtubule-supported structures except during mitosis. However, flagella do occur among the Archamoebae, and many slime moulds produce biflagellate gametes. The flagellum is generally anchored by a cone of microtubules, suggesting a close relationship to the opisthokonts. The mitochondria in amoebozoan cells characteristically have branching tubular cristae. However, among the Archamoebae, which are adapted to anoxic or microaerophilic habitats, mitochondria have been lost. Amoebiasis, also known as amebiasis or entamoebiasis, is an infection caused by any of the amoebozoans of the Entamoeba group. Symptoms are most common upon infection by Entamoeba histolytica. Amoebiasis can present with no, mild, or severe symptoms. Symptoms may include abdominal pain, mild diarrhoea, bloody diarrhea or severe colitis with tissue death and perforation. This last complication may cause peritonitis. People affected may develop anemia due to loss of blood. Invasion of the intestinal lining causes amoebic bloody diarrhea or amoebic colitis. If the parasite reaches the bloodstream it can spread through the body, most frequently ending up in the liver where it causes amoebic liver abscesses. Liver abscesses can occur without previous diarrhea. Cysts of Entamoeba can survive for up to a month in soil or for up to 45 minutes under fingernails. It is important to differentiate between amoebiasis and bacterial colitis. The preferred diagnostic method is through faecal examination under microscope, but requires a skilled microscopist and may not be reliable when excluding infection. This method however may not be able to separate between specific types. Increased white blood cell count is present in severe cases, but not in mild ones. The most accurate test is for antibodies in the blood, but it may remain positive following treatment. Prevention of amoebiasis is by separating food and water from faeces and by proper sanitation measures. There is no vaccine. There are two treatment options depending on the location of the infection. Amoebiasis in tissues is treated with either metronidazole, tinidazole, nitazoxanide, dehydroemetine or chloroquine, while luminal infection is treated with diloxanide furoate or iodoquinoline. For treatment to be effective against all stages of the amoeba may require a combination of medications. Infections without symptoms do not require treatment but infected individuals can spread the parasite to others and treatment can be considered. Treatment of other Entamoeba infections apart from E. histolytica is not needed. Amoebiasis is present all over the world. About 480 million people are infected with what appears to be E. histolytica and these result in the death of between 40,000–110,000 people every year. Most infections are now ascribed to E. dispar. E. dispar is more common in certain areas and symptomatic cases may be fewer than previously reported. The first case of amoebiasis was documented in 1875 and in 1891 the disease was described in detail, resulting in the terms amoebic dysentery and amoebic liver abscess. Further evidence from the Philippines in 1913 found that upon ingesting cysts of E. histolytica volunteers developed the disease. It has been known since 1897 that at least one non-disease-causing species of Entamoeba existed (Entamoeba coli), but it was first formally recognized by the WHO in 1997 that E. histolytica was two species, despite this having first been proposed in 1925. In addition to the now-recognized E. dispar evidence shows there are at least two other species of Entamoeba that look the same in humans - E. moshkovskii and Entamoeba bangladeshi. The reason these species haven’t been differentiated until recently is because of the reliance on appearance. 5.8 Algae The Archaeplastida (or kingdom Plantae sensu lato) are a major group of autotrophic eukaryotes, comprising the red algae (Rhodophyta), the green algae, and the land plants, together with a small group of freshwater unicellular algae called glaucophytes. The Archaeplastida have chloroplasts that are surrounded by two membranes, suggesting that they were acquired directly from endosymbiotic cyanobacteria. All other groups besides the amoeboid Paulinella chromatophora, have chloroplasts surrounded by three or four membranes, suggesting they were acquired secondarily from red or green algae. Unlike red and green algae, glaucophytes have never been involved in secondary endosymbiosis events. The cells of the Archaeplastida typically lack centrioles and have mitochondria with flat cristae. They usually have a cell wall that contain cellulose, and food is stored in the form of starch. However, these characteristics are also shared with other eukaryotes. The main evidence that the Archaeplastida form a monophyletic group comes from genetic studies, which indicate their plastids probably had a single origin. This evidence is disputed. Based on the evidence to date, it is not possible to confirm or refute alternative evolutionary scenarios to a single primary endosymbiosis. Photosynthetic organisms with plastids of different origin (such as brown algae) do not belong to the Archaeplastida. The archaeplastidans fall into two main evolutionary lines. The red algae are pigmented with chlorophyll a and phycobiliproteins, like most cyanobacteria, and accumulate starch outside the chloroplasts. The green algae and land plants – together known as Viridiplantae (Latin for “green plants”) or Chloroplastida – are pigmented with chlorophylls a and b, but lack phycobiliproteins, and starch is accumulated inside the chloroplasts. The glaucophytes have typical cyanobacterial pigments, and are unusual in retaining a cell wall within their plastids (called cyanelles). Algae is an informal term for a large and diverse group of photosynthetic eukaryotic organisms. It is a polyphyletic grouping, including species from multiple distinct clades. Included organisms range from unicellular microalgae, such as Chlorella and the diatoms, to multicellular forms, such as the giant kelp, a large brown alga which may grow up to 50 m in length. Most are aquatic and autotrophic and lack many of the distinct cell and tissue types, such as stomata, xylem and phloem, which are found in land plants. The largest and most complex marine algae are called seaweeds, while the most complex freshwater forms are the Charophyta, a division of green algae which includes, for example, Spirogyra and stoneworts. Figure 5.26: A variety of microscopic unicellular and colonial freshwater algae No definition of algae is generally accepted. One definition is that algae “have chlorophyll as their primary photosynthetic pigment and lack a sterile covering of cells around their reproductive cells”. Although cyanobacteria are often referred to as “blue-green algae”, most authorities exclude all prokaryotes from the definition of algae. Algae constitute a polyphyletic group since they do not include a common ancestor, and although their plastids seem to have a single origin, from cyanobacteria, they were acquired in different ways. Green algae are examples of algae that have primary chloroplasts derived from endosymbiotic cyanobacteria. Diatoms and brown algae are examples of algae with secondary chloroplasts derived from an endosymbiotic red alga. Algae exhibit a wide range of reproductive strategies, from simple asexual cell division to complex forms of sexual reproduction. Figure 5.27: The sexual life cycle of Laminaria, a representative of some 30 different species of brown algae that are commonly called “kelp”. Algae lack the various structures that characterize land plants, such as the phyllids (leaf-like structures) of bryophytes, rhizoids in nonvascular plants, and the roots, leaves, and other organs found in tracheophytes (vascular plants). Most are phototrophic, although some are mixotrophic, deriving energy both from photosynthesis and uptake of organic carbon either by osmotrophy, myzotrophy, or phagotrophy. Some unicellular species of green algae, many golden algae, euglenids, dinoflagellates, and other algae have become heterotrophs (also called colorless or apochlorotic algae), sometimes parasitic, relying entirely on external energy sources and have limited or no photosynthetic apparatus. Some other heterotrophic organisms, such as the apicomplexans, are also derived from cells whose ancestors possessed plastids, but are not traditionally considered as algae. Algae have photosynthetic machinery ultimately derived from cyanobacteria that produce oxygen as a by-product of photosynthesis, unlike other photosynthetic bacteria such as purple and green sulfur bacteria. Fossilized filamentous algae from the Vindhya basin have been dated back to 1.6 to 1.7 billion years ago. The first land plants probably evolved from shallow freshwater charophyte algae much like Chara almost 500 million years ago. These probably had an isomorphic alternation of generations and were probably filamentous. Fossils of isolated land plant spores suggest land plants may have been around as long as 475 million years ago. Most of the simpler algae are unicellular flagellates or amoeboids, but colonial and nonmotile forms have developed independently among several of the groups. In three lines of algae, even higher levels of organization have been reached, with full tissue differentiation. These are the brown algae,—some of which may reach 50 m in length (kelps)—the red algae, and the green algae. The most complex forms are found among the charophyte algae (see Charales and Charophyta), in a lineage that eventually led to the higher land plants. The innovation that defines these nonalgal plants is the presence of female reproductive organs with protective cell layers that protect the zygote and developing embryo. Hence, the land plants are referred to as the Embryophytes. Rhodophyta, Chlorophyta, and Heterokontophyta, the three main algal divisions, have lifecycles which show considerable variation and complexity. In general, an asexual phase exists where the seaweed’s cells are diploid, a sexual phase where the cells are haploid, followed by fusion of the male and female gametes. Asexual reproduction permits efficient population increases, but less variation is possible. Commonly, in sexual reproduction of unicellular and colonial algae, two specialized, sexually compatible, haploid gametes make physical contact and fuse to form a zygote. To ensure a successful mating, the development and release of gametes is highly synchronized and regulated; pheromones may play a key role in these processes. Meiosis has been shown to occur in many different species of algae. For example, Fucus is a genus of brown algae found in the intertidal zones of rocky seashores almost throughout the world. Species of Fucus are recorded almost worldwide. They are dominant on the shores of the British Isles, the northeastern coast of North America and California. These algae have a relatively simple life cycle and produce only one type of thallus which grows to a maximum size of 2 m. Fertile cavities, the conceptacles, containing the reproductive cells are immersed in the receptacles near the ends of the branches. After meiosis oogonia and antheridia, the female and male reproductive organs, produce egg cells and sperm respectively that are released into the sea where fertilisation takes place. The resulting zygote develops directly into the diploid plant. This contrasts with the life cycle of the flowering plant, where the egg cells and sperm are produced by a haploid multicellular generation, albeit very strongly reduced, and the egg cells are fertilised within the ovules of the parent plant and then released as seeds. Algae are prominent in bodies of water, common in terrestrial environments, and are found in unusual environments, such as on snow and ice. Seaweeds grow mostly in shallow marine waters, under 100 m (330 ft) deep; however, some such as Navicula pennata have been recorded to a depth of 360 m (1,180 ft). A type of algae, Ancylonema nordenskioeldii, was found in Greenland in areas known as the ‘Dark Zone’, which caused an increase in the rate of melting ice sheet. Same algae was found in the Italian Alps, after pink ice appeared on parts of the Presena glacier. The various sorts of algae play significant roles in aquatic ecology. Microscopic forms that live suspended in the water column (phytoplankton) provide the food base for most marine food chains. In very high densities (algal blooms), these algae may discolor the water and outcompete, poison, or asphyxiate other life forms. 5.9 Slime Molds Slime mold or slime mould is an informal name given to several kinds of unrelated eukaryotic organisms that can live freely as single cells, but can aggregate together to form multicellular reproductive structures. Slime molds were formerly classified as fungi but are no longer considered part of that kingdom. Although not forming a single monophyletic clade, they are grouped within the paraphyletic group referred to as kingdom Protista. More than 900 species of slime mold occur globally. Their common name refers to part of some of these organisms’ life cycles where they can appear as gelatinous “slime”. This is mostly seen with the Myxogastria, which are the only macroscopic slime molds. Most slime molds are smaller than a few centimeters, but some species may reach sizes up to several square meters and masses up to 20 kilograms. Many slime molds, mainly the “cellular” slime molds, do not spend most of their time in this state. When food is abundant, these slime molds exist as single-celled organisms. When food is in short supply, many of these single-celled organisms will congregate and start moving as a single body. In this state they are sensitive to airborne chemicals and can detect food sources. They can readily change the shape and function of parts, and may form stalks that produce fruiting bodies, releasing countless spores, light enough to be carried on the wind or hitch a ride on passing animals. They feed on microorganisms that live in any type of dead plant material. They contribute to the decomposition of dead vegetation, and feed on bacteria, yeasts, and fungi. For this reason, slime molds are usually found in soil, lawns, and on the forest floor, commonly on deciduous logs. In tropical areas they are also common on inflorescences and fruits, and in aerial situations (e.g., in the canopy of trees). In urban areas, they are found on mulch or in the leaf mold in rain gutters, and also grow in air conditioners, especially when the drain is blocked. Slime molds begin life as amoeba-like cells. These unicellular amoebae are commonly haploid and feed on bacteria. These amoebae can mate if they encounter the correct mating type and form zygotes that then grow into plasmodia. These contain many nuclei without cell membranes between them, and can grow to meters in size. The species Fuligo septica is often seen as a slimy yellow network in and on rotting logs. The amoebae and the plasmodia engulf microorganisms. The plasmodium grows into an interconnected network of protoplasmic strands. Figure 5.28: Fuligo septica, a slime mold Fuligo septica is a species of plasmodial slime mold, and a member of the Myxomycetes class. It is commonly known as the scrambled egg slime, or flowers of tan because of its peculiar yellowish, bile-colored appearance. Also known as the dog vomit slime mold, it is common with a worldwide distribution, and it is often found on bark mulch in urban areas after heavy rain or excessive watering. Their spores are produced on or in aerial sporangia and are spread by wind. Within each protoplasmic strand, the cytoplasmic contents rapidly stream. If one strand is carefully watched for about 50 seconds, the cytoplasm can be seen to slow, stop, and then reverse direction. The streaming protoplasm within a plasmodial strand can reach speeds of up to 1.35 mm per second, which is the fastest rate recorded for any microorganism. Migration of the plasmodium is accomplished when more protoplasm streams to advancing areas and protoplasm is withdrawn from rear areas. When the food supply wanes, the plasmodium will migrate to the surface of its substrate and transform into rigid fruiting bodies. The fruiting bodies or sporangia are what are commonly seen. They superficially look like fungi or molds but are not related to the true fungi. These sporangia will then release spores which hatch into amoebae to begin the life cycle again. Figure 5.29: Dictyostelium Fruiting Body Dictyostelium is a genus of single- and multi-celled eukaryotic, phagotrophic bacterivores. Though they are Protista and in no way fungal, they traditionally are known as “slime molds”. They are present in most terrestrial ecosystems as a normal and often abundant component of the soil microflora, and play an important role in the maintenance of balanced bacterial populations in soils. Figure 5.30: Dictyostelium colony in process of aggregation Figure 5.31: Pseudoplasmodium or “slug” of a Dictyostelium 5.9.1 Reproduction of Protists Some protists reproduce sexually using gametes, while others reproduce asexually. Some species, for example Plasmodium falciparum, have extremely complex life cycles that involve multiple forms of the organism, some of which reproduce sexually and others asexually. However, it is unclear how frequently sexual reproduction causes genetic exchange between different strains of Plasmodium in nature and most populations of parasitic protists may be clonal lines that rarely exchange genes with other members of their species. Eukaryotes emerged in evolution more than 1.5 billion years ago. The earliest eukaryotes were likely protists. Although sexual reproduction is widespread among extant eukaryotes, it seemed unlikely until recently, that sex could be a primordial and fundamental characteristic of eukaryotes. A principal reason for this view was that sex appeared to be lacking in certain pathogenic protists whose ancestors branched off early from the eukaryotic family tree. However, several of these protists are now known to be capable of, or to recently have had the capability for, meiosis and hence sexual reproduction. For example, the common intestinal parasite Giardia lamblia was once considered to be a descendant of a protist lineage that predated the emergence of meiosis and sex. However, G. lamblia was recently found to have a core set of genes that function in meiosis and that are widely present among sexual eukaryotes. These results suggested that G. lamblia is capable of meiosis and thus sexual reproduction. Furthermore, direct evidence for meiotic recombination, indicative of sex, was also found in G. lamblia. The pathogenic parasitic protists of the genus Leishmania have been shown to be capable of a sexual cycle in the invertebrate vector, likened to the meiosis undertaken in the trypanosomes. Protists generally reproduce asexually under favorable environmental conditions, but tend to reproduce sexually under stressful conditions, such as starvation or heat shock. Oxidative stress, which is associated with the production of reactive oxygen species leading to DNA damage, also appears to be an important factor in the induction of sex in protists. Some commonly found Protist pathogens such as Toxoplasma gondii are capable of infecting and undergoing asexual reproduction in a wide variety of animals – which act as secondary or intermediate host – but can undergo sexual reproduction only in the primary or definitive host (for example: felids such as domestic cats in this case). Free-living Protists occupy almost any environment that contains liquid water. Many protists, such as algae, are photosynthetic and are vital primary producers in ecosystems, particularly in the ocean as part of the plankton. Protists make up a large portion of the biomass in both marine and terrestrial environments. Other protists include pathogenic species, such as the kinetoplastid Trypanosoma brucei, which causes sleeping sickness, and species of the apicomplexan Plasmodium, which cause malaria. Some protists are significant parasites of animals (e.g.; five species of the parasitic genus Plasmodium cause malaria in humans and many others cause similar diseases in other vertebrates), plants (the oomycete Phytophthora infestans causes late blight in potatoes) or even of other protists. Protist pathogens share many metabolic pathways with their eukaryotic hosts. This makes therapeutic target development extremely difficult – a drug that harms a protist parasite is also likely to harm its animal/plant host. A more thorough understanding of protist biology may allow these diseases to be treated more efficiently. For example, the apicoplast (a nonphotosynthetic chloroplast but essential to carry out important functions other than photosynthesis) present in apicomplexans provides an attractive target for treating diseases caused by dangerous pathogens such as plasmodium. "],["an-introduction-to-viruses.html", "6 An Introduction To Viruses 6.1 Theories Of The Origin Of Viruses 6.2 Structure And Morphology Of Viruses 6.3 Replication Of Viruses 6.4 Classification Of Viruses 6.5 The Baltimore Classification Of Viruses", " 6 An Introduction To Viruses A virus is a submicroscopic infectious agent that replicates only inside the living cells of an organism. Viruses infect all life forms, from animals and plants to microorganisms, including bacteria and archaea. Since Dmitri Ivanovsky’s 1892 article describing a non-bacterial pathogen infecting tobacco plants and the discovery of the tobacco mosaic virus by Martinus Beijerinck in 1898, more than 9,000 virus species have been described in detail of the millions of types of viruses in the environment. Viruses are found in almost every ecosystem on Earth and are the most numerous type of biological entity. The study of viruses is known as virology, a subspeciality of microbiology. When infected, a host cell is forced to rapidly produce thousands of copies of the original virus. When not inside an infected cell or in the process of infecting a cell, viruses exist in the form of independent particles, or virions, consisting of (i) the genetic material, i.e., long molecules of DNA or RNA that encode the structure of the proteins by which the virus acts; (ii) a protein coat, the capsid, which surrounds and protects the genetic material; and in some cases (iii) an outside envelope of lipids. The shapes of these virus particles range from simple helical and icosahedral forms to more complex structures. Most virus species have virions too small to be seen with an optical microscope, as they are one-hundredth the size of most bacteria. The origins of viruses in the evolutionary history of life are unclear: some may have evolved from plasmids—pieces of DNA that can move between cells—while others may have evolved from bacteria. In evolution, viruses are an important means of horizontal gene transfer, which increases genetic diversity in a way analogous to sexual reproduction. Viruses are considered by some biologists to be a life form, because they carry genetic material, reproduce, and evolve through natural selection, although they lack the key characteristics, such as cell structure, that are generally considered necessary criteria for defining life. Because they possess some but not all such qualities, viruses have been described as “organisms at the edge of life”, and as self-replicators. Viruses spread in many ways. One transmission pathway is through disease-bearing organisms known as vectors: for example, viruses are often transmitted from plant to plant by insects that feed on plant sap, such as aphids; and viruses in animals can be carried by blood-sucking insects. Influenza viruses spread in the air by coughing and sneezing. Norovirus and rotavirus, common causes of viral gastroenteritis, are transmitted by the faecal–oral route, passed by hand-to-mouth contact or in food or water. The infectious dose of norovirus required to produce infection in humans is less than 100 particles. HIV is one of several viruses transmitted through sexual contact and by exposure to infected blood. The variety of host cells that a virus can infect is called its “host range”. This can be narrow, meaning a virus is capable of infecting few species, or broad, meaning it is capable of infecting many. Viral infections in animals provoke an immune response that usually eliminates the infecting virus. Immune responses can also be produced by vaccines, which confer an artificially acquired immunity to the specific viral infection. Some viruses, including those that cause AIDS, HPV infection, and viral hepatitis, evade these immune responses and result in chronic infections. Several antiviral drugs have been developed. The word is from the Latin neuter vīrus referring to poison and other noxious liquids, from the same Indo-European base as Sanskrit viṣa, Avestan vīša, and ancient Greek ἰός (all meaning “poison”), first attested in English in 1398 in John Trevisa’s translation of Bartholomeus Anglicus’s De Proprietatibus Rerum. Virulent, from Latin virulentus (poisonous), dates to c. 1400. A meaning of “agent that causes infectious disease” is first recorded in 1728, long before the discovery of viruses by Dmitri Ivanovsky in 1892. The English plural is viruses (sometimes also vira), whereas the Latin word is a mass noun, which has no classically attested plural (vīra is used in Neo-Latin). The adjective viral dates to 1948. The term virion (plural virions), which dates from 1959, is also used to refer to a single viral particle that is released from the cell and is capable of infecting other cells of the same type. Louis Pasteur was unable to find a causative agent for rabies and speculated about a pathogen too small to be detected by microscopes. In 1884, the French microbiologist Charles Chamberland invented the Chamberland filter (or Pasteur-Chamberland filter) with pores small enough to remove all bacteria from a solution passed through it. In 1892, the Russian biologist Dmitri Ivanovsky used this filter to study what is now known as the tobacco mosaic virus: crushed leaf extracts from infected tobacco plants remained infectious even after filtration to remove bacteria. Ivanovsky suggested the infection might be caused by a toxin produced by bacteria, but he did not pursue the idea. At the time it was thought that all infectious agents could be retained by filters and grown on a nutrient medium—this was part of the germ theory of disease. In 1898, the Dutch microbiologist Martinus Beijerinck repeated the experiments and became convinced that the filtered solution contained a new form of infectious agent. He observed that the agent multiplied only in cells that were dividing, but as his experiments did not show that it was made of particles, he called it a contagium vivum fluidum (soluble living germ) and reintroduced the word virus. Beijerinck maintained that viruses were liquid in nature, a theory later discredited by Wendell Stanley, who proved they were particulate. In the same year, Friedrich Loeffler and Paul Frosch passed the first animal virus, aphthovirus (the agent of foot-and-mouth disease), through a similar filter. In the early 20th century, the English bacteriologist Frederick Twort discovered a group of viruses that infect bacteria, now called bacteriophages (or commonly ‘phages’), and the French-Canadian microbiologist Félix d’Herelle described viruses that, when added to bacteria on an agar plate, would produce areas of dead bacteria. He accurately diluted a suspension of these viruses and discovered that the highest dilutions (lowest virus concentrations), rather than killing all the bacteria, formed discrete areas of dead organisms. Counting these areas and multiplying by the dilution factor allowed him to calculate the number of viruses in the original suspension. Phages were heralded as a potential treatment for diseases such as typhoid and cholera, but their promise was forgotten with the development of penicillin. The development of bacterial resistance to antibiotics has renewed interest in the therapeutic use of bacteriophages. By the end of the 19th century, viruses were defined in terms of their infectivity, their ability to pass filters, and their requirement for living hosts. Viruses had been grown only in plants and animals. In 1906 Ross Granville Harrison invented a method for growing tissue in lymph, and in 1913 E. Steinhardt, C. Israeli, and R.A. Lambert used this method to grow vaccinia virus in fragments of guinea pig corneal tissue. In 1928, H. B. Maitland and M. C. Maitland grew vaccinia virus in suspensions of minced hens’ kidneys. Their method was not widely adopted until the 1950s when poliovirus was grown on a large scale for vaccine production. Another breakthrough came in 1931 when the American pathologist Ernest William Goodpasture and Alice Miles Woodruff grew influenza and several other viruses in fertilised chicken eggs. In 1949, John Franklin Enders, Thomas Weller, and Frederick Robbins grew poliovirus in cultured cells from aborted human embryonic tissue, the first virus to be grown without using solid animal tissue or eggs. This work enabled Hilary Koprowski, and then Jonas Salk, to make an effective polio vaccine. The first images of viruses were obtained upon the invention of electron microscopy in 1931 by the German engineers Ernst Ruska and Max Knoll. In 1935, American biochemist and virologist Wendell Meredith Stanley examined the tobacco mosaic virus and found it was mostly made of protein. A short time later, this virus was separated into protein and RNA parts. The tobacco mosaic virus was the first to be crystallised and its structure could, therefore, be elucidated in detail. The first X-ray diffraction pictures of the crystallised virus were obtained by Bernal and Fankuchen in 1941. Based on her X-ray crystallographic pictures, Rosalind Franklin discovered the full structure of the virus in 1955. In the same year, Heinz Fraenkel-Conrat and Robley Williams showed that purified tobacco mosaic virus RNA and its protein coat can assemble by themselves to form functional viruses, suggesting that this simple mechanism was probably the means through which viruses were created within their host cells. The second half of the 20th century was the golden age of virus discovery, and most of the documented species of animal, plant, and bacterial viruses were discovered during these years. In 1957 equine arterivirus and the cause of Bovine virus diarrhoea (a pestivirus) were discovered. In 1963 the hepatitis B virus was discovered by Baruch Blumberg, and in 1965 Howard Temin described the first retrovirus. Reverse transcriptase, the enzyme that retroviruses use to make DNA copies of their RNA, was first described in 1970 by Temin and David Baltimore independently. In 1983 Luc Montagnier’s team at the Pasteur Institute in France, first isolated the retrovirus now called HIV. In 1989 Michael Houghton’s team at Chiron Corporation discovered Hepatitis C. Viruses are found wherever there is life and have probably existed since living cells first evolved. The origin of viruses is unclear because they do not form fossils, so molecular techniques are used to investigate how they arose. In addition, viral genetic material occasionally integrates into the germline of the host organisms, by which they can be passed on vertically to the offspring of the host for many generations. This provides an invaluable source of information for paleovirologists to trace back ancient viruses that have existed up to millions of years ago. There are three main hypotheses that aim to explain the origins of viruses: 6.1 Theories Of The Origin Of Viruses Viruses may have once been small cells that parasitised larger cells. Over time, genes not required by their parasitism were lost. The bacteria rickettsia and chlamydia are living cells that, like viruses, can reproduce only inside host cells. They lend support to this hypothesis, as their dependence on parasitism is likely to have caused the loss of genes that enabled them to survive outside a cell. This is also called the ‘degeneracy hypothesis’, or ‘reduction hypothesis’. Some viruses may have evolved from bits of DNA or RNA that “escaped” from the genes of a larger organism. The escaped DNA could have come from plasmids (pieces of naked DNA that can move between cells) or transposons (molecules of DNA that replicate and move around to different positions within the genes of the cell). Once called “jumping genes”, transposons are examples of mobile genetic elements and could be the origin of some viruses. They were discovered in maize by Barbara McClintock in 1950. This is sometimes called the ‘vagrancy hypothesis’, or the ‘escape hypothesis’. This is also called the ‘virus-first hypothesis’ and proposes that viruses may have evolved from complex molecules of protein and nucleic acid at the same time that cells first appeared on Earth and would have been dependent on cellular life for billions of years. Viroids are molecules of RNA that are not classified as viruses because they lack a protein coat. They have characteristics that are common to several viruses and are often called subviral agents. Viroids are important pathogens of plants. They do not code for proteins but interact with the host cell and use the host machinery for their replication. The hepatitis delta virus of humans has an RNA genome similar to viroids but has a protein coat derived from hepatitis B virus and cannot produce one of its own. It is, therefore, a defective virus. Although hepatitis delta virus genome may replicate independently once inside a host cell, it requires the help of hepatitis B virus to provide a protein coat so that it can be transmitted to new cells. In similar manner, the sputnik virophage is dependent on mimivirus, which infects the protozoan Acanthamoeba castellanii. These viruses, which are dependent on the presence of other virus species in the host cell, are called ‘satellites’ and may represent evolutionary intermediates of viroids and viruses. In the past, there were problems with all of these hypotheses: the regressive hypothesis did not explain why even the smallest of cellular parasites do not resemble viruses in any way. The escape hypothesis did not explain the complex capsids and other structures on virus particles. The virus-first hypothesis contravened the definition of viruses in that they require host cells. Viruses are now recognised as ancient and as having origins that pre-date the divergence of life into the three domains. This discovery has led modern virologists to reconsider and re-evaluate these three classical hypotheses. The evidence for an ancestral world of RNA cells and computer analysis of viral and host DNA sequences are giving a better understanding of the evolutionary relationships between different viruses and may help identify the ancestors of modern viruses. To date, such analyses have not proved which of these hypotheses is correct. It seems unlikely that all currently known viruses have a common ancestor, and viruses have probably arisen numerous times in the past by one or more mechanisms. Viruses are found wherever there is life and have probably existed since living cells first evolved. The origin of viruses is unclear because they do not form fossils, so molecular techniques are used to investigate how they arose. In addition, viral genetic material occasionally integrates into the germline of the host organisms, by which they can be passed on vertically to the offspring of the host for many generations. This provides an invaluable source of information for paleovirologists to trace back ancient viruses that have existed up to millions of years ago. There are three main hypotheses that aim to explain the origins of viruses: The word is from the Latin neuter vīrus referring to poison and other noxious liquids, from the same Indo-European base as Sanskrit viṣa, Avestan vīša, and ancient Greek ἰός (all meaning “poison”), first attested in English in 1398 in John Trevisa’s translation of Bartholomeus Anglicus’s De Proprietatibus Rerum. Virulent, from Latin virulentus (poisonous), dates to c. 1400. A meaning of “agent that causes infectious disease” is first recorded in 1728, long before the discovery of viruses by Dmitri Ivanovsky in 1892. The English plural is viruses (sometimes also vira) whereas the Latin word is a mass noun, which has no classically attested plural (vīra is used in Neo-Latin). The adjective viral dates to 1948. The term virion (plural virions), which dates from 1959, is also used to refer to a single viral particle that is released from the cell and is capable of infecting other cells of the same type. Scientific opinions differ on whether viruses are a form of life, or organic structures that interact with living organisms. They have been described as “organisms at the edge of life”, since they resemble organisms in that they possess genes, evolve by natural selection, and reproduce by creating multiple copies of themselves through self-assembly. Although they have genes, they do not have a cellular structure, which is often seen as the basic unit of life. Viruses do not have their own metabolism, and require a host cell to make new products. They therefore cannot naturally reproduce outside a host cell—although bacterial species such as rickettsia and chlamydia are considered living organisms despite the same limitation. Accepted forms of life use cell division to reproduce, whereas viruses spontaneously assemble within cells. They differ from autonomous growth of crystals as they inherit genetic mutations while being subject to natural selection. Virus self-assembly within host cells has implications for the study of the origin of life, as it lends further credence to the hypothesis that life could have started as self-assembling organic molecules. 6.2 Structure And Morphology Of Viruses Viruses display a wide diversity of shapes and sizes, called ‘morphologies’. In general, viruses are much smaller than bacteria. Most viruses that have been studied have a diameter between 20 and 300 nanometres. Some filoviruses have a total length of up to 1400 nm; their diameters are only about 80 nm. Most viruses cannot be seen with an optical microscope, so scanning and transmission electron microscopes are used to visualise them. To increase the contrast between viruses and the background, electron-dense “stains” are used. These are solutions of salts of heavy metals, such as tungsten, that scatter the electrons from regions covered with the stain. When virions are coated with stain (positive staining), fine detail is obscured. Negative staining overcomes this problem by staining the background only. A complete virus particle, known as a virion, consists of nucleic acid surrounded by a protective coat of protein called a capsid. These are formed from identical protein subunits called capsomeres. Viruses can have a lipid “envelope” derived from the host cell membrane. The capsid is made from proteins encoded by the viral genome and its shape serves as the basis for morphological distinction. Virally-coded protein subunits will self-assemble to form a capsid, in general requiring the presence of the virus genome. Complex viruses code for proteins that assist in the construction of their capsid. Proteins associated with nucleic acid are known as nucleoproteins, and the association of viral capsid proteins with viral nucleic acid is called a nucleocapsid. The capsid and entire virus structure can be mechanically (physically) probed through atomic force microscopy. In general, there are four main morphological virus types: Helical viruses are composed of a single type of capsomere stacked around a central axis to form a helical structure, which may have a central cavity, or tube. This arrangement results in rod-shaped or filamentous virions which can be short and highly rigid, or long and very flexible. The genetic material (typically single-stranded RNA, but ssDNA in some cases) is bound into the protein helix by interactions between the negatively charged nucleic acid and positive charges on the protein. Overall, the length of a helical capsid is related to the length of the nucleic acid contained within it, and the diameter is dependent on the size and arrangement of capsomeres. The well-studied tobacco mosaic virus is an example of a helical virus. Figure 6.1: Structure of tobacco mosaic virus: RNA coiled in a helix of repeating protein sub-units Most animal viruses are icosahedral or near-spherical with chiral icosahedral symmetry. A regular icosahedron is the optimum way of forming a closed shell from identical sub-units. The minimum number of identical capsomeres required for each triangular face is 3, which gives 60 for the icosahedron. Many viruses, such as rotavirus, have more than 60 capsomers and appear spherical but they retain this symmetry. To achieve this, the capsomeres at the apices are surrounded by five other capsomeres and are called pentons. Capsomeres on the triangular faces are surrounded by six others and are called hexons. Hexons are in essence flat and pentons, which form the 12 vertices, are curved. The same protein may act as the subunit of both the pentamers and hexamers or they may be composed of different proteins. Figure 6.2: Structure of an icosahedral cowpea mosaic virus Some species of virus envelop themselves in a modified form of one of the cell membranes, either the outer membrane surrounding an infected host cell or internal membranes such as nuclear membrane or endoplasmic reticulum, thus gaining an outer lipid bilayer known as a viral envelope. This membrane is studded with proteins coded for by the viral genome and host genome; the lipid membrane itself and any carbohydrates present originate entirely from the host. The influenza virus and HIV use this strategy. Most enveloped viruses are dependent on the envelope for their infectivity. These viruses possess a capsid that is neither purely helical nor purely icosahedral, and that may possess extra structures such as protein tails or a complex outer wall. Some bacteriophages, such as Enterobacteria phage T4, have a complex structure consisting of an icosahedral head bound to a helical tail, which may have a hexagonal base plate with protruding protein tail fibres. This tail structure acts like a molecular syringe, attaching to the bacterial host and then injecting the viral genome into the cell. The poxviruses are large, complex viruses that have an unusual morphology. The viral genome is associated with proteins within a central disc structure known as a nucleoid. The nucleoid is surrounded by a membrane and two lateral bodies of unknown function. The virus has an outer envelope with a thick layer of protein studded over its surface. The whole virion is slightly pleomorphic, ranging from ovoid to brick-shaped. Mimivirus is one of the largest characterised viruses, with a capsid diameter of 400 nm. Protein filaments measuring 100 nm project from the surface. The capsid appears hexagonal under an electron microscope, therefore the capsid is probably icosahedral. In 2011, researchers discovered the largest then known virus in samples of water collected from the ocean floor off the coast of Las Cruces, Chile. Provisionally named Megavirus chilensis, it can be seen with a basic optical microscope. In 2013, the Pandoravirus genus was discovered in Chile and Australia, and has genomes about twice as large as Megavirus and Mimivirus. All giant viruses have dsDNA genomes and they are classified into several families: Mimiviridae, Pithoviridae, Pandoraviridae, Phycodnaviridae, and the Mollivirus genus. Some viruses that infect Archaea have complex structures unrelated to any other form of virus, with a wide variety of unusual shapes, ranging from spindle-shaped structures to viruses that resemble hooked rods, teardrops or even bottles. Other archaeal viruses resemble the tailed bacteriophages, and can have multiple tail structures. An enormous variety of genomic structures can be seen among viral species; as a group, they contain more structural genomic diversity than plants, animals, archaea, or bacteria. There are millions of different types of viruses, although fewer than 7,000 types have been described in detail. As of September 2015, the NCBI Virus genome database has more than 75,000 complete genome sequences, but there are doubtlessly many more to be discovered. A virus has either a DNA or an RNA genome and is called a DNA virus or an RNA virus, respectively. The vast majority of viruses have RNA genomes. Plant viruses tend to have single-stranded RNA genomes and bacteriophages tend to have double-stranded DNA genomes. Viral genomes are circular, as in the polyomaviruses, or linear, as in the adenoviruses. The type of nucleic acid is irrelevant to the shape of the genome. Among RNA viruses and certain DNA viruses, the genome is often divided up into separate parts, in which case it is called segmented. For RNA viruses, each segment often codes for only one protein and they are usually found together in one capsid. All segments are not required to be in the same virion for the virus to be infectious, as demonstrated by brome mosaic virus and several other plant viruses. A viral genome, irrespective of nucleic acid type, is almost always either single-stranded or double-stranded. Single-stranded genomes consist of an unpaired nucleic acid, analogous to one-half of a ladder split down the middle. Double-stranded genomes consist of two complementary paired nucleic acids, analogous to a ladder. The virus particles of some virus families, such as those belonging to the Hepadnaviridae, contain a genome that is partially double-stranded and partially single-stranded. For most viruses with RNA genomes and some with single-stranded DNA genomes, the single strands are said to be either positive-sense (called the ‘plus-strand’) or negative-sense (called the ‘minus-strand’), depending on if they are complementary to the viral messenger RNA (mRNA). Positive-sense viral RNA is in the same sense as viral mRNA and thus at least a part of it can be immediately translated by the host cell. Negative-sense viral RNA is complementary to mRNA and thus must be converted to positive-sense RNA by an RNA-dependent RNA polymerase before translation. DNA nomenclature for viruses with single-sense genomic ssDNA is similar to RNA nomenclature, in that positive-strand viral ssDNA is identical in sequence to the viral mRNA and is thus a coding strand, while negative-strand viral ssDNA is complementary to the viral mRNA and is thus a template strand. Several types of ssDNA and ssRNA viruses have genomes that are ambisense in that transcription can occur off both strands in a double-stranded replicative intermediate. Examples include geminiviruses, which are ssDNA plant viruses and arenaviruses, which are ssRNA viruses of animals. Figure 6.3: This negative-stained transmission electron micrograph (TEM) depicts the ultrastructural details of an influenza virus particle, or “virion”. A member of the taxonomic family Orthomyxoviridae, the influenza virus is an enveloped, single-stranded RNA virus. Eight helical capsis are surrounded by the viral envelope. Particle diameter: 80 -120 nm Genome size varies greatly between species. The smallest—the ssDNA circoviruses, family Circoviridae—code for only two proteins and have a genome size of only two kilobases; the largest—the pandoraviruses—have genome sizes of around two megabases which code for about 2500 proteins. Virus genes rarely have introns and often are arranged in the genome so that they overlap. In general, RNA viruses have smaller genome sizes than DNA viruses because of a higher error-rate when replicating, and have a maximum upper size limit. Beyond this, errors when replicating render the virus useless or uncompetitive. To compensate, RNA viruses often have segmented genomes—the genome is split into smaller molecules—thus reducing the chance that an error in a single-component genome will incapacitate the entire genome. In contrast, DNA viruses generally have larger genomes because of the high fidelity of their replication enzymes. Single-strand DNA viruses are an exception to this rule, as mutation rates for these genomes can approach the extreme of the ssRNA virus case. Viruses undergo genetic change by several mechanisms. These include a process called antigenic drift where individual bases in the DNA or RNA mutate to other bases. Most of these point mutations are “silent”—they do not change the protein that the gene encodes—but others can confer evolutionary advantages such as resistance to antiviral drugs. Antigenic shift occurs when there is a major change in the genome of the virus. This can be a result of recombination or reassortment. When this happens with influenza viruses, pandemics might result. RNA viruses often exist as quasispecies or swarms of viruses of the same species but with slightly different genome nucleoside sequences. Such quasispecies are a prime target for natural selection. Segmented genomes confer evolutionary advantages; different strains of a virus with a segmented genome can shuffle and combine genes and produce progeny viruses (or offspring) that have unique characteristics. This is called reassortment or ‘viral sex’. Genetic recombination is the process by which a strand of DNA is broken and then joined to the end of a different DNA molecule. This can occur when viruses infect cells simultaneously and studies of viral evolution have shown that recombination has been rampant in the species studied. Recombination is common to both RNA and DNA viruses. 6.3 Replication Of Viruses Viral populations do not grow through cell division, because they are acellular. Instead, they use the machinery and metabolism of a host cell to produce multiple copies of themselves, and they assemble in the cell. When infected, the host cell is forced to rapidly produce thousands of identical copies of the original virus. Figure 6.4: A typical virus replication cycle. Their life cycle differs greatly between species, but there are six basic stages in their life cycle: Attachment is a specific binding between viral capsid proteins and specific receptors on the host cellular surface. This specificity determines the host range and type of host cell of a virus. For example, HIV infects a limited range of human leucocytes. This is because its surface protein, gp120, specifically interacts with the CD4 molecule—a chemokine receptor—which is most commonly found on the surface of CD4+ T-Cells. This mechanism has evolved to favour those viruses that infect only cells in which they are capable of replication. Attachment to the receptor can induce the viral envelope protein to undergo changes that result in the fusion of viral and cellular membranes, or changes of non-enveloped virus surface proteins that allow the virus to enter. Penetration follows attachment: Virions enter the host cell through receptor-mediated endocytosis or membrane fusion in a process often known as viral entry. The infection of plant and fungal cells is different from that of animal cells. Plants have a rigid cell wall made of cellulose, and fungi one of chitin, so most viruses can get inside these cells only after trauma to the cell wall. Nearly all plant viruses (such as tobacco mosaic virus) can also move directly from cell to cell, in the form of single-stranded nucleoprotein complexes, through pores called plasmodesmata. Bacteria, like plants, have strong cell walls that a virus must breach to infect the cell. Given that bacterial cell walls are much thinner than plant cell walls due to their much smaller size, some viruses have evolved mechanisms that inject their genome into the bacterial cell across the cell wall, while the viral capsid remains outside. Uncoating is a process in which the viral capsid is removed: This may be by degradation by viral enzymes or host enzymes or by simple dissociation; the end-result is the releasing of the viral genomic nucleic acid. Replication of viruses involves primarily multiplication of the genome. Replication involves synthesis of viral messenger RNA (mRNA) from “early” genes (with exceptions for positive sense RNA viruses), viral protein synthesis, possible assembly of viral proteins, then viral genome replication mediated by early or regulatory protein expression. This may be followed, for complex viruses with larger genomes, by one or more further rounds of mRNA synthesis: “late” gene expression is, in general, of structural or virion proteins. Assembly – Following the structure-mediated self-assembly of the virus particles, some modification of the proteins often occurs. In viruses such as HIV, this modification (sometimes called maturation) occurs after the virus has been released from the host cell. Release – Viruses can be released from the host cell by lysis, a process that kills the cell by bursting its membrane and cell wall if present: this is a feature of many bacterial and some animal viruses. Some viruses undergo a lysogenic cycle where the viral genome is incorporated by genetic recombination into a specific place in the host’s chromosome. The viral genome is then known as a “provirus” or, in the case of bacteriophages a “prophage”. Whenever the host divides, the viral genome is also replicated. The viral genome is mostly silent within the host. At some point, the provirus or prophage may give rise to active virus, which may lyse the host cells. Enveloped viruses (e.g., HIV) typically are released from the host cell by budding. During this process the virus acquires its envelope, which is a modified piece of the host’s plasma or other, internal membrane. The genetic material within virus particles, and the method by which the material is replicated, varies considerably between different types of viruses. The genome replication of most DNA viruses takes place in the cell’s nucleus. If the cell has the appropriate receptor on its surface, these viruses enter the cell either by direct fusion with the cell membrane (e.g., herpesviruses) or—more usually—by receptor-mediated endocytosis. Most DNA viruses are entirely dependent on the host cell’s DNA and RNA synthesising machinery, and RNA processing machinery. Viruses with larger genomes may encode much of this machinery themselves. In eukaryotes the viral genome must cross the cell’s nuclear membrane to access this machinery, while in bacteria it need only enter the cell. Replication of RNA viruses usually takes place in the cytoplasm. RNA viruses can be placed into four different groups depending on their modes of replication. The polarity (whether or not it can be used directly by ribosomes to make proteins) of single-stranded RNA viruses largely determines the replicative mechanism; the other major criterion is whether the genetic material is single-stranded or double-stranded. All RNA viruses use their own RNA replicase enzymes to create copies of their genomes. Reverse transcribing viruses have ssRNA (Retroviridae, Metaviridae, Pseudoviridae) or dsDNA (Caulimoviridae, and Hepadnaviridae) in their particles. Reverse transcribing viruses with RNA genomes (retroviruses) use a DNA intermediate to replicate, whereas those with DNA genomes (pararetroviruses) use an RNA intermediate during genome replication. Both types use a reverse transcriptase, or RNA-dependent DNA polymerase enzyme, to carry out the nucleic acid conversion. Retroviruses integrate the DNA produced by reverse transcription into the host genome as a provirus as a part of the replication process; pararetroviruses do not, although integrated genome copies of especially plant pararetroviruses can give rise to infectious virus. They are susceptible to antiviral drugs that inhibit the reverse transcriptase enzyme, e.g. zidovudine and lamivudine. An example of the first type is HIV, which is a retrovirus. Examples of the second type are the Hepadnaviridae, which includes Hepatitis B virus. Figure 6.5: Taxonomy and replication strategies of RNA viruses. A) Simplified taxonomy of the genome architecture of the RNA viruses described in this review. See main text for used abbreviations. B) (+RNA virus) Infection with a +RNA virus—as exemplified here with a CoV-like virion—releases a single-stranded RNA genome into the cytoplasm (1). (2) Translation of the 5′-terminal open-reading frame of the genome produces the viral replicase. (3) This multi-enzyme complex includes RdRp activity (orange) and associates with intracellular membranes before −RNA synthesis commences. Newly synthesised −RNAs are subsequently used to produce new +RNAs (4), which are typically capped (yellow) and polyadenylated (polyA). (Retrovirus) HIV-1 genomes are packaged as ssRNA in virions. When the ssRNA is released (1) a cDNA copy is synthesised by the RT (2). The RNA is next degraded by the intrinsic RNase H activity in the RT (3) and the single stranded cDNA converted to dsDNA (4). The dsDNA is imported in the nucleus (5) for integration into the host’s genetic material. (−RNA virus) (1) As illustrated here with an IAV-like particle, infection with an −RNA virus releases a viral RNA genome that is associated with a viral polymerase (orange) and nucleoprotein (green). (2) In the case of non-segmented −RNA viruses, these complexes support transcription to produce viral mRNAs or cRNAs. (3) Viral mRNAs are next translated and new viral proteins complex with cRNAs to synthesise new vRNAs. (5) The vRNA-containing complexes of some segmented −RNA viruses are imported into the nucleus of the host cell, where (6) the RdRp produces mRNAs or cRNAs. (7) mRNAs are transported to the cytoplasm, while cRNAs are bound by new viral proteins to form cRNPs for −RNA synthesis. (dsRNA virus) Fully duplexed RNA genomes lack cap and polyA elements. (1) The RdRp (orange), therefore, transcribes the viral genome inside the capsid of the virion (blue and red), so viral mRNAs can be (2) released into the cytoplasm as illustrated here with a rotavirus-like virion. In the cytoplasm the mRNA is translated (3) or replicated by newly synthesised viral RdRps (4)] 6.3.1 Role Of Viruses In Human Disease The range of structural and biochemical effects that viruses have on the host cell is extensive. These are called ‘cytopathic effects’. Most virus infections eventually result in the death of the host cell. The causes of death include cell lysis, alterations to the cell’s surface membrane and apoptosis. Often cell death is caused by cessation of its normal activities because of suppression by virus-specific proteins, not all of which are components of the virus particle. The distinction between cytopathic and harmless is gradual. Some viruses, such as Epstein–Barr virus, can cause cells to proliferate without causing malignancy, while others, such as papillomaviruses, are established causes of cancer. Some viruses cause no apparent changes to the infected cell. Cells in which the virus is latent and inactive show few signs of infection and often function normally. This causes persistent infections and the virus is often dormant for many months or years. This is often the case with herpes viruses. Viruses are by far the most abundant biological entities on Earth and they outnumber all the others put together. They infect all types of cellular life including animals, plants, bacteria and fungi. Different types of viruses can infect only a limited range of hosts and many are species-specific. Some, such as smallpox virus for example, can infect only one species—in this case humans, and are said to have a narrow host range. Other viruses, such as rabies virus, can infect different species of mammals and are said to have a broad range. The viruses that infect plants are harmless to animals, and most viruses that infect other animals are harmless to humans. The host range of some bacteriophages is limited to a single strain of bacteria and they can be used to trace the source of outbreaks of infections by a method called phage typing. The complete set of viruses in an organism or habitat is called the virome; for example, all human viruses constitute the human virome. Examples of common human diseases caused by viruses include the common cold, influenza, chickenpox, and cold sores. Many serious diseases such as rabies, Ebola virus disease, AIDS (HIV), avian influenza, and SARS are caused by viruses. The relative ability of viruses to cause disease is described in terms of virulence. Other diseases are under investigation to discover if they have a virus as the causative agent, such as the possible connection between human herpesvirus 6 (HHV6) and neurological diseases such as multiple sclerosis and chronic fatigue syndrome. There is controversy over whether the bornavirus, previously thought to cause neurological diseases in horses, could be responsible for psychiatric illnesses in humans. Viruses have different mechanisms by which they produce disease in an organism, which depends largely on the viral species. Mechanisms at the cellular level primarily include cell lysis, the breaking open and subsequent death of the cell. In multicellular organisms, if enough cells die, the whole organism will start to suffer the effects. Although viruses cause disruption of healthy homeostasis, resulting in disease, they may exist relatively harmlessly within an organism. An example would include the ability of the herpes simplex virus, which causes cold sores, to remain in a dormant state within the human body. This is called latency and is a characteristic of the herpes viruses, including Epstein–Barr virus, which causes glandular fever, and varicella zoster virus, which causes chickenpox and shingles. Most people have been infected with at least one of these types of herpes virus. These latent viruses might sometimes be beneficial, as the presence of the virus can increase immunity against bacterial pathogens, such as Yersinia pestis. Some viruses can cause lifelong or chronic infections, where the viruses continue to replicate in the body despite the host’s defence mechanisms. This is common in hepatitis B virus and hepatitis C virus infections. People chronically infected are known as carriers, as they serve as reservoirs of infectious virus. In populations with a high proportion of carriers, the disease is said to be endemic. Viral epidemiology is the branch of medical science that deals with the transmission and control of virus infections in humans. Transmission of viruses can be vertical, which means from mother to child, or horizontal, which means from person to person. Examples of vertical transmission include hepatitis B virus and HIV, where the baby is born already infected with the virus. Another, more rare, example is the varicella zoster virus, which, although causing relatively mild infections in children and adults, can be fatal to the foetus and newborn baby. Horizontal transmission is the most common mechanism of spread of viruses in populations. Horizontal transmission can occur when body fluids are exchanged during sexual activity, by exchange of saliva or when contaminated food or water is ingested. It can also occur when aerosols containing viruses are inhaled or by insect vectors such as when infected mosquitoes penetrate the skin of a host. Most types of viruses are restricted to just one or two of these mechanisms and they are referred to as “respiratory viruses” or “enteric viruses” and so forth. The rate or speed of transmission of viral infections depends on factors that include population density, the number of susceptible individuals, (i.e., those not immune), the quality of healthcare and the weather. Epidemiology is used to break the chain of infection in populations during outbreaks of viral diseases. Control measures are used that are based on knowledge of how the virus is transmitted. It is important to find the source, or sources, of the outbreak and to identify the virus. Once the virus has been identified, the chain of transmission can sometimes be broken by vaccines. When vaccines are not available, sanitation and disinfection can be effective. Often, infected people are isolated from the rest of the community, and those that have been exposed to the virus are placed in quarantine. To control the outbreak of foot-and-mouth disease in cattle in Britain in 2001, thousands of cattle were slaughtered. Most viral infections of humans and other animals have incubation periods during which the infection causes no signs or symptoms. Incubation periods for viral diseases range from a few days to weeks, but are known for most infections. Somewhat overlapping, but mainly following the incubation period, there is a period of communicability—a time when an infected individual or animal is contagious and can infect another person or animal. This, too, is known for many viral infections, and knowledge of the length of both periods is important in the control of outbreaks. When outbreaks cause an unusually high proportion of cases in a population, community, or region, they are called epidemics. If outbreaks spread worldwide, they are called pandemics. A pandemic is a worldwide epidemic. The 1918 flu pandemic, which lasted until 1919, was a category 5 influenza pandemic caused by an unusually severe and deadly influenza A virus. The victims were often healthy young adults, in contrast to most influenza outbreaks, which predominantly affect juvenile, elderly, or otherwise-weakened patients. Older estimates say it killed 40–50 million people, while more recent research suggests that it may have killed as many as 100 million people, or 5% of the world’s population in 1918. Although viral pandemics are rare events, HIV—which evolved from viruses found in monkeys and chimpanzees—has been pandemic since at least the 1980s. During the 20th century there were four pandemics caused by influenza virus and those that occurred in 1918, 1957 and 1968 were severe. Most researchers believe that HIV originated in sub-Saharan Africa during the 20th century; it is now a pandemic, with an estimated 37.9 million people now living with the disease worldwide. There were about 770,000 deaths from AIDS in 2018. The Joint United Nations Programme on HIV/AIDS (UNAIDS) and the World Health Organization (WHO) estimate that AIDS has killed more than 25 million people since it was first recognised on 5 June 1981, making it one of the most destructive epidemics in recorded history. In 2007 there were 2.7 million new HIV infections and 2 million HIV-related deaths. Several highly lethal viral pathogens are members of the Filoviridae. Filoviruses are filament-like viruses that cause viral hemorrhagic fever, and include ebolaviruses and marburgviruses. Marburg virus, first discovered in 1967, attracted widespread press attention in April 2005 for an outbreak in Angola. Ebola virus disease has also caused intermittent outbreaks with high mortality rates since 1976 when it was first identified. The worst and most recent one is the 2013–2016 West Africa epidemic. With the exception of smallpox, most pandemics are caused by newly evolved viruses. These “emergent” viruses are usually mutants of less harmful viruses that have circulated previously either in humans or other animals. Severe acute respiratory syndrome (SARS) and Middle East respiratory syndrome (MERS) are caused by new types of coronaviruses. Other coronaviruses are known to cause mild infections in humans, so the virulence and rapid spread of SARS infections—that by July 2003 had caused around 8,000 cases and 800 deaths—was unexpected and most countries were not prepared. A related coronavirus emerged in Wuhan, China in November 2019 and spread rapidly around the world. Thought to have originated in bats and subsequently named severe acute respiratory syndrome coronavirus 2, infections with the virus caused a pandemic in 2020. Unprecedented restrictions in peacetime have been placed on international travel, and curfews imposed in several major cities worldwide. Viruses are an established cause of cancer in humans and other species. Viral cancers occur only in a minority of infected persons (or animals). Cancer viruses come from a range of virus families, including both RNA and DNA viruses, and so there is no single type of “oncovirus” (an obsolete term originally used for acutely transforming retroviruses). The development of cancer is determined by a variety of factors such as host immunity and mutations in the host. Viruses accepted to cause human cancers include some genotypes of human papillomavirus, hepatitis B virus, hepatitis C virus, Epstein–Barr virus, Kaposi’s sarcoma-associated herpesvirus and human T-lymphotropic virus. The most recently discovered human cancer virus is a polyomavirus (Merkel cell polyomavirus) that causes most cases of a rare form of skin cancer called Merkel cell carcinoma. Hepatitis viruses can develop into a chronic viral infection that leads to liver cancer. Infection by human T-lymphotropic virus can lead to tropical spastic paraparesis and adult T-cell leukaemia. Human papillomaviruses are an established cause of cancers of cervix, skin, anus, and penis. Within the Herpesviridae, Kaposi’s sarcoma-associated herpesvirus causes Kaposi’s sarcoma and body-cavity lymphoma, and Epstein–Barr virus causes Burkitt’s lymphoma, Hodgkin’s lymphoma, B lymphoproliferative disorder, and nasopharyngeal carcinoma. Merkel cell polyomavirus closely related to SV40 and mouse polyomaviruses that have been used as animal models for cancer viruses for over 50 years. The body’s first line of defence against viruses is the innate immune system. This comprises cells and other mechanisms that defend the host from infection in a non-specific manner. This means that the cells of the innate system recognise, and respond to, pathogens in a generic way, but, unlike the adaptive immune system, it does not confer long-lasting or protective immunity to the host. RNA interference is an important innate defence against viruses. Many viruses have a replication strategy that involves double-stranded RNA (dsRNA). When such a virus infects a cell, it releases its RNA molecule or molecules, which immediately bind to a protein complex called a dicer that cuts the RNA into smaller pieces. A biochemical pathway—the RISC complex—is activated, which ensures cell survival by degrading the viral mRNA. Rotaviruses have evolved to avoid this defence mechanism by not uncoating fully inside the cell, and releasing newly produced mRNA through pores in the particle’s inner capsid. Their genomic dsRNA remains protected inside the core of the virion. When the adaptive immune system of a vertebrate encounters a virus, it produces specific antibodies that bind to the virus and often render it non-infectious. This is called humoral immunity. Two types of antibodies are important. The first, called IgM, is highly effective at neutralising viruses but is produced by the cells of the immune system only for a few weeks. The second, called IgG, is produced indefinitely. The presence of IgM in the blood of the host is used to test for acute infection, whereas IgG indicates an infection sometime in the past. IgG antibody is measured when tests for immunity are carried out. Antibodies can continue to be an effective defence mechanism even after viruses have managed to gain entry to the host cell. A protein that is in cells, called TRIM21, can attach to the antibodies on the surface of the virus particle. This primes the subsequent destruction of the virus by the enzymes of the cell’s proteosome system. A second defence of vertebrates against viruses is called cell-mediated immunity and involves immune cells known as T cells. The body’s cells constantly display short fragments of their proteins on the cell’s surface, and, if a T cell recognises a suspicious viral fragment there, the host cell is destroyed by ‘killer T’ cells and the virus-specific T-cells proliferate. Cells such as the macrophage are specialists at this antigen presentation. The production of interferon is an important host defence mechanism. This is a hormone produced by the body when viruses are present. Its role in immunity is complex; it eventually stops the viruses from reproducing by killing the infected cell and its close neighbours. Not all virus infections produce a protective immune response in this way. HIV evades the immune system by constantly changing the amino acid sequence of the proteins on the surface of the virion. This is known as “escape mutation” as the viral epitopes escape recognition by the host immune response. These persistent viruses evade immune control by sequestration, blockade of antigen presentation, cytokine resistance, evasion of natural killer cell activities, escape from apoptosis, and antigenic shift. Other viruses, called ‘neurotropic viruses’, are disseminated by neural spread where the immune system may be unable to reach them. Because viruses use vital metabolic pathways within host cells to replicate, they are difficult to eliminate without using drugs that cause toxic effects to host cells in general. The most effective medical approaches to viral diseases are vaccinations to provide immunity to infection, and antiviral drugs that selectively interfere with viral replication. Vaccination is a cheap and effective way of preventing infections by viruses. Vaccines were used to prevent viral infections long before the discovery of the actual viruses. Their use has resulted in a dramatic decline in morbidity (illness) and mortality (death) associated with viral infections such as polio, measles, mumps and rubella. Smallpox infections have been eradicated. Vaccines are available to prevent over thirteen viral infections of humans, and more are used to prevent viral infections of animals. Vaccines can consist of live-attenuated or killed viruses, or viral proteins (antigens). Live vaccines contain weakened forms of the virus, which do not cause the disease but, nonetheless, confer immunity. Such viruses are called attenuated. Live vaccines can be dangerous when given to people with a weak immunity (who are described as immunocompromised), because in these people, the weakened virus can cause the original disease. Biotechnology and genetic engineering techniques are used to produce subunit vaccines. These vaccines use only the capsid proteins of the virus. Hepatitis B vaccine is an example of this type of vaccine. Subunit vaccines are safe for immunocompromised patients because they cannot cause the disease. The yellow fever virus vaccine, a live-attenuated strain called 17D, is probably the safest and most effective vaccine ever generated. Antiviral drugs are often nucleoside analogues (fake DNA building-blocks), which viruses mistakenly incorporate into their genomes during replication. The life-cycle of the virus is then halted because the newly synthesised DNA is inactive. This is because these analogues lack the hydroxyl groups, which, along with phosphorus atoms, link together to form the strong “backbone” of the DNA molecule. This is called DNA chain termination. Examples of nucleoside analogues are aciclovir for Herpes simplex virus infections and lamivudine for HIV and hepatitis B virus infections. Aciclovir is one of the oldest and most frequently prescribed antiviral drugs. Other antiviral drugs in use target different stages of the viral life cycle. HIV is dependent on a proteolytic enzyme called the HIV-1 protease for it to become fully infectious. There is a large class of drugs called protease inhibitors that inactivate this enzyme. Hepatitis C is caused by an RNA virus. In 80% of people infected, the disease is chronic, and without treatment, they are infected for the remainder of their lives. There is now an effective treatment that uses the nucleoside analogue drug ribavirin combined with interferon. The treatment of chronic carriers of the hepatitis B virus by using a similar strategy using lamivudine has been developed. 6.3.2 Animal Viruses Viruses are important pathogens of livestock. Diseases such as foot-and-mouth disease and bluetongue are caused by viruses. Companion animals such as cats, dogs, and horses, if not vaccinated, are susceptible to serious viral infections. Canine parvovirus is caused by a small DNA virus and infections are often fatal in pups. Like all invertebrates, the honey bee is susceptible to many viral infections. Most viruses co-exist harmlessly in their host and cause no signs or symptoms of disease. 6.3.3 Plant Viruses There are many types of plant virus, but often they cause only a loss of yield, and it is not economically viable to try to control them. Plant viruses are often spread from plant to plant by organisms, known as vectors. These are usually insects, but some fungi, nematode worms, and single-celled organisms have been shown to be vectors. When control of plant virus infections is considered economical, for perennial fruits, for example, efforts are concentrated on killing the vectors and removing alternate hosts such as weeds. Plant viruses cannot infect humans and other animals because they can reproduce only in living plant cells. Originally from Peru, the potato has become a staple crop worldwide. The potato virus Y causes disease in potatoes and related species including tomatoes and peppers. In the 1980s, this virus acquired economical importance when it proved difficult to control in seed potato crops. Transmitted by aphids, this virus can reduce crop yields by up to 80 per cent, causing significant losses to potato yields. Plants have elaborate and effective defence mechanisms against viruses. One of the most effective is the presence of so-called resistance (R) genes. Each R gene confers resistance to a particular virus by triggering localised areas of cell death around the infected cell, which can often be seen with the unaided eye as large spots. This stops the infection from spreading. RNA interference is also an effective defence in plants. When they are infected, plants often produce natural disinfectants that kill viruses, such as salicylic acid, nitric oxide, and reactive oxygen molecules. Plant virus particles or virus-like particles (VLPs) have applications in both biotechnology and nanotechnology. The capsids of most plant viruses are simple and robust structures and can be produced in large quantities either by the infection of plants or by expression in a variety of heterologous systems. Plant virus particles can be modified genetically and chemically to encapsulate foreign material and can be incorporated into supramolecular structures for use in biotechnology. 6.3.4 Bacterial Viruses A bacteriophage, also known informally as a phage, is a virus that infects and replicates within bacteria and archaea. The term was derived from “bacteria” and the Greek φαγεῖν (phagein), meaning “to devour”. Bacteriophages are composed of proteins that encapsulate a DNA or RNA genome, and may have structures that are either simple or elaborate. Their genomes may encode as few as four genes and as many as hundreds of genes. Figure 6.6: Structural overview of T2 phage These viruses infect specific bacteria by binding to surface receptor molecules and then entering the cell. Within a short amount of time, in some cases just minutes, bacterial polymerase starts translating viral mRNA into protein. These proteins go on to become either new virions within the cell, helper proteins, which help assembly of new virions, or proteins involved in cell lysis. Viral enzymes aid in the breakdown of the cell membrane, and, in the case of the T4 phage, in just over twenty minutes after injection over three hundred phages could be released. Figure 6.7: Diagram showing bacteriophages infecting a bacterial cell (not to scale; bacteriophages are much smaller than bacteria) The major way bacteria defend themselves from bacteriophages is by producing enzymes that destroy foreign DNA. These enzymes, called restriction endonucleases, cut up the viral DNA that bacteriophages inject into bacterial cells. Bacteria also contain a system that uses CRISPR sequences to retain fragments of the genomes of viruses that the bacteria have come into contact with in the past, which allows them to block the virus’s replication through a form of RNA interference. This genetic system provides bacteria with acquired immunity to infection. Bacteriophages are among the most common and diverse entities in the biosphere. Bacteriophages are ubiquitous viruses, found wherever bacteria exist. It is estimated there are more than 1031 bacteriophages on the planet, more than every other organism on Earth, including bacteria, combined. One of the densest natural sources for phages and other viruses is seawater, where up to 9x108 virions per millilitre have been found in microbial mats at the surface, and up to 70% of marine bacteria may be infected by phages. Phages have been used since the late 20th century as an alternative to antibiotics in the former Soviet Union and Central Europe, as well as in France. They are seen as a possible therapy against multi-drug-resistant strains of many bacteria (see phage therapy). On the other hand, phages of Inoviridae have been shown to complicate biofilms involved in pneumonia and cystic fibrosis and to shelter the bacteria from drugs meant to eradicate disease, thus promoting persistent infection. 6.4 Classification Of Viruses Classification seeks to describe the diversity of viruses by naming and grouping them on the basis of similarities. In 1962, André Lwoff, Robert Horne, and Paul Tournier were the first to develop a means of virus classification, based on the Linnaean hierarchical system. This system based classification on phylum, class, order, family, genus, and species. Viruses were grouped according to their shared properties (not those of their hosts) and the type of nucleic acid forming their genomes. In 1966, the International Committee on Taxonomy of Viruses (ICTV) was formed. The system proposed by Lwoff, Horne and Tournier was initially not accepted by the ICTV because the small genome size of viruses and their high rate of mutation made it difficult to determine their ancestry beyond order. As such, the Baltimore classification system has come to be used to supplement the more traditional hierarchy. Starting in 2018, the ICTV began to acknowledge deeper evolutionary relationships between viruses that have been discovered over time and adopted a 15-rank classification system ranging from realm to species. ICTV classification The ICTV developed the current classification system and wrote guidelines that put a greater weight on certain virus properties to maintain family uniformity. A unified taxonomy (a universal system for classifying viruses) has been established. Only a small part of the total diversity of viruses has been studied. As of 2020, 6 realms, 10 kingdoms, 17 phyla, 2 subphyla, 39 classes, 59 orders, 8 suborders, 189 families, 136 subfamilies, 2,224 genera, 70 subgenera, and 9,110 species of viruses have been defined by the ICTV. 6.5 The Baltimore Classification Of Viruses The Nobel Prize-winning biologist David Baltimore devised the Baltimore classification system. The ICTV classification system is used in conjunction with the Baltimore classification system in modern virus classification. The Baltimore classification of viruses is based on the mechanism of mRNA production. Viruses must generate mRNAs from their genomes to produce proteins and replicate themselves, but different mechanisms are used to achieve this in each virus family. Viral genomes may be single-stranded (ss) or double-stranded (ds), RNA or DNA, and may or may not use reverse transcriptase (RT). In addition, ssRNA viruses may be either sense (+) or antisense (−). This classification places viruses into seven groups: I: dsDNA viruses (e.g. Adenoviruses, Herpesviruses, Poxviruses) II: ssDNA viruses (+ strand or “sense”) DNA (e.g. Parvoviruses) III: dsRNA viruses (e.g. Reoviruses) IV: (+)ssRNA viruses (+ strand or sense) RNA (e.g. Coronaviruses, Picornaviruses, Togaviruses) V: (−)ssRNA viruses (− strand or antisense) RNA (e.g. Orthomyxoviruses, Rhabdoviruses) VI: ssRNA-RT viruses (+ strand or sense) RNA with DNA intermediate in life-cycle (e.g. Retroviruses) VII: dsDNA-RT viruses DNA with RNA intermediate in life-cycle (e.g. Hepadnaviruses) "],["microbial-nutrition-ecology-and-growth.html", "7 Microbial Nutrition, Ecology And Growth 7.1 Primary Sources Of Energy 7.2 Primary Sources Of Reducing Equivalents 7.3 Primary Sources of Carbon 7.4 Nutrients 7.5 The Nutrient Cycle 7.6 Transport And Movement Of Substances Across The Cell Membrane 7.7 Microbial Growth 7.8 Cell Counting 7.9 Environmental Factors Influencing Growth", " 7 Microbial Nutrition, Ecology And Growth Nutrition is the biochemical and physiological process by which an organism uses food to support its life. It includes ingestion, absorption, assimilation, biosynthesis, catabolism and excretion. The science that studies the physiological process of nutrition is called nutritional science (also nutrition science). Organisms primarily provide themselves with carbon in one of two ways: autotrophy (the self-production of organic food) and heterotrophy (the consumption of existing organic carbon). Combined with the source of energy, either light (phototrophy) or chemical (chemotrophy), there are four primary nutritional groups of organisms. Primary nutritional groups are groups of organisms, divided in relation to the nutrition mode according to the sources of energy and carbon, needed for living, growth and reproduction. The sources of energy can be light or chemical compounds; the sources of carbon can be of organic or inorganic origin. 7.1 Primary Sources Of Energy Phototrophs absorb light in photoreceptors and transform it into chemical energy. Chemotrophs release bond energy from chemical compounds. The freed energy is stored as potential energy in ATP, carbohydrates, or proteins. Eventually, the energy is used for life processes such as moving, growth and reproduction. Plants and some bacteria can alternate between phototrophy and chemotrophy, depending on the availability of light. 7.2 Primary Sources Of Reducing Equivalents Organotrophs use organic compounds as electron/hydrogen donors. Lithotrophs use inorganic compounds as electron/hydrogen donors. The electrons or hydrogen atoms from reducing equivalents (electron donors) are needed by both phototrophs and chemotrophs in reduction-oxidation reactions that transfer energy in the anabolic processes of ATP synthesis (in heterotrophs) or biosynthesis (in autotrophs). The electron or hydrogen donors are taken up from the environment. Organotrophic organisms are often also heterotrophic, using organic compounds as sources of both electrons and carbon. Similarly, lithotrophic organisms are often also autotrophic, using inorganic sources of electrons and CO2 as their inorganic carbon source. Some lithotrophic bacteria can utilize diverse sources of electrons, depending on the availability of possible donors. The organic or inorganic substances (e.g., oxygen) used as electron acceptors needed in the catabolic processes of aerobic or anaerobic respiration and fermentation are not taken into account here. For example, plants are lithotrophs because they use water as their electron donor for biosynthesis. Animals are organotrophs because they use organic compounds as electron donors to synthesize ATP (plants also do this, but this is not taken into account). Both use oxygen in respiration as electron acceptor and the main source of energy, but this character is not used to define them as lithotrophs. 7.3 Primary Sources of Carbon Heterotrophs metabolize organic compounds to obtain carbon for growth and development. Autotrophs use carbon dioxide (CO2) as their source of carbon. 7.4 Nutrients A nutrient is a substance used by an organism to survive, grow, and reproduce. The requirement for dietary nutrient intake applies to animals, plants, fungi, and protists. Nutrients can be incorporated into cells for metabolic purposes or excreted by cells to create non-cellular structures, such as hair, scales, feathers, or exoskeletons. Some nutrients can be metabolically converted to smaller molecules in the process of releasing energy, such as for carbohydrates, lipids, proteins, and fermentation products (ethanol or vinegar), leading to end-products of water and carbon dioxide. All organisms require water. Essential nutrients for animals are the energy sources, some of the amino acids that are combined to create proteins, a subset of fatty acids, vitamins and certain minerals. Plants require more diverse minerals absorbed through roots, plus carbon dioxide and oxygen absorbed through leaves. Fungi live on dead or living organic matter and meet nutrient needs from their host. Different types of organisms have different essential nutrients. Ascorbic acid (vitamin C) is essential, meaning it must be consumed in sufficient amounts, to humans and some other animal species, but some animals and plants are able to synthesize it. Nutrients may be organic or inorganic: organic compounds include most compounds containing carbon, while all other chemicals are inorganic. Inorganic nutrients include nutrients such as iron, selenium, and zinc, while organic nutrients include, among many others, energy-providing compounds and vitamins. 7.5 The Nutrient Cycle A nutrient cycle (or ecological recycling) is the movement and exchange of organic and inorganic matter back into the production of matter. Energy flow is a unidirectional and noncyclic pathway, whereas the movement of mineral nutrients is cyclic. Mineral cycles include the carbon cycle, sulfur cycle, nitrogen cycle, water cycle, phosphorus cycle, oxygen cycle, among others that continually recycle along with other mineral nutrients into productive ecological nutrition. The nutrient cycle is nature’s recycling system. All forms of recycling have feedback loops that use energy in the process of putting material resources back into use. Recycling in ecology is regulated to a large extent during the process of decomposition. Ecosystems employ biodiversity in the food webs that recycle natural materials, such as mineral nutrients, which includes water. Recycling in natural systems is one of the many ecosystem services that sustain and contribute to the well-being of human societies. There is much overlap between the terms for the biogeochemical cycle and nutrient cycle. Most textbooks integrate the two and seem to treat them as synonymous terms. However, the terms often appear independently. Nutrient cycle is more often used in direct reference to the idea of an intra-system cycle, where an ecosystem functions as a unit. From a practical point, it does not make sense to assess a terrestrial ecosystem by considering the full column of air above it as well as the great depths of Earth below it. While an ecosystem often has no clear boundary, as a working model it is practical to consider the functional community where the bulk of matter and energy transfer occurs. Nutrient cycling occurs in ecosystems that participate in the \"larger biogeochemical cycles of the earth through a system of inputs and outputs. The ability to harness energy from a variety of metabolic pathways is a property of all living organisms. Growth, development, anabolism and catabolism are some of the central processes in the study of biological organisms, because the role of energy is fundamental to such biological processes. Life is dependent on energy transformations; living organisms survive because of exchange of energy between living tissues/ cells and the outside environment. Some organisms, such as autotrophs, can acquire energy from sunlight (through photosynthesis) without needing to consume nutrients and break them down. Other organisms, like heterotrophs, must intake nutrients from food to be able to sustain energy by breaking down chemical bonds in nutrients during metabolic processes such as glycolysis and the citric acid cycle. Importantly, as a direct consequence of the first law of thermodynamics, autotrophs and heterotrophs participate in a universal metabolic network—by eating autotrophs (plants), heterotrophs harness energy that was initially transformed by the plants during photosynthesis. In a living organism, chemical bonds are broken and made as part of the exchange and transformation of energy. Energy is available for work (such as mechanical work) or for other processes (such as chemical synthesis and anabolic processes in growth), when weak bonds are broken and stronger bonds are made. The production of stronger bonds allows release of usable energy. Adenosine triphosphate (ATP) is the main “energy currency” for organisms; the goal of metabolic and catabolic processes are to synthesize ATP from available starting materials (from the environment), and to break- down ATP (into adenosine diphosphate (ADP) and inorganic phosphate) by utilizing it in biological processes. In a cell, the ratio of ATP to ADP concentrations is known as the “energy charge” of the cell. A cell can use this energy charge to relay information about cellular needs; if there is more ATP than ADP available, the cell can use ATP to do work, but if there is more ADP than ATP available, the cell must synthesize ATP via oxidative phosphorylation. Figure 7.1: Structure of adenosine triphosphate (ATP), protonated Living organisms produce ATP from energy sources, such as sunlight and organic compounds including carbohydrates, lipids and proteins, mainly via oxidative phosphorylation. The terminal phosphate bonds of ATP are relatively weak compared with the stronger bonds formed when ATP is hydrolyzed to adenosine diphosphate and inorganic phosphate. Here it is the thermodynamically favorable free energy of hydrolysis that results in energy release; the phosphoanhydride bond between the terminal phosphate group and the rest of the ATP molecule does not itself contain this energy. An organism’s stockpile of ATP is used as a battery to store energy in cells. Utilization of chemical energy from such molecular bond rearrangement powers biological processes in every biological organism. Living organisms obtain energy from organic and inorganic materials; i.e. ATP can be synthesized from a variety of biochemical precursors. For example, lithotrophs can oxidize minerals such as nitrites or forms of sulfur, such as elemental sulfur, sulfites, and hydrogen sulfide to produce ATP. In photosynthesis, autotrophs produce ATP using light energy, whereas heterotrophs must consume organic compounds, mostly including carbohydrates, fats, and proteins. The amount of energy actually obtained by the organism is lower than the amount released in combustion of the food; there are losses in digestion, metabolism, and thermogenesis. 7.6 Transport And Movement Of Substances Across The Cell Membrane The cell membrane (also known as the plasma membrane (PM) or cytoplasmic membrane, and historically referred to as the plasmalemma) is a biological membrane that separates the interior of all cells from the outside environment (the extracellular space) which protects the cell from its environment. The cell membrane consists of a lipid bilayer, including sterols (e. g. cholesterol) that sit between phospholipids to maintain their fluidity at various temperatures. The membrane also contains membrane proteins, including integral proteins that go across the membrane serving as membrane transporters, and peripheral proteins that loosely attach to the outer (peripheral) side of the cell membrane, acting as enzymes shaping the cell. The cell mebrane controls the movement of substances in and out of cells and organelles. In this way, it is selectively permeable to ions and organic molecules. In addition, cell membranes are involved in a variety of cellular processes such as cell adhesion, ion conductivity and cell signalling and serve as the attachment surface for several extracellular structures, including the cell wall, the carbohydrate layer called the glycocalyx, and the intracellular network of protein fibers called the cytoskeleton. In the field of synthetic biology, cell membranes can be artificially reassembled. Figure 5.3: Picture of a molecular dynamics simulation of a cell membrane/protein complex consisting of bovine rhodopsin incorporated of a phosphatidylcholine (1-palmitoyl-2-oleoyl-sn-glycero-3-phosphocholine, POPC) lipid bylayer. POPC and water molecules are depicted as sticks. The lipid layers facing the extracellular and cytoplasmic spaces are shown in white and blue, respectively. Both the extra- and intracellular interfaces are covered with layers of water. The secondary structure of rhodopsin is depicted in rainbow colored cartoon representation. Potassium and chloride ions are shown as spheres (colored in cyan and green, respectively). Image generated from PDB file obtained from the CHARMM-GUI Archive - Protein/Membrane Complex Library using the open source molecular visualization tool PyMol. The permeability of a membrane is the rate of passive diffusion of molecules through the membrane. These molecules are known as permeant molecules. Permeability depends mainly on the electric charge and polarity of the molecule and to a lesser extent the molar mass of the molecule. Due to the cell membrane’s hydrophobic nature, small electrically neutral molecules pass through the membrane more easily than charged, large ones. The inability of charged molecules to pass through the cell membrane results in pH partition of substances throughout the fluid compartments of the body. Because of these properties, the cell membrane is referred to as as selectively (or semi-) permeable membrane. 7.6.1 Diffusion Diffusion is the net movement of material from an area of high concentration to an area with lower concentration. The difference of concentration between the two areas is often termed as the concentration gradient, and diffusion will continue until this gradient has been eliminated. Since diffusion moves materials from an area of higher concentration to an area of lower concentration, it is described as moving solutes “down the concentration gradient” (compared with active transport, which often moves material from area of low concentration to area of higher concentration, and therefore referred to as moving the material “against the concentration gradient”). However, in many cases (e.g. passive drug transport) the driving force of passive transport can not be simplified to the concentration gradient. If there are different solutions at the two sides of the membrane with different equilibrium solubility of the drug, the difference in degree of saturation is the driving force of passive membrane transport. It is also true for supersaturated solutions which are more and more important owing to the spreading of the application of amorphous solid dispersions for drug bioavailability enhancement. Figure 7.2: Diffusion of a purple dye in water. Simple diffusion and osmosis are in some ways similar. Simple diffusion is the passive movement of solute from a high concentration to a lower concentration until the concentration of the solute is uniform throughout and reaches equilibrium. Osmosis is much like simple diffusion but it specifically describes the movement of water (not the solute) across a selectively permeable membrane until there is an equal concentration of water and solute on both sides of the membrane. Simple diffusion and osmosis are both forms of passive transport and require none of the cell’s ATP energy. 7.6.2 Facilitated Diffusion Facilitated diffusion, also called carrier-mediated osmosis, is the movement of molecules across the cell membrane via special transport proteins that are embedded in the plasma membrane by actively taking up or excluding ions. Active transport of protons by H+ ATPases alters membrane potential allowing for facilitated passive transport of particular ions such as potassium down their charge gradient through high affinity transporters and channels. 7.6.3 Osmosis Osmosis is the movement of water molecules across a selectively permeable membrane. The net movement of water molecules through a partially permeable membrane from a solution of high water potential to an area of low water potential. A cell with a less negative water potential will draw in water but this depends on other factors as well such as solute potential (pressure in the cell e.g. solute molecules) and pressure potential (external pressure e.g. cell wall). There are three types of Osmosis solutions: the isotonic solution, hypotonic solution, and hypertonic solution. Isotonic solution is when the extracellular solute concentration is balanced with the concentration inside the cell. In the Isotonic solution, the water molecules still moves between the solutions, but the rates are the same from both directions, thus the water movement is balanced between the inside of the cell as well as the outside of the cell. A hypotonic solution is when the solute concentration outside the cell is lower than the concentration inside the cell. In hypotonic solutions, the water moves into the cell, down its concentration gradient (from higher to lower water concentrations). That can cause the cell to swell. Cells that don’t have a cell wall, such as animal cells, could burst in this solution. A hypertonic solution is when the solute concentration is higher (think of hyper - as high) than the concentration inside the cell. In hypertonic solution, the water will move out, causing the cell to shrink. Figure 7.3: An example of osmosis: a semi-permeable (selectively permebable) membrane separates two compartments containing a higher concentration of a dissolved salt on the left side compared to the right side (i.e. the left side is hypertonic compared to the (hypotonic) right side). A net flow of water will occur from the right to the left side until the concentration of salt on both sides of the membrane is equal (i.e. both sides are isotonic).) 7.6.4 Active Transport Unlike passive transport, which uses the kinetic energy and natural entropy of molecules moving down a gradient, active transport uses cellular energy to move them against a gradient, polar repulsion, or other resistance. Active transport is usually associated with accumulating high concentrations of molecules that the cell needs, such as ions, glucose and amino acids. Examples of active transport include the uptake of glucose in the intestines in humans and the uptake of mineral ions into root hair cells of plants. There are two types of active transport: primary active transport that uses adenosine triphosphate (ATP), and secondary active transport that uses an electrochemical gradient. An example of active transport in human physiology is the uptake of glucose in the intestines. 7.6.5 Bulk transport Endocytosis and exocytosis are both forms of bulk transport that move materials into and out of cells, respectively, via vesicles. In the case of endocytosis, the cellular membrane folds around the desired materials outside the cell. The ingested particle becomes trapped within a pouch, known as a vesicle, inside the cytoplasm. Often enzymes from lysosomes are then used to digest the molecules absorbed by this process. Substances that enter the cell via signal mediated electrolysis include proteins, hormones and growth and stabilization factors. Viruses enter cells through a form of endocytosis that involves their outer membrane fusing with the membrane of the cell. This forces the viral DNA into the host cell. Biologists distinguish two main types of endocytosis: pinocytosis and phagocytosis. In pinocytosis, cells engulf liquid particles (in humans this process occurs in the small intestine, where cells engulf fat droplets). In phagocytosis, cells engulf solid particles. Exocytosis involves the removal of substances through the fusion of the outer cell membrane and a vesicle membrane An example of exocytosis would be the transmission of neurotransmitters across a synapse between brain cells. 7.7 Microbial Growth Bacterial growth is proliferation of bacterium into two daughter cells, in a process called binary fission. Providing no event occurs, the resulting daughter cells are genetically identical to the original cell. Hence, bacterial growth occurs. Both daughter cells from the division do not necessarily survive. However, if the number surviving exceeds unity on average, the bacterial population undergoes exponential growth. The measurement of an exponential bacterial growth curve in batch culture was traditionally a part of the training of all microbiologists; the basic means requires bacterial enumeration (cell counting) by direct and individual (microscopic, flow cytometry), direct and bulk (biomass), indirect and individual (colony counting), or indirect and bulk (most probable number, turbidity, nutrient uptake) methods. Models reconcile theory with the measurements. Figure 7.4: A Bacterial growth curveCurve In autecological studies, the growth of bacteria (or other microorganisms, as protozoa, microalgae or yeasts) in batch culture can be modeled with four different phases: lag phase (A), log phase or exponential phase (B), stationary phase (C), and death phase (D). During lag phase, bacteria adapt themselves to growth conditions. It is the period where the individual bacteria are maturing and not yet able to divide. During the lag phase of the bacterial growth cycle, synthesis of RNA, enzymes and other molecules occurs. During the lag phase cells change very little because the cells do not immediately reproduce in a new medium. This period of little to no cell division is called the lag phase and can last for 1 hour to several days. During this phase cells are not dormant. The log phase (sometimes called the logarithmic phase or the exponential phase) is a period characterized by cell doubling. The number of new bacteria appearing per unit time is proportional to the present population. If growth is not limited, doubling will continue at a constant rate so both the number of cells and the rate of population increase doubles with each consecutive time period. For this type of exponential growth, plotting the natural logarithm of cell number against time produces a straight line. The slope of this line is the specific growth rate of the organism, which is a measure of the number of divisions per cell per unit time. The actual rate of this growth (i.e. the slope of the line in the figure) depends upon the growth conditions, which affect the frequency of cell division events and the probability of both daughter cells surviving. Under controlled conditions, cyanobacteria can double their population four times a day and then they can triple their population. Exponential growth cannot continue indefinitely, however, because the medium is soon depleted of nutrients and enriched with wastes. The stationary phase is often due to a growth-limiting factor such as the depletion of an essential nutrient, and/or the formation of an inhibitory product such as an organic acid. Stationary phase results from a situation in which growth rate and death rate are equal. The number of new cells created is limited by the growth factor and as a result the rate of cell growth matches the rate of cell death. The result is a “smooth,” horizontal linear part of the curve during the stationary phase. Mutations can occur during stationary phase. Bridges et al. (2001) presented evidence that DNA damage is responsible for many of the mutations arising in the genomes of stationary phase or starving bacteria. Endogenously generated reactive oxygen species appear to be a major source of such damages. At death phase (decline phase), bacteria die. This could be caused by lack of nutrients, environmental temperature above or below the tolerance band for the species, or other injurious conditions. This basic batch culture growth model draws out and emphasizes aspects of bacterial growth which may differ from the growth of macrofauna. It emphasizes clonality, asexual binary division, the short development time relative to replication itself, the seemingly low death rate, the need to move from a dormant state to a reproductive state or to condition the media, and finally, the tendency of lab adapted strains to exhaust their nutrients. In reality, even in batch culture, the four phases are not well defined. The cells do not reproduce in synchrony without explicit and continual prompting (as in experiments with stalked bacteria ) and their exponential phase growth is often not ever a constant rate, but instead a slowly decaying rate, a constant stochastic response to pressures both to reproduce and to go dormant in the face of declining nutrient concentrations and increasing waste concentrations. Near the end of the logarithmic phase of a batch culture, competence for natural genetic transformation may be induced, as in Bacillus subtilis and in other bacteria. Natural genetic transformation is a form of DNA transfer that appears to be an adaptation for repairing DNA damages. Batch culture is the most common laboratory growth method in which bacterial growth is studied, but it is only one of many. It is ideally spatially unstructured and temporally structured. The bacterial culture is incubated in a closed vessel with a single batch of medium. In some experimental regimes, some of the bacterial culture is periodically removed and added to fresh sterile medium. In the extreme case, this leads to the continual renewal of the nutrients. This is a chemostat, also known as continuous culture. It is ideally spatially unstructured and temporally unstructured, in a steady state defined by the rates of nutrient supply and bacterial growth. In comparison to batch culture, bacteria are maintained in exponential growth phase, and the growth rate of the bacteria is known. Related devices include turbidostats and auxostats. When Escherichia coli is growing very slowly with a doubling time of 16 hours in a chemostat most cells have a single chromosome. Bacterial growth can be suppressed with bacteriostats, without necessarily killing the bacteria. In a synecological, true-to-nature situation in which more than one bacterial species is present, the growth of microbes is more dynamic and continual. Liquid is not the only laboratory environment for bacterial growth. Spatially structured environments such as biofilms or agar surfaces present additional complex growth models. 7.8 Cell Counting Numerous procedures in biology and medicine require the counting of cells. By the counting of cells in a known small volume, the concentration can be mediated. Examples of the need for cell counting include: In medicine, the concentration of various blood cells, such as red blood cells and white blood cells, can give crucial information regarding the health situation of a person (see: complete blood count). In cell therapy, to control the dose of cells administered to a patient. Similarly, the concentration of bacteria, viruses and other pathogens in the blood or in other bodily fluids can reveal information about the progress of an infectious disease and about the degree of success with which the immune system is dealing with the infection. The cell concentration needs to be known for many experiments in molecular biology, in order to adjust accordingly the amount of reagents and chemicals that are to be applied in the experiment. Studies that examine the growth rate of microorganisms (in other words, how fast they divide to create new cells) require cell counting. Calculating the fraction of dead to live cells as a measure of cell viability, such as of cells exposed to poison. There are several methods for cell counting. Some are primitive and do not require special equipment, thus can be done in any biological laboratory, whereas others rely on sophisticated electronic appliances. 7.8.1 Counting Chamber A counting chamber, is a microscope slide that is especially designed to enable cell counting. Hemocytometers and Sedgewick Rafter counting chambers are two types of counting chambers. The hemocytometer has two gridded chambers in its middle, which are covered with a special glass slide when counting. A drop of cell culture is placed in the space between the chamber and the glass cover, filling it via capillary action. Looking at the sample under the microscope, the researcher uses the grid to manually count the number of cells in a certain area of known size. The separating distance between the chamber and the cover is predefined, thus the volume of the counted culture can be calculated and with it the concentration of cells. Cell viability can also be determined if viability dyes are added to the fluid. Their advantage is being cheap and fast; this makes them the preferred counting method in fast biological experiments where it is only necessary to determine if a cell culture has grown as expected. Usually the culture examined needs to be diluted, otherwise the high density of cells would make counting impossible. The need for dilution is a disadvantage as every dilution adds inaccuracy to the measurement. 7.8.2 Plating And The Colony-Forming Unit Counting To quantify the number of cells in a culture, the cells can be simply plated on a petri dish with growth medium. If the cells are efficiently distributed on the plate, it can be generally assumed that each cell will give rise to a single colony or Colony Forming Unit (CFU). The colonies can then be counted, and based on the known volume of culture that was spread on the plate, the cell concentration can be calculated. This is often carried out following the ASTM D5465 standard. As is with counting chambers, cultures usually need to be heavily diluted prior to plating; otherwise, instead of obtaining single colonies that can be counted, a so-called “lawn” will form: thousands of colonies lying over each other. Additionally, plating is the slowest method of all: most microorganisms need at least 12 hours to form visible colonies. Although this method can be time-consuming, it gives an accurate estimate of the number of viable cells (because only they will be able to grow and form visible colonies). It is therefore extensively used in experiments aiming to quantify the number of cells resisting drugs or other external conditions (for instance the Luria–Delbrück experiment or the gentamicin protection assay). In addition, the enumeration of colonies on agar plates can be greatly facilitated by using colony counters. A colony-forming unit (CFU, cfu, Cfu) is a unit used in microbiology to estimate the number of viable bacteria or fungal cells in a sample. Viable is defined as the ability to multiply via binary fission under the controlled conditions. Counting with colony-forming units requires culturing the microbes and counts only viable cells, in contrast with microscopic examination which counts all cells, living or dead. The visual appearance of a colony in a cell culture requires significant growth, and when counting colonies it is uncertain if the colony arose from one cell or a group of cells. Expressing results as colony-forming units reflects this uncertainty. The purpose of plate counting is to estimate the number of cells present based on their ability to give rise to colonies under specific conditions of nutrient medium, temperature and time. Theoretically, one viable cell can give rise to a colony through replication. However, solitary cells are the exception in nature, and most likely the progenitor of the colony was a mass of cells deposited together. In addition, many bacteria grow in chains (e.g. Streptococcus) or clumps (e.g., Staphylococcus). Estimation of microbial numbers by CFU will, in most cases, undercount the number of living cells present in a sample for these reasons. This is because the counting of CFU assumes that every colony is separate and founded by a single viable microbial cell. The plate count is linear for E. coli over the range of 30 to 300 CFU on a standard sized Petri dish. Therefore, to ensure that a sample will yield CFU in this range requires dilution of the sample and plating of several dilutions. Typically, ten-fold dilutions are used, and the dilution series is plated in replicates of 2 or 3 over the chosen range of dilutions. Often 100µl are plated but also larger amounts up to 1ml are used. Higher plating volumes increase drying times but often don’t result in higher accuracy, since additional dilution steps may be needed. The CFU/plate is read from a plate in the linear range, and then the CFU/g (or CFU/mL) of the original is deduced mathematically, factoring in the amount plated and its dilution factor (e.g. CLSI VET01S).An advantage to this method is that different microbial species may give rise to colonies that are clearly different from each other, both microscopically and macroscopically. The colony morphology can be of great use in the identification of the microorganism present. A prior understanding of the microscopic anatomy of the organism can give a better understanding of how the observed CFU/mL relates to the number of viable cells per milliliter. Alternatively it is possible to decrease the average number of cells per CFU in some cases by vortexing the sample before conducting the dilution. However many microorganisms are delicate and would suffer a decrease in the proportion of cells that are viable when placed in a vortex. Counting colonies is traditionally performed manually using a pen and a click-counter. This is generally a straightforward task, but can become very laborious and time-consuming when many plates have to be enumerated. Alternatively semi-automatic (software) and automatic (hardware + software) solutions can be used. 7.8.3 Electrical Resistance ￼ The electrode of a Coulter counter A Coulter counter is an appliance that can count cells as well as measure their volume. It is based on the fact that cells show great electrical resistance; in other words, they conduct almost no electricity. In a Coulter counter the cells, swimming in a solution that conducts electricity, are sucked one by one into a tiny gap. Flanking the gap are two electrodes that conduct electricity. When no cell is in the gap, electricity flows unabated, but when a cell is sucked into the gap the current is resisted. The Coulter counter counts the number of such events and also measures the current (and hence the resistance), which directly correlates to the volume of the cell trapped. A similar system is the CASY cell counting technology. Coulter and CASY counters are much cheaper than flow cytometers, and for applications that require cell numbers and sizes, such as cell-cycle research, they are the method of choice. Its advantage over the methods above is the large number of cells that can be processed in a short time, namely: thousands of cells per second. This offers great accuracy and statistical significance. 7.8.4 Flow Cytometry Flow cytometry is by far the most sophisticated and expensive method for cell counting. In a flow cytometer the cells flow in a narrow stream in front of a laser beam. The beam hits them one by one, and a light detector picks up the light that is reflected from the cells. Flow cytometers have many other abilities, such as analyzing the shape of cells and their internal and external structures, as well as measuring the amount of specific proteins and other biochemicals in the cells. Therefore, flow cytometers are rarely purchased for the sole purpose of counting cells. 7.8.5 Spectrophotometry Cell suspensions are turbid. Cells absorb and scatter the light. The higher the cell concentration, the higher the turbidity. Spectrophotometers can measure intensity of light very accurately. The cell culture is placed in a transparent cuvette and the absorption is measured relative to medium alone. Optical density (OD) is directly proportional to the biomass in the cell suspension in a given range that is specific to the cell type. Using spectrophotometry for measuring the turbidity of cultures is known as turbidometry. This has made spectrophotometry the methods of choice for measurements of bacterial growth and related applications. Spectrophotometry’s drawback is its inability to provide an absolute count or distinguish between living and dead cells. 7.9 Environmental Factors Influencing Growth Environmental factors influence rate of bacterial growth such as acidity (pH), temperature, water activity, macro and micro nutrients, oxygen levels, and toxins. Conditions tend to be relatively consistent between bacteria with the exception of extremophiles. Bacterium have optimal growth conditions under which they thrive, but once outside of those conditions the stress can result in either reduced or stalled growth, dormancy (such as formation spores), or death. Maintaining sub-optimal growth conditions is a key principle to food preservation. 7.9.1 Nutrient Availability 7.9.2 Temperature Low temperatures tend to reduce growth rates which has led to refrigeration being instrumental in food preservation. Depending on temperature, bacteria can be classified as: Psychrophiles Psychrophiles are extremophilic cold-loving bacteria or archaea with an optimal temperature for growth at about 15 °C or lower (maximal temperature for growth at 20 °C, minimal temperature for growth at 0 °C or lower). Psychrophiles are typically found in Earth’s extremely cold ecosystems, such as polar ice-cap regions, permafrost, polar surface, and deep oceans. Mesophiles Mesophiles are bacteria that thrive at moderate temperatures, growing best between 20° and 45 °C. These temperatures align with the natural body temperatures of humans, which is why many human pathogens are mesophiles. Thermophiles Survive under temperatures of 45–60 °C Ambrose 7.9.3 Acidity Optimal acidity for bacteria tends to be around pH 6.5 to 7.0 with the exception of acidophiles. Some bacteria can change the pH such as by excreting acid resulting in sub-optimal conditions. 7.9.4 Water activity Water activity (aw) is the partial vapor pressure of water in a solution divided by the standard state partial vapor pressure of water. In the field of food science, the standard state is most often defined as the partial vapor pressure of pure water at the same temperature. Using this particular definition, pure distilled water has a water activity of exactly one. As temperature increases, aw typically increases, except in some products with crystalline salt or sugar. Higher aw substances tend to support more microorganisms. Water migrates from areas of high aw to areas of low aw. For example, if honey (aw ≈ 0.6) is exposed to humid air (a~w ≈ 0.7), the honey absorbs water from the air. If salami (aw ≈ 0.87) is exposed to dry air (aw ≈ 0.5), the salami dries out, which could preserve it or spoil it. 7.9.5 Oxygen Bacteria can be aerobes or anaerobes. Depending on the degree of oxygen required bacteria can fall into the following classes: facultative-anaerobes-ie aerotolerant absence or minimal oxygen required for their growth obligate-anaerobes grow only in complete absence of oxygen facultative aerobes-can grow either in presence or minimal oxygen obligate aerobes-grow only in the presence of oxygen 7.9.6 Toxic compounds Toxic compounds such as ethanol can hinder growth or kill bacteria. This is used beneficially for disinfection and in food preservation. "],["an-introduction-to-microbial-metabolism.html", "8 An Introduction To Microbial Metabolism 8.1 Thermodynamics of Living Organisms 8.2 Metabolism 8.3 Types Of Microbial Metabolism 8.4 Phototrophy 8.5 Chemolithotrophy 8.6 Energy Transformations 8.7 Enzymes 8.8 Heterotrophic Microbial Metabolism 8.9 Photosynthesis And Cellular Respiration 8.10 Fermentation 8.11 Anaerobic Respiration", " 8 An Introduction To Microbial Metabolism 8.1 Thermodynamics of Living Organisms Living organisms must obey the laws of thermodynamics. Thermodynamics is a branch of physics that deals with heat, work, and temperature, and their relation to energy, radiation, and properties of matter. The behavior of these quantities is governed by the four laws of thermodynamics which convey a quantitative description using measurable macroscopic physical quantities, but may be explained in terms of microscopic constituents by statistical mechanics. Historically, thermodynamics developed out of a desire to increase the efficiency of early steam engines, particularly through the work of French physicist Nicolas Léonard Sadi Carnot (1824) who believed that engine efficiency was the key that could help France win the Napoleonic Wars. Scots-Irish physicist William Thomson (Lord Kelvin) was the first to formulate a concise definition of thermodynamics in 1854 which stated, “Thermo-dynamics is the subject of the relation of heat to forces acting between contiguous parts of bodies, and the relation of heat to electrical agency.” The initial application of thermodynamics to mechanical heat engines was quickly extended to the study of chemical compounds and chemical reactions. Biological thermodynamics is the quantitative study of the energy transductions that occur in or between living organisms, structures, and cells and of the nature and function of the chemical processes underlying these transductions. Biological thermodynamics may address the question of whether the benefit associated with any particular phenotypic trait is worth the energy investment it requires. The First Law of Thermodynamics is a statement of the conservation of energy; though it can be changed from one form to another, energy can be neither created nor destroyed. The Second Law of Thermodynamics is concerned primarily with whether or not a given process is possible. The Second Law states that no natural process can occur unless it is accompanied by an increase in the entropy of the universe. Stated differently, an isolated system will always tend to disorder. Although living organisms’ amazing complexity appears to contradict this law, life is possible as all organisms are open systems that exchange matter and energy with their surroundings. Thus living systems are not in equilibrium, but instead are dissipative systems that maintain their state of high complexity by causing a larger increase in the entropy of their environments. The metabolism of a cell achieves this by coupling the spontaneous processes of catabolism to the non-spontaneous processes of anabolism. In thermodynamic terms, metabolism maintains order by creating disorder. As the environments of most organisms are constantly changing, the reactions of metabolism must be finely regulated to maintain a constant set of conditions within cells, a condition called homeostasis. Metabolic regulation also allows organisms to respond to signals and interact actively with their environments. Two closely linked concepts are important for understanding how metabolic pathways are controlled. Firstly, the regulation of an enzyme in a pathway is how its activity is increased and decreased in response to signals. Secondly, the control exerted by this enzyme is the effect that these changes in its activity have on the overall rate of the pathway (the flux through the pathway). For example, an enzyme may show large changes in activity (i.e. it is highly regulated) but if these changes have little effect on the flux of a metabolic pathway, then this enzyme is not involved in the control of the pathway. There are multiple levels of metabolic regulation. In intrinsic regulation, the metabolic pathway self-regulates to respond to changes in the levels of substrates or products; for example, a decrease in the amount of product can increase the flux through the pathway to compensate. This type of regulation often involves allosteric regulation of the activities of multiple enzymes in the pathway. Extrinsic control involves a cell changing its metabolism in response to environmental signals. These signals are usually in the form of water soluble messengers such as hormones and growth factors and are detected by specific receptors on the cell surface. These signals are then transmitted inside the cell by second messenger systems that often involved the phosphorylation of proteins. The central pathways of metabolism described below, such as glycolysis and the citric acid cycle, are present in all three domains of living things and were present in the last universal common ancestor. This universal ancestral cell was prokaryotic and probably a methanogen that had extensive amino acid, nucleotide, carbohydrate and lipid metabolism. The retention of these ancient pathways during later evolution may be the result of these reactions having been an optimal solution to their particular metabolic problems, with pathways such as glycolysis and the citric acid cycle producing their end products highly efficiently and in a minimal number of steps. The first pathways of enzyme-based metabolism may have been parts of purine nucleotide metabolism, while previous metabolic pathways were a part of the ancient RNA world. Many models have been proposed to describe the mechanisms by which novel metabolic pathways evolve. These include the sequential addition of novel enzymes to a short ancestral pathway, the duplication and then divergence of entire pathways as well as the recruitment of pre-existing enzymes and their assembly into a novel reaction pathway. The relative importance of these mechanisms is unclear, but genomic studies have shown that enzymes in a pathway are likely to have a shared ancestry, suggesting that many pathways have evolved in a step-by-step fashion with novel functions created from pre-existing steps in the pathway. An alternative model comes from studies that trace the evolution of proteins’ structures in metabolic networks, this has suggested that enzymes are pervasively recruited, borrowing enzymes to perform similar functions in different metabolic pathways. These recruitment processes result in an evolutionary enzymatic mosaic. A third possibility is that some parts of metabolism might exist as “modules” that can be reused in different pathways and perform similar functions on different molecules. As well as the evolution of new metabolic pathways, evolution can also cause the loss of metabolic functions. For example, in some parasites metabolic processes that are not essential for survival are lost and preformed amino acids, nucleotides and carbohydrates may instead be scavenged from the host. Similar reduced metabolic capabilities are seen in endosymbiotic organisms. Figure 8.1: The Sun is the source of energy for most of life on Earth. It derives its energy mainly from nuclear fusion in its core, converting mass to energy as protons are combined to form helium. This energy is transported to the sun’s surface then released into space mainly in the form of radiant (light) energy. The sun is the primary source of energy for living organisms on earth. The relationship between the energy of the incoming sunlight and its wavelength λ or frequency ν is given by \\[ E={\\frac {hc}{\\lambda }}=h\\nu \\] where h is the Planck constant (6.63x10−34Js) and c is the speed of light (2.998x108m/s). Plants trap this energy from the sunlight and perform photosynthesis, effectively converting solar energy into chemical energy. To transfer the energy once again, animals will feed on plants (or other animals) and use the energy of digested plant (or animal) materials to create biological macromolecules. Energy flow, also called the calorific flow, refers to the flow of energy through a food chain. A general energy flow scenario follows: Solar energy is fixed by the photoautotrophs, called primary producers, like green plants. Primary consumers absorb most of the stored energy in the plant through digestion, and transform it into the form of energy they need, such as adenosine triphosphate (ATP), through respiration. A part of the energy received by primary consumers, herbivores, is converted to body heat (an effect of respiration), which is radiated away and lost from the system. The loss of energy through body heat is far greater in warm-blooded animals, which must eat much more frequently than those that are cold-blooded. Energy loss also occurs in the expulsion of undigested food (egesta) by excretion or regurgitation. Secondary consumers, carnivores, then consume the primary consumers, although omnivores also consume primary producers. Energy that had been used by the primary consumers for growth and storage is thus absorbed into the secondary consumers through the process of digestion. As with primary consumers, secondary consumers convert this energy into a more suitable form (ATP) during respiration. Again, some energy is lost from the system, since energy which the primary consumers had used for respiration and regulation of body temperature cannot be utilized by the secondary consumers. Tertiary consumers, which may or may not be apex predators, then consume the secondary consumers, with some energy passed on and some lost, as with the lower levels of the food chain. A final link in the food chain are decomposers which break down the organic matter of the tertiary consumers (or whichever consumer is at the top of the chain) and release nutrients into the soil. They also break down plants, herbivores and carnivores that were not eaten by organisms higher on the food chain, as well as the undigested food that is excreted by herbivores and carnivores. Saprotrophic bacteria and fungi are decomposers, and play a pivotal role in the nitrogen and carbon cycles. The energy is passed on from trophic level to trophic level and each time about 90% of the energy is lost, with some being lost as heat into the environment (an effect of respiration) and some being lost as incompletely digested food (egesta). Therefore, primary consumers get about 10% of the energy produced by autotrophs, while secondary consumers get 1% and tertiary consumers get 0.1%. This means the top consumer of a food chain receives the least energy, as much of the food chain’s energy has been lost between trophic levels. This loss of energy at each level limits typical food chains to only four to six links. 8.2 Metabolism Metabolism (from Greek: μεταβολή metabolē, “change”) is the set of life-sustaining chemical reactions in organisms. The three main purposes of metabolism are: the conversion of food to energy to run cellular processes; the conversion of food/fuel to building blocks for proteins, lipids, nucleic acids, and some carbohydrates; and the elimination of nitrogenous wastes. These enzyme-catalyzed reactions allow organisms to grow and reproduce, maintain their structures, and respond to their environments. (The word metabolism can also refer to the sum of all chemical reactions that occur in living organisms, including digestion and the transport of substances into and between different cells, in which case the above described set of reactions within the cells is called intermediary metabolism or intermediate metabolism). Metabolic reactions may be categorized as catabolic – the breaking down of compounds (for example, the breaking down of glucose to pyruvate by cellular respiration); or anabolic – the building up (synthesis) of compounds (such as proteins, carbohydrates, lipids, and nucleic acids). Usually, catabolism releases energy, and anabolism consumes energy. Figure 8.2: Simplified view of the cellular metabolism The chemical reactions of metabolism are organized into metabolic pathways, in which one chemical is transformed through a series of steps into another chemical, each step being facilitated by a specific enzyme. Enzymes are crucial to metabolism because they allow organisms to drive desirable reactions that require energy that will not occur by themselves, by coupling them to spontaneous reactions that release energy. Enzymes act as catalysts – they allow a reaction to proceed more rapidly – and they also allow the regulation of the rate of a metabolic reaction, for example in response to changes in the cell’s environment or to signals from other cells. The metabolic system of a particular organism determines which substances it will find nutritious and which poisonous. For example, some prokaryotes use hydrogen sulfide as a nutrient, yet this gas is poisonous to animals. The basal metabolic rate of an organism is the measure of the amount of energy consumed by all of these chemical reactions. A striking feature of metabolism is the similarity of the basic metabolic pathways among vastly different species. For example, the set of carboxylic acids that are best known as the intermediates in the citric acid cycle are present in all known organisms, being found in species as diverse as the unicellular bacterium Escherichia coli and huge multicellular organisms like elephants. These similarities in metabolic pathways are likely due to their early appearance in evolutionary history, and their retention because of their efficacy. The metabolism of cancer cells is also different from the metabolism of normal cells and these differences can be used to find targets for therapeutic intervention in cancer. Most of the structures that make up animals, plants and microbes are made from four basic classes of molecule: amino acids, carbohydrates , nucleic acid and lipids (often called fats). As these molecules are vital for life, metabolic reactions either focus on making these molecules during the construction of cells and tissues, or by breaking them down and using them as a source of energy, by their digestion. These biochemicals can be joined together to make polymers such as DNA and proteins, essential macromolecules of life. Table 8.1: The three essential polymeric macromolecules of life Type of molecule Name of monomer forms Name of polymer forms Examples of polymer forms Amino acids Amino acids Proteins (made of polypeptides) Fibrous proteins and globular proteins Carbohydrates Monosaccharides Polysaccharides Starch, glycogen and cellulose Nucleic acids Nucleotides Polynucleotides DNA and RNA The history of the scientific study of metabolism spans several centuries and has moved from examining whole animals in early studies, to examining individual metabolic reactions in modern biochemistry. The first controlled experiments in human metabolism were published by Santorio Santorio in 1614 in his book Ars de statica medicina. He described how he weighed himself before and after eating, sleep, working, sex, fasting, drinking, and excreting. He found that most of the food he took in was lost through what he called “insensible perspiration”. In these early studies, the mechanisms of these metabolic processes had not been identified and a vital force was thought to animate living tissue. In the 19th century, when studying the fermentation of sugar to alcohol by yeast, Louis Pasteur concluded that fermentation was catalyzed by substances within the yeast cells he called “ferments”. He wrote that “alcoholic fermentation is an act correlated with the life and organization of the yeast cells, not with the death or putrefaction of the cells.” This discovery, along with the publication by Friedrich Wöhler in 1828 of a paper on the chemical synthesis of urea, and is notable for being the first organic compound prepared from wholly inorganic precursors. This proved that the organic compounds and chemical reactions found in cells were no different in principle than any other part of chemistry. It was the discovery of enzymes at the beginning of the 20th century by Eduard Buchner that separated the study of the chemical reactions of metabolism from the biological study of cells, and marked the beginnings of biochemistry. The mass of biochemical knowledge grew rapidly throughout the early 20th century. One of the most prolific of these modern biochemists was Hans Krebs who made huge contributions to the study of metabolism. He discovered the urea cycle and later, working with Hans Kornberg, the citric acid cycle and the glyoxylate cycle. Modern biochemical research has been greatly aided by the development of new techniques such as chromatography, X-ray diffraction, NMR spectroscopy, radioisotopic labelling, electron microscopy and molecular dynamics simulations. These techniques have allowed the discovery and detailed analysis of the many molecules and metabolic pathways in cells. 8.3 Types Of Microbial Metabolism All microbial metabolisms can be arranged according to three principles: How the organism obtains carbon for synthesizing cell mass: autotrophic – carbon is obtained from carbon dioxide (CO2) heterotrophic – carbon is obtained from organic compounds mixotrophic – carbon is obtained from both organic compounds and by fixing carbon dioxide How the organism obtains reducing equivalents (hydrogen atoms or electrons) used either in energy conservation or in biosynthetic reactions: lithotrophic – reducing equivalents are obtained from inorganic compounds organotrophic – reducing equivalents are obtained from organic compounds How the organism obtains energy for living and growing: phototrophic – energy is obtained from light chemotrophic – energy is obtained from external chemical compounds In practice, these terms are almost freely combined. Typical examples are as follows: chemolithoautotrophs obtain energy from the oxidation of inorganic compounds and carbon from the fixation of carbon dioxide. Examples: Nitrifying bacteria, sulfur-oxidizing bacteria, iron-oxidizing bacteria, Knallgas-bacteria photolithoautotrophs obtain energy from light and carbon from the fixation of carbon dioxide, using reducing equivalents from inorganic compounds. Examples: Cyanobacteria (water (H2O) as reducing equivalent = hydrogen donor), Chlorobiaceae, Chromatiaceae (hydrogen sulfide (H2S) as hydrogen donor), Chloroflexus (hydrogen (H2) as reducing equivalent donor) chemolithoheterotrophs obtain energy from the oxidation of inorganic compounds, but cannot fix carbon dioxide (CO2). Examples: some Thiobacilus, some Beggiatoa, some Nitrobacter spp., Wolinella (with H2 as reducing equivalent donor), some Knallgas-bacteria, some sulfate-reducing bacteria chemoorganoheterotrophs obtain energy, carbon, and hydrogen for biosynthetic reactions from organic compounds. Examples: most bacteria, e. g. Escherichia coli, Bacillus spp., Actinobacteria photoorganoheterotrophs obtain energy from light, carbon and reducing equivalents for biosynthetic reactions from organic compounds. Some species are strictly heterotrophic, many others can also fix carbon dioxide and are mixotrophic. Examples: Rhodobacter, Rhodopseudomonas, Rhodospirillum, Rhodomicrobium, Rhodocyclus, Heliobacterium, Chloroflexus (alternatively to photolithoautotrophy with hydrogen) 8.4 Phototrophy Many microbes (phototrophs) are capable of using light as a source of energy to produce ATP and organic compounds such as carbohydrates, lipids, and proteins. Of these, algae are particularly significant because they are oxygenic, using water as an electron donor for electron transfer during photosynthesis. Phototrophic bacteria are found in the phyla Cyanobacteria, Chlorobi, Proteobacteria, Chloroflexi, and Firmicutes. Along with plants these microbes are responsible for all biological generation of oxygen gas on Earth. Because chloroplasts were derived from a lineage of the Cyanobacteria, the general principles of metabolism in these endosymbionts can also be applied to chloroplasts. In addition to oxygenic photosynthesis, many bacteria can also photosynthesize anaerobically, typically using sulfide (H2S) as an electron donor to produce sulfate. Inorganic sulfur (S0), thiosulfate (S2O32-) and ferrous iron (Fe2+) can also be used by some organisms. Phylogenetically, all oxygenic photosynthetic bacteria are Cyanobacteria, while anoxygenic photosynthetic bacteria belong to the purple bacteria (Proteobacteria), Green sulfur bacteria (e.g. Chlorobium), Green non-sulfur bacteria (e.g. Chloroflexus), or the heliobacteria (Low %G+C Gram positives). In addition to these organisms, some microbes (e.g. the Archaeon Halobacterium or the bacterium Roseobacter, among others) can utilize light to produce energy using the enzyme bacteriorhodopsin, a light-driven proton pump. However, there are no known Archaea that carry out photosynthesis. As befits the large diversity of photosynthetic bacteria, there are many different mechanisms by which light is converted into energy for metabolism. All photosynthetic organisms locate their photosynthetic reaction centers within a membrane, which may be invaginations of the cytoplasmic membrane (Proteobacteria), thylakoid membranes (Cyanobacteria), specialized antenna structures called chlorosomes (Green sulfur and non-sulfur bacteria), or the cytoplasmic membrane itself (heliobacteria). Different photosynthetic bacteria also contain different photosynthetic pigments, such as chlorophylls and carotenoids, allowing them to take advantage of different portions of the electromagnetic spectrum and thereby inhabit different niches. Some groups of organisms contain more specialized light-harvesting structures (e.g. phycobilisomes in Cyanobacteria and chlorosomes in Green sulfur and non-sulfur bacteria), allowing for increased efficiency in light utilization. Biochemically, anoxygenic photosynthesis is very different from oxygenic photosynthesis. Cyanobacteria (and by extension, chloroplasts) use the Z scheme of electron flow in which electrons eventually are used to form NADH. Two different reaction centers (photosystems) are used and proton motive force is generated both by using cyclic electron flow and the quinone pool. In anoxygenic photosynthetic bacteria, electron flow is cyclic, with all electrons used in photosynthesis eventually being transferred back to the single reaction center. A proton motive force is generated using only the quinone pool. In heliobacteria, Green sulfur, and Green non-sulfur bacteria, NADH is formed using the protein ferredoxin, an energetically favorable reaction. In purple bacteria, NADH is formed by reverse electron flow due to the lower chemical potential of this reaction center. In all cases, however, a proton motive force is generated and used to drive ATP production via an ATPase. Most photosynthetic microbes are autotrophic, fixing carbon dioxide via the Calvin cycle. Some photosynthetic bacteria (e.g. Chloroflexus) are photoheterotrophs, meaning that they use organic carbon compounds as a carbon source for growth. Some photosynthetic organisms also fix nitrogen (see below). 8.5 Chemolithotrophy Chemolithotrophy is a type of metabolism where energy is obtained from the oxidation of inorganic compounds. Most chemolithotrophic organisms are also autotrophic. There are two major objectives to chemolithotrophy: the generation of energy (ATP) and the generation of reducing power (NADH). 8.5.1 Hydrogen oxidation Many organisms are capable of using hydrogen (H2) as a source of energy. While several mechanisms of anaerobic hydrogen oxidation have been mentioned previously (e.g. sulfate reducing- and acetogenic bacteria), hydrogen can also be used to unlock the chemical energy of O2 in the aerobic Knallgas reaction: 2 H2 + O2 → 2 H2O + energy In these organisms, hydrogen is oxidized by a membrane-bound hydrogenase causing proton pumping via electron transfer to various quinones and cytochromes. In many organisms, a second cytoplasmic hydrogenase is used to generate reducing power in the form of NADH, which is subsequently used to fix carbon dioxide via the Calvin cycle. Hydrogen-oxidizing organisms, such as Cupriavidus necator (formerly Ralstonia eutropha), often inhabit oxic-anoxic interfaces in nature to take advantage of the hydrogen produced by anaerobic fermentative organisms while still maintaining a supply of oxygen. 8.5.2 Sulfur oxidation Sulfur oxidation involves the oxidation of reduced sulfur compounds (such as sulfide H2S), inorganic sulfur (S), and thiosulfate (S2O32-) to form sulfuric acid (H2SO4). A classic example of a sulfur-oxidizing bacterium is Beggiatoa, a microbe originally described by Sergei Winogradsky, one of the founders of environmental microbiology. Another example is Paracoccus. Generally, the oxidation of sulfide occurs in stages, with inorganic sulfur being stored either inside or outside of the cell until needed. This two step process occurs because energetically sulfide is a better electron donor than inorganic sulfur or thiosulfate, allowing for a greater number of protons to be translocated across the membrane. Sulfur-oxidizing organisms generate reducing power for carbon dioxide fixation via the Calvin cycle using reverse electron flow, an energy-requiring process that pushes the electrons against their thermodynamic gradient to produce NADH. Biochemically, reduced sulfur compounds are converted to sulfite (SO32-) and subsequently converted to sulfate (SO42-) by the enzyme sulfite oxidase. Some organisms, however, accomplish the same oxidation using a reversal of the APS reductase system used by sulfate-reducing bacteria (see above). In all cases the energy liberated is transferred to the electron transport chain for ATP and NADH production. In addition to aerobic sulfur oxidation, some organisms (e.g. Thiobacillus denitrificans) use nitrate (NO3-) as a terminal electron acceptor and therefore grow anaerobically. 8.5.3 Ferrous Iron (Fe2) Oxidation Ferrous iron is a soluble form of iron that is stable at extremely low pHs or under anaerobic conditions. Under aerobic, moderate pH conditions ferrous iron is oxidized spontaneously to the ferric (Fe3+) form and is hydrolyzed abiotically to insoluble ferric hydroxide (Fe(OH)3). There are three distinct types of ferrous iron-oxidizing microbes. The first are acidophiles, such as the bacteria Acidithiobacillus ferrooxidans and Leptospirillum ferrooxidans, as well as the archaeon Ferroplasma. These microbes oxidize iron in environments that have a very low pH and are important in acid mine drainage. The second type of microbes oxidize ferrous iron at near-neutral pH. These micro-organisms (for example Gallionella ferruginea, Leptothrix ochracea, or Mariprofundus ferrooxydans) live at the oxic-anoxic interfaces and are microaerophiles. The third type of iron-oxidizing microbes are anaerobic photosynthetic bacteria such as Rhodopseudomonas, which use ferrous iron to produce NADH for autotrophic carbon dioxide fixation. Biochemically, aerobic iron oxidation is a very energetically poor process which therefore requires large amounts of iron to be oxidized by the enzyme rusticyanin to facilitate the formation of proton motive force. Like sulfur oxidation, reverse electron flow must be used to form the NADH used for carbon dioxide fixation via the Calvin cycle. 8.5.4 Nitrification Nitrification is the process by which ammonia (NH3) is converted to nitrate (NO3-). Nitrification is actually the net result of two distinct processes: oxidation of ammonia to nitrite (NO2-) by nitrosifying bacteria (e.g. Nitrosomonas) and oxidation of nitrite to nitrate by the nitrite-oxidizing bacteria (e.g. Nitrobacter). Both of these processes are extremely energetically poor leading to very slow growth rates for both types of organisms. Biochemically, ammonia oxidation occurs by the stepwise oxidation of ammonia to hydroxylamine (NH2OH) by the enzyme ammonia monooxygenase in the cytoplasm, followed by the oxidation of hydroxylamine to nitrite by the enzyme hydroxylamine oxidoreductase in the periplasm. Electron and proton cycling are very complex but as a net result only one proton is translocated across the membrane per molecule of ammonia oxidized. Nitrite oxidation is much simpler, with nitrite being oxidized by the enzyme nitrite oxidoreductase coupled to proton translocation by a very short electron transport chain, again leading to very low growth rates for these organisms. Oxygen is required in both ammonia and nitrite oxidation, meaning that both nitrosifying and nitrite-oxidizing bacteria are aerobes. As in sulfur and iron oxidation, NADH for carbon dioxide fixation using the Calvin cycle is generated by reverse electron flow, thereby placing a further metabolic burden on an already energy-poor process. In 2015, two groups independently showed the microbial genus Nitrospira is capable of complete nitrification (Comammox). 8.5.5 Nitrogen Fixation Nitrogen is an element required for growth by all biological systems. While extremely common (80% by volume) in the atmosphere, dinitrogen gas (N2) is generally biologically inaccessible due to its high activation energy. Throughout all of nature, only specialized bacteria and Archaea are capable of nitrogen fixation, converting dinitrogen gas into ammonia (NH3), which is easily assimilated by all organisms. These prokaryotes, therefore, are very important ecologically and are often essential for the survival of entire ecosystems. This is especially true in the ocean, where nitrogen-fixing cyanobacteria are often the only sources of fixed nitrogen, and in soils, where specialized symbioses exist between legumes and their nitrogen-fixing partners to provide the nitrogen needed by these plants for growth. Nitrogen fixation can be found distributed throughout nearly all bacterial lineages and physiological classes but is not a universal property. Because the enzyme nitrogenase, responsible for nitrogen fixation, is very sensitive to oxygen which will inhibit it irreversibly, all nitrogen-fixing organisms must possess some mechanism to keep the concentration of oxygen low. Examples include: heterocyst formation (cyanobacteria e.g. Anabaena) where one cell does not photosynthesize but instead fixes nitrogen for its neighbors which in turn provide it with energy root nodule symbioses (e.g. Rhizobium) with plants that supply oxygen to the bacteria bound to molecules of leghaemoglobin anaerobic lifestyle (e.g. Clostridium pasteurianum) very fast metabolism (e.g. Azotobacter vinelandii) The production and activity of nitrogenases is very highly regulated, both because nitrogen fixation is an extremely energetically expensive process (16–24 ATP are used per N2 fixed) and due to the extreme sensitivity of the nitrogenase to oxygen. 8.5.6 Catabolism Catabolism is the set of metabolic processes that break down large molecules. These include breaking down and oxidizing food molecules. The purpose of the catabolic reactions is to provide the energy and components needed by anabolic reactions which build molecules. The exact nature of these catabolic reactions differ from organism to organism, and organisms can be classified based on their sources of energy and carbon (their primary nutritional groups), as shown in the table below. Organic molecules are used as a source of energy by organotrophs, while lithotrophs use inorganic substrates, and phototrophs capture sunlight as chemical energy. However, all these different forms of metabolism depend on redox reactions that involve the transfer of electrons from reduced donor molecules such as organic molecules, water, ammonia, hydrogen sulfide or ferrous ions to acceptor molecules such as oxygen, nitrate or sulfate. In animals, these reactions involve complex organic molecules that are broken down to simpler molecules, such as carbon dioxide and water. In photosynthetic organisms, such as plants and cyanobacteria, these electron-transfer reactions do not release energy but are used as a way of storing energy absorbed from sunlight. Figure 8.3: Simplified diagram of catabolism of proteins, carbohydrates and fats. The most common set of catabolic reactions in animals can be separated into three main stages. In the first stage, large organic molecules, such as proteins, polysaccharides or lipids, are digested into their smaller components outside cells. Next, these smaller molecules are taken up by cells and converted to smaller molecules, usually acetyl coenzyme A (acetyl-CoA), which releases some energy. Finally, the acetyl group on the CoA is oxidised to water and carbon dioxide in the citric acid cycle and electron transport chain, releasing the energy that is stored by reducing the coenzyme nicotinamide adenine dinucleotide (NAD+) into NADH. 8.5.7 Digestion Macromolecules cannot be directly processed by cells. Macromolecules must be broken into smaller units before they can be used in cell metabolism. Different classes of enzymes were being used to digest these polymers. These digestive enzymes include proteases that digest proteins into amino acids, as well as glycoside hydrolases that digest polysaccharides into simple sugars known as monosaccharides Microbes simply secrete digestive enzymes into their surroundings, while animals only secrete these enzymes from specialized cells in their guts, including the stomach and pancreas, and salivary glands. The amino acids or sugars released by these extracellular enzymes are then pumped into cells by active transport proteins. 8.5.8 Energy From Organic Compounds Carbohydrate catabolism is the breakdown of carbohydrates into smaller units. Carbohydrates are usually taken into cells once they have been digested into monosaccharides. Once inside, the major route of breakdown is glycolysis, where sugars such as glucose and fructose are converted into pyruvate and some ATP is generated. Pyruvate is an intermediate in several metabolic pathways, but the majority is converted to acetyl-CoA through aerobic (with oxygen) glycolysis and fed into the citric acid cycle. Although some more ATP is generated in the citric acid cycle, the most important product is NADH, which is made from NAD+ as the acetyl-CoA is oxidized. This oxidation releases carbon dioxide as a waste product. In anaerobic conditions, glycolysis produces lactate, through the enzyme lactate dehydrogenase re-oxidizing NADH to NAD+ for re-use in glycolysis. An alternative route for glucose breakdown is the pentose phosphate pathway, which reduces the coenzyme NADPH and produces pentose sugars such as ribose, the sugar component of nucleic acids. Fats are catabolised by hydrolysis to free fatty acids and glycerol. The glycerol enters glycolysis and the fatty acids are broken down by beta oxidation to release acetyl-CoA, which then is fed into the citric acid cycle. Fatty acids release more energy upon oxidation than carbohydrates because carbohydrates contain more oxygen in their structures. Steroids are also broken down by some bacteria in a process similar to beta oxidation, and this breakdown process involves the release of significant amounts of acetyl-CoA, propionyl-CoA, and pyruvate, which can all be used by the cell for energy. M. tuberculosis can also grow on the lipid cholesterol as a sole source of carbon, and genes involved in the cholesterol use pathway(s) have been validated as important during various stages of the infection lifecycle of M. tuberculosis. Amino acids are either used to synthesize proteins and other biomolecules, or oxidized to urea and carbon dioxide as a source of energy. The oxidation pathway starts with the removal of the amino group by a transaminase. The amino group is fed into the urea cycle, leaving a deaminated carbon skeleton in the form of a keto acid. Several of these keto acids are intermediates in the citric acid cycle, for example the deamination of glutamate forms α-ketoglutarate. The glucogenic amino acids can also be converted into glucose, through gluconeogenesis (discussed below). 8.6 Energy Transformations Adenosine triphosphate (ATP) is an organic compound that provides energy to drive many processes living cells, such as muscle contraction, nerve impulse propagation, condensate dissolution, and chemical synthesis. Found in all known forms of life, ATP is often referred to as the “molecular unit of currency” of intracellular energy transfer. When consumed in metabolic processes, it converts either to adenosine diphosphate (ADP) or to adenosine monophosphate (AMP). Other processes regenerate ATP so that the human body recycles its own body weight equivalent in ATP each day. It is also a precursor to DNA and RNA, and is used as a coenzyme. From the perspective of biochemistry, ATP is classified as a nucleoside triphosphate, which indicates that it consists of three components: a nitrogenous base (adenine), the sugar ribose, and the triphosphate. A typical intracellular concentration of ATP is hard to pin down, however, reports have shown there to be 1–10 μmol per gram of tissue in a variety of eukaryotes. The dephosphorylation of ATP and rephosphorylation of ADP and AMP occur repeatedly in the course of aerobic metabolism. ATP can be produced by a number of distinct cellular processes; the three main pathways are (1) glycolysis, (2) the citric acid cycle/oxidative phosphorylation, and (3) beta-oxidation. The overall process of oxidizing glucose to carbon dioxide, the combination of pathways 1 and 2, known as cellular respiration, produces about 30 equivalents of ATP from each molecule of glucose. ATP production by a non-photosynthetic aerobic eukaryote occurs mainly in the mitochondria, which comprise nearly 25% of the volume of a typical cell. In plants, ATP is synthesized in the thylakoid membrane of the chloroplast. The process is called photophosphorylation. The “machinery” is similar to that in mitochondria except that light energy is used to pump protons across a membrane to produce a proton-motive force. ATP synthase then ensues exactly as in oxidative phosphorylation. Some of the ATP produced in the chloroplasts is consumed in the Calvin cycle, which produces triose sugars. The total quantity of ATP in the human body is about 0.2 moles. The majority of ATP is recycled from ADP by the aforementioned processes. Thus, at any given time, the total amount of ATP + ADP remains fairly constant. The energy used by human cells in an adult requires the hydrolysis of 100 to 150 moles of ATP daily, which is around 50 to 75 kg. A human will typically use up their body weight of ATP over the course of the day. Each equivalent of ATP is recycled 1000–1500 times during a single day (100 / 0.2 = 500). 8.6.1 Oxidative Phosphorylation In oxidative phosphorylation, the electrons removed from organic molecules are transferred to oxygen and the energy released is used to make ATP. This is done in eukaryotes by a series of proteins in the membranes of mitochondria called the electron transport chain. In prokaryotes, these proteins are found in the cell’s inner membrane. These proteins use the energy released from passing electrons from reduced molecules like NADH onto oxygen to pump protons across a membrane. Pumping protons out of the mitochondria creates a proton concentration difference across the membrane and generates an electrochemical gradient. This force drives protons back into the mitochondrion through the base of an enzyme called ATP synthase. The flow of protons makes the stalk subunit rotate, causing the active site of the synthase domain to change shape and phosphorylate adenosine diphosphate – turning it into ATP. 8.6.2 Energy From Inorganic Compounds Chemolithotrophy is a type of metabolism found in prokaryotes where energy is obtained from the oxidation of inorganic compounds. These organisms can use hydrogen, reduced sulfur compounds (such as sulfide, hydrogen sulfide and thiosulfate), ferrous iron (FeII) or ammonia as sources of reducing power and they gain energy from the oxidation of these compounds with electron acceptors such as oxygen or nitrite. These microbial processes are important in global biogeochemical cycles such as acetogenesis, nitrification and denitrification and are critical for soil fertility. 8.6.3 Energy From Light The energy in sunlight is captured by plants, cyanobacteria, purple bacteria, green sulfur bacteria and some protists. This process is often coupled to the conversion of carbon dioxide into organic compounds, as part of photosynthesis, which is discussed below. The energy capture and carbon fixation systems can however operate separately in prokaryotes, as purple bacteria and green sulfur bacteria can use sunlight as a source of energy, while switching between carbon fixation and the fermentation of organic compounds. In many organisms, the capture of solar energy is similar in principle to oxidative phosphorylation, as it involves the storage of energy as a proton concentration gradient. This proton motive force then drives ATP synthesis The electrons needed to drive this electron transport chain come from light-gathering proteins called photosynthetic reaction centres. Reaction centers are classed into two types depending on the nature of photosynthetic pigment present, with most photosynthetic bacteria only having one type, while plants and cyanobacteria have two. In plants, algae, and cyanobacteria, photosystem II uses light energy to remove electrons from water, releasing oxygen as a waste product. The electrons then flow to the cytochrome b6f complex, which uses their energy to pump protons across the thylakoid membrane in the chloroplast. These protons move back through the membrane as they drive the ATP synthase, as before. The electrons then flow through photosystem I and can then either be used to reduce the coenzyme NADP+.fThese cooenzyme can be used in the Calvin cycle, which is discussed below, or recycled for further ATP generation. 8.6.4 Anabolism Anabolism is the set of constructive metabolic processes where the energy released by catabolism is used to synthesize complex molecules. In general, the complex molecules that make up cellular structures are constructed step-by-step from small and simple precursors. Anabolism involves three basic stages. First, the production of precursors such as amino acids, monosaccharides, isoprenoids and nucleotides, secondly, their activation into reactive forms using energy from ATP, and thirdly, the assembly of these precursors into complex molecules such as proteins, polysaccharides, lipids and nucleic acids. 8.7 Enzymes Enzymes are proteins that act as biological catalysts (biocatalysts). Catalysts accelerate chemical reactions. A catalyst increases the rate of reaction without being consumed in the reaction. In addition, the catalyst lowers the activation energy, but it does not change the energies of the original reactants or products, and so does not change equilibrium. Rather, the reactant energy and the product energy remain the same and only the activation energy is altered (lowered). A catalyst is able to reduce the activation energy by forming a transition state in a more favorable manner. Catalysts, by nature, create a more “comfortable” fit for the substrate of a reaction to progress to a transition state. This is possible due to a release of energy that occurs when the substrate binds to the active site of a catalyst. This energy is known as Binding Energy. Upon binding to a catalyst, substrates partake in numerous stabilizing forces while within the active site (i.e. Hydrogen bonding, van der Waals forces). Specific and favorable bonding occurs within the active site until the substrate forms to become the high-energy transition state. Forming the transition state is more favorable with the catalyst because the favorable stabilizing interactions within the active site release energy. A chemical reaction is able to manufacture a high-energy transition state molecule more readily when there is a stabilizing fit within the active site of a catalyst. The binding energy of a reaction is this energy released when favorable interactions between substrate and catalyst occur. The binding energy released assists in achieving the unstable transition state. Reactions otherwise without catalysts need a higher input of energy to achieve the transition state. Non-catalyzed reactions do not have free energy available from active site stabilizing interactions, such as catalytic enzyme reactions. Enzymes are known to catalyze more than 5,000 biochemical reaction types. Other biocatalysts are catalytic RNA molecules, called ribozymes. Enzymes’ specificity comes from their unique three-dimensional structures. The molecules upon which enzymes may act are called substrates, and the enzyme converts the substrates into different molecules known as products. Almost all metabolic processes in the cell need enzyme catalysis in order to occur at rates fast enough to sustain life. Metabolic pathways depend upon enzymes to catalyze individual steps. Like all catalysts, enzymes increase the reaction rate by lowering its activation energy. Some enzymes can make their conversion of substrate to product occur many millions of times faster. An extreme example is orotidine 5’-phosphate decarboxylase, which allows a reaction that would otherwise take millions of years to occur in milliseconds. Chemically, enzymes are like any catalyst and are not consumed in chemical reactions, nor do they alter the equilibrium of a reaction. Enzymes differ from most other catalysts by being much more specific. Enzyme activity can be affected by other molecules: inhibitors are molecules that decrease enzyme activity, and activators are molecules that increase activity. Many therapeutic drugs and poisons are enzyme inhibitors. An enzyme’s activity decreases markedly outside its optimal temperature and pH, and many enzymes are (permanently) denatured when exposed to excessive heat, losing their structure and catalytic properties. Figure 8.4: Example of an enzyme-catalysed exothermic reaction Some enzymes are used commercially, for example, in the synthesis of antibiotics. Some household products use enzymes to speed up chemical reactions: enzymes in biological washing powders break down protein, starch or fat stains on clothes, and enzymes in meat tenderizer break down proteins into smaller molecules, making the meat easier to chew. By the late 17th and early 18th centuries, the digestion of meat by stomach secretions and the conversion of starch to sugars by plant extracts and saliva were known but the mechanisms by which these occurred had not been identified. French chemist Anselme Payen was the first to discover an enzyme, diastase, in 1833. A few decades later, when studying the fermentation of sugar to alcohol by yeast, Louis Pasteur concluded that this fermentation was caused by a vital force contained within the yeast cells called “ferments”, which were thought to function only within living organisms. He wrote that “alcoholic fermentation is an act correlated with the life and organization of the yeast cells, not with the death or putrefaction of the cells.” Eduard Buchner submitted his first paper on the study of yeast extracts in 1897. In a series of experiments at the University of Berlin, he found that sugar was fermented by yeast extracts even when there were no living yeast cells in the mixture. He named the enzyme that brought about the fermentation of sucrose “zymase”. In 1907, he received the Nobel Prize in Chemistry for “his discovery of cell-free fermentation”. Following Buchner’s example, enzymes are usually named according to the reaction they carry out: the suffix -ase is combined with the name of the substrate (e.g., lactase is the enzyme that cleaves lactose) or to the type of reaction (e.g., DNA polymerase forms DNA polymers). The biochemical identity of enzymes was still unknown in the early 1900s. Many scientists observed that enzymatic activity was associated with proteins, but others (such as Nobel laureate Richard Willstätter) argued that proteins were merely carriers for the true enzymes and that proteins per se were incapable of catalysis. In 1926, James B. Sumner showed that the enzyme urease was a pure protein and crystallized it; he did likewise for the enzyme catalase in 1937. The conclusion that pure proteins can be enzymes was definitively demonstrated by John Howard Northrop and Wendell Meredith Stanley, who worked on the digestive enzymes pepsin (1930), trypsin and chymotrypsin. These three scientists were awarded the 1946 Nobel Prize in Chemistry. The discovery that enzymes could be crystallized eventually allowed their structures to be solved by x-ray crystallography. This was first done for lysozyme, an enzyme found in tears, saliva and egg whites that digests the coating of some bacteria; the structure was solved by a group led by David Chilton Phillips and published in 1965. This high-resolution structure of lysozyme marked the beginning of the field of structural biology and the effort to understand how enzymes work at an atomic level of detail. An enzyme’s name is often derived from its substrate or the chemical reaction it catalyzes, with the word ending in -ase. Examples are lactase, alcohol dehydrogenase and DNA polymerase. Different enzymes that catalyze the same chemical reaction are called isozymes. 8.7.1 Classification And Nomenclature Of Enzymes Classification and nomenclature Enzymes can be classified by two main criteria: either amino acid sequence similarity (and thus evolutionary relationship) or enzymatic activity. Enzyme activity. An enzyme’s name is often derived from its substrate or the chemical reaction it catalyzes, with the word ending in -ase.:8.1.3 Examples are lactase, alcohol dehydrogenase and DNA polymerase. Different enzymes that catalyze the same chemical reaction are called isozymes.:10.3 The International Union of Biochemistry and Molecular Biology have developed a nomenclature for enzymes, the EC numbers (for “Enzyme Commission”). Each enzyme is described by “EC” followed by a sequence of four numbers which represent the hierarchy of enzymatic activity (from very general to very specific). That is, the first number broadly classifies the enzyme based on its mechanism while the other digits add more and more specificity. The top-level classification is: EC 1, Oxidoreductases: catalyze oxidation/reduction reactions EC 2, Transferases: transfer a functional group (e.g. a methyl or phosphate group) EC 3, Hydrolases: catalyze the hydrolysis of various bonds EC 4, Lyases: cleave various bonds by means other than hydrolysis and oxidation EC 5, Isomerases: catalyze isomerization changes within a single molecule EC 6, Ligases: join two molecules with covalent bonds. These sections are subdivided by other features such as the substrate, products, and chemical mechanism. An enzyme is fully specified by four numerical designations. For example, hexokinase (EC 2.7.1.1) is a transferase (EC 2) that adds a phosphate group (EC 2.7) to a hexose sugar, a molecule containing an alcohol group (EC 2.7.1). Sequence similarity. EC categories do not reflect sequence similarity. For instance, two ligases of the same EC number that catalyze exactly the same reaction can have completely different sequences. Independent of their function, enzymes, like any other proteins, have been classified by their sequence similarity into numerous families. These families have been documented in dozens of different protein and protein family databases such as Pfam. 8.7.2 Stucture Of Enzymes Enzymes are generally globular proteins, acting alone or in larger complexes. The sequence of the amino acids specifies the structure which in turn determines the catalytic activity of the enzyme. Although structure determines function, a novel enzymatic activity cannot yet be predicted from structure alone. Enzyme structures unfold (denature) when heated or exposed to chemical denaturants and this disruption to the structure typically causes a loss of activity. Enzyme denaturation is normally linked to temperatures above a species’ normal level; as a result, enzymes from bacteria living in volcanic environments such as hot springs are prized by industrial users for their ability to function at high temperatures, allowing enzyme-catalysed reactions to be operated at a very high rate. Enzymes are usually much larger than their substrates. Sizes range from just 62 amino acid residues, for the monomer of 4-oxalocrotonate tautomerase, to over 2,500 residues in the animal fatty acid synthase. Only a small portion of their structure (around 2–4 amino acids) is directly involved in catalysis: the catalytic site. This catalytic site is located next to one or more binding sites where residues orient the substrates. The catalytic site and binding site together compose the enzyme’s active site. The remaining majority of the enzyme structure serves to maintain the precise orientation and dynamics of the active site. In some enzymes, no amino acids are directly involved in catalysis; instead, the enzyme contains sites to bind and orient catalytic cofactors. Enzyme structures may also contain allosteric sites where the binding of a small molecule causes a conformational change that increases or decreases activity. A small number of RNA-based biological catalysts called ribozymes exist, which again can act alone or in complex with proteins. The most common of these is the ribosome which is a complex of protein and catalytic RNA components. 8.7.3 Mechanism Of Action Of Enzymes Enzymes must bind their substrates before they can catalyse any chemical reaction. Enzymes are usually very specific as to what substrates they bind and then the chemical reaction catalysed. Specificity is achieved by binding pockets with complementary shape, charge and hydrophilic/hydrophobic characteristics to the substrates. Enzymes can therefore distinguish between very similar substrate molecules to be chemoselective, regioselective and stereospecific. Some of the enzymes showing the highest specificity and accuracy are involved in the copying and expression of the genome. Some of these enzymes have “proof-reading” mechanisms. Here, an enzyme such as DNA polymerase catalyzes a reaction in a first step and then checks that the product is correct in a second step. This two-step process results in average error rates of less than 1 error in 100 million reactions in high-fidelity mammalian polymerases. Similar proofreading mechanisms are also found in RNA polymerase, aminoacyl tRNA synthetases and ribosomes. Conversely, some enzymes display enzyme promiscuity, having broad specificity and acting on a range of different physiologically relevant substrates. Many enzymes possess small side activities which arose fortuitously (i.e. neutrally), which may be the starting point for the evolutionary selection of a new function. To explain the observed specificity of enzymes, in 1894 Emil Fischer proposed that both the enzyme and the substrate possess specific complementary geometric shapes that fit exactly into one another. This is often referred to as “the lock and key” model. This early model explains enzyme specificity, but fails to explain the stabilization of the transition state that enzymes achieve. In 1958, Daniel Koshland suggested a modification to the lock and key model: since enzymes are rather flexible structures, the active site is continuously reshaped by interactions with the substrate as the substrate interacts with the enzyme. As a result, the substrate does not simply bind to a rigid active site; the amino acid side-chains that make up the active site are molded into the precise positions that enable the enzyme to perform its catalytic function. In some cases, such as glycosidases, the substrate molecule also changes shape slightly as it enters the active site. The active site continues to change until the substrate is completely bound, at which point the final shape and charge distribution is determined. Induced fit may enhance the fidelity of molecular recognition in the presence of competition and noise via the conformational proofreading mechanism. Enzymes can accelerate reactions in several ways, all of which lower the activation energy (ΔG, Gibbs free energy) By stabilizing the transition state: Creating an environment with a charge distribution complementary to that of the transition state to lower its energy By providing an alternative reaction pathway: Temporarily reacting with the substrate, forming a covalent intermediate to provide a lower energy transition state By destabilising the substrate ground state: Distorting bound substrate(s) into their transition state form to reduce the energy required to reach the transition state By orienting the substrates into a productive arrangement to reduce the reaction entropy change (the contribution of this mechanism to catalysis is relatively small) Enzymes may use several of these mechanisms simultaneously. For example, proteases such as trypsin perform covalent catalysis using a catalytic triad, stabilise charge build-up on the transition states using an oxyanion hole, complete hydrolysis using an oriented water substrate. Enzymes are not rigid, static structures; instead they have complex internal dynamic motions – that is, movements of parts of the enzyme’s structure such as individual amino acid residues, groups of residues forming a protein loop or unit of secondary structure, or even an entire protein domain. These motions give rise to a conformational ensemble of slightly different structures that interconvert with one another at equilibrium. Different states within this ensemble may be associated with different aspects of an enzyme’s function. For example, different conformations of the enzyme dihydrofolate reductase are associated with the substrate binding, catalysis, cofactor release, and product release steps of the catalytic cycle, consistent with catalytic resonance theory. Substrate presentation is a process where the enzyme is sequestered away from its substrate. Enzymes can be sequestered to the plasma membrane away from a substrate in the nucleus or cytosol. Or within the membrane, an enzyme can be sequestered into lipid rafts away from its substrate in the disordered region. When the enzyme is releases it mixes with its substrate. Alternatively, the enzyme can be sequestered near its substrate to activate the enzyme. For example, the enzyme can be soluble and upon activation bind to a lipid in the plasma membrane and then act upon molecules in the plasma membrane. 8.7.4 Allosteric Modulation Allosteric sites are pockets on the enzyme, distinct from the active site, that bind to molecules in the cellular environment. These molecules then cause a change in the conformation or dynamics of the enzyme that is transduced to the active site and thus affects the reaction rate of the enzyme. In this way, allosteric interactions can either inhibit or activate enzymes. Allosteric interactions with metabolites upstream or downstream in an enzyme’s metabolic pathway cause feedback regulation, altering the activity of the enzyme according to the flux through the rest of the pathway. 8.7.5 Cofactors Of Enzymes And Coenzymes Some enzymes do not need additional components to show full activity. Others require non-protein molecules called cofactors to be bound for activity. Cofactors can be either inorganic (e.g., metal ions and iron-sulfur clusters) or organic compounds (e.g., flavin and heme). These cofactors serve many purposes; for instance, metal ions can help in stabilizing nucleophilic species within the active site. Organic cofactors can be either coenzymes, which are released from the enzyme’s active site during the reaction, or prosthetic groups, which are tightly bound to an enzyme. Organic prosthetic groups can be covalently bound (e.g., biotin in enzymes such as pyruvate carboxylase). An example of an enzyme that contains a cofactor is carbonic anhydrase, which uses a zinc cofactor bound as part of its active site. These tightly bound ions or molecules are usually found in the active site and are involved in catalysis. For example, flavin and heme cofactors are often involved in redox reactions. Enzymes that require a cofactor but do not have one bound are called apoenzymes or apoproteins. An enzyme together with the cofactor(s) required for activity is called a holoenzyme (or haloenzyme). The term holoenzyme can also be applied to enzymes that contain multiple protein subunits, such as the DNA polymerases; here the holoenzyme is the complete complex containing all the subunits needed for activity. Coenzymes are small organic molecules that can be loosely or tightly bound to an enzyme. Coenzymes transport chemical groups from one enzyme to another. Examples include NADH, NADPH and adenosine triphosphate (ATP). Some coenzymes, such as flavin mononucleotide (FMN), flavin adenine dinucleotide (FAD), thiamine pyrophosphate (TPP), and tetrahydrofolate (THF), are derived from vitamins. These coenzymes cannot be synthesized by the body de novo and closely related compounds (vitamins) must be acquired from the diet. The chemical groups carried include: the hydride ion (H-), carried by NAD or NADP+ the phosphate group, carried by adenosine triphosphate the acetyl group, carried by coenzyme A formyl, methenyl or methyl groups, carried by folic acid and the methyl group, carried by S-adenosylmethionine Since coenzymes are chemically changed as a consequence of enzyme action, it is useful to consider coenzymes to be a special class of substrates, or second substrates, which are common to many different enzymes. For example, about 1000 enzymes are known to use the coenzyme NADH. Coenzymes are usually continuously regenerated and their concentrations maintained at a steady level inside the cell. For example, NADPH is regenerated through the pentose phosphate pathway and S-adenosylmethionine by methionine adenosyltransferase. This continuous regeneration means that small amounts of coenzymes can be used very intensively. For example, the human body turns over its own weight in ATP each day. 8.7.6 Inhibition Of Enzymes An enzyme binding site that would normally bind substrate can alternatively bind a competitive inhibitor, preventing substrate access. Dihydrofolate reductase is inhibited by methotrexate which prevents binding of its substrate, folic acid. Binding site in blue, inhibitor in green, and substrate in black. (PDB: 4QI9​) Two dimensional representations of the chemical structure of folic acid and methotrexate highlighting the differences between these two substances (amidation of pyrimidone and methylation of secondary amine). The coenzyme folic acid (left) and the anti-cancer drug methotrexate (right) are very similar in structure (differences show in green). As a result, methotrexate is a competitive inhibitor of many enzymes that use folates. Enzyme reaction rates can be decreased by various types of enzyme inhibitors. A competitive inhibitor and substrate cannot bind to the enzyme at the same time. Often competitive inhibitors strongly resemble the real substrate of the enzyme. For example, the drug methotrexate is a competitive inhibitor of the enzyme dihydrofolate reductase, which catalyzes the reduction of dihydrofolate to tetrahydrofolate. The similarity between the structures of dihydrofolate and this drug are shown in the accompanying figure. This type of inhibition can be overcome with high substrate concentration. In some cases, the inhibitor can bind to a site other than the binding-site of the usual substrate and exert an allosteric effect to change the shape of the usual binding-site. A non-competitive inhibitor binds to a site other than where the substrate binds. The substrate still binds with its usual affinity and hence Km remains the same. However the inhibitor reduces the catalytic efficiency of the enzyme so that Vmax is reduced. In contrast to competitive inhibition, non-competitive inhibition cannot be overcome with high substrate concentration. An uncompetitive inhibitor cannot bind to the free enzyme, only to the enzyme-substrate complex; hence, these types of inhibitors are most effective at high substrate concentration. In the presence of the inhibitor, the enzyme-substrate complex is inactive. This type of inhibition is rare. A mixed inhibitor binds to an allosteric site and the binding of the substrate and the inhibitor affect each other. The enzyme’s function is reduced but not eliminated when bound to the inhibitor. This type of inhibitor does not follow the Michaelis–Menten equation. An irreversible inhibitor permanently inactivates the enzyme, usually by forming a covalent bond to the protein. Penicillin and aspirin are common drugs that act in this manner. In many organisms, inhibitors may act as part of a feedback mechanism. If an enzyme produces too much of one substance in the organism, that substance may act as an inhibitor for the enzyme at the beginning of the pathway that produces it, causing production of the substance to slow down or stop when there is sufficient amount. This is a form of negative feedback. Major metabolic pathways such as the citric acid cycle make use of this mechanism. Since inhibitors modulate the function of enzymes they are often used as drugs. Many such drugs are reversible competitive inhibitors that resemble the enzyme’s native substrate, similar to methotrexate above; other well-known examples include statins used to treat high cholesterol, and protease inhibitors used to treat retroviral infections such as HIV. A common example of an irreversible inhibitor that is used as a drug is aspirin, which inhibits the COX-1 and COX-2 enzymes that produce the inflammation messenger prostaglandin. Other enzyme inhibitors are poisons. For example, the poison cyanide is an irreversible enzyme inhibitor that combines with the copper and iron in the active site of the enzyme cytochrome c oxidase and blocks cellular respiration. 8.7.7 Factors Affecting Enzyme Activity As enzymes are made up of proteins, their actions are sensitive to change in many physio chemical factors such as pH, temperature, substrate concentration, etc. Enzymes serve a wide variety of functions inside living organisms. They are indispensable for signal transduction and cell regulation, often via kinases and phosphatases. They also generate movement, with myosin hydrolyzing ATP to generate muscle contraction, and also transport cargo around the cell as part of the cytoskeleton. Other ATPases in the cell membrane are ion pumps involved in active transport. Enzymes are also involved in more exotic functions, such as luciferase generating light in fireflies. Viruses can also contain enzymes for infecting cells, such as the HIV integrase and reverse transcriptase, or for viral release from cells, like the influenza virus neuraminidase. An important function of enzymes is in the digestive systems of animals. Enzymes such as amylases and proteases break down large molecules (starch or proteins, respectively) into smaller ones, so they can be absorbed by the intestines. Starch molecules, for example, are too large to be absorbed from the intestine, but enzymes hydrolyze the starch chains into smaller molecules such as maltose and eventually glucose, which can then be absorbed. Different enzymes digest different food substances. In ruminants, which have herbivorous diets, microorganisms in the gut produce another enzyme, cellulase, to break down the cellulose cell walls of plant fiber. Several enzymes can work together in a specific order, creating metabolic pathways. In a metabolic pathway, one enzyme takes the product of another enzyme as a substrate. After the catalytic reaction, the product is then passed on to another enzyme. Sometimes more than one enzyme can catalyze the same reaction in parallel; this can allow more complex regulation with, for example, a low constant activity provided by one enzyme but an inducible high activity from a second enzyme. Enzymes determine what steps occur in these pathways. Without enzymes, metabolism would neither progress through the same steps and could not be regulated to serve the needs of the cell. Most central metabolic pathways are regulated at a few key steps, typically through enzymes whose activity involves the hydrolysis of ATP. Because this reaction releases so much energy, other reactions that are thermodynamically unfavorable can be coupled to ATP hydrolysis, driving the overall series of linked metabolic reactions. 8.7.8 Control Of Activity There are five main ways that enzyme activity is controlled in the cell. Enzymes can be either activated or inhibited by other molecules. For example, the end product(s) of a metabolic pathway are often inhibitors for one of the first enzymes of the pathway (usually the first irreversible step, called committed step), thus regulating the amount of end product made by the pathways. Such a regulatory mechanism is called a negative feedback mechanism, because the amount of the end product produced is regulated by its own concentration. Negative feedback mechanism can effectively adjust the rate of synthesis of intermediate metabolites according to the demands of the cells. This helps with effective allocations of materials and energy economy, and it prevents the excess manufacture of end products. Like other homeostatic devices, the control of enzymatic action helps to maintain a stable internal environment in living organisms. 8.7.9 Post-translational Modification Examples of post-translational modification include phosphorylation, myristoylation and glycosylation. For example, in the response to insulin, the phosphorylation of multiple enzymes, including glycogen synthase, helps control the synthesis or degradation of glycogen and allows the cell to respond to changes in blood sugar. Another example of post-translational modification is the cleavage of the polypeptide chain. Chymotrypsin, a digestive protease, is produced in inactive form as chymotrypsinogen in the pancreas and transported in this form to the stomach where it is activated. This stops the enzyme from digesting the pancreas or other tissues before it enters the gut. This type of inactive precursor to an enzyme is known as a zymogen or proenzyme. 8.7.10 Quantity Enzyme production (transcription and translation of enzyme genes) can be enhanced or diminished by a cell in response to changes in the cell’s environment. This form of gene regulation is called enzyme induction. For example, bacteria may become resistant to antibiotics such as penicillin because enzymes called beta-lactamases are induced that hydrolyse the crucial beta-lactam ring within the penicillin molecule. Another example comes from enzymes in the liver called cytochrome P450 oxidases, which are important in drug metabolism. Induction or inhibition of these enzymes can cause drug interactions. Enzyme levels can also be regulated by changing the rate of enzyme degradation. The opposite of enzyme induction is enzyme repression. 8.7.11 Subcellular Distribution Enzymes can be compartmentalized, with different metabolic pathways occurring in different cellular compartments. For example, fatty acids are synthesized by one set of enzymes in the cytosol, endoplasmic reticulum and Golgi and used by a different set of enzymes as a source of energy in the mitochondrion, through β-oxidation. In addition, trafficking of the enzyme to different compartments may change the degree of protonation (e.g., the neutral cytoplasm and the acidic lysosome) or oxidative state (e.g., oxidizing periplasm or reducing cytoplasm) which in turn affects enzyme activity. In contrast to partitioning into membrane bound organelles, enzyme subcellular localisation may also be altered through polymerisation of enzymes into macromolecular cytoplasmic filaments. 8.7.12 Organ Specialization In multicellular eukaryotes, cells in different organs and tissues have different patterns of gene expression and therefore have different sets of enzymes (known as isozymes) available for metabolic reactions. This provides a mechanism for regulating the overall metabolism of the organism. For example, hexokinase, the first enzyme in the glycolysis pathway, has a specialized form called glucokinase expressed in the liver and pancreas that has a lower affinity for glucose yet is more sensitive to glucose concentration. This enzyme is involved in sensing blood sugar and regulating insulin production. 8.7.13 Coenzymes Metabolism involves a vast array of chemical reactions, but most fall under a few basic types of reactions that involve the transfer of functional groups of atoms and their bonds within molecules. This common chemistry allows cells to use a small set of metabolic intermediates to carry chemical groups between different reactions. These group-transfer intermediates are called coenzymes. Each class of group-transfer reactions is carried out by a particular coenzyme, which is the substrate for a set of enzymes that produce it, and a set of enzymes that consume it. These coenzymes are therefore continuously made, consumed and then recycled. One central coenzyme is adenosine triphosphate (ATP), the universal energy currency of cells. This nucleotide is used to transfer chemical energy between different chemical reactions. There is only a small amount of ATP in cells, but as it is continuously regenerated, the human body can use about its own weight in ATP per day. ATP acts as a bridge between catabolism and anabolism. Catabolism breaks down molecules, and anabolism puts them together. Catabolic reactions generate ATP, and anabolic reactions consume it. It also serves as a carrier of phosphate groups in phosphorylation reactions. A vitamin is an organic compound needed in small quantities that cannot be made in cells. In human nutrition, most vitamins function as coenzymes after modification; for example, all water-soluble vitamins are phosphorylated or are coupled to nucleotides when they are used in cells. Nicotinamide adenine dinucleotide (NAD+), a derivative of vitamin B3 (niacin), is an important coenzyme that acts as a hydrogen acceptor. Hundreds of separate types of dehydrogenases remove electrons from their substrates and reduce NAD+ into NADH. This reduced form of the coenzyme is then a substrate for any of the reductases in the cell that need to reduce their substrates. Nicotinamide adenine dinucleotide exists in two related forms in the cell, NADH and NADPH. The NAD+/NADH form is more important in catabolic reactions, while NADP+/NADPH is used in anabolic reactions. 8.7.14 Mineral Cofactors Inorganic elements play critical roles in metabolism; some are abundant (e.g. sodium and potassium) while others function at minute concentrations. About 99% of a human’s body weight is made up of the elements carbon, nitrogen, calcium, sodium, chlorine, potassium, hydrogen, phosphorus, oxygen and sulfur. Organic compounds (proteins, lipids and carbohydrates) contain the majority of the carbon and nitrogen; most of the oxygen and hydrogen is present as water. The abundant inorganic elements act as electrolytes. The most important ions are sodium, potassium, calcium, magnesium, chloride, phosphate and the organic ion bicarbonate. The maintenance of precise ion gradients across cell membranes maintains osmotic pressure and pH. Ions are also critical for nerve and muscle function, as action potentials in these tissues are produced by the exchange of electrolytes between the extracellular fluid and the cell’s fluid, the cytosol. Electrolytes enter and leave cells through proteins in the cell membrane called ion channels. For example, muscle contraction depends upon the movement of calcium, sodium and potassium through ion channels in the cell membrane and T-tubules. Transition metals are usually present as trace elements in organisms, with zinc and iron being most abundant of those. These metals are used in some proteins as cofactors and are essential for the activity of enzymes such as catalase and oxygen-carrier proteins such as hemoglobin Metal cofactors are bound tightly to specific sites in proteins; although enzyme cofactors can be modified during catalysis, they always return to their original state by the end of the reaction catalyzed. Metal micronutrients are taken up into organisms by specific transporters and bind to storage proteins such as ferritin or metallothionein when not in use. 8.8 Heterotrophic Microbial Metabolism Some microbes are heterotrophic (more precisely chemoorganoheterotrophic), using organic compounds as both carbon and energy sources. Heterotrophic microbes live off of nutrients that they scavenge from living hosts (as commensals or parasites) or find in dead organic matter of all kind (saprophages). Microbial metabolism is the main contribution for the bodily decay of all organisms after death. Many eukaryotic microorganisms are heterotrophic by predation or parasitism, properties also found in some bacteria such as Bdellovibrio (an intracellular parasite of other bacteria, causing death of its victims) and Myxobacteria such as Myxococcus (predators of other bacteria which are killed and lysed by cooperating swarms of many single cells of Myxobacteria). Most pathogenic bacteria can be viewed as heterotrophic parasites of humans or the other eukaryotic species they affect. Heterotrophic microbes are extremely abundant in nature and are responsible for the breakdown of large organic polymers such as cellulose, chitin or lignin which are generally indigestible to larger animals. Generally, the oxidative breakdown of large polymers to carbon dioxide (mineralization) requires several different organisms, with one breaking down the polymer into its constituent monomers, one able to use the monomers and excreting simpler waste compounds as by-products, and one able to use the excreted wastes. There are many variations on this theme, as different organisms are able to degrade different polymers and secrete different waste products. Some organisms are even able to degrade more recalcitrant compounds such as petroleum compounds or pesticides, making them useful in bioremediation. Biochemically, prokaryotic heterotrophic metabolism is much more versatile than that of eukaryotic organisms, although many prokaryotes share the most basic metabolic models with eukaryotes, e. g. using glycolysis (also called EMP pathway) for sugar metabolism and the citric acid cycle to degrade acetate, producing energy in the form of ATP and reducing power in the form of NADH or quinols. These basic pathways are well conserved because they are also involved in biosynthesis of many conserved building blocks needed for cell growth (sometimes in reverse direction). However, many bacteria and archaea utilize alternative metabolic pathways other than glycolysis and the citric acid cycle. A well-studied example is sugar metabolism via the keto-deoxy-phosphogluconate pathway (also called ED pathway) in Pseudomonas. Moreover, there is a third alternative sugar-catabolic pathway used by some bacteria, the pentose phosphate pathway. The metabolic diversity and ability of prokaryotes to use a large variety of organic compounds arises from the much deeper evolutionary history and diversity of prokaryotes, as compared to eukaryotes. It is also noteworthy that the mitochondrion, the small membrane-bound intracellular organelle that is the site of eukaryotic oxygen-driven energy metabolism, arose from the endosymbiosis of a bacterium related to obligate intracellular Rickettsia, and also to plant-associated Rhizobium or Agrobacterium. Therefore, it is not surprising that all mitrochondriate eukaryotes share metabolic properties with these Proteobacteria. Most microbes respire (use an electron transport chain), although oxygen is not the only terminal electron acceptor that may be used. As discussed below, the use of terminal electron acceptors other than oxygen has important biogeochemical consequences. Anabolism in organisms can be different according to the source of constructed molecules in their cells. Autotrophs such as plants can construct the complex organic molecules in cells such as polysaccharides and proteins from simple molecules like carbon dioxide and water. Heterotrophs, on the other hand, require a source of more complex substances, such as monosaccharides and amino acids, to produce these complex molecules. Organisms can be further classified by ultimate source of their energy: photoautotrophs and photoheterotrophs obtain energy from light, whereas chemoautotrophs and chemoheterotrophs obtain energy from inorganic oxidation reactions. 8.8.1 Carbon Fixation Photosynthesis is the synthesis of carbohydrates from sunlight and carbon dioxide (CO2). In plants, cyanobacteria and algae, oxygenic photosynthesis splits water, with oxygen produced as a waste product. This process uses the ATP and NADPH produced by the photosynthetic reaction centres, as described above, to convert CO2 into glycerate 3-phosphate, which can then be converted into glucose. This carbon-fixation reaction is carried out by the enzyme RuBisCO as part of the Calvin cycle. Three types of photosynthesis occur in plants, C3 carbon fixation, C4 carbon fixation and CAM photosynthesis. These differ by the route that carbon dioxide takes to the Calvin cycle, with C3 plants fixing CO2 directly, while C4 and CAM photosynthesis incorporate the CO2 into other compounds first, as adaptations to deal with intense sunlight and dry conditions. In photosynthetic prokaryotes the mechanisms of carbon fixation are more diverse. Here, carbon dioxide can be fixed by the Calvin cycle, a reversed citric acid cycle, or the carboxylation of acetyl-CoA. Prokaryotic chemoautotrophs also fix CO2 through the Calvin cycle, but use energy from inorganic compounds to drive the reaction. 8.8.2 Carbohydrates And Glycans In carbohydrate anabolism, simple organic acids can be converted into monosaccharides such as glucose and then used to assemble polysaccharides such as starch. The generation of glucose from compounds like pyruvate, lactate, glycerol, glycerate 3-phosphate and amino acids is called gluconeogenesis. Gluconeogenesis converts pyruvate to glucose-6-phosphate through a series of intermediates, many of which are shared with glycolysis. However, this pathway is not simply glycolysis run in reverse, as several steps are catalyzed by non-glycolytic enzymes. This is important as it allows the formation and breakdown of glucose to be regulated separately, and prevents both pathways from running simultaneously in a futile cycle. Although fat is a common way of storing energy, in vertebrates such as humans the fatty acids in these stores cannot be converted to glucose through gluconeogenesis as these organisms cannot convert acetyl-CoA into pyruvate; plants do, but animals do not, have the necessary enzymatic machinery. As a result, after long-term starvation, vertebrates need to produce ketone bodies from fatty acids to replace glucose in tissues such as the brain that cannot metabolize fatty acids. In other organisms such as plants and bacteria, this metabolic problem is solved using the glyoxylate cycle, which bypasses the decarboxylation step in the citric acid cycle and allows the transformation of acetyl-CoA to oxaloacetate, where it can be used for the production of glucose. Other than fat, glucose is stored in most tissues, as an energy resource available within the tissue through glycogenesis which was usually being used to maintained glucose level in blood. Polysaccharides and glycans are made by the sequential addition of monosaccharides by glycosyltransferase from a reactive sugar-phosphate donor such as uridine diphosphate glucose (UDP-Glc) to an acceptor hydroxyl group on the growing polysaccharide. As any of the hydroxyl groups on the ring of the substrate can be acceptors, the polysaccharides produced can have straight or branched structures. The polysaccharides produced can have structural or metabolic functions themselves, or be transferred to lipids and proteins by enzymes called oligosaccharyltransferases. 8.8.3 Fatty Acids, Isoprenoids and Sterol Simplified version of the steroid synthesis pathway with the intermediates isopentenyl pyrophosphate (IPP), dimethylallyl pyrophosphate , geranyl pyrophosphate (GPP) and squalene shown. Some intermediates are omitted for clarity. Fatty acids are made by fatty acid synthases that polymerize and then reduce acetyl-CoA units. The acyl chains in the fatty acids are extended by a cycle of reactions that add the acyl group, reduce it to an alcohol, dehydrate it to an alkene group and then reduce it again to an alkane group. The enzymes of fatty acid biosynthesis are divided into two groups: in animals and fungi, all these fatty acid synthase reactions are carried out by a single multifunctional type I protein, while in plant plastids and bacteria separate type II enzymes perform each step in the pathway. Terpenes and isoprenoids are a large class of lipids that include the carotenoids and form the largest class of plant natural products. These compounds are made by the assembly and modification of isoprene units donated from the reactive precursors isopentenyl pyrophosphate and dimethylallyl pyrophosphate. These precursors can be made in different ways. In animals and archaea, the mevalonate pathway produces these compounds from acetyl-CoA, while in plants and bacteria the non-mevalonate pathway uses pyruvate and glyceraldehyde 3-phosphate as substrates. One important reaction that uses these activated isoprene donors is sterol biosynthesis. Here, the isoprene units are joined together to make squalene and then folded up and formed into a set of rings to make lanosterol. Lanosterol can then be converted into other sterol such as cholesterol and ergosterol. 8.8.4 Proteins Organisms vary in their ability to synthesize the 20 common amino acids. Most bacteria and plants can synthesize all twenty, but mammals can only synthesize eleven nonessential amino acids, so nine essential amino acids must be obtained from food. Some simple parasites, such as the bacteria Mycoplasma pneumoniae, lack all amino acid synthesis and take their amino acids directly from their hosts. All amino acids are synthesized from intermediates in glycolysis, the citric acid cycle, or the pentose phosphate pathway. Nitrogen is provided by glutamate and glutamine. Nonessensial amino acid synthesis depends on the formation of the appropriate alpha-keto acid, which is then transaminated to form an amino acid. Amino acids are made into proteins by being joined together in a chain of peptide bonds. Each different protein has a unique sequence of amino acid residues: this is its primary structure. Just as the letters of the alphabet can be combined to form an almost endless variety of words, amino acids can be linked in varying sequences to form a huge variety of proteins. Proteins are made from amino acids that have been activated by attachment to a transfer RNA molecule through an ester bond. This aminoacyl-tRNA precursor is produced in an ATP-dependent reaction carried out by an aminoacyl tRNA synthetase. This aminoacyl-tRNA is then a substrate for the ribosome, which joins the amino acid onto the elongating protein chain, using the sequence information in a messenger RNA. 8.8.5 Nucleotide Synthesis And Salvage Nucleotides are made from amino acids, carbon dioxide and formic acid in pathways that require large amounts of metabolic energy. Consequently, most organisms have efficient systems to salvage preformed nucleotides. Purines are synthesized as nucleosides (bases attached to ribose). Both adenine and guanine are made from the precursor nucleoside inosine monophosphate, which is synthesized using atoms from the amino acids glycine, glutamine, and aspartic acid, as well as formate transferred from the coenzyme tetrahydrofolate. Pyrimidines, on the other hand, are synthesized from the base orotate, which is formed from glutamine and aspartate. Microbial metabolism is the means by which a microbe obtains the energy and nutrients (e.g. carbon) it needs to live and reproduce. Microbes use many different types of metabolic strategies and species can often be differentiated from each other based on metabolic characteristics. The specific metabolic properties of a microbe are the major factors in determining that microbe’s ecological niche, and often allow for that microbe to be useful in industrial processes or responsible for biogeochemical cycles. All microbial metabolisms can be arranged according to three principles: How the organism obtains carbon for synthesizing cell mass: autotrophic – carbon is obtained from carbon dioxide (CO heterotrophic – carbon is obtained from organic compounds mixotrophic – carbon is obtained from both organic compounds and by fixing carbon dioxide How the organism obtains reducing equivalents (hydrogen atoms or electrons) used either in energy conservation or in biosynthetic reactions: lithotrophic – reducing equivalents are obtained from inorganic compounds organotrophic – reducing equivalents are obtained from organic compounds How the organism obtains energy for living and growing: phototrophic – energy is obtained from light chemotrophic – energy is obtained from external chemical compounds In practice, these terms are almost freely combined. Typical examples are as follows: chemolithoautotrophs obtain energy from the oxidation of inorganic compounds and carbon from the fixation of carbon dioxide. Examples: Nitrifying bacteria, sulfur-oxidizing bacteria, iron-oxidizing bacteria, Knallgas-bacteria photolithoautotrophs obtain energy from light and carbon from the fixation of carbon dioxide, using reducing equivalents from inorganic compounds. Examples: Cyanobacteria (water (H 2O) as reducing equivalent = hydrogen donor), Chlorobiaceae, Chromatiaceae (hydrogen sulfide (H 2S) as hydrogen donor), Chloroflexus (hydrogen (H as reducing equivalent donor) chemolithoheterotrophs obtain energy from the oxidation of inorganic compounds, but cannot fix carbon dioxide (CO 2). Examples: some Thiobacilus, some Beggiatoa, some Nitrobacter spp., Wolinella (with H 2 as reducing equivalent donor), some Knallgas-bacteria, some sulfate-reducing bacteria chemoorganoheterotrophs obtain energy, carbon, and hydrogen for biosynthetic reactions from organic compounds. Examples: most bacteria, e. g. Escherichia coli, Bacillus spp., Actinobacteria photoorganoheterotrophs obtain energy from light, carbon and reducing equivalents for biosynthetic reactions from organic compounds. Some species are strictly heterotrophic, many others can also fix carbon dioxide and are mixotrophic. Examples: Rhodobacter, Rhodopseudomonas, Rhodospirillum, Rhodomicrobium, Rhodocyclus, Heliobacterium, Chloroflexus (alternatively to photolithoautotrophy with hydrogen) 8.9 Photosynthesis And Cellular Respiration Some microroganisms acquire energy from sunlight through photosynthesis, others get their energy by breaking down chemical bonds in nutrients during cellular respiration. In eukaryiotic cells, photosynthesis happens in chloroplasts, cellular respiration in mitochondria. In both photosynthesis and cellular respiration, ATP production involves an electron transfer chain and chemiosmosis. Figure 8.5: Schematic of photosynthesis in plants. The carbohydrates produced are stored in or used by the plant which in turn may provide food for heterotrophic organims such as animals. 8.9.1 The Electron Transport Chain And Chemiosmosis The electron transport chain (ETC) is a series of complexes that transfer electrons from electron donors to electron acceptors via redox (both reduction and oxidation occurring simultaneously) reactions, and couples this electron transfer with the transfer of protons (H+ ions) across a membrane. The electron transport chain is built up of peptides, enzymes, and other molecules. The flow of electrons through the electron transport chain is an exergonic process. The energy from the redox reactions create an electrochemical proton gradient that drives the synthesis of adenosine triphosphate (ATP). In aerobic respiration, the flow of electrons terminates with molecular oxygen being the final electron acceptor. In anaerobic respiration, other organic or inorganic electron acceptors are used, such as lactic acid and sulfate, for example. In the electron transport chain, the redox reactions are driven by the Gibbs free energy state of the components. Gibbs free energy is related to a quantity called the redox potential. The complexes in the electron transport chain harvest the energy of the redox reactions that occur when transferring electrons from a low redox potential to a higher redox potential, creating an electrochemical gradient. It is the electrochemical gradient created that drives the synthesis of ATP via coupling with oxidative phosphorylation with ATP synthase. The electron transport chain, and site of oxidative phosphorylation is found on the inner mitochondrial membrane. The energy stored from the process of respiration in reduced compounds (such as NADH and FADH) is used by the electron transport chain to pump protons into the inter membrane space, generating the electrochemical gradient over the inner mitochrondrial membrane. Figure 8.6: The electron transport chain in the mitochondrion is the site of oxidative phosphorylation in eukaryotes. The NADH and succinate generated in the citric acid cycle are oxidized, providing energy to power ATP synthase. In photosynthetic eukaryotes, the electron transport chain is found on the thylakoid membrane. Here, light energy drives the reduction of components of the electron transport chain and therefore causes subsequent synthesis of ATP. The electron transport chain, and site of oxidative phosphorylation is found on the inner mitochondrial membrane. The energy stored from the process of respiration in reduced compounds (such as NADH and FADH) is used by the electron transport chain to pump protons into the inter membrane space, generating the electrochemical gradient over the inner mitochrondrial membrane. Hydrogen ions, or protons, will diffuse from an area of high proton concentration to an area of lower proton concentration, and an electrochemical concentration gradient of protons across a membrane can be harnessed to make ATP. This process is related to osmosis, the diffusion of water across a membrane, which is why it is called “chemiosmosis”. The formation of adenosine triphosphate (ATP) by the movement of hydrogen ions (H+) across a membrane during cellular respiration or photosynthesis is an example of chemiosmosis. ATP synthase is the enzyme that makes ATP by chemiosmosis. It allows protons to pass through the membrane and uses the free energy difference to phosphorylate adenosine diphosphate (ADP), making ATP. The generation of ATP by chemiosmosis occurs in mitochondria and chloroplasts, as well as in most bacteria and archaea, an electron transport chain pumps H+ ions in the thylakoid spaces through thylakoid membranes to stroma (fluid). The energy from the electron movement through electron transport chains cross through ATP synthase which allows the proton to pass through them and use this free energy difference to photophosphorylate ADP making ATP. 8.9.2 Photosynthesis Photosynthesis is a process used by plants and other organisms to convert light energy into chemical energy that can later be released to fuel the organisms’ activities. This chemical energy is stored in carbohydrate molecules, such as sugars, which are synthesized from carbon dioxide and water – hence the name photosynthesis, from the Greek phōs (φῶς), “light”, and sunthesis (σύνθεσις), “putting together”. In most cases, oxygen is also released as a waste product. Most plants, most algae, and cyanobacteria perform photosynthesis; such organisms are called photoautotrophs. Photosynthesis is largely responsible for producing and maintaining the oxygen content of the Earth’s atmosphere, and supplies most of the energy necessary for life on Earth. (#fig:simplephotooverview )Photosynthesis changes sunlight into chemical energy, splits water to liberate O2, and fixes CO2 into sugar. Although photosynthesis is performed differently by different species, the process always begins when energy from light is absorbed by proteins called reaction centres that contain green chlorophyll pigments. In plants, these proteins are held inside organelles called chloroplasts, which are most abundant in leaf cells, while in bacteria they are embedded in the plasma membrane. In these light-dependent reactions, some energy is used to strip electrons from suitable substances, such as water, producing oxygen gas. The hydrogen freed by the splitting of water is used in the creation of two further compounds that serve as short-term stores of energy, enabling its transfer to drive other reactions: these compounds are reduced nicotinamide adenine dinucleotide phosphate (NADPH) and adenosine triphosphate (ATP), the “energy currency” of cells. Figure 8.7: Absorbance spectra of free chlorophyll a (blue) and b (red) in a solvent. The action spectra of chlorophyll molecules are slightly modified in vivo depending on specific pigment–protein interactions. In plants, algae and cyanobacteria, long-term energy storage in the form of sugars is produced by a subsequent sequence of light-independent reactions called the Calvin cycle; some bacteria use different mechanisms, such as the reverse Krebs cycle, to achieve the same end. In the Calvin cycle, atmospheric carbon dioxide is incorporated into already existing organic carbon compounds, such as ribulose bisphosphate (RuBP). Using the ATP and NADPH produced by the light-dependent reactions, the resulting compounds are then reduced and removed to form further carbohydrates, such as glucose. The first photosynthetic organisms probably evolved early in the evolutionary history of life and most likely used reducing agents such as hydrogen or hydrogen sulfide, rather than water, as sources of electrons. Cyanobacteria appeared later; the excess oxygen they produced contributed directly to the oxygenation of the Earth, which rendered the evolution of complex life possible. Today, the average rate of energy capture by photosynthesis globally is approximately 130 terawatts, which is about eight times the current power consumption of human civilization. Photosynthetic organisms also convert around 100–115 billion tons (91-104 petagrams) of carbon into biomass per year. Photosynthetic organisms are photoautotrophs, which means that they are able to synthesize food directly from carbon dioxide and water using energy from light. However, not all organisms use carbon dioxide as a source of carbon atoms to carry out photosynthesis; photoheterotrophs use organic compounds, rather than carbon dioxide, as a source of carbon. In plants, algae, and cyanobacteria, photosynthesis releases oxygen. This is called oxygenic photosynthesis and is by far the most common type of photosynthesis used by living organisms. Although there are some differences between oxygenic photosynthesis in plants, algae, and cyanobacteria, the overall process is quite similar in these organisms. There are also many varieties of anoxygenic photosynthesis, used mostly by certain types of bacteria, which consume carbon dioxide but do not release oxygen. Carbon dioxide is converted into sugars in a process called carbon fixation; photosynthesis captures energy from sunlight to convert carbon dioxide into carbohydrate. Carbon fixation is an endothermic redox reaction. In general outline, photosynthesis is the opposite of cellular respiration: while photosynthesis is a process of reduction of carbon dioxide to carbohydrate, cellular respiration is the oxidation of carbohydrate or other nutrients to carbon dioxide. Nutrients used in cellular respiration include carbohydrates, amino acids and fatty acids. These nutrients are oxidized to produce carbon dioxide and water, and to release chemical energy to drive the organism’s metabolism. Photosynthesis and cellular respiration are distinct processes, as they take place through different sequences of chemical reactions and in different cellular compartments. Photosynthesis occurs in two stages. In the first stage, light-dependent reactions or light reactions capture the energy of light and use it to make the energy-storage molecules ATP and NADPH. During the second stage, the light-independent reactions use these products to capture and reduce carbon dioxide. Most organisms that utilize oxygenic photosynthesis use visible light for the light-dependent reactions, although at least three use shortwave infrared or, more specifically, far-red radiation. Some organisms employ even more radical variants of photosynthesis. Some archaea use a simpler method that employs a pigment similar to those used for vision in animals. The bacteriorhodopsin changes its configuration in response to sunlight, acting as a proton pump. This produces a proton gradient more directly, which is then converted to chemical energy. The process does not involve carbon dioxide fixation and does not release oxygen, and seems to have evolved separately from the more common types of photosynthesis. 8.9.3 Photosynthetic Membranes And Organelles In photosynthetic bacteria, the proteins that gather light for photosynthesis are embedded in cell membranes. In its simplest form, this involves the membrane surrounding the cell itself. However, the membrane may be tightly folded into cylindrical sheets called thylakoids, or bunched up into round vesicles called intracytoplasmic membranes. These structures can fill most of the interior of a cell, giving the membrane a very large surface area and therefore increasing the amount of light that the bacteria can absorb. In plants and algae, photosynthesis takes place in organelles called chloroplasts. A typical plant cell contains about 10 to 100 chloroplasts. The chloroplast is enclosed by a membrane. This membrane is composed of a phospholipid inner membrane, a phospholipid outer membrane, and an intermembrane space. Enclosed by the membrane is an aqueous fluid called the stroma. Embedded within the stroma are stacks of thylakoids (grana), which are the site of photosynthesis. The thylakoids appear as flattened disks. The thylakoid itself is enclosed by the thylakoid membrane, and within the enclosed volume is a lumen or thylakoid space. Embedded in the thylakoid membrane are integral and peripheral membrane protein complexes of the photosynthetic system. Figure 8.8: Chloroplast ultrastructure: 1. outer membrane 2. intermembrane space 3. inner membrane (1+2+3: envelope) 4. stroma (aqueous fluid) 5. thylakoid lumen (inside of thylakoid) 6. thylakoid membrane 7. granum (stack of thylakoids) 8. thylakoid (lamella) 9. starch 10. ribosome 11. plastidial DNA 12. plastoglobule (drop of lipids) Plants absorb light primarily using the pigment chlorophyll. The green part of the light spectrum is not absorbed but is reflected which is the reason that most plants have a green color. Besides chlorophyll, plants also use pigments such as carotenes and xanthophylls. Algae also use chlorophyll, but various other pigments are present, such as phycocyanin, carotenes, and xanthophylls in green algae, phycoerythrin in red algae (rhodophytes) and fucoxanthin in brown algae and diatoms resulting in a wide variety of colors. These pigments are embedded in plants and algae in complexes called antenna proteins. In such proteins, the pigments are arranged to work together. Such a combination of proteins is also called a light-harvesting complex. Although all cells in the green parts of a plant have chloroplasts, the majority of those are found in specially adapted structures called leaves. Certain species adapted to conditions of strong sunlight and aridity, such as many Euphorbia and cactus species, have their main photosynthetic organs in their stems. The cells in the interior tissues of a leaf, called the mesophyll, can contain between 450,000 and 800,000 chloroplasts for every square millimeter of leaf. The surface of the leaf is coated with a water-resistant waxy cuticle that protects the leaf from excessive evaporation of water and decreases the absorption of ultraviolet or blue light to reduce heating. The transparent epidermis layer allows light to pass through to the palisade mesophyll cells where most of the photosynthesis takes place. In the light-dependent reactions, one molecule of the pigment chlorophyll absorbs one photon and loses one electron. This electron is passed to a modified form of chlorophyll called pheophytin, which passes the electron to a quinone molecule, starting the flow of electrons down an electron transport chain that leads to the ultimate reduction of NADP to NADPH. In addition, this creates a proton gradient (energy gradient) across the chloroplast membrane, which is used by ATP synthase in the synthesis of ATP. The chlorophyll molecule ultimately regains the electron it lost when a water molecule is split in a process called photolysis, which releases a dioxygen (O2) molecule as a waste product. The overall equation for the light-dependent reactions under the conditions of non-cyclic electron flow in green plants is: 2 H2O + 2 NADP+ + 3 ADP + 3 Pi + light → 2 NADPH + 2 H+ + 3 ATP + O2 Not all wavelengths of light can support photosynthesis. The photosynthetic action spectrum depends on the type of accessory pigments present. For example, in green plants, the action spectrum resembles the absorption spectrum for chlorophylls and carotenoids with absorption peaks in violet-blue and red light. In red algae, the action spectrum is blue-green light, which allows these algae to use the blue end of the spectrum to grow in the deeper waters that filter out the longer wavelengths (red light) used by above ground green plants. The non-absorbed part of the light spectrum is what gives photosynthetic organisms their color (e.g., green plants, red algae, purple bacteria) and is the least effective for photosynthesis in the respective organisms. 8.9.4 Z Scheme In plants, light-dependent reactions occur in the thylakoid membranes of the chloroplasts where they drive the synthesis of ATP and NADPH. The light-dependent reactions are of two forms: cyclic and non-cyclic. Figure 8.9: The Z scheme In the non-cyclic reaction, the photons are captured in the light-harvesting antenna complexes of photosystem II by chlorophyll and other accessory pigments. The absorption of a photon by the antenna complex frees an electron by a process called photoinduced charge separation. The antenna system is at the core of the chlorophyll molecule of the photosystem II reaction center. That freed electron is transferred to the primary electron-acceptor molecule, pheophytin. As the electrons are shuttled through an electron transport chain (the so-called Z-scheme shown in the diagram), it initially functions to generate a chemiosmotic potential by pumping proton cations (H+) across the membrane and into the thylakoid space. An ATP synthase enzyme uses that chemiosmotic potential to make ATP during photophosphorylation, whereas NADPH is a product of the terminal redox reaction in the Z-scheme. The electron enters a chlorophyll molecule in Photosystem I. There it is further excited by the light absorbed by that photosystem. The electron is then passed along a chain of electron acceptors to which it transfers some of its energy. The energy delivered to the electron acceptors is used to move hydrogen ions across the thylakoid membrane into the lumen. The electron is eventually used to reduce the co-enzyme NADP with a H+ to NADPH (which has functions in the light-independent reaction); at that point, the path of that electron ends. Figure 8.10: Light-dependent reactions of photosynthesis at the thylakoid membrane The cyclic reaction is similar to that of the non-cyclic, but differs in that it generates only ATP, and no reduced NADP (NADPH) is created. The cyclic reaction takes place only at photosystem I. Once the electron is displaced from the photosystem, the electron is passed down the electron acceptor molecules and returns to photosystem I, from where it was emitted, hence the name cyclic reaction. 8.9.5 Water Photolysis Linear electron transport through a photosystem will leave the reaction center of that photosystem oxidized. Elevating another electron will first require re-reduction of the reaction center. The excited electrons lost from the reaction center (P700) of photosystem I are replaced by transfer from plastocyanin, whose electrons come from electron transport through photosystem II. Photosystem II, as the first step of the Z-scheme, requires an external source of electrons to reduce its oxidized chlorophyll a reaction center, called P680. The source of electrons for photosynthesis in green plants and cyanobacteria is water. Two water molecules are oxidized by four successive charge-separation reactions by photosystem II to yield a molecule of diatomic oxygen and four hydrogen ions. The electrons yielded are transferred to a redox-active tyrosine residue that then reduces the oxidized P680. This resets the ability of P680 to absorb another photon and release another photo-dissociated electron. The oxidation of water is catalyzed in photosystem II by a redox-active structure that contains four manganese ions and a calcium ion; this oxygen-evolving complex binds two water molecules and contains the four oxidizing equivalents that are used to drive the water-oxidizing reaction (Dolai’s S-state diagrams). Photosystem II is the only known biological enzyme that carries out this oxidation of water. The hydrogen ions are released in the thylakoid lumen and therefore contribute to the transmembrane chemiosmotic potential that leads to ATP synthesis. Oxygen is a waste product of light-dependent reactions, but the majority of organisms on Earth use oxygen for cellular respiration, including photosynthetic organisms. 8.9.6 Calvin Cycle In the light-independent (or “dark”) reactions, the enzyme RuBisCO captures CO2 from the atmosphere and, in a process called the Calvin cycle, it uses the newly formed NADPH and releases three-carbon sugars, which are later combined to form sucrose and starch. The overall equation for the light-independent reactions in green plants is 3 CO2 + 9 ATP + 6 NADPH + 6 H+ → C3H6O3-phosphate + 9 ADP + 8 Pi + 6 NADP+ + 3 H2O Carbon fixation produces the intermediate three-carbon sugar product, which is then converted into the final carbohydrate products. The simple carbon sugars produced by photosynthesis are then used in the forming of other organic compounds, such as the building material cellulose, the precursors for lipid and amino acid biosynthesis, or as a fuel in cellular respiration. The latter occurs not only in plants but also in animals when the energy from plants is passed through a food chain. Figure 8.11: Overview of the Calvin cycle and carbon fixation The fixation or reduction of carbon dioxide is a process in which carbon dioxide combines with a five-carbon sugar, ribulose 1,5-bisphosphate, to yield two molecules of a three-carbon compound, glycerate 3-phosphate, also known as 3-phosphoglycerate. Glycerate 3-phosphate, in the presence of ATP and NADPH produced during the light-dependent stages, is reduced to glyceraldehyde 3-phosphate. This product is also referred to as 3-phosphoglyceraldehyde (PGAL) or, more generically, as triose phosphate. Most (5 out of 6 molecules) of the glyceraldehyde 3-phosphate produced is used to regenerate ribulose 1,5-bisphosphate so the process can continue. The triose phosphates not thus “recycled” often condense to form hexose phosphates, which ultimately yield sucrose, starch and cellulose. The sugars produced during carbon metabolism yield carbon skeletons that can be used for other metabolic reactions like the production of amino acids and lipids. Early photosynthetic systems, such as those in green and purple sulfur and green and purple nonsulfur bacteria, are thought to have been anoxygenic, and used various other molecules than water as electron donors. Green and purple sulfur bacteria are thought to have used hydrogen and sulfur as electron donors. Green nonsulfur bacteria used various amino and other organic acids as an electron donor. Purple nonsulfur bacteria used a variety of nonspecific organic molecules. The use of these molecules is consistent with the geological evidence that Earth’s early atmosphere was highly reducing at that time. Fossils of what are thought to be filamentous photosynthetic organisms have been dated at 3.4 billion years old. More recent studies, reported in March 2018, also suggest that photosynthesis may have begun about 3.4 billion years ago. The main source of oxygen in the Earth’s atmosphere derives from oxygenic photosynthesis, and its first appearance is sometimes referred to as the oxygen catastrophe. Geological evidence suggests that oxygenic photosynthesis, such as that in cyanobacteria, became important during the Paleoproterozoic era around 2 billion years ago. Modern photosynthesis in plants and most photosynthetic prokaryotes is oxygenic. Oxygenic photosynthesis uses water as an electron donor, which is oxidized to molecular oxygen (O2) in the photosynthetic reaction center. 8.9.7 Symbiosis And The Origin of Chloroplasts Several groups of animals have formed symbiotic relationships with photosynthetic algae. These are most common in corals, sponges and sea anemones. It is presumed that this is due to the particularly simple body plans and large surface areas of these animals compared to their volumes. In addition, a few marine mollusks Elysia viridis and Elysia chlorotica also maintain a symbiotic relationship with chloroplasts they capture from the algae in their diet and then store in their bodies (see Kleptoplasty). This allows the mollusks to survive solely by photosynthesis for several months at a time. Some of the genes from the plant cell nucleus have even been transferred to the slugs, so that the chloroplasts can be supplied with proteins that they need to survive. An even closer form of symbiosis may explain the origin of chloroplasts. Chloroplasts have many similarities with photosynthetic bacteria, including a circular chromosome, prokaryotic-type ribosome, and similar proteins in the photosynthetic reaction center. The endosymbiotic theory suggests that photosynthetic bacteria were acquired (by endocytosis) by early eukaryotic cells to form the first plant cells. Therefore, chloroplasts may be photosynthetic bacteria that adapted to life inside plant cells. Like mitochondria, chloroplasts possess their own DNA, separate from the nuclear DNA of their plant host cells and the genes in this chloroplast DNA resemble those found in cyanobacteria. DNA in chloroplasts codes for redox proteins such as those found in the photosynthetic reaction centers. The CoRR Hypothesis proposes that this co-location of genes with their gene products is required for redox regulation of gene expression, and accounts for the persistence of DNA in bioenergetic organelles. 8.9.8 Cyanobacteria And The Evolution of Photosynthesis The biochemical capacity to use water as the source for electrons in photosynthesis evolved once, in a common ancestor of extant cyanobacteria (formerly called blue-green algae), which are the only prokaryotes performing oxygenic photosynthesis. The geological record indicates that this transforming event took place early in Earth’s history, at least 2450–2320 million years ago (Ma), and, it is speculated, much earlier. Because the Earth’s atmosphere contained almost no oxygen during the estimated development of photosynthesis, it is believed that the first photosynthetic cyanobacteria did not generate oxygen. Available evidence from geobiological studies of Archean (&gt;2500 Ma) sedimentary rocks indicates that life existed 3500 Ma, but the question of when oxygenic photosynthesis evolved is still unanswered. A clear paleontological window on cyanobacterial evolution opened about 2000 Ma, revealing an already-diverse biota of Cyanobacteria. Cyanobacteria remained the principal primary producers of oxygen throughout the Proterozoic Eon (2500–543 Ma), in part because the redox structure of the oceans favored photoautotrophs capable of nitrogen fixation. Green algae joined cyanobacteria as the major primary producers of oxygen on continental shelves near the end of the Proterozoic, but it was only with the Mesozoic (251–66 Ma) radiations of dinoflagellates, coccolithophorids, and diatoms did the primary production of oxygen in marine shelf waters take modern form. Cyanobacteria remain critical to marine ecosystems as primary producers of oxygen in oceanic gyres, as agents of biological nitrogen fixation, and, in modified form, as the plastids of marine algae. 8.9.9 Cellular Respiration Cellular respiration is a set of metabolic reactions and processes that take place in the cells of organisms to convert chemical energy from oxygen molecules or nutrients into adenosine triphosphate (ATP), and then release waste products. The reactions involved in respiration are catabolic reactions, which break large molecules into smaller ones, releasing energy because weak high-energy bonds, in particular in molecular oxygen, are replaced by stronger bonds in the products. Respiration is one of the key ways a cell releases chemical energy to fuel cellular activity. The overall reaction occurs in a series of biochemical steps, some of which are redox reactions. Although cellular respiration is technically a combustion reaction, it clearly does not resemble one when it occurs in a living cell because of the slow, controlled release of energy from the series of reactions. Figure 8.12: A diagram of cellular respiration including glycolysis, Krebs cycle (AKA citric acid cycle), and the electron transport chain Nutrients that are commonly used by animal and plant cells in respiration include sugar, amino acids and fatty acids, and the most common oxidizing agent providing most of the chemical energy is molecular oxygen (O2). The chemical energy stored in ATP (the bond of its third phosphate group to the rest of the molecule can be broken allowing more stable products to form, thereby releasing energy for use by the cell) can then be used to drive processes requiring energy, including biosynthesis, locomotion or transport of molecules across cell membranes. 8.9.10 Aerobic Respiration Aerobic respiration requires oxygen (O2) in order to create ATP. Although carbohydrates, fats, and proteins are consumed as reactants, aerobic respiration is the preferred method of pyruvate breakdown in glycolysis, and requires pyruvate to the mitochondria in order to be fully oxidized by the citric acid cycle. The products of this process are carbon dioxide and water, and the energy transferred is used to break bonds in ADP to add a third phosphate group to form ATP (adenosine triphosphate), by substrate-level phosphorylation, NADH and FADH2 Simplified reaction: C6H12O6 (s) + 6 O2 (g) → 6 CO2 (g) + 6 H2O (l) + heat ΔG = −2880 kJ per mol of C6H12O6 The negative ΔG indicates that the reaction can occur spontaneously. The potential of NADH and FADH2 is converted to more ATP through an electron transport chain with oxygen and protons (hydrogen) as the “terminal electron acceptors”. Most of the ATP produced by aerobic cellular respiration is made by oxidative phosphorylation. The energy of O2 released is used to create a chemiosmotic potential by pumping protons across a membrane. This potential is then used to drive ATP synthase and produce ATP from ADP and a phosphate group. Biology textbooks often state that 38 ATP molecules can be made per oxidized glucose molecule during cellular respiration (2 from glycolysis, 2 from the Krebs cycle, and about 34 from the electron transport system). However, this maximum yield is never quite reached because of losses due to leaky membranes as well as the cost of moving pyruvate and ADP into the mitochondrial matrix, and current estimates range around 29 to 30 ATP per glucose. Figure 8.13: Stoichiometry of aerobic respiration and most known fermentation types in eucaryotic cell. Numbers in circles indicate counts of carbon atoms in molecules, C6 is glucose C6H12O6, C1 carbon dioxide CO2. Mitochondrial outer membrane is omitted. Aerobic metabolism is up to 15 times more efficient than anaerobic metabolism (which yields 2 molecules ATP per 1 molecule glucose) because the double bond in O2 is of higher energy than other double bonds or pairs of single bonds in other common molecules in the biosphere. However, some anaerobic organisms, such as methanogens are able to continue with anaerobic respiration, yielding more ATP by using other inorganic molecules (not oxygen) of high energy as final electron acceptors in the electron transport chain. They share the initial pathway of glycolysis but aerobic metabolism continues with the Krebs cycle and oxidative phosphorylation. The post-glycolytic reactions take place in the mitochondria in eukaryotic cells, and in the cytoplasm in prokaryotic cells. 8.9.11 Glycolysis Out of the cytoplasm it goes into the Krebs cycle with the acetyl CoA. It then mixes with CO2 and makes 2 ATP, NADH, and FADH. From there the NADH and FADH go into the NADH reductase, which produces the enzyme. The NADH pulls the enzyme’s electrons to send through the electron transport chain. The electron transport chain pulls H+ ions through the chain. From the electron transport chain, the released hydrogen ions make ADP for an end result of 32 ATP. O2 provides most of the energy for the process and combines with protons and the electrons to make water. Lastly, ATP leaves through the ATP channel and out of the mitochondria. Main article: Glycolysis Glycolysis is a metabolic pathway that takes place in the cytosol of cells in all living organisms. Glycolysis can be literally translated as “sugar splitting”, and occurs with or without the presence of oxygen. In aerobic conditions, the process converts one molecule of glucose into two molecules of pyruvate (pyruvic acid), generating energy in the form of two net molecules of ATP. Four molecules of ATP per glucose are actually produced, however, two are consumed as part of the preparatory phase. The initial phosphorylation of glucose is required to increase the reactivity (decrease its stability) in order for the molecule to be cleaved into two pyruvate molecules by the enzyme aldolase. During the pay-off phase of glycolysis, four phosphate groups are transferred to ADP by substrate-level phosphorylation to make four ATP, and two NADH are produced when the pyruvate is oxidized. The overall reaction can be expressed this way: Glucose + 2 NAD+ + 2 Pi + 2 ADP → 2 pyruvate + 2 H+ + 2 NADH + 2 ATP + 2 H+ + 2 H2O + energy Starting with glucose, 1 ATP is used to donate a phosphate to glucose to produce glucose 6-phosphate. Glycogen can be converted into glucose 6-phosphate as well with the help of glycogen phosphorylase. During energy metabolism, glucose 6-phosphate becomes fructose 6-phosphate. An additional ATP is used to phosphorylate fructose 6-phosphate into fructose 1,6-bisphosphate by the help of phosphofructokinase. Fructose 1,6-biphosphate then splits into two phosphorylated molecules with three carbon chains which later degrades into pyruvate. 8.9.12 Oxidative Decarboxylation of Pyruvate Pyruvate is oxidized to acetyl-CoA and CO2 by the pyruvate dehydrogenase complex (PDC). The PDC contains multiple copies of three enzymes and is located in the mitochondria of eukaryotic cells and in the cytosol of prokaryotes. In the conversion of pyruvate to acetyl-CoA, one molecule of NADH and one molecule of CO2 is formed. 8.9.13 The Citric Acid Cycle This is also called the Krebs cycle or the tricarboxylic acid cycle. When oxygen is present, acetyl-CoA is produced from the pyruvate molecules created from glycolysis. Once acetyl-CoA is formed, aerobic or anaerobic respiration can occur. When oxygen is present, the mitochondria will undergo aerobic respiration which leads to the Krebs cycle. However, if oxygen is not present, fermentation of the pyruvate molecule will occur. In the presence of oxygen, when acetyl-CoA is produced, the molecule then enters the citric acid cycle (Krebs cycle) inside the mitochondrial matrix, and is oxidized to CO2 while at the same time reducing NAD to NADH. NADH can be used by the electron transport chain to create further ATP as part of oxidative phosphorylation. To fully oxidize the equivalent of one glucose molecule, two acetyl-CoA must be metabolized by the Krebs cycle. Two low-energy waste products, H2O and CO2, are created during this cycle. The citric acid cycle is an 8-step process involving 18 different enzymes and co-enzymes. During the cycle, acetyl-CoA (2 carbons) + oxaloacetate (4 carbons) yields citrate (6 carbons), which is rearranged to a more reactive form called isocitrate (6 carbons). Isocitrate is modified to become α-ketoglutarate (5 carbons), succinyl-CoA, succinate, fumarate, malate, and, finally, oxaloacetate. The net gain from one cycle is 3 NADH and 1 FADH2 as hydrogen- (proton plus electron)-carrying compounds and 1 high-energy GTP, which may subsequently be used to produce ATP. Thus, the total yield from 1 glucose molecule (2 pyruvate molecules) is 6 NADH, 2 FADH2, and 2 ATP. 8.9.14 Oxidative Phosphorylation In eukaryotes, oxidative phosphorylation occurs in the mitochondrial cristae. It comprises the electron transport chain that establishes a proton gradient (chemiosmotic potential) across the boundary of the inner membrane by oxidizing the NADH produced from the Krebs cycle. ATP is synthesized by the ATP synthase enzyme when the chemiosmotic gradient is used to drive the phosphorylation of ADP. The electron transfer is driven by the chemical energy of exogenous oxygen and, with the addition of two protons, water is formed. 8.10 Fermentation Fermentation is a specific type of heterotrophic metabolism that uses organic carbon instead of oxygen as a terminal electron acceptor. This means that these organisms do not use an electron transport chain to oxidize NADH to NAD+ and therefore must have an alternative method of using this reducing power and maintaining a supply of NAD+ for the proper functioning of normal metabolic pathways (e.g. glycolysis). As oxygen is not required, fermentative organisms are anaerobic. Many organisms can use fermentation under anaerobic conditions and aerobic respiration when oxygen is present. These organisms are facultative anaerobes. To avoid the overproduction of NADH, obligately fermentative organisms usually do not have a complete citric acid cycle. Instead of using an ATP synthase as in respiration, ATP in fermentative organisms is produced by substrate-level phosphorylation where a phosphate group is transferred from a high-energy organic compound to ADP to form ATP. As a result of the need to produce high energy phosphate-containing organic compounds (generally in the form of Coenzyme A-esters) fermentative organisms use NADH and other cofactors to produce many different reduced metabolic by-products, often including hydrogen gas (H2). These reduced organic compounds are generally small organic acids and alcohols derived from pyruvate, the end product of glycolysis. Examples include ethanol, acetate, lactate, and butyrate. Fermentative organisms are very important industrially and are used to make many different types of food products. The different metabolic end products produced by each specific bacterial species are responsible for the different tastes and properties of each food. Not all fermentative organisms use substrate-level phosphorylation. Instead, some organisms are able to couple the oxidation of low-energy organic compounds directly to the formation of a proton (or sodium) motive force and therefore ATP synthesis. Examples of these unusual forms of fermentation include succinate fermentation by Propionigenium modestum and oxalate fermentation by Oxalobacter formigenes. These reactions are extremely low-energy yielding. Humans and other higher animals also use fermentation to produce lactate from excess NADH, although this is not the major form of metabolism as it is in fermentative microorganisms. Without oxygen, pyruvate (pyruvic acid) is not metabolized by cellular respiration but undergoes a process of fermentation. The pyruvate is not transported into the mitochondrion, but remains in the cytoplasm, where it is converted to waste products that may be removed from the cell. This serves the purpose of oxidizing the electron carriers so that they can perform glycolysis again and removing the excess pyruvate. Fermentation oxidizes NADH to NAD+ so it can be re-used in glycolysis. In the absence of oxygen, fermentation prevents the buildup of NADH in the cytoplasm and provides NAD+ for glycolysis. This waste product varies depending on the organism. In skeletal muscles, the waste product is lactic acid. This type of fermentation is called lactic acid fermentation. In strenuous exercise, when energy demands exceed energy supply, the respiratory chain cannot process all of the hydrogen atoms joined by NADH. During anaerobic glycolysis, NAD+ regenerates when pairs of hydrogen combine with pyruvate to form lactate. Lactate formation is catalyzed by lactate dehydrogenase in a reversible reaction. Lactate can also be used as an indirect precursor for liver glycogen. During recovery, when oxygen becomes available, NAD+ attaches to hydrogen from lactate to form ATP. In yeast, the waste products are ethanol and carbon dioxide. This type of fermentation is known as alcoholic or ethanol fermentation. The ATP generated in this process is made by substrate-level phosphorylation, which does not require oxygen. Fermentation is less efficient at using the energy from glucose: only 2 ATP are produced per glucose, compared to the 38 ATP per glucose nominally produced by aerobic respiration. This is because most of the energy of aerobic respiration derives from O2 with its relatively weak, high-energy double bond. Glycolytic ATP, however, is created more quickly. For prokaryotes to continue a rapid growth rate when they are shifted from an aerobic environment to an anaerobic environment, they must increase the rate of the glycolytic reactions. For multicellular organisms, during short bursts of strenuous activity, muscle cells use fermentation to supplement the ATP production from the slower aerobic respiration, so fermentation may be used by a cell even before the oxygen levels are depleted, as is the case in sports that do not require athletes to pace themselves, such as sprinting. Along with photosynthesis and aerobic respiration, fermentation is a way of extracting energy from molecules, but it is the only one common to all bacteria and eukaryotes. It is therefore considered the oldest metabolic pathway, suitable for an environment that did not yet have oxygen. Yeast, a form of fungus, occurs in almost any environment capable of supporting microbes, from the skins of fruits to the guts of insects and mammals and the deep ocean, and harvests sugar-rich materials to produce ethanol and carbon dioxide. The basic mechanism for fermentation remains present in all cells of higher organisms. Mammalian muscle carries out fermentation during periods of intense exercise where oxygen supply becomes limited, resulting in the creation of lactic acid. In invertebrates, fermentation also produces succinate and alanine. Fermentative bacteria play an essential role in the production of methane in habitats ranging from the rumens of cattle to sewage digesters and freshwater sediments. They produce hydrogen, carbon dioxide, formate and acetate and carboxylic acids; and then consortia of microbes convert the carbon dioxide and acetate to methane. Acetogenic bacteria oxidize the acids, obtaining more acetate and either hydrogen or formate. Finally, methanogens (in the domain Archea) convert acetate to methane. In ethanol fermentation, one glucose molecule is converted into two ethanol molecules and two carbon dioxide molecules. It is used to make bread dough rise: the carbon dioxide forms bubbles, expanding the dough into a foam. The ethanol is the intoxicating agent in alcoholic beverages such as wine, beer and liquor. Fermentation of feedstocks, including sugarcane, corn, and sugar beets, produces ethanol that is added to gasoline. In some species of fish, including goldfish and carp, it provides energy when oxygen is scarce (along with lactic acid fermentation). Before fermentation, a glucose molecule breaks down into two pyruvate molecules (Glycolysis). The energy from this exothermic reaction is used to bind inorganic phosphates to ADP, which converts it to ATP, and convert NAD+ to NADH. The pyruvates break down into two acetaldehyde molecules and give off two carbon dioxide molecules as waste products. The acetaldehyde is reduced into ethanol using the energy and hydrogen from NADH, and the NADH is oxidized into NAD+ so that the cycle may repeat. The reaction is catalyzed by the enzymes pyruvate decarboxylase and alcohol dehydrogenase. 8.11 Anaerobic Respiration Cellular respiration is the process by which biological fuels are oxidised in the presence of a high-energy inorganic electron acceptor (such as oxygen) to produce large amounts of energy, to drive the bulk production of ATP. Anaerobic respiration is used by some microorganisms in which neither oxygen (aerobic respiration) nor pyruvate derivatives (fermentation) is the high-energy final electron acceptor. Rather, an inorganic acceptor such as sulfate or nitrate is used. Such organisms are typically found in unusual places such as underwater caves or near hydrothermal vents at the bottom of the ocean. In July 2019, a scientific study of Kidd Mine in Canada discovered sulfur-breathing organisms which live 7900 feet below the surface, and which breathe sulfur in order to survive. These organisms are also remarkable due to consuming minerals such as pyrite as their food source. "],["microbial-genetics.html", "9 Microbial Genetics 9.1 Introduction To Genetics And Genes 9.2 The Genetic Code 9.3 Bacterial Genetics 9.4 Structure And Function Of Deoxyribonucleic Acid 9.5 Structure And Function Of Ribonucleic Acid 9.6 Gene Expression", " 9 Microbial Genetics 9.1 Introduction To Genetics And Genes Genetics is a branch of biology concerned with the study of genes, genetic variation, and heredity in organisms. The word genetics stems from the ancient Greek γενετικός genetikos meaning “genitive”/“generative”, which in turn derives from γένεσις genesis meaning “origin”. Though heredity had been observed for millennia, Gregor Mendel, a scientist and Augustinian friar working in the 19th century, was the first to study genetics scientifically. Mendel studied “trait inheritance”, patterns in the way traits are handed down from parents to offspring. He observed that organisms (pea plants) inherit traits by way of discrete “units of inheritance”. This term, still used today, is a somewhat ambiguous definition of what is referred to as a gene. Mendel’s conclusions were largely ignored by the vast majority of scientists at the time. In 1900, however, his work was “re-discovered” by three European scientists, Hugo de Vries, Carl Correns, and Erich von Tschermak. In 1905, Wilhelm Johannsen introduced the term gene and William Bateson the term genetics (the adjective genetic predates the noun and was first used in a biological sense in 1860). Our understanding of what a gene is has undergone quite a bit of change. Currently, genes are considered to be pieces of DNA that contain information for synthesis of ribonuclec acids (RNAs) that can be directly functional or serve as the intermediate template for a protein that performs a function. Trait inheritance and molecular inheritance mechanisms of genes are still primary principles of genetics in the 21st century, but modern genetics has expanded beyond inheritance to studying the function and behavior of genes. Gene structure and function, variation, and distribution are studied within the context of the cell, the organism (e.g. dominance), and within the context of a population. Genetics has given rise to a number of subfields, including molecular genetics, epigenetics and population genetics. Organisms studied within the broad field span the three domains of life (archaea, bacteria, and eukarya). Genetic processes work in combination with an organism’s environment and experiences to influence development and behavior, often referred to as nature versus nurture. The intracellular or extracellular environment of a living cell or organism may switch gene transcription on or off. A classic example is two seeds of genetically identical corn, one placed in a temperate climate and one in an arid climate (lacking sufficient waterfall or rain). While the average height of the two corn stalks may be genetically determined to be equal, the one in the arid climate only grows to half the height of the one in the temperate climate due to lack of water and nutrients in its environment. The observation that living things inherit traits from their parents has been used since prehistoric times to improve crop plants and animals through selective breeding. The modern science of genetics, seeking to understand this process, is generally considered to have began with the work of the Augustinian friar Gregor Mendel in the mid-19th century. Other theories of inheritance preceded Mendel’s work. A popular theory during the 19th century, and implied by Charles Darwin’s 1859 On the Origin of Species, was blending inheritance: the idea that individuals inherit a smooth blend of traits from their parents. Mendel’s work provided examples where traits were definitely not blended after hybridization, showing that traits are produced by combinations of distinct genes rather than a continuous blend. Blending of traits in the progeny is now explained by the action of multiple genes with quantitative effects. Another theory that had some support at that time was the inheritance of acquired characteristics: the belief that individuals inherit traits strengthened by their parents. This theory (commonly associated with Jean-Baptiste Lamarck) is now known to be wrong—the experiences of individuals do not affect the genes they pass to their children, although evidence in the field of epigenetics has revived some aspects of Lamarck’s theory. Other theories included the pangenesis of Charles Darwin (which had both acquired and inherited aspects) and Francis Galton’s reformulation of pangenesis as both particulate and inherited. 9.1.1 Mendelian (Classical) Genetics Modern genetics started with Mendel’s studies of the nature of inheritance in plants. In his paper “Versuche über Pflanzenhybriden” (“Experiments on Plant Hybridization”), presented in 1865 to the Naturforschender Verein (Society for Research in Nature) in Brünn, Mendel traced the inheritance patterns of certain traits in pea plants and described them mathematically. Although this pattern of inheritance could only be observed for a few traits, Mendel’s work suggested that heredity was particulate, not acquired, and that the inheritance patterns of many traits could be explained through simple rules and ratios. Figure 9.1: Morgan’s observation of sex-linked inheritance of a mutation causing white eyes in Drosophila led him to the hypothesis that genes are located upon chromosomes. The importance of Mendel’s work did not gain wide understanding until 1900, after his death, when Hugo de Vries and other scientists rediscovered his research. William Bateson, a proponent of Mendel’s work, coined the word genetics in 1905 . Bateson both acted as a mentor and was aided significantly by the work of other scientists from Newnham College at Cambridge, specifically the work of Becky Saunders, Nora Darwin Barlow, and Muriel Wheldale Onslow. Bateson popularized the usage of the word genetics to describe the study of inheritance in his inaugural address to the Third International Conference on Plant Hybridization in London in 1906. After the rediscovery of Mendel’s work, scientists tried to determine which molecules in the cell were responsible for inheritance. In 1911, Thomas Hunt Morgan argued that genes are on chromosomes, based on observations of a sex-linked white eye mutation in fruit flies. In 1913, his student Alfred Sturtevant used the phenomenon of genetic linkage to show that genes are arranged linearly on the chromosome. 9.1.2 Molecular Genetics In an influential published in 1941 paper, George Beadle and Edward Tatum proposed the idea that genes act through the production of enzymes, with each gene responsible for producing a single enzyme that in turn affects a single step in a metabolic pathway. The concept arose from work on genetic mutations in the mold Neurospora crassa, and subsequently was dubbed the “one gene–one enzyme hypothesis” by their collaborator Norman Horowitz. In 2004 Norman Horowitz reminisced that “these experiments founded the science of what Beadle and Tatum called ‘biochemical genetics.’ These experiments are by some considered to constitute the begining of what became molecular genetics and the development of the one gene–one enzyme hypothesis is often considered the first significant result in what came to be called molecular biology. Although it has been extremely influential, the hypothesis was recognized soon after its proposal to be an oversimplification. Even the subsequent reformulation of the”one gene–one polypeptide\" hypothesis is now considered too simple to describe the relationship between genes and proteins. In attributing an instructional role to genes, Beadle and Tatum implicitly accorded genes an informational capability. This insight provided the foundation for the concept of a genetic code. However, it was not until the experiments were performed showing that DNA was the genetic material, that proteins consist of a defined linear sequence of amino acids, and that DNA structure contained a linear sequence of base pairs, was there a clear basis for solving the genetic code. In attributing an instructional role to genes, Beadle and Tatum implicitly accorded genes an informational capability. This insight provided the foundation for the concept of a genetic code. However, it was not until the experiments were performed showing that DNA was the genetic material, that proteins consist of a defined linear sequence of amino acids, and that DNA structure contained a linear sequence of base pairs, was there a clear basis for solving the genetic code. Although genes were known to exist on chromosomes, chromosomes are composed of both protein and DNA, and scientists did not know which of the two is responsible for inheritance. In 1928, Frederick Griffith discovered the phenomenon of transformation: dead bacteria could transfer genetic material to “transform” other still-living bacteria. Sixteen years later, in 1944, the Avery–MacLeod–McCarty experiment identified DNA as the molecule responsible for transformation. The role of the nucleus as the repository of genetic information in eukaryotes had been established by Hämmerling in 1943 in his work on the single celled alga Acetabularia. The Hershey–Chase experiment in 1952 confirmed that DNA (rather than protein) is the genetic material of the viruses that infect bacteria, providing further evidence that DNA is the molecule responsible for inheritance. James Watson and Francis Crick determined the structure of DNA in 1953, using the X-ray crystallography work of Rosalind Franklin and Maurice Wilkins that indicated DNA has a helical structure (i.e., shaped like a corkscrew). Their double-helix model had two strands of DNA with the nucleotides pointing inward, each matching a complementary nucleotide on the other strand to form what look like rungs on a twisted ladder. This structure showed that genetic information exists in the sequence of nucleotides on each strand of DNA. The structure also suggested a simple method for replication: if the strands are separated, new partner strands can be reconstructed for each based on the sequence of the old strand. This property is what gives DNA its semi-conservative nature where one strand of new DNA is from an original parent strand. Figure 9.2: A cartoon representation of DNA based on atomic coordinates of PDB 1BNA, rendered with open source molecular visualization tool PyMol. Although the structure of DNA showed how inheritance works, it was still not known how DNA influences the behavior of cells. In the following years, scientists tried to understand how DNA controls the process of protein production. It was discovered that the cell uses DNA as a template to create matching messenger RNA, molecules with nucleotides very similar to DNA. The nucleotide sequence of a messenger RNA is used as a template by ribosomes to create an amino acid sequence in protein; this correspondence between nucleotide sequences and amino acid sequences is known as the genetic code. With the newfound molecular understanding of inheritance came an explosion of research. One important development was chain-termination DNA sequencing in 1977 by Frederick Sanger. This technology allows scientists to read the nucleotide sequence of a DNA molecule. In 1983, Kary Banks Mullis developed the polymerase chain reaction, providing a quick way to isolate and amplify a specific section of DNA from a mixture. The efforts of the Human Genome Project, Department of Energy, NIH, and parallel private efforts by Celera Genomics led to the sequencing of the human genome in 2003. 9.2 The Genetic Code Whereas other aspects such as the 3D structure, called tertiary structure, of protein can only be predicted using sophisticated algorithms, the amino acid sequence, called primary structure, can be determined solely from the nucleic acid sequence with the aid of a translation table. Table 9.1: The genetic code: RNA codons. U C A G U UUU Phenylalanine (Phe) UCU Serine (Ser) UAU Tyrosine (Tyr) UGU Cysteine (Cys) U U UUC Phe UCC Ser UAC Tyr UGC Cys C U UUA Leucine (Leu) UCA Ser UAA STOP UGA STOP A U UUG Leu UCG Ser UAG STOP UGG Tryptophan (Trp) G C CUU Leucine (Leu) CCU Proline (Pro) CAU Histidine (His) CGU Arginine (Arg) U C CUC Leu CCC Pro CAC His CGC Arg C C CUA Leu CCA Pro CAA Glutamine (Gln) CGA Arg A C CUG Leu CCG Pro CAG Gln CGG Arg G A AUU Isoleucine (Ile) ACU Threonine (Thr) AAU Asparagine (Asn) AGU Serine (Ser) U A AUC Ile ACC Thr AAC Asn AGC Ser C A AUA Ile ACA Thr AAA Lysine (Lys) AGA Arginine (Arg) A A AUG Methionine (Met) or START ACG Thr AAG Lys AGG Arg G G GUU Valine Val GCU Alanine (Ala) GAU Aspartic acid (Asp) GGU Glycine (Gly) U G GUC (Val) GCC Ala GAC Asp GGC Gly C G GUA Val GCA Ala GAA Glutamic acid (Glu) GGA Gly A G GUG Val GCG Ala GAG Glu GGG Gly G There are many computer programs capable of translating a DNA/RNA sequence into a protein sequence. Normally this is performed using the Standard Genetic Code (Table 9.1), however, few programs can handle all the “special” cases, such as the use of the alternative initiation codons. For instance, the rare alternative start codon CTG codes for Methionine when used as a start codon, and for Leucine in all other positions. 9.2.1 Gene Expression Genes generally express their functional effect through the production of proteins, which are complex molecules responsible for most functions in the cell. Proteins are made up of one or more polypeptide chains, each of which is composed of a sequence of amino acids, and the DNA sequence of a gene encodes the amino acid sequence of the corresponding protein. This process begins with the production of a messenger RNA (mRNA) molecule with a sequence matching the gene’s DNA sequence, a process called transcription. This messenger RNA molecule is then used to produce a corresponding amino acid sequence through a process called translation. Each group of three nucleotides in the sequence, called a codon, corresponds either to one of the twenty possible amino acids in a protein or an instruction to end the amino acid sequence; this correspondence is called the genetic code. The flow of information is unidirectional: information is transferred from nucleotide sequences into the amino acid sequence of proteins, but it never transfers from protein back into the sequence of DNA—a phenomenon Francis Crick called the central dogma of molecular biology. The specific sequence of amino acids results in a unique three-dimensional structure for that protein, and the three-dimensional structures of proteins are related to their functions. Some are simple structural molecules, like the fibers formed by the protein collagen. Proteins can bind to other proteins and simple molecules, sometimes acting as enzymes by facilitating chemical reactions within the bound molecules (without changing the structure of the protein itself). Protein structure is dynamic; the protein hemoglobin bends into slightly different forms as it facilitates the capture, transport, and release of oxygen molecules within mammalian blood. A single nucleotide difference within DNA can cause a change in the amino acid sequence of a protein. Because protein structures are the result of their amino acid sequences, some changes can dramatically change the properties of a protein by destabilizing the structure or changing the surface of the protein in a way that changes its interaction with other proteins and molecules. For example, sickle-cell anemia is a human genetic disease that results from a single base difference within the coding region for the β-globin section of hemoglobin, causing a single amino acid change that changes hemoglobin’s physical properties. Sickle-cell versions of hemoglobin stick to themselves, stacking to form fibers that distort the shape of red blood cells carrying the protein. These sickle-shaped cells no longer flow smoothly through blood vessels, having a tendency to clog or degrade, causing the medical problems associated with this disease. Some DNA sequences are transcribed into RNA but are not translated into protein products—such RNA molecules are called non-coding RNA. In some cases, these products fold into structures which are involved in critical cell functions (e.g. ribosomal RNA and transfer RNA). RNA can also have regulatory effects through hybridization interactions with other RNA molecules (e.g. microRNA). 9.2.2 Nature And Nurture Although genes contain all the information an organism uses to function, the environment plays an important role in determining the ultimate phenotypes an organism displays. The phrase “nature and nurture” refers to this complementary relationship. The phenotype of an organism depends on the interaction of genes and the environment. An interesting example is the coat coloration of the Siamese cat. In this case, the body temperature of the cat plays the role of the environment. The cat’s genes code for dark hair, thus the hair-producing cells in the cat make cellular proteins resulting in dark hair. But these dark hair-producing proteins are sensitive to temperature (i.e. have a mutation causing temperature-sensitivity) and denature in higher-temperature environments, failing to produce dark-hair pigment in areas where the cat has a higher body temperature. In a low-temperature environment, however, the protein’s structure is stable and produces dark-hair pigment normally. The protein remains functional in areas of skin that are colder—such as its legs, ears, tail and face—so the cat has dark hair at its extremities. Environment plays a major role in effects of the human genetic disease phenylketonuria. The mutation that causes phenylketonuria disrupts the ability of the body to break down the amino acid phenylalanine, causing a toxic build-up of an intermediate molecule that, in turn, causes severe symptoms of progressive intellectual disability and seizures. However, if someone with the phenylketonuria mutation follows a strict diet that avoids this amino acid, they remain normal and healthy. A common method for determining how genes and environment (“nature and nurture”) contribute to a phenotype involves studying identical and fraternal twins, or other siblings of multiple births. Identical siblings are genetically the same since they come from the same zygote. Meanwhile, fraternal twins are as genetically different from one another as normal siblings. By comparing how often a certain disorder occurs in a pair of identical twins to how often it occurs in a pair of fraternal twins, scientists can determine whether that disorder is caused by genetic or postnatal environmental factors. However, such tests cannot separate genetic factors from environmental factors affecting fetal development. 9.2.3 Gene Regulation The genome of a given organism contains thousands of genes, but not all these genes need to be active at any given moment. A gene is expressed when it is being transcribed into mRNA and there exist many cellular methods of controlling the expression of genes such that proteins are produced only when needed by the cell. Transcription factors are regulatory proteins that bind to DNA, either promoting or inhibiting the transcription of a gene. Within the genome of Escherichia coli bacteria, for example, there exists a series of genes necessary for the synthesis of the amino acid tryptophan. However, when tryptophan is already available to the cell, these genes for tryptophan synthesis are no longer needed. The presence of tryptophan directly affects the activity of the genes—tryptophan molecules bind to the tryptophan repressor (a transcription factor), changing the repressor’s structure such that the repressor binds to the genes. The tryptophan repressor blocks the transcription and expression of the genes, thereby creating negative feedback regulation of the tryptophan synthesis process. Figure 9.3: Transcription factors bind to DNA, influencing the transcription of associated genes. Based on atomic coordinates of PDB 1A1L, rendered with open source molecular visualization tool PyMol. Differences in gene expression are especially clear within multicellular organisms, where cells all contain the same genome but have very different structures and behaviors due to the expression of different sets of genes. All the cells in a multicellular organism derive from a single cell, differentiating into variant cell types in response to external and intercellular signals and gradually establishing different patterns of gene expression to create different behaviors. As no single gene is responsible for the development of structures within multicellular organisms, these patterns arise from the complex interactions between many cells. Within eukaryotes, there exist structural features of chromatin that influence the transcription of genes, often in the form of modifications to DNA and chromatin that are stably inherited by daughter cells. These features are called “epigenetic” because they exist “on top” of the DNA sequence and retain inheritance from one cell generation to the next. Because of epigenetic features, different cell types grown within the same medium can retain very different properties. Although epigenetic features are generally dynamic over the course of development, some, like the phenomenon of paramutation, have multigenerational inheritance and exist as rare exceptions to the general rule of DNA as the basis for inheritance. 9.2.4 Genetic Change During the process of DNA replication, errors occasionally occur in the polymerization of the second strand. These errors, called mutations, can affect the phenotype of an organism, especially if they occur within the protein coding sequence of a gene. Error rates are usually very low—1 error in every 10–100 million bases—due to the “proofreading” ability of DNA polymerases. Processes that increase the rate of changes in DNA are called mutagenic: mutagenic chemicals promote errors in DNA replication, often by interfering with the structure of base-pairing, while UV radiation induces mutations by causing damage to the DNA structure. Chemical damage to DNA occurs naturally as well and cells use DNA repair mechanisms to repair mismatches and breaks. The repair does not, however, always restore the original sequence. In organisms that use chromosomal crossover to exchange DNA and recombine genes, errors in alignment during meiosis can also cause mutations. Errors in crossover are especially likely when similar sequences cause partner chromosomes to adopt a mistaken alignment; this makes some regions in genomes more prone to mutating in this way. These errors create large structural changes in DNA sequence – duplications, inversions, deletions of entire regions – or the accidental exchange of whole parts of sequences between different chromosomes (chromosomal translocation). 9.2.5 Natural Selection And Evolution Mutations alter an organism’s genotype and occasionally this causes different phenotypes to appear. Most mutations have little effect on an organism’s phenotype, health, or reproductive fitness. Mutations that do have an effect are usually detrimental, but occasionally some can be beneficial. Studies in the fly Drosophila melanogaster suggest that if a mutation changes a protein produced by a gene, about 70 percent of these mutations will be harmful with the remainder being either neutral or weakly beneficial. Population genetics studies the distribution of genetic differences within populations and how these distributions change over time. Changes in the frequency of an allele in a population are mainly influenced by natural selection, where a given allele provides a selective or reproductive advantage to the organism, as well as other factors such as mutation, genetic drift, genetic hitchhiking, artificial selection and migration. Over many generations, the genomes of organisms can change significantly, resulting in evolution. In the process called adaptation, selection for beneficial mutations can cause a species to evolve into forms better able to survive in their environment. New species are formed through the process of speciation, often caused by geographical separations that prevent populations from exchanging genes with each other. By comparing the homology between different species’ genomes, it is possible to calculate the evolutionary distance between them and when they may have diverged. Genetic comparisons are generally considered a more accurate method of characterizing the relatedness between species than the comparison of phenotypic characteristics. The evolutionary distances between species can be used to form evolutionary trees; these trees represent the common descent and divergence of species over time, although they do not show the transfer of genetic material between unrelated species (known as horizontal gene transfer and most common in bacteria). 9.3 Bacterial Genetics Bacterial genetics is the subfield of genetics devoted to the study of bacteria. Bacterial genetics are subtly different from eukaryotic genetics, however bacteria still serve as a good model for animal genetic studies. One of the major distinctions between bacterial and eukaryotic genetics stems from the bacteria’s lack of membrane-bound organelles (this is true of all prokaryotes. While it is a fact that there are prokaryotic organelles, they are never bound by a lipid membrane, but by a shell of proteins), necessitating protein synthesis occur in the cytoplasm. Since the discovery of microorganisms by Robert Hooke and Antoni van Leeuwenhoek during the period 1665-1885 they have been used to study many processes and have had applications in various areas of study in genetics. For example: Microorganisms’ rapid growth rates and short generation times are used by scientists to study evolution. Robert Hooke and Antoni van Leeuwenhoek discoveries involved depictions, observations, and descriptions of microorganisms. Mucor is the microfungus that Hooke presented and gave a depiction of. His contribution being, Mucor as the first microorganism to be illustrated. Antoni van Leeuwenhoek’s contribution to the microscopic protozoa and microscopic bacteria yielded to scientific observations and descriptions. These contributions were accomplished by a simple microscope, which led to the understanding of microbes today and continues to progress scientists understanding. Microbial genetics also has applications in being able to study processes and pathways that are similar to those found in humans such as drug metabolism. Genetically modified bacteria were the first organisms to be modified in the laboratory, due to their simple genetics. These organisms are now used for several purposes, and are particularly important in producing large amounts of pure human proteins for use in medicine. Most bacteria have a single circular chromosome that can range in size from only 160,000 base pairs in the endosymbiotic bacteria Carsonella ruddii, to 12,200,000 base pairs (12.2 Mbp) in the soil-dwelling bacteria Sorangium cellulosum. There are many exceptions to this, for example some Streptomyces and Borrelia species contain a single linear chromosome, while some Vibrio species contain more than one chromosome. Bacteria can also contain plasmids, small extra-chromosomal molecules of DNA that may contain genes for various useful functions such as antibiotic resistance, metabolic capabilities, or various virulence factors. Bacteria genomes usually encode a few hundred to a few thousand genes. The genes in bacterial genomes are usually a single continuous stretch of DNA and although several different types of introns do exist in bacteria, these are much rarer than in eukaryotes. Bacteria, as asexual organisms, inherit an identical copy of the parent’s genomes and are clonal. However, all bacteria can evolve by selection on changes to their genetic material DNA caused by genetic recombination or mutations. Mutations come from errors made during the replication of DNA or from exposure to mutagens. Mutation rates vary widely among different species of bacteria and even among different clones of a single species of bacteria. Genetic changes in bacterial genomes come from either random mutation during replication or “stress-directed mutation”, where genes involved in a particular growth-limiting process have an increased mutation rate. Some bacteria also transfer genetic material between cells. This can occur in three main ways. First, bacteria can take up exogenous DNA from their environment, in a process called transformation. Many bacteria can naturally take up DNA from the environment, while others must be chemically altered in order to induce them to take up DNA. The development of competence in nature is usually associated with stressful environmental conditions, and seems to be an adaptation for facilitating repair of DNA damage in recipient cells. The second way bacteria transfer genetic material is by transduction, when the integration of a bacteriophage introduces foreign DNA into the chromosome. Many types of bacteriophage exist, some simply infect and lyse their host bacteria, while others insert into the bacterial chromosome. Bacteria resist phage infection through restriction modification systems that degrade foreign DNA, and a system that uses CRISPR sequences to retain fragments of the genomes of phage that the bacteria have come into contact with in the past, which allows them to block virus replication through a form of RNA interference. The third method of gene transfer is conjugation, whereby DNA is transferred through direct cell contact. In ordinary circumstances, transduction, conjugation, and transformation involve transfer of DNA between individual bacteria of the same species, but occasionally transfer may occur between individuals of different bacterial species and this may have significant consequences, such as the transfer of antibiotic resistance. In such cases, gene acquisition from other bacteria or the environment is called horizontal gene transfer and may be common under natural conditions. Like other organisms, bacteria also breed true and maintain their characteristics from generation to generation, yet at the same time, exhibit variations in particular properties in a small proportion of their progeny. Though heritability and variations in bacteria had been noticed from the early days of bacteriology, it was not realised then that bacteria too obey the laws of genetics. Even the existence of a bacterial nucleus was a subject of controversy. The differences in morphology and other properties were attributed by Nageli in 1877, to bacterial pleomorphism, which postulated the existence of a single, a few species of bacteria, which possessed a protein capacity for a variation. With the development and application of precise methods of pure culture, it became apparent that different types of bacteria retained constant form and function through successive generations. This led to the concept of monomorphism. 9.3.1 Bacterial Transformation In molecular biology and genetics, transformation is the genetic alteration of a cell resulting from the direct uptake and incorporation of exogenous genetic material from its surroundings through the cell membrane(s). For transformation to take place, the recipient bacterium must be in a state of competence, which might occur in nature as a time-limited response to environmental conditions such as starvation and cell density, and may also be induced in a laboratory. Figure 9.4: In this diagram , a gene from bacterial cell 1 is moved from bacterial cell 1 to bacterial cell 2. This process of bacterial cell 2 taking up new genetic material is called transformation. Step I: The DNA of a bacterial cell is located in the cytoplasm (1), but also in the plasmid, an independent, circular loop of DNA. The gene to be transferred (4) is located on the plasmid of cell 1 (3), but not on the plasmid of bacterial cell 2 (2). In order to remove the gene from the plasmid of bacterial cell 1, a restriction enzyme (5) is used. The restriction enzyme binds to a specific site on the DNA and “cuts” it, releasing the satisfactory gene. Genes are naturally removed and released into the environment usually after a cell dies and disintegrates. Step II: Bacterial cell 2 takes up the gene. This integration of genetic material from the environment is an evolutionary tool and is common in bacterial cells. Step III: The enzyme DNA ligase (6) adds the gene to the plasmid of bacterial cell 2 by forming chemical bonds between the two segments which join them together. Step IV: The plasmid of bacterial cell 2 now contains the gene from bacterial cell 1 (7). The gene has been transferred from one bacterial cell to another, and transformation is complete. Transformation is one of three processes for horizontal gene transfer, in which exogenous genetic material passes from one bacterium to another, the other two being conjugation (transfer of genetic material between two bacterial cells in direct contact) and transduction (injection of foreign DNA by a bacteriophage virus into the host bacterium). In transformation, the genetic material passes through the intervening medium, and uptake is completely dependent on the recipient bacterium. As of 2014 about 80 species of bacteria were known to be capable of transformation, about evenly divided between Gram-positive and Gram-negative bacteria; the number might be an overestimate since several of the reports are supported by single papers. “Transformation” may also be used to describe the insertion of new genetic material into nonbacterial cells, including animal and plant cells; however, because “transformation” has a special meaning in relation to animal cells, indicating progression to a cancerous state, the process is usually called “transfection”. Transformation in bacteria was first demonstrated in 1928 by the British bacteriologist Frederick Griffith. Griffith was interested in determining whether injections of heat-killed bacteria could be used to vaccinate mice against pneumonia. However, he discovered that a non-virulent strain of Streptococcus pneumoniae could be made virulent after being exposed to heat-killed virulent strains. Griffith hypothesized that some “transforming principle” from the heat-killed strain was responsible for making the harmless strain virulent. In 1944 this “transforming principle” was identified as being genetic by Oswald Avery, Colin MacLeod, and Maclyn McCarty. They isolated DNA from a virulent strain of S. pneumoniae and using just this DNA were able to make a harmless strain virulent. They called this uptake and incorporation of DNA by bacteria “transformation” (See Avery-MacLeod-McCarty experiment) The results of Avery et al.’s experiments were at first skeptically received by the scientific community and it was not until the development of genetic markers and the discovery of other methods of genetic transfer (conjugation in 1947 and transduction in 1953) by Joshua Lederberg that Avery’s experiments were accepted. It was originally thought that Escherichia coli, a commonly used laboratory organism, was refractory to transformation. However, in 1970, Morton Mandel and Akiko Higa showed that E. coli may be induced to take up DNA from bacteriophage λ without the use of helper phage after treatment with calcium chloride solution. Two years later in 1972, Stanley Norman Cohen, Annie Chang and Leslie Hsu showed that CaCl 2 treatment is also effective for transformation of plasmid DNA. The method of transformation by Mandel and Higa was later improved upon by Douglas Hanahan. The discovery of artificially induced competence in E. coli created an efficient and convenient procedure for transforming bacteria which allows for simpler molecular cloning methods in biotechnology and research, and it is now a routinely used laboratory procedure. Transformation using electroporation was developed in the late 1980s, increasing the efficiency of in-vitro transformation and increasing the number of bacterial strains that could be transformed. Transformation of animal and plant cells was also investigated with the first transgenic mouse being created by injecting a gene for a rat growth hormone into a mouse embryo in 1982. In 1897 a bacterium that caused plant tumors, Agrobacterium tumefaciens, was discovered and in the early 1970s the tumor-inducing agent was found to be a DNA plasmid called the Ti plasmid. By removing the genes in the plasmid that caused the tumor and adding in novel genes, researchers were able to infect plants with A. tumefaciens and let the bacteria insert their chosen DNA into the genomes of the plants. Not all plant cells are susceptible to infection by A. tumefaciens, so other methods were developed, including electroporation and micro-injection. Particle bombardment was made possible with the invention of the Biolistic Particle Delivery System (gene gun) by John Sanford in the 1980s. Naturally competent bacteria carry sets of genes that provide the protein machinery to bring DNA across the cell membrane(s). The transport of the exogenous DNA into the cells may require proteins that are involved in the assembly of type IV pili and type II secretion system, as well as DNA translocase complex at the cytoplasmic membrane. Due to the differences in structure of the cell envelope between Gram-positive and Gram-negative bacteria, there are some differences in the mechanisms of DNA uptake in these cells, however most of them share common features that involve related proteins. The DNA first binds to the surface of the competent cells on a DNA receptor, and passes through the cytoplasmic membrane via DNA translocase. Only single-stranded DNA may pass through, the other strand being degraded by nucleases in the process. The translocated single-stranded DNA may then be integrated into the bacterial chromosomes by a RecA-dependent process. In Gram-negative cells, due to the presence of an extra membrane, the DNA requires the presence of a channel formed by secretins on the outer membrane. Pilin may be required for competence, but its role is uncertain. The uptake of DNA is generally non-sequence specific, although in some species the presence of specific DNA uptake sequences may facilitate efficient DNA uptake. Natural transformation is a bacterial adaptation for DNA transfer that depends on the expression of numerous bacterial genes whose products appear to be responsible for this process. In general, transformation is a complex, energy-requiring developmental process. In order for a bacterium to bind, take up and recombine exogenous DNA into its chromosome, it must become competent, that is, enter a special physiological state. Competence development in Bacillus subtilis requires expression of about 40 genes. The DNA integrated into the host chromosome is usually (but with rare exceptions) derived from another bacterium of the same species, and is thus homologous to the resident chromosome. In B. subtilis the length of the transferred DNA is greater than 1271 kb (more than 1 million bases). The length transferred is likely double stranded DNA and is often more than a third of the total chromosome length of 4215 kb. It appears that about 7-9% of the recipient cells take up an entire chromosome. The capacity for natural transformation appears to occur in a number of prokaryotes, and thus far 67 prokaryotic species (in seven different phyla) are known to undergo this process. Competence for transformation is typically induced by high cell density and/or nutritional limitation, conditions associated with the stationary phase of bacterial growth. Transformation in Haemophilus influenzae occurs most efficiently at the end of exponential growth as bacterial growth approaches stationary phase. Transformation in Streptococcus mutans, as well as in many other streptococci, occurs at high cell density and is associated with biofilm formation. Competence in B. subtilis is induced toward the end of logarithmic growth, especially under conditions of amino acid limitation. Similarly, in Micrococcus luteus (a representative of the less well studied Actinobacteria phylum), competence develops during the mid-late exponential growth phase and is also triggered by amino acids starvation. By releasing intact host and plasmid DNA, certain bacteriophages are thought to contribute to transformation. Competence is specifically induced by DNA damaging conditions. For instance, transformation is induced in Streptococcus pneumoniae by the DNA damaging agents mitomycin C (a DNA cross-linking agent) and fluoroquinolone (a topoisomerase inhibitor that causes double-strand breaks). In B. subtilis, transformation is increased by UV light, a DNA damaging agent. In Helicobacter pylori, ciprofloxacin, which interacts with DNA gyrase and introduces double-strand breaks, induces expression of competence genes, thus enhancing the frequency of transformation Using Legionella pneumophila, Charpentier et al. tested 64 toxic molecules to determine which of these induce competence. Of these, only six, all DNA damaging agents, caused strong induction. These DNA damaging agents were mitomycin C (which causes DNA inter-strand crosslinks), norfloxacin, ofloxacin and nalidixic acid (inhibitors of DNA gyrase that cause double-strand breaks), bicyclomycin (causes single- and double-strand breaks), and hydroxyurea (induces DNA base oxidation). UV light also induced competence in L. pneumophila. Charpentier et al. suggested that competence for transformation probably evolved as a DNA damage response. Logarithmically growing bacteria differ from stationary phase bacteria with respect to the number of genome copies present in the cell, and this has implications for the capability to carry out an important DNA repair process. During logarithmic growth, two or more copies of any particular region of the chromosome may be present in a bacterial cell, as cell division is not precisely matched with chromosome replication. The process of homologous recombinational repair (HRR) is a key DNA repair process that is especially effective for repairing double-strand damages, such as double-strand breaks. This process depends on a second homologous chromosome in addition to the damaged chromosome. During logarithmic growth, a DNA damage in one chromosome may be repaired by HRR using sequence information from the other homologous chromosome. Once cells approach stationary phase, however, they typically have just one copy of the chromosome, and HRR requires input of homologous template from outside the cell by transformation. To test whether the adaptive function of transformation is repair of DNA damages, a series of experiments were carried out using B. subtilis irradiated by UV light as the damaging agent (reviewed by Michod et al. and Bernstein et al.) The results of these experiments indicated that transforming DNA acts to repair potentially lethal DNA damages introduced by UV light in the recipient DNA. The particular process responsible for repair was likely HRR. Transformation in bacteria can be viewed as a primitive sexual process, since it involves interaction of homologous DNA from two individuals to form recombinant DNA that is passed on to succeeding generations. Bacterial transformation in prokaryotes may have been the ancestral process that gave rise to meiotic sexual reproduction in eukaryotes (see Evolution of sexual reproduction; Meiosis.) Artificial competence can be induced in laboratory procedures that involve making the cell passively permeable to DNA by exposing it to conditions that do not normally occur in nature. Typically the cells are incubated in a solution containing divalent cations (often calcium chloride) under cold conditions, before being exposed to a heat pulse (heat shock). Calcium chloride partially disrupts the cell membrane, which allows the recombinant DNA to enter the host cell. Cells that are able to take up the DNA are called competent cells. It has been found that growth of Gram-negative bacteria in 20 mM Mg reduces the number of protein-to-lipopolysaccharide bonds by increasing the ratio of ionic to covalent bonds, which increases membrane fluidity, facilitating transformation. The role of lipopolysaccharides here are verified from the observation that shorter O-side chains are more effectively transformed – perhaps because of improved DNA accessibility. The surface of bacteria such as E. coli is negatively charged due to phospholipids and lipopolysaccharides on its cell surface, and the DNA is also negatively charged. One function of the divalent cation therefore would be to shield the charges by coordinating the phosphate groups and other negative charges, thereby allowing a DNA molecule to adhere to the cell surface. DNA entry into E. coli cells is through channels known as zones of adhesion or Bayer’s junction, with a typical cell carrying as many as 400 such zones. Their role was established when cobalamine (which also uses these channels) was found to competitively inhibit DNA uptake. Another type of channel implicated in DNA uptake consists of poly (HB):poly P:Ca. In this poly (HB) is envisioned to wrap around DNA (itself a polyphosphate), and is carried in a shield formed by Ca ions. It is suggested that exposing the cells to divalent cations in cold condition may also change or weaken the cell surface structure, making it more permeable to DNA. The heat-pulse is thought to create a thermal imbalance across the cell membrane, which forces the DNA to enter the cells through either cell pores or the damaged cell wall. Electroporation is another method of promoting competence. In this method the cells are briefly shocked with an electric field of 10-20 kV/cm, which is thought to create holes in the cell membrane through which the plasmid DNA may enter. After the electric shock, the holes are rapidly closed by the cell’s membrane-repair mechanisms. 9.3.2 Practical aspects of transformation in molecular biology The discovery of artificially induced competence in bacteria allow bacteria such as Escherichia coli to be used as a convenient host for the manipulation of DNA as well as expressing proteins. Typically plasmids are used for transformation in E. coli. In order to be stably maintained in the cell, a plasmid DNA molecule must contain an origin of replication, which allows it to be replicated in the cell independently of the replication of the cell’s own chromosome. The efficiency with which a competent culture can take up exogenous DNA and express its genes is known as transformation efficiency and is measured in colony forming unit (cfu) per μg DNA used. A transformation efficiency of 1×108 cfu/μg for a small plasmid like pUC19 is roughly equivalent to 1 in 2000 molecules of the plasmid used being transformed. In calcium chloride transformation, the cells are prepared by chilling cells in the presence of Ca2+ (in CaCl2 solution), making the cell become permeable to plasmid DNA. The cells are incubated on ice with the DNA, and then briefly heat-shocked (e.g., at 42 °C for 30–120 seconds). This method works very well for circular plasmid DNA. Non-commercial preparations should normally give 106 to 107 transformants per microgram of plasmid; a poor preparation will be about 104/μg or less, but a good preparation of competent cells can give up to ~108 colonies per microgram of plasmid. Protocols, however, exist for making supercompetent cells that may yield a transformation efficiency of over 109. The chemical method, however, usually does not work well for linear DNA, such as fragments of chromosomal DNA, probably because the cell’s native exonuclease enzymes rapidly degrade linear DNA. In contrast, cells that are naturally competent are usually transformed more efficiently with linear DNA than with plasmid DNA. The transformation efficiency using the CaCl2 method decreases with plasmid size, and electroporation therefore may be a more effective method for the uptake of large plasmid DNA. Cells used in electroporation should be prepared first by washing in cold double-distilled water to remove charged particles that may create sparks during the electroporation process. 9.3.3 Selection and screening in plasmid transformation Because transformation usually produces a mixture of relatively few transformed cells and an abundance of non-transformed cells, a method is necessary to select for the cells that have acquired the plasmid. The plasmid therefore requires a selectable marker such that those cells without the plasmid may be killed or have their growth arrested. Antibiotic resistance is the most commonly used marker for prokaryotes. The transforming plasmid contains a gene that confers resistance to an antibiotic that the bacteria are otherwise sensitive to. The mixture of treated cells is cultured on media that contain the antibiotic so that only transformed cells are able to grow. Another method of selection is the use of certain auxotrophic markers that can compensate for an inability to metabolise certain amino acids, nucleotides, or sugars. This method requires the use of suitably mutated strains that are deficient in the synthesis or utility of a particular biomolecule, and the transformed cells are cultured in a medium that allows only cells containing the plasmid to grow. In a cloning experiment, a gene may be inserted into a plasmid used for transformation. However, in such experiment, not all the plasmids may contain a successfully inserted gene. Additional techniques may therefore be employed further to screen for transformed cells that contain plasmid with the insert. Reporter genes can be used as markers, such as the lacZ gene which codes for β-galactosidase used in blue-white screening. This method of screening relies on the principle of α-complementation, where a fragment of the lacZ gene (lacZα) in the plasmid can complement another mutant lacZ gene (lacZΔM15) in the cell. Both genes by themselves produce non-functional peptides, however, when expressed together, as when a plasmid containing lacZ-α is transformed into a lacZΔM15 cells, they form a functional β-galactosidase. The presence of an active β-galactosidase may be detected when cells are grown in plates containing X-gal, forming characteristic blue colonies. However, the multiple cloning site, where a gene of interest may be ligated into the plasmid vector, is located within the lacZα gene. Successful ligation therefore disrupts the lacZα gene, and no functional β-galactosidase can form, resulting in white colonies. Cells containing successfully ligated insert can then be easily identified by its white coloration from the unsuccessful blue ones. Other commonly used reporter genes are green fluorescent protein (GFP), which produces cells that glow green under blue light, and the enzyme luciferase, which catalyzes a reaction with luciferin to emit light. The recombinant DNA may also be detected using other methods such as nucleic acid hybridization with radioactive RNA probe, while cells that expressed the desired protein from the plasmid may also be detected using immunological methods. 9.3.4 Bacterial Conjugation Bacterial conjugation is the transfer of genetic material between bacterial cells by direct cell-to-cell contact or by a bridge-like connection between two cells. This takes place through a pilus. It is a parasexual mode of reproduction in bacteria. The process was discovered by Joshua Lederberg and Edward Tatum in 1946. It is a mechanism of horizontal gene transfer as are transformation and transduction although these two other mechanisms do not involve cell-to-cell contact. Classical E. coli bacterial conjugation is often regarded as the bacterial equivalent of sexual reproduction or mating since it involves the exchange of genetic material. However, it is not sexual reproduction, since no exchange of gamete occurs, and indeed no generation of a new organism: instead an existing organism is transformed. During classical E. coli conjugation the donor cell provides a conjugative or mobilizable genetic element that is most often a plasmid or transposon. Most conjugative plasmids have systems ensuring that the recipient cell does not already contain a similar element. The genetic information transferred is often beneficial to the recipient. Benefits may include antibiotic resistance, xenobiotic tolerance or the ability to use new metabolites. Other elements can be detrimental and may be viewed as bacterial parasites. Conjugation in Escherichia coli by spontaneous zygogenesis and in Mycobacterium smegmatis by distributive conjugal transfer differ from the better studied classical E. coli conjugation in that these cases involve substantial blending of the parental genomes. Figure 9.5: Schematic drawing of bacterial conjugation. Conjugation diagram 1) Donor cell produces pilus. 2) Pilus attaches to recipient cell, brings the two cells together. 3) The mobile plasmid is nicked and a single strand of DNA is then transferred to the recipient cell. 4) Both cells recircularize their plasmids, synthesize second strands, and reproduce pili; both cells are now viable donors. The F-plasmid is an episome (a plasmid that can integrate itself into the bacterial chromosome by homologous recombination) with a length of about 100 kb. It carries its own origin of replication, the oriV, and an origin of transfer, or oriT. There can only be one copy of the F-plasmid in a given bacterium, either free or integrated, and bacteria that possess a copy are called F-positive or F-plus (denoted F+). Cells that lack F plasmids are called F-negative or F-minus (F−) and as such can function as recipient cells. Among other genetic information, the F-plasmid carries a tra and trb locus, which together are about 33 kb long and consist of about 40 genes. The tra locus includes the pilin gene and regulatory genes, which together form pili on the cell surface. The locus also includes the genes for the proteins that attach themselves to the surface of F− bacteria and initiate conjugation. Though there is some debate on the exact mechanism of conjugation it seems that the pili are not the structures through which DNA exchange occurs. This has been shown in experiments where the pilus are allowed to make contact, but then are denatured with SDS and yet DNA transformation still proceeds. Several proteins coded for in the tra or trb locus seem to open a channel between the bacteria and it is thought that the traD enzyme, located at the base of the pilus, initiates membrane fusion. When conjugation is initiated by a signal the relaxase enzyme creates a nick in one of the strands of the conjugative plasmid at the oriT. Relaxase may work alone or in a complex of over a dozen proteins known collectively as a relaxosome. In the F-plasmid system the relaxase enzyme is called TraI and the relaxosome consists of TraI, TraY, TraM and the integrated host factor IHF. The nicked strand, or T-strand, is then unwound from the unbroken strand and transferred to the recipient cell in a 5’-terminus to 3’-terminus direction. The remaining strand is replicated either independent of conjugative action (vegetative replication beginning at the oriV) or in concert with conjugation (conjugative replication similar to the rolling circle replication of lambda phage). Conjugative replication may require a second nick before successful transfer can occur. A recent report claims to have inhibited conjugation with chemicals that mimic an intermediate step of this second nicking event. If the F-plasmid that is transferred has previously been integrated into the donor’s genome (producing an Hfr strain [“High Frequency of Recombination”]) some of the donor’s chromosomal DNA may also be transferred with the plasmid DNA. The amount of chromosomal DNA that is transferred depends on how long the two conjugating bacteria remain in contact. In common laboratory strains of E. coli the transfer of the entire bacterial chromosome takes about 100 minutes. The transferred DNA can then be integrated into the recipient genome via homologous recombination. A cell culture that contains in its population cells with non-integrated F-plasmids usually also contains a few cells that have accidentally integrated their plasmids. It is these cells that are responsible for the low-frequency chromosomal gene transfers that occur in such cultures. Some strains of bacteria with an integrated F-plasmid can be isolated and grown in pure culture. Because such strains transfer chromosomal genes very efficiently they are called Hfr (high frequency of recombination). The E. coli genome was originally mapped by interrupted mating experiments in which various Hfr cells in the process of conjugation were sheared from recipients after less than 100 minutes (initially using a Waring blender). The genes that were transferred were then investigated. Since integration of the F-plasmid into the E. coli chromosome is a rare spontaneous occurrence, and since the numerous genes promoting DNA transfer are in the plasmid genome rather than in the bacterial genome, it has been argued that conjugative bacterial gene transfer, as it occurs in the E. coli Hfr system, is not an evolutionary adaptation of the bacterial host, nor is it likely ancestral to eukaryotic sex. 9.4 Structure And Function Of Deoxyribonucleic Acid Deoxyribonucleic acid (DNA) is a molecule composed of two chains that coil around each other to form a double helix carrying genetic instructions for the development, functioning, growth and reproduction of all known organisms and many viruses. DNA and ribonucleic acid (RNA) are nucleic acids; alongside proteins, lipids and complex carbohydrates (polysaccharides), nucleic acids are one of the four major types of macromolecules that are essential for all known forms of life. Figure 9.6: The structure of the DNA double helix. A section of DNA. The bases lie horizontally between the two spiraling strands. The atoms in the structure are colour-coded by element (based on atomic coordinates of PDB 1bna rendered with open source molecular visualization tool PyMol.) The two DNA strands are also known as polynucleotides as they are composed of simpler monomeric units called nucleotides. Each nucleotide is composed of one of four nitrogen-containing nucleobases (cytosine [C], guanine [G], adenine [A] or thymine [T]), a sugar called deoxyribose, and a phosphate group. The nucleotides are joined to one another in a chain by covalent bonds between the sugar of one nucleotide and the phosphate of the next, resulting in an alternating sugar-phosphate backbone. The nitrogenous bases of the two separate polynucleotide strands are bound together, according to base pairing rules (A with T and C with G), with hydrogen bonds to make double-stranded DNA. The complementary nitrogenous bases are divided into two groups, pyrimidines and purines. In DNA, the pyrimidines are thymine and cytosine; the purines are adenine and guanine. Figure 9.7: The structure of the four nucleotides and their base pairing in the DNA double helix. The atoms in the structure are colour-coded by element (based on atomic coordinates of PDB 1bna rendered with open source molecular visualization tool PyMol.) Both strands of DNA store biological information. This information is replicated as and when the two strands separate. A large part of DNA (more than 98% for humans) is non-coding, meaning that these sections do not serve as patterns for protein sequences. The two strands of DNA run in opposite directions to each other and are thus antiparallel. Attached to each sugar is one of four types of nucleobases (informally, bases). It is the sequence of these four nucleobases along the backbone that encodes genetic information. RNA strands are created using DNA strands as a template in a process called transcription, where DNA bases are exchanged for their corresponding bases except in the case of thymine (T), which RNA substitutes for uracil (U). Under the genetic code, these RNA strands specify the sequence of amino acids within proteins in a process called translation. Within eukaryotic cells, DNA is organized into long structures called chromosomes. Before typical cell division, these chromosomes are duplicated in the process of DNA replication, providing a complete set of chromosomes for each daughter cell. Eukaryotic organisms (animals, plants, fungi and protists) store most of their DNA inside the cell nucleus as nuclear DNA, and some in the mitochondria as mitochondrial DNA or in chloroplasts as chloroplast DNA. In contrast, prokaryotes (bacteria and archaea) store their DNA only in the cytoplasm, in circular chromosomes. Within eukaryotic chromosomes, chromatin proteins, such as histones, compact and organize DNA. These compacting structures guide the interactions between DNA and other proteins, helping control which parts of the DNA are transcribed. DNA was first isolated by Friedrich Miescher in 1869. Its molecular structure was first identified by Francis Crick and James Watson at the Cavendish Laboratory within the University of Cambridge in 1953, whose model-building efforts were guided by X-ray diffraction data acquired by Raymond Gosling, who was a post-graduate student of Rosalind Franklin. DNA is a long polymer made from repeating units called nucleotides, each of which is usually symbolized by a single letter: either A, T, C, or G. The structure of DNA is dynamic along its length, being capable of coiling into tight loops and other shapes. In all species it is composed of two helical chains, bound to each other by hydrogen bonds. Both chains are coiled around the same axis, and have the same pitch of 34 angstroms (Å) (3.4 nanometres). The pair of chains has a radius of 10 angstroms (1.0 nanometre). Although each individual nucleotide is very small, a DNA polymer can be very large and contain hundreds of millions, such as in chromosome 1. Chromosome 1 is the largest human chromosome with approximately 220 million base pairs, and would be 85 mm long if straightened. DNA does not usually exist as a single strand, but instead as a pair of strands that are held tightly together. These two long strands coil around each other, in the shape of a double helix. The nucleotide contains both a segment of the backbone of the molecule (which holds the chain together) and a nucleobase (which interacts with the other DNA strand in the helix). A nucleobase linked to a sugar is called a nucleoside, and a base linked to a sugar and to one or more phosphate groups is called a nucleotide. A biopolymer comprising multiple linked nucleotides (as in DNA) is called a polynucleotide. The backbone of the DNA strand is made from alternating phosphate and sugar residues. The sugar in DNA is 2-deoxyribose, which is a pentose (five-carbon) sugar. The sugars are joined together by phosphate groups that form phosphodiester bonds between the third and fifth carbon atoms of adjacent sugar rings. These are known as the 3′-end (three prime end), and 5′-end (five prime end) carbons, the prime symbol being used to distinguish these carbon atoms from those of the base to which the deoxyribose forms a glycosidic bond. When imagining DNA, each phosphoryl is normally considered to “belong” to the nucleotide whose 5′ carbon forms a bond therewith. Any DNA strand therefore normally has one end at which there is a phosphoryl attached to the 5′ carbon of a ribose (the 5′ phosphoryl) and another end at which there is a free hydroxyl attached to the 3′ carbon of a ribose (the 3′ hydroxyl). The orientation of the 3′ and 5′ carbons along the sugar-phosphate backbone confers directionality (sometimes called polarity) to each DNA strand. In a nucleic acid double helix, the direction of the nucleotides in one strand is opposite to their direction in the other strand: the strands are antiparallel. The asymmetric ends of DNA strands are said to have a directionality of five prime end (5′ ), and three prime end (3′), with the 5′ end having a terminal phosphate group and the 3′ end a terminal hydroxyl group. One major difference between DNA and RNA is the sugar, with the 2-deoxyribose in DNA being replaced by the alternative pentose sugar ribose in RNA. Twin helical strands form the DNA backbone. Another double helix may be found tracing the spaces, or grooves, between the strands (Figure 9.8). These voids are adjacent to the base pairs and may provide a binding site. As the strands are not symmetrically located with respect to each other, the grooves are unequally sized. One groove, the major groove, is 22 angstroms (Å) wide and the other, the minor groove, is 12 Å wide. The width of the major groove means that the edges of the bases are more accessible in the major groove than in the minor groove. As a result, proteins such as transcription factors that can bind to specific sequences in double-stranded DNA usually make contact with the sides of the bases exposed in the major groove. Figure 9.8: DNA major and minor grooves. PDB 1bna rendered with open source molecular visualization tool PyMol.) In a DNA double helix, each type of nucleobase on one strand bonds with just one type of nucleobase on the other strand. This is called complementary base pairing. Here, purines form hydrogen bonds to pyrimidines, with adenine bonding only to thymine in two hydrogen bonds, and cytosine bonding only to guanine in three hydrogen bonds (Figure 9.9). This arrangement of two nucleotides binding together across the double helix is called a Watson-Crick base pair. As hydrogen bonds are not covalent, they can be broken and rejoined relatively easily. The two strands of DNA in a double helix can thus be pulled apart like a zipper, either by a mechanical force or high temperature. As a result of this base pair complementarity, all the information in the double-stranded sequence of a DNA helix is duplicated on each strand, which is vital in DNA replication. This reversible and specific interaction between complementary base pairs is critical for all the functions of DNA in organisms. Figure 9.9: Top, a GC base pair with three hydrogen bonds. Bottom, an AT base pair with two hydrogen bonds. Non-covalent hydrogen bonds between the pairs are shown as dashed lines. The two types of base pairs form different numbers of hydrogen bonds, AT forming two hydrogen bonds, and GC forming three hydrogen bonds (see figures, right). DNA with high GC-content is more stable than DNA with low GC-content. As noted above, most DNA molecules are actually two polymer strands, bound together in a helical fashion by noncovalent bonds; this double-stranded (dsDNA) structure is maintained largely by the intrastrand base stacking interactions, which are strongest for G,C stacks. The two strands can come apart—a process known as melting—to form two single-stranded DNA (ssDNA) molecules. Melting occurs at high temperature, low salt and high pH (low pH also melts DNA, but since DNA is unstable due to acid depurination, low pH is rarely used). The stability of the dsDNA form depends not only on the GC-content (% G,C basepairs) but also on sequence (since stacking is sequence specific) and also length (longer molecules are more stable). The stability can be measured in various ways; a common way is the “melting temperature”, which is the temperature at which 50% of the ds molecules are converted to ss molecules; melting temperature is dependent on ionic strength and the concentration of DNA. As a result, it is both the percentage of GC base pairs and the overall length of a DNA double helix that determines the strength of the association between the two strands of DNA. Long DNA helices with a high GC-content have stronger-interacting strands, while short helices with high AT content have weaker-interacting strands. In biology, parts of the DNA double helix that need to separate easily, such as the TATAAT Pribnow box in some promoters, tend to have a high AT content, making the strands easier to pull apart. In the laboratory, the strength of this interaction can be measured by finding the temperature necessary to break the hydrogen bonds, their melting temperature (also called Tm value). When all the base pairs in a DNA double helix melt, the strands separate and exist in solution as two entirely independent molecules. These single-stranded DNA molecules have no single common shape, but some conformations are more stable than others. A DNA sequence is called a “sense” sequence if it is the same as that of a messenger RNA copy that is translated into protein. The sequence on the opposite strand is called the “antisense” sequence. Both sense and antisense sequences can exist on different parts of the same strand of DNA (i.e. both strands can contain both sense and antisense sequences). In both prokaryotes and eukaryotes, antisense RNA sequences are produced, but the functions of these RNAs are not entirely clear. One proposal is that antisense RNAs are involved in regulating gene expression through RNA-RNA base pairing. A few DNA sequences in prokaryotes and eukaryotes, and more in plasmids and viruses, blur the distinction between sense and antisense strands by having overlapping genes. In these cases, some DNA sequences do double duty, encoding one protein when read along one strand, and a second protein when read in the opposite direction along the other strand. In bacteria, this overlap may be involved in the regulation of gene transcription, while in viruses, overlapping genes increase the amount of information that can be encoded within the small viral genome. DNA can be twisted like a rope in a process called DNA supercoiling. With DNA in its “relaxed” state, a strand usually circles the axis of the double helix once every 10.4 base pairs, but if the DNA is twisted the strands become more tightly or more loosely wound. If the DNA is twisted in the direction of the helix, this is positive supercoiling, and the bases are held more tightly together. If they are twisted in the opposite direction, this is negative supercoiling, and the bases come apart more easily. In nature, most DNA has slight negative supercoiling that is introduced by enzymes called topoisomerases. These enzymes are also needed to relieve the twisting stresses introduced into DNA strands during processes such as transcription and DNA replication. The expression of genes is influenced by how the DNA is packaged in chromosomes, in a structure called chromatin. Base modifications can be involved in packaging, with regions that have low or no gene expression usually containing high levels of methylation of cytosine bases. DNA packaging and its influence on gene expression can also occur by covalent modifications of the histone protein core around which DNA is wrapped in the chromatin structure or else by remodeling carried out by chromatin remodeling complexes. There is, further, crosstalk between DNA methylation and histone modification, so they can coordinately affect chromatin and gene expression. For one example, cytosine methylation produces 5-methylcytosine, which is important for X-inactivation of chromosomes. The average level of methylation varies between organisms—the worm Caenorhabditis elegans lacks cytosine methylation, while vertebrates have higher levels, with up to 1% of their DNA containing 5-methylcytosine. Despite the importance of 5-methylcytosine, it can deaminate to leave a thymine base, so methylated cytosines are particularly prone to mutations. Other base modifications include adenine methylation in bacteria, the presence of 5-hydroxymethylcytosine in the brain, and the glycosylation of uracil to produce the “J-base” in kinetoplastids. 9.4.1 DNA Damage DNA can be damaged by many sorts of mutagens, which change the DNA sequence. Mutagens include oxidizing agents, alkylating agents and also high-energy electromagnetic radiation such as ultraviolet light and X-rays. The type of DNA damage produced depends on the type of mutagen. For example, UV light can damage DNA by producing thymine dimers, which are cross-links between pyrimidine bases. On the other hand, oxidants such as free radicals or hydrogen peroxide produce multiple forms of damage, including base modifications, particularly of guanosine, and double-strand breaks. A typical human cell contains about 150,000 bases that have suffered oxidative damage. Of these oxidative lesions, the most dangerous are double-strand breaks, as these are difficult to repair and can produce point mutations, insertions, deletions from the DNA sequence, and chromosomal translocations. These mutations can cause cancer. DNA damage that is naturally occurring, due to normal cellular processes that produce reactive oxygen species, the hydrolytic activities of cellular water, etc., also occurs frequently. Although most of this damage is repaired, in any cell some DNA damage may remain despite the action of repair processes. This DNA damage accumulates with age in mammalian postmitotic tissues. This accumulation appears to be an important underlying cause of aging. Many mutagens fit into the space between two adjacent base pairs, this is called intercalation. Most intercalators are aromatic and planar molecules; examples include ethidium bromide, acridines, daunomycin, and doxorubicin. For an intercalator to fit between base pairs, the bases must separate, distorting the DNA strands by unwinding of the double helix. This inhibits both transcription and DNA replication, causing toxicity and mutations. As a result, DNA intercalators may be carcinogens, and in the case of thalidomide, a teratogen. Others such as benzo[a]pyrene diol epoxide and aflatoxin form DNA adducts that induce errors in replication. Nevertheless, due to their ability to inhibit DNA transcription and replication, other similar toxins are also used in chemotherapy to inhibit rapidly growing cancer cells. DNA usually occurs as linear chromosomes in eukaryotes, and circular chromosomes in prokaryotes. The set of chromosomes in a cell makes up its genome; the human genome has approximately 3 billion base pairs of DNA arranged into 46 chromosomes. Transmission of genetic information in genes is achieved via complementary base pairing. For example, in transcription, the DNA sequence is copied into a complementary RNA sequence. Usually, this RNA copy is then used to make a matching protein sequence in a process called translation. In alternative fashion, a cell may simply copy its genetic information in a process called DNA replication. 9.4.2 Genes And Genomes Genomic DNA is tightly and orderly packed in the process called DNA condensation, to fit the small available volumes of the cell. In eukaryotes, DNA is located in the cell nucleus, with small amounts in mitochondria and chloroplasts. In prokaryotes, the DNA is held within an irregularly shaped body in the cytoplasm called the nucleoid. In many species, only a small fraction of the total sequence of the genome encodes protein. For example, only about 1.5% of the human genome consists of protein-coding exons, with over 50% of human DNA consisting of non-coding repetitive sequences. The reasons for the presence of so much noncoding DNA in eukaryotic genomes and the extraordinary differences in genome size, or C-value, among species, represent a long-standing puzzle known as the “C-value enigma”. However, some DNA sequences that do not code protein may still encode functional non-coding RNA molecules, which are involved in the regulation of gene expression. Some noncoding DNA sequences play structural roles in chromosomes. Telomeres and centromeres typically contain few genes but are important for the function and stability of chromosomes. An abundant form of noncoding DNA in humans are pseudogenes, which are copies of genes that have been disabled by mutation. These sequences are usually just molecular fossils, although they can occasionally serve as raw genetic material for the creation of new genes through the process of gene duplication and divergence. 9.4.3 Transcription And Translation A gene is a sequence of DNA that contains genetic information and can influence the phenotype of an organism. Within a gene, the sequence of bases along a DNA strand defines a messenger RNA sequence, which then defines one or more protein sequences. The relationship between the nucleotide sequences of genes and the amino-acid sequences of proteins is determined by the rules of translation, known collectively as the genetic code. The genetic code consists of three-letter ‘words’ called codons formed from a sequence of three nucleotides (e.g. ACT, CAG, TTT). In transcription, the codons of a gene are copied into messenger RNA by RNA polymerase. This RNA copy is then decoded by a ribosome that reads the RNA sequence by base-pairing the messenger RNA to transfer RNA, which carries amino acids. Since there are 4 bases in 3-letter combinations, there are 64 possible codons. These encode the twenty standard amino acids, giving most amino acids more than one possible codon. There are also three ‘stop’ or ‘nonsense’ codons signifying the end of the coding region; these are the TAA, TGA, and TAG codons. 9.4.4 DNA Replication Cell division is essential for an organism to grow, but, when a cell divides, it must replicate the DNA in its genome so that the two daughter cells have the same genetic information as their parent. The double-stranded structure of DNA provides a simple mechanism for DNA replication. Here, the two strands are separated and then each strand’s complementary DNA sequence is recreated by an enzyme called DNA polymerase. This enzyme makes the complementary strand by finding the correct base through complementary base pairing and bonding it onto the original strand. As DNA polymerases can only extend a DNA strand in a 5′ to 3′ direction, different mechanisms are used to copy the antiparallel strands of the double helix. In this way, the base on the old strand dictates which base appears on the new strand, and the cell ends up with a perfect copy of its DNA. In molecular biology, DNA replication is the biological process of producing two identical replicas of DNA from one original DNA molecule. DNA replication occurs in all living organisms acting as the basis for biological inheritance. DNA is made up of a double helix of two complementary strands. During replication, these strands are separated. Each strand of the original DNA molecule then serves as a template for the production of its counterpart, a process referred to as semi-conservative replication. As a result of semi-conservative replication, the new helix will be composed of an original DNA strand as well as a newly synthesized strand. Cellular proofreading and error-checking mechanisms ensure near perfect fidelity for DNA replication. Figure 9.10: DNA polymerases adds nucleotides to the 3′ end of a strand of DNA. If a mismatch is accidentally incorporated, the polymerase is inhibited from further extension. Proofreading removes the mismatched nucleotide and extension continues. In a cell, DNA replication begins at specific locations, or origins of replication, in the genome. Unwinding of DNA at the origin and synthesis of new strands, accommodated by an enzyme known as helicase, results in replication forks growing bi-directionally from the origin. A number of proteins are associated with the replication fork to help in the initiation and continuation of DNA synthesis. Most prominently, DNA polymerase synthesizes the new strands by adding nucleotides that complement each (template) strand. DNA replication occurs during the S-stage of interphase. DNA replication (DNA amplification) can also be performed in vitro (artificially, outside a cell). DNA polymerases isolated from cells and artificial DNA primers can be used to start DNA synthesis at known sequences in a template DNA molecule. Polymerase chain reaction (PCR), ligase chain reaction (LCR), and transcription-mediated amplification (TMA) are examples. The replisome is a complex molecular machine that carries out replication of DNA. The replisome first unwinds double stranded DNA into two single strands. For each of the resulting single strands, a new complementary sequence of DNA is synthesized. The net result is formation of two new double stranded DNA sequences that are exact copies of the original double stranded DNA sequence. In terms of structure, the replisome is composed of two replicative polymerase complexes, one of which synthesizes the leading strand, while the other synthesizes the lagging strand. The replisome is composed of a number of proteins including helicase, RFC, PCNA, gyrase/topoisomerase, SSB/RPA, primase, DNA polymerase III, RNAse H, and ligase. For prokaryotes, each dividing nucleoid (region containing genetic material which is not a nucleus) requires two replisomes for bidirectional replication. The two replisomes continue replication at both forks in the middle of the cell. Finally, as the termination site replicates, the two replisomes separate from the DNA. The replisome remains at a fixed, midcell location in the cell, attached to the membrane, and the template DNA threads through it. DNA is fed through the stationary pair of replisomes located at the cell membrane. For eukaryotes, numerous replication bubbles form at origins of replication throughout the chromosome. As with prokaryotes, two replisomes are required, one at each replication fork located at the terminus of the replication bubble. Because of significant differences in chromosome size, and the associated complexities of highly condensed chromosomes, various aspects of the DNA replication process in eukaryotes, including the terminal phases, are less well-characterised than for prokaryotes. The replisome is responsible for copying the entirety of genomic DNA in each proliferative cell. This process allows for the high-fidelity passage of hereditary/genetic information from parental cell to daughter cell and is thus essential to all organisms. Much of the cell cycle is built around ensuring that DNA replication occurs without errors. Figure 9.11: Many enzymes are involved in forming the DNA replication fork and DNA polymerization. In G1 phase of the cell cycle, many of the DNA replication regulatory processes are initiated. In eukaryotes, the vast majority of DNA synthesis occurs during S phase of the cell cycle, and the entire genome must be unwound and duplicated to form two daughter copies. During G2, any damaged DNA or replication errors are corrected. Finally, one copy of the genomes is segregated to each daughter cell at mitosis or M phase. These daughter copies each contain one strand from the parental duplex DNA and one nascent antiparallel strand. 9.4.5 Eukaryotic DNA Replication Eukaryotic DNA replication is a conserved mechanism that restricts DNA replication to once per cell cycle. Eukaryotic DNA replication of chromosomal DNA is central for the duplication of a cell and is necessary for the maintenance of the eukaryotic genome. DNA replication is the action of DNA polymerases synthesizing a DNA strand complementary to the original template strand. To synthesize DNA, the double-stranded DNA is unwound by DNA helicases ahead of polymerases, forming a replication fork containing two single-stranded templates. Replication processes permit the copying of a single DNA double helix into two DNA helices, which are divided into the daughter cells at mitosis. The major enzymatic functions carried out at the replication fork are well conserved from prokaryotes to eukaryotes, but the replication machinery in eukaryotic DNA replication is a much larger complex, coordinating many proteins at the site of replication, forming the replisome. After the replicative helicase has unwound the parental DNA duplex, exposing two single-stranded DNA templates, replicative polymerases are needed to generate two copies of the parental genome. DNA polymerase function is highly specialized and accomplish replication on specific templates and in narrow localizations. At the eukaryotic replication fork, there are three distinct replicative polymerase complexes that contribute to DNA replication: Polymerase α, Polymerase δ, and Polymerase ε. These three polymerases are essential for viability of the cell. Figure 9.12: DNA polymerases adds nucleotides to the 3′ end of a strand of DNA. If a mismatch is accidentally incorporated, the polymerase is inhibited from further extension. Proofreading removes the mismatched nucleotide and extension continues. Because DNA polymerases require a primer on which to begin DNA synthess, polymerase α (Pol α) acts as a replicative primase. Pol α is associated with an RNA primase and this complex accomplishes the priming task by synthesizing a primer that contains a short 10 nucleotide stretch of RNA followed by 10 to 20 DNA bases. Importantly, this priming action occurs at replication initiation at origins to begin leading-strand synthesis and also at the 5’ end of each Okazaki fragment on the lagging strand. However, Pol α is not able to continue DNA replication and must be replaced with another polymerase to continue DNA synthesis. Polymerase switching requires clamp loaders and it has been proven that normal DNA replication requires the coordinated actions of all three DNA polymerases: Pol α for priming synthesis, Pol ε for leading-strand replication, and the Pol δ, which is constantly loaded, for generating Okazaki fragments during lagging-strand synthesis. Polymerase α (Pol α): Forms a complex with a small catalytic subunit (PriS) and a large noncatalytic (PriL) subunit. First, synthesis of an RNA primer allows DNA synthesis by DNA polymerase alpha. Occurs once at the origin on the leading strand and at the start of each Okazaki fragment on the lagging strand. Pri subunits act as a primase, synthesizing an RNA primer. DNA Pol α elongates the newly formed primer with DNA nucleotides. After around 20 nucleotides, elongation is taken over by Pol ε on the leading strand and Pol δ on the lagging strand. Polymerase δ (Pol δ): Highly processive and has proofreading, 3’-&gt;5’ exonuclease activity. In vivo, it is the main polymerase involved in both lagging strand and leading strand synthesis. Polymerase ε (Pol ε): Highly processive and has proofreading, 3’-&gt;5’ exonuclease activity. Highly related to pol δ, in vivo it functions mainly in error checking of pol δ. DNA replication, like all biological polymerization processes, proceeds in three enzymatically catalyzed and coordinated steps: initiation, elongation and termination. 9.4.6 Initiation For a cell to divide, it must first replicate its DNA. DNA replication is an all-or-none process; once replication begins, it proceeds to completion. Once replication is complete, it does not occur again in the same cell cycle. This is made possible by the division of initiation into two temporally distinct steps: formation of the pre-replication complex and the preinitiation complex. 9.4.7 Pre-Replication Complex In late mitosis and early G1 phase, a large complex of initiator proteins assembles into the pre-replication complex at particular points in the DNA, known as “origins”. In E. coli the primary initiator protein is DnaA; in yeast, this is the origin recognition complex. Sequences used by initiator proteins tend to be “AT-rich” (rich in adenine and thymine bases), because A-T base pairs have two hydrogen bonds (rather than the three formed in a C-G pair) and thus are easier to strand-separate. In eukaryotes, the origin recognition complex catalyzes the assembly of initiator proteins into the pre-replication complex. Cdc6 and Cdt1 then associate with the bound origin recognition complex at the origin in order to form a larger complex necessary to load the Mcm complex onto the DNA. The Mcm complex is the helicase that will unravel the DNA helix at the replication origins and replication forks in eukaryotes. The Mcm complex is recruited at late G1 phase and loaded by the ORC-Cdc6-Cdt1 complex onto the DNA via ATP-dependent protein remodeling. The loading of the Mcm complex onto the origin DNA marks the completion of pre-replication complex formation. If environmental conditions are right in late G1 phase, the G1 and G1/S cyclin-Cdk complexes are activated, which stimulate expression of genes that encode components of the DNA synthetic machinery. G1/S-Cdk activation also promotes the expression and activation of S-Cdk complexes, which may play a role in activating replication origins depending on species and cell type. Control of these Cdks vary depending cell type and stage of development. In a similar manner, Cdc7 is also required through S phase to activate replication origins. Cdc7 is not active throughout the cell cycle, and its activation is strictly timed to avoid premature initiation of DNA replication. In late G1, Cdc7 activity rises abruptly as a result of association with the regulatory subunit Dbf4, which binds Cdc7 directly and promotes its protein kinase activity. Cdc7 has been found to be a rate-limiting regulator of origin activity. Together, the G1/S-Cdks and/or S-Cdks and Cdc7 collaborate to directly activate the replication origins, leading to initiation of DNA synthesis. 9.4.8 Preinitiation Complex In early S phase, S-Cdk and Cdc7 activation lead to the assembly of the preinitiation complex, a massive protein complex formed at the origin. Formation of the preinitiation complex displaces Cdc6 and Cdt1 from the origin replication complex, inactivating and disassembling the pre-replication complex. Loading the preinitiation complex onto the origin activates the Mcm helicase, causing unwinding of the DNA helix. The preinitiation complex also loads α-primase and other DNA polymerases onto the DNA. After α-primase synthesizes the first primers, the primer-template junctions interact with the clamp loader, which loads the sliding clamp onto the DNA to begin DNA synthesis. The components of the preinitiation complex remain associated with replication forks as they move out from the origin. 9.4.9 Elongation DNA polymerase has 5′–3′ activity. All known DNA replication systems require a free 3′ hydroxyl group before synthesis can be initiated (note: the DNA template is read in 3′ to 5′ direction whereas a new strand is synthesized in the 5′ to 3′ direction—this is often confused). Four distinct mechanisms for DNA synthesis are recognized: All cellular life forms and many DNA viruses, phages and plasmids use a primase to synthesize a short RNA primer with a free 3′ OH group which is subsequently elongated by a DNA polymerase. The 5′ end of the nicked strand is transferred to a tyrosine residue on the nuclease and the free 3′ OH group is then used by the DNA polymerase to synthesize the new strand. The first is the best known of these mechanisms and is used by the cellular organisms. In this mechanism, once the two strands are separated, primase adds RNA primers to the template strands. The leading strand receives one RNA primer while the lagging strand receives several. The leading strand is continuously extended from the primer by a DNA polymerase with high processivity, while the lagging strand is extended discontinuously from each primer forming Okazaki fragments. RNase removes the primer RNA fragments, and a low processivity DNA polymerase distinct from the replicative polymerase enters to fill the gaps. When this is complete, a single nick on the leading strand and several nicks on the lagging strand can be found. Ligase works to fill these nicks in, thus completing the newly replicated DNA molecule. Multiple DNA polymerases take on different roles in the DNA replication process. In E. coli, DNA Pol III is the polymerase enzyme primarily responsible for DNA replication. It assembles into a replication complex at the replication fork that exhibits extremely high processivity, remaining intact for the entire replication cycle. In contrast, DNA Pol I is the enzyme responsible for replacing RNA primers with DNA. DNA Pol I has a 5′ to 3′ exonuclease activity in addition to its polymerase activity, and uses its exonuclease activity to degrade the RNA primers ahead of it as it extends the DNA strand behind it, in a process called nick translation. Pol I is much less processive than Pol III because its primary function in DNA replication is to create many short DNA regions rather than a few very long regions. In eukaryotes, the low-processivity enzyme, Pol α, helps to initiate replication because it forms a complex with primase. In eukaryotes, leading strand synthesis is thought to be conducted by Pol ε; however, this view has recently been challenged, suggesting a role for Pol δ. Primer removal is completed by Pol δ while repair of DNA during replication is completed by Pol ε. As DNA synthesis continues, the original DNA strands continue to unwind on each side of the bubble, forming a replication fork with two prongs. In bacteria, which have a single origin of replication on their circular chromosome, this process creates a “theta structure” (resembling the Greek letter theta: θ). In contrast, eukaryotes have longer linear chromosomes and initiate replication at multiple origins within these. 9.4.10 Replication Fork The replication fork is a structure that forms within the long helical DNA during DNA replication. It is created by helicases, which break the hydrogen bonds holding the two DNA strands together in the helix. The resulting structure has two branching “prongs”, each one made up of a single strand of DNA. These two strands serve as the template for the leading and lagging strands, which will be created as DNA polymerase matches complementary nucleotides to the templates; the templates may be properly referred to as the leading strand template and the lagging strand template. DNA is always synthesized by adding nucleotides to the 3′ end of a strand. Since the leading and lagging strand templates are oriented in opposite directions at the replication fork, a major issue is how to achieve synthesis of nascent (new) lagging strand DNA, whose direction of synthesis is opposite to the direction of the growing replication fork. 9.4.11 Replication Of The Leading Strand The leading strand is the strand of nascent DNA which is synthesized in the same direction as the growing replication fork. This sort of DNA replication is continuous. 9.4.12 Replication Of The Lagging Strand The lagging strand is the strand of nascent DNA whose direction of synthesis is opposite to the direction of the growing replication fork. Because of its orientation, replication of the lagging strand is more complicated as compared to that of the leading strand. As a consequence, the DNA polymerase on this strand is seen to “lag behind” the other strand. The lagging strand is synthesized in short, separated segments. On the lagging strand template, a primase “reads” the template DNA and initiates synthesis of a short complementary RNA primer. A DNA polymerase extends the primed segments, forming Okazaki fragments. The RNA primers are then removed and replaced with DNA, and the fragments of DNA are joined together by DNA ligase. In all cases the helicase is composed of six polypeptides that wrap around only one strand of the DNA being replicated. The two polymerases are bound to the helicase heximer. In eukaryotes the helicase wraps around the leading strand, and in prokaryotes it wraps around the lagging strand. As helicase unwinds DNA at the replication fork, the DNA ahead is forced to rotate. This process results in a build-up of twists in the DNA ahead. This build-up forms a torsional resistance that would eventually halt the progress of the replication fork. Topoisomerases are enzymes that temporarily break the strands of DNA, relieving the tension caused by unwinding the two strands of the DNA helix; topoisomerases (including DNA gyrase) achieve this by adding negative supercoils to the DNA helix. Bare single-stranded DNA tends to fold back on itself forming secondary structures; these structures can interfere with the movement of DNA polymerase. To prevent this, single-strand binding proteins bind to the DNA until a second strand is synthesized, preventing secondary structure formation. Clamp proteins form a sliding clamp around DNA, helping the DNA polymerase maintain contact with its template, thereby assisting with processivity. The inner face of the clamp enables DNA to be threaded through it. Once the polymerase reaches the end of the template or detects double-stranded DNA, the sliding clamp undergoes a conformational change that releases the DNA polymerase. Clamp-loading proteins are used to initially load the clamp, recognizing the junction between template and RNA primers. 9.4.13 DNA Replication Proteins At the replication fork, many replication enzymes assemble on the DNA into a complex molecular machine called the replisome. The following is a list of major DNA replication enzymes that participate in the replisome: Table 9.2: A list of major DNA replication enzymes that participate in the replisome Enzymes Function in DNA replication DNA helicase Also known as helix destabilizing enzyme. Helicase separates the two strands of DNA at the Replication Fork behind the topoisomerase. DNA polymerase The enzyme responsible for catalyzing the addition of nucleotide substrates to DNA in the 5′ to 3′ direction during DNA replication. Also performs proof-reading and error correction. There exist many different types of DNA Polymerase, each of which perform different functions in different types of cells. DNA clamp A protein which prevents elongating DNA polymerases from dissociating from the DNA parent strand. Single-strand DNA-binding protein Bind to ssDNA and prevent the DNA double helix from re-annealing after DNA helicase unwinds it, thus maintaining the strand separation, and facilitating the synthesis of the nascent strand. Topoisomerase Relaxes the DNA from its super-coiled nature. DNA gyrase Relieves strain of unwinding by DNA helicase; this is a specific type of topoisomerase DNA ligase Re-anneals the semi-conservative strands and joins Okazaki Fragments of the lagging strand. Primase Provides a starting point of RNA (or DNA) for DNA polymerase to begin synthesis of the new DNA strand. Telomerase Lengthens telomeric DNA by adding repetitive nucleotide sequences to the ends of eukaryotic chromosomes. This allows germ cells and stem cells to avoid the Hayflick limit on cell divisi 9.4.14 Termination Eukaryotes initiate DNA replication at multiple points in the chromosome, so replication forks meet and terminate at many points in the chromosome. Because eukaryotes have linear chromosomes, DNA replication is unable to reach the very end of the chromosomes. Due to this problem, DNA is lost in each replication cycle from the end of the chromosome. Telomeres are regions of repetitive DNA close to the ends and help prevent loss of genes due to this shortening. Shortening of the telomeres is a normal process in somatic cells. This shortens the telomeres of the daughter DNA chromosome. As a result, cells can only divide a certain number of times before the DNA loss prevents further division. (This is known as the Hayflick limit.) Within the germ cell line, which passes DNA to the next generation, telomerase extends the repetitive sequences of the telomere region to prevent degradation. Telomerase can become mistakenly active in somatic cells, sometimes leading to cancer formation. Increased telomerase activity is one of the hallmarks of cancer. Termination requires that the progress of the DNA replication fork must stop or be blocked. Termination at a specific locus, when it occurs, involves the interaction between two components: (1) a termination site sequence in the DNA, and (2) a protein which binds to this sequence to physically stop DNA replication. In various bacterial species, this is named the DNA replication terminus site-binding protein, or Ter protein. Because bacteria have circular chromosomes, termination of replication occurs when the two replication forks meet each other on the opposite end of the parental chromosome. E. coli regulates this process through the use of termination sequences that, when bound by the Tus protein, enable only one direction of replication fork to pass through. As a result, the replication forks are constrained to always meet within the termination region of the chromosome. 9.4.15 Regulation Of DNA Replication Within eukaryotes, DNA replication is controlled within the context of the cell cycle. As the cell grows and divides, it progresses through stages in the cell cycle; DNA replication takes place during the S phase (synthesis phase). The progress of the eukaryotic cell through the cycle is controlled by cell cycle checkpoints. Progression through checkpoints is controlled through complex interactions between various proteins, including cyclins and cyclin-dependent kinases. The G1/S checkpoint (or restriction checkpoint) regulates whether eukaryotic cells enter the process of DNA replication and subsequent division. Cells that do not proceed through this checkpoint remain in the G0 stage and do not replicate their DNA. After passing through the G1/S checkpoint, DNA must be replicated only once in each cell cycle. When the Mcm complex moves away from the origin, the pre-replication complex is dismantled. Because a new Mcm complex cannot be loaded at an origin until the pre-replication subunits are reactivated, one origin of replication can not be used twice in the same cell cycle. Activation of S-Cdks in early S phase promotes the destruction or inhibition of individual pre-replication complex components, preventing immediate reassembly. S and M-Cdks continue to block pre-replication complex assembly even after S phase is complete, ensuring that assembly cannot occur again until all Cdk activity is reduced in late mitosis. Replication of chloroplast and mitochondrial genomes occurs independently of the cell cycle, through the process of D-loop replication. 9.4.16 Interactions Of DNA with Proteins All the functions of DNA depend on interactions with proteins. These protein interactions can be non-specific, or the protein can bind specifically to a single DNA sequence. Enzymes can also bind to DNA and of these, the polymerases that copy the DNA base sequence in transcription and DNA replication are particularly important. 9.4.17 DNA-Binding Proteins Structural proteins that bind DNA are well-understood examples of non-specific DNA-protein interactions. Within chromosomes, DNA is held in complexes with structural proteins. These proteins organize the DNA into a compact structure called chromatin. In eukaryotes, this structure involves DNA binding to a complex of small basic proteins called histones, while in prokaryotes multiple types of proteins are involved. The histones form a disk-shaped complex called a nucleosome, which contains two complete turns of double-stranded DNA wrapped around its surface. These non-specific interactions are formed through basic residues in the histones, making ionic bonds to the acidic sugar-phosphate backbone of the DNA, and are thus largely independent of the base sequence. Chemical modifications of these basic amino acid residues include methylation, phosphorylation, and acetylation. These chemical changes alter the strength of the interaction between the DNA and the histones, making the DNA more or less accessible to transcription factors and changing the rate of transcription. Other non-specific DNA-binding proteins in chromatin include the high-mobility group proteins, which bind to bent or distorted DNA. These proteins are important in bending arrays of nucleosomes and arranging them into the larger structures that make up chromosomes. A distinct group of DNA-binding proteins is the DNA-binding proteins that specifically bind single-stranded DNA. In humans, replication protein A is the best-understood member of this family and is used in processes where the double helix is separated, including DNA replication, recombination, and DNA repair. These binding proteins seem to stabilize single-stranded DNA and protect it from forming stem-loops or being degraded by nucleases. In contrast, other proteins have evolved to bind to particular DNA sequences. The most intensively studied of these are the various transcription factors, which are proteins that regulate transcription. Each transcription factor binds to one particular set of DNA sequences and activates or inhibits the transcription of genes that have these sequences close to their promoters. The transcription factors do this in two ways. Firstly, they can bind the RNA polymerase responsible for transcription, either directly or through other mediator proteins; this locates the polymerase at the promoter and allows it to begin transcription. Alternatively, transcription factors can bind enzymes that modify the histones at the promoter. This changes the accessibility of the DNA template to the polymerase. As these DNA targets can occur throughout an organism’s genome, changes in the activity of one type of transcription factor can affect thousands of genes. Consequently, these proteins are often the targets of the signal transduction processes that control responses to environmental changes or cellular differentiation and development. The specificity of these transcription factors’ interactions with DNA come from the proteins making multiple contacts to the edges of the DNA bases, allowing them to “read” the DNA sequence. Most of these base-interactions are made in the major groove, where the bases are most accessible. 9.4.18 DNA-modifying Enzymes 9.4.19 Nucleases And Ligases Nucleases are enzymes that cut DNA strands by catalyzing the hydrolysis of the phosphodiester bonds. Nucleases that hydrolyse nucleotides from the ends of DNA strands are called exonucleases, while endonucleases cut within strands. The most frequently used nucleases in molecular biology are the restriction endonucleases, which cut DNA at specific sequences. For instance, the EcoRI enzyme recognizes the 6-base sequence 5′-GAATTC-3′ and cuts each strand after the G creating 4 nucleotide sticky ends with a 5’ end overhang of AATT. In nature, these enzymes protect bacteria against phage infection by digesting the phage DNA when it enters the bacterial cell, acting as part of the restriction modification system. These sequence-specific nucleases are used in molecular cloning and DNA fingerprinting. Enzymes called DNA ligases can rejoin cut or broken DNA strands. Ligases are particularly important in lagging strand DNA replication, as they join together the short segments of DNA produced at the replication fork into a complete copy of the DNA template. They are also used in DNA repair and genetic recombination. 9.4.20 Topoisomerases And Helicases Topoisomerases are enzymes with both nuclease and ligase activity. These proteins change the amount of supercoiling in DNA. Some of these enzymes work by cutting the DNA helix and allowing one section to rotate, thereby reducing its level of supercoiling; the enzyme then seals the DNA break. Other types of these enzymes are capable of cutting one DNA helix and then passing a second strand of DNA through this break, before rejoining the helix. Topoisomerases are required for many processes involving DNA, such as DNA replication and transcription. Helicases are proteins that are a type of molecular motor. They use the chemical energy in nucleoside triphosphates, predominantly adenosine triphosphate (ATP), to break hydrogen bonds between bases and unwind the DNA double helix into single strands. These enzymes are essential for most processes where enzymes need to access the DNA bases. 9.4.21 Polymerases Polymerases are enzymes that synthesize polynucleotide chains from nucleoside triphosphates. The sequence of their products is created based on existing polynucleotide chains—which are called templates. These enzymes function by repeatedly adding a nucleotide to the 3′ hydroxyl group at the end of the growing polynucleotide chain. As a consequence, all polymerases work in a 5′ to 3′ direction. In the active site of these enzymes, the incoming nucleoside triphosphate base-pairs to the template: this allows polymerases to accurately synthesize the complementary strand of their template. Polymerases are classified according to the type of template that they use. In DNA replication, DNA-dependent DNA polymerases make copies of DNA polynucleotide chains. To preserve biological information, it is essential that the sequence of bases in each copy are precisely complementary to the sequence of bases in the template strand. Many DNA polymerases have a proofreading activity. Here, the polymerase recognizes the occasional mistakes in the synthesis reaction by the lack of base pairing between the mismatched nucleotides. If a mismatch is detected, a 3′ to 5′ exonuclease activity is activated and the incorrect base removed. In most organisms, DNA polymerases function in a large complex called the replisome that contains multiple accessory subunits, such as the DNA clamp or helicases. RNA-dependent DNA polymerases are a specialized class of polymerases that copy the sequence of an RNA strand into DNA. They include reverse transcriptase, which is a viral enzyme involved in the infection of cells by retroviruses, and telomerase, which is required for the replication of telomeres. For example, HIV reverse transcriptase is an enzyme for AIDS virus replication. Telomerase is an unusual polymerase because it contains its own RNA template as part of its structure. It synthesizes telomeres at the ends of chromosomes. Telomeres prevent fusion of the ends of neighboring chromosomes and protect chromosome ends from damage. Transcription is carried out by a DNA-dependent RNA polymerase that copies the sequence of a DNA strand into RNA. To begin transcribing a gene, the RNA polymerase binds to a sequence of DNA called a promoter and separates the DNA strands. It then copies the gene sequence into a messenger RNA transcript until it reaches a region of DNA called the terminator, where it halts and detaches from the DNA. As with human DNA-dependent DNA polymerases, RNA polymerase II, the enzyme that transcribes most of the genes in the human genome, operates as part of a large protein complex with multiple regulatory and accessory subunits. 9.4.22 DNA Recombination A DNA helix usually does not interact with other segments of DNA, and in human cells, the different chromosomes even occupy separate areas in the nucleus called “chromosome territories”. This physical separation of different chromosomes is important for the ability of DNA to function as a stable repository for information, as one of the few times chromosomes interact is in chromosomal crossover which occurs during sexual reproduction, when genetic recombination occurs. Chromosomal crossover is when two DNA helices break, swap a section and then rejoin. Recombination allows chromosomes to exchange genetic information and produces new combinations of genes, which increases the efficiency of natural selection and can be important in the rapid evolution of new proteins. Genetic recombination can also be involved in DNA repair, particularly in the cell’s response to double-strand breaks. The most common form of chromosomal crossover is homologous recombination, where the two chromosomes involved share very similar sequences. Non-homologous recombination can be damaging to cells, as it can produce chromosomal translocations and genetic abnormalities. The recombination reaction is catalyzed by enzymes known as recombinases, such as RAD51. The first step in recombination is a double-stranded break caused by either an endonuclease or damage to the DNA. A series of steps catalyzed in part by the recombinase then leads to joining of the two helices by at least one Holliday junction, in which a segment of a single strand in each helix is annealed to the complementary strand in the other helix. The Holliday junction is a tetrahedral junction structure that can be moved along the pair of chromosomes, swapping one strand for another. The recombination reaction is then halted by cleavage of the junction and re-ligation of the released DNA. Only strands of like polarity exchange DNA during recombination. There are two types of cleavage: east-west cleavage and north-south cleavage. The north-south cleavage nicks both strands of DNA, while the east-west cleavage has one strand of DNA intact. 9.4.23 Evolutionary History Of DNA DNA contains the genetic information that allows all forms of life to function, grow and reproduce. However, it is unclear how long in the 4-billion-year history of life DNA has performed this function, as it has been proposed that the earliest forms of life may have used RNA as their genetic material. RNA may have acted as the central part of early cell metabolism as it can both transmit genetic information and carry out catalysis as part of ribozymes. This ancient RNA world where nucleic acid would have been used for both catalysis and genetics may have influenced the evolution of the current genetic code based on four nucleotide bases. This would occur, since the number of different bases in such an organism is a trade-off between a small number of bases increasing replication accuracy and a large number of bases increasing the catalytic efficiency of ribozymes. However, there is no direct evidence of ancient genetic systems, as recovery of DNA from most fossils is impossible because DNA survives in the environment for less than one million years, and slowly degrades into short fragments in solution. Building blocks of DNA (adenine, guanine, and related organic molecules) may have been formed extraterrestrially in outer space. Complex DNA and RNA organic compounds of life, including uracil, cytosine, and thymine, have also been formed in the laboratory under conditions mimicking those found in outer space, using starting chemicals, such as pyrimidine, found in meteorites. Pyrimidine, like polycyclic aromatic hydrocarbons (PAHs), the most carbon-rich chemical found in the universe, may have been formed in red giants or in interstellar cosmic dust and gas clouds. 9.4.24 Genetic Engineering Methods have been developed to purify DNA from organisms, such as phenol-chloroform extraction, and to manipulate it in the laboratory, such as restriction digests and the polymerase chain reaction. Modern biology and biochemistry make intensive use of these techniques in recombinant DNA technology. Recombinant DNA is a man-made DNA sequence that has been assembled from other DNA sequences. They can be transformed into organisms in the form of plasmids or in the appropriate format, by using a viral vector. The genetically modified organisms produced can be used to produce products such as recombinant proteins, used in medical research, or be grown in agriculture. 9.4.25 Dna Profiling Forensic scientists can use DNA in blood, semen, skin, saliva or hair found at a crime scene to identify a matching DNA of an individual, such as a perpetrator. This process is formally termed DNA profiling, also called DNA fingerprinting. In DNA profiling, the lengths of variable sections of repetitive DNA, such as short tandem repeats and minisatellites, are compared between people. This method is usually an extremely reliable technique for identifying a matching DNA. However, identification can be complicated if the scene is contaminated with DNA from several people. DNA profiling was developed in 1984 by British geneticist Sir Alec Jeffreys, and first used in forensic science to convict Colin Pitchfork in the 1988 Enderby murders case. DNA profiling is also used in DNA paternity testing to determine if someone is the biological parent or grandparent of a child with the probability of parentage is typically 99.99% when the alleged parent is biologically related to the child. Normally, paternity testing is performed after birth, but recently developed methods allow isolation and sequencing of fetal DNA from the blood of the mother. 9.5 Structure And Function Of Ribonucleic Acid Ribonucleic acid (RNA) is a polymeric molecule essential in various biological roles in coding, decoding, regulation and expression of genes. Like DNA, RNA is assembled as a chain of nucleotides, but unlike DNA it is more often found in nature as a single-strand folded onto itself, rather than a paired double-strand. Cellular organisms use messenger RNA (mRNA) to convey genetic information (using the nitrogenous bases of guanine, uracil, adenine, and cytosine, denoted by the letters G, U, A, and C) and direct synthesis of proteins by ribosomes. Many viruses encode their genetic information using an RNA genome. Some RNA molecules play an active role within cells by catalyzing biological reactions, controlling gene expression, or sensing and communicating responses to cellular signals. One of these active processes is protein synthesis, a universal function in which RNA molecules direct the synthesis of proteins on ribosomes. This process uses transfer RNA (tRNA) molecules to deliver amino acids to the ribosome, where ribosomal RNA (rRNA) then links amino acids together to form coded proteins. 9.5.1 Comparison With DNA The chemical structure of RNA is very similar to that of DNA, but differs in three primary ways: Unlike double-stranded DNA, RNA is a single-stranded molecule in many of its biological roles and consists of much shorter chains of nucleotides. However, a single RNA molecule can, by complementary base pairing, form intrastrand double helixes, as in tRNA. While the sugar-phosphate “backbone” of DNA contains deoxyribose, RNA contains ribose instead. Ribose has a hydroxyl group attached to the pentose ring in the 2’ position, whereas deoxyribose does not. The hydroxyl groups in the ribose backbone make RNA more chemically labile than DNA by lowering the activation energy of hydrolysis. The complementary base to adenine in DNA is thymine, whereas in RNA, it is uracil, which is an unmethylated form of thymine. Like DNA, most biologically active RNAs, including mRNA, tRNA, rRNA, snRNAs, and other non-coding RNAs, contain self-complementary sequences that allow parts of the RNA to fold and pair with itself to form double helices. Analysis of these RNAs has revealed that they are highly structured. Unlike DNA, their structures do not consist of long double helices, but rather collections of short helices packed together into structures akin to proteins. In this fashion, RNAs can achieve chemical catalysis (like enzymes). For instance, determination of the structure of the ribosome—an RNA-protein complex that catalyzes peptide bond formation—revealed that its active site is composed entirely of RNA. 9.5.2 Structure Of RNA Each nucleotide in RNA contains a ribose sugar, with carbons numbered 1’ through 5’. A base is attached to the 1’ position, in general, adenine (A), cytosine (C), guanine (G), or uracil (U). Adenine and guanine are purines, cytosine and uracil are pyrimidines. A phosphate group is attached to the 3’ position of one ribose and the 5’ position of the next. The phosphate groups have a negative charge each, making RNA a charged molecule (polyanion). The bases form hydrogen bonds between cytosine and guanine, between adenine and uracil and between guanine and uracil. However, other interactions are possible, such as a group of adenine bases binding to each other in a bulge, or the GNRA tetraloop that has a guanine–adenine base-pair. An important structural component of RNA that distinguishes it from DNA is the presence of a hydroxyl group at the 2’ position of the ribose sugar. RNA is transcribed with only four bases (adenine, cytosine, guanine and uracil), but these bases and attached sugars can be modified in numerous ways as the RNAs mature. Pseudouridine (Ψ), in which the linkage between uracil and ribose is changed from a C–N bond to a C–C bond, and ribothymidine (T) are found in various places (the most notable ones being in the TΨC loop of tRNA). Another notable modified base is hypoxanthine, a deaminated adenine base whose nucleoside is called inosine (I). Inosine plays a key role in the wobble hypothesis of the genetic code. There are more than 100 other naturally occurring modified nucleosides. The greatest structural diversity of modifications can be found in tRNA, while pseudouridine and nucleosides with 2’-O-methylribose often present in rRNA are the most common. The specific roles of many of these modifications in RNA are not fully understood. However, it is notable that, in ribosomal RNA, many of the post-transcriptional modifications occur in highly functional regions, such as the peptidyl transferase center and the subunit interface, implying that they are important for normal function. The functional form of single-stranded RNA molecules, just like proteins, frequently requires a specific tertiary structure. The scaffold for this structure is provided by secondary structural elements that are hydrogen bonds within the molecule. This leads to several recognizable “domains” of secondary structure like hairpin loops, bulges, and internal loops. Since RNA is charged, metal ions such as Mg2+ are needed to stabilise many secondary and tertiary structures. The naturally occurring enantiomer of RNA is D-RNA composed of D-ribonucleotides. All chirality centers are located in the D-ribose. By the use of L-ribose or rather L-ribonucleotides, L-RNA can be synthesized. L-RNA is much more stable against degradation by RNase. 9.5.3 Synthesis Of RNA Synthesis of RNA is usually catalyzed by an enzyme—RNA polymerase—using DNA as a template, a process known as transcription. Initiation of transcription begins with the binding of the enzyme to a promoter sequence in the DNA (usually found “upstream” of a gene). The DNA double helix is unwound by the helicase activity of the enzyme. The enzyme then progresses along the template strand in the 3’ to 5’ direction, synthesizing a complementary RNA molecule with elongation occurring in the 5’ to 3’ direction. The DNA sequence also dictates where termination of RNA synthesis will occur. Primary transcript RNAs are often modified by enzymes after transcription. For example, a poly(A) tail and a 5’ cap are added to eukaryotic pre-mRNA and introns are removed by the spliceosome. There are also a number of RNA-dependent RNA polymerases that use RNA as their template for synthesis of a new strand of RNA. For instance, a number of RNA viruses (such as poliovirus) use this type of enzyme to replicate their genetic material. Also, RNA-dependent RNA polymerase is part of the RNA interference pathway in many organisms. 9.5.4 Coding And Non-coding RNA Messenger RNA (mRNA) is the RNA that carries information from DNA to the ribosome, the sites of protein synthesis (translation) in the cell. The coding sequence of the mRNA determines the amino acid sequence in the protein that is produced. However, many RNAs do not code for protein (about 97% of the transcriptional output is non-protein-coding in eukaryotes). These so-called non-coding RNAs (“ncRNA”) can be encoded by their own genes (RNA genes), but can also derive from mRNA introns. The most prominent examples of non-coding RNAs are transfer RNA (tRNA) and ribosomal RNA (rRNA), both of which are involved in the process of translation. There are also non-coding RNAs involved in gene regulation, RNA processing and other roles. Certain RNAs are able to catalyse chemical reactions such as cutting and ligating other RNA molecules, and the catalysis of peptide bond formation in the ribosome; these are known as ribozymes. According to the length of RNA chain, RNA includes small RNA and long RNA. Usually, small RNAs are shorter than 200 nt in length, and long RNAs are greater than 200 nt long. Long RNAs, also called large RNAs, mainly include long non-coding RNA (lncRNA) and mRNA. Small RNAs mainly include 5.8S ribosomal RNA (rRNA), 5S rRNA, transfer RNA (tRNA), microRNA (miRNA), small interfering RNA (siRNA), small nucleolar RNA (snoRNAs), Piwi-interacting RNA (piRNA), tRNA-derived small RNA (tsRNA) and small rDNA-derived RNA (srRNA). Messenger RNA (mRNA) carries genetic information from the nucleus to the cytoplasm and serves as template for the synthesis of protein by ribosomes, a process called translation. In eukaryotic cells, once precursor mRNA (pre-mRNA) has been transcribed from DNA, it is processed to mature mRNA. This removes its introns (non-coding stretches of DNA sequence) from the pre-mRNA. The mRNA is then exported from the nucleus to the cytoplasm, where ribosomes bind to it and translate its the corresponding protein form with the help of tRNA. In prokaryotic cells, which do not have nucleus and cytoplasm compartments, mRNA can bind to ribosomes while it is being transcribed from DNA. After a certain amount of time, the message degrades into its component nucleotides with the assistance of ribonucleases. Transfer RNA (tRNA) is a small RNA chain of about 80 nucleotides that transfers a specific amino acid to a growing polypeptide chain at the ribosomal site of protein synthesis during translation. It has sites for amino acid attachment and an anticodon region for codon recognition that binds to a specific sequence on the messenger RNA chain through hydrogen bonding. Figure 9.13: Tertiary structure of tRNA (based on atomic coordinates of PDB 1ehz rendered with open source molecular visualization tool PyMol.) Ribosomal RNA (rRNA) is the catalytic component of the ribosomes. Eukaryotic ribosomes contain four different rRNA molecules: 18S, 5.8S, 28S and 5S rRNA. Three of the rRNA molecules are synthesized in the nucleolus, and one is synthesized elsewhere. In the cytoplasm, ribosomal RNA and protein combine to form a nucleoprotein called a ribosome. The ribosome binds mRNA and carries out protein synthesis. Several ribosomes may be attached to a single mRNA at any time. Nearly all the RNA found in a typical eukaryotic cell is rRNA. Transfer-messenger RNA (tmRNA) is found in many bacteria and plastids. It tags proteins encoded by mRNAs that lack stop codons for degradation and prevents the ribosome from stalling. 9.5.5 Regulatory RNA The earliest known regulators of gene expression were proteins known as repressors and activators, regulators with specific short binding sites within enhancer regions near the genes to be regulated. More recently, RNAs have been found to regulate genes as well. There are several kinds of RNA-dependent processes in eukaryotes regulating the expression of genes at various points, such as RNAi repressing genes post-transcriptionally, long non-coding RNAs shutting down blocks of chromatin epigenetically, and enhancer RNAs inducing increased gene expression. In addition to these mechanisms in eukaryotes, both bacteria and archaea have been found to use regulatory RNAs extensively. Bacterial small RNA and the CRISPR system are examples of such prokaryotic regulatory RNA systems. 9.5.6 RNA Interference By miRNAs Post-transcriptional expression levels of many genes can be controlled by RNA interference, in which miRNAs, specific short RNA molecules, pair with mRNA regions and target them for degradation. This antisense-based process involves steps that first process the RNA so that it can base-pair with a region of its target mRNAs. Once the base pairing occurs, other proteins direct the mRNA to be destroyed by nucleases. Next to be linked to regulation were Xist and other long noncoding RNAs associated with X chromosome inactivation. Their roles, at first mysterious, were shown to be the silencing of blocks of chromatin via recruitment of Polycomb complex so that messenger RNA could not be transcribed from them. Additional lncRNAs, currently defined as RNAs of more than 200 base pairs that do not appear to have coding potential, have been found associated with regulation of stem cell pluripotency and cell division. The third major group of regulatory RNAs is called enhancer RNAs. It is not clear at present whether they are a unique category of RNAs of various lengths or constitute a distinct subset of lncRNAs. In any case, they are transcribed from enhancers, which are known regulatory sites in the DNA near genes they regulate. They up-regulate the transcription of the gene(s) under control of the enhancer from which they are transcribed. At first, regulatory RNA was thought to be a eukaryotic phenomenon, a part of the explanation for why so much more transcription in higher organisms was seen than had been predicted. But as soon as researchers began to look for possible RNA regulators in bacteria, they turned up there as well, termed as small RNA (sRNA). Bacterial small RNAs generally act via antisense pairing with mRNA to down-regulate its translation, either by affecting stability or affecting cis-binding ability. Riboswitches have also been discovered. They are cis-acting regulatory RNA sequences acting allosterically. They change shape when they bind metabolites so that they gain or lose the ability to bind chromatin to regulate expression of genes. Archaea also have systems of regulatory RNA. The CRISPR system, recently being used to edit DNA in situ, acts via regulatory RNAs in archaea and bacteria to provide protection against virus invaders. Many RNAs are involved in modifying other RNAs. Introns are spliced out of pre-mRNA by spliceosomes, which contain several small nuclear RNAs (snRNA), or the introns can be ribozymes that are spliced by themselves. RNA can also be altered by having its nucleotides modified to nucleotides other than A, C, G and U. In eukaryotes, modifications of RNA nucleotides are in general directed by small nucleolar RNAs (snoRNA; 60–300 nt), found in the nucleolus and cajal bodies. snoRNAs associate with enzymes and guide them to a spot on an RNA by basepairing to that RNA. These enzymes then perform the nucleotide modification. rRNAs and tRNAs are extensively modified, but snRNAs and mRNAs can also be the target of base modification. RNA can also be methylated. RNA viruses have genomes composed of RNA that encodes a number of proteins. The viral genome is replicated by some of those proteins, while other proteins protect the genome as the virus particle moves to a new host cell. Viroids are another group of pathogens, but they consist only of RNA, do not encode any protein and are replicated by a host plant cell’s polymerase. Reverse transcribing viruses replicate their genomes by reverse transcribing DNA copies from their RNA; these DNA copies are then transcribed to new RNA. Retrotransposons also spread by copying DNA and RNA from one another, and telomerase contains an RNA that is used as template for building the ends of eukaryotic chromosomes. Research on RNA has led to many important biological discoveries and numerous Nobel Prizes. Nucleic acids were discovered in 1868 by Friedrich Miescher, who called the material ‘nuclein’ since it was found in the nucleus. It was later discovered that prokaryotic cells, which do not have a nucleus, also contain nucleic acids. The role of RNA in protein synthesis was suspected already in 1939. Severo Ochoa won the 1959 Nobel Prize in Medicine (shared with Arthur Kornberg) after he discovered an enzyme that can synthesize RNA in the laboratory. However, the enzyme discovered by Ochoa (polynucleotide phosphorylase) was later shown to be responsible for RNA degradation, not RNA synthesis. In 1956 Alex Rich and David Davies hybridized two separate strands of RNA to form the first crystal of RNA whose structure could be determined by X-ray crystallography. The sequence of the 77 nucleotides of a yeast tRNA was found by Robert W. Holley in 1965, winning Holley the 1968 Nobel Prize in Medicine (shared with Har Gobind Khorana and Marshall Nirenberg). During the early 1970s, retroviruses and reverse transcriptase were discovered, showing for the first time that enzymes could copy RNA into DNA (the opposite of the usual route for transmission of genetic information). For this work, David Baltimore, Renato Dulbecco and Howard Temin were awarded a Nobel Prize in 1975. In 1976, Walter Fiers and his team determined the first complete nucleotide sequence of an RNA virus genome, that of bacteriophage MS2. In 1977, introns and RNA splicing were discovered in both mammalian viruses and in cellular genes, resulting in a 1993 Nobel to Philip Sharp and Richard Roberts. Catalytic RNA molecules (ribozymes) were discovered in the early 1980s, leading to a 1989 Nobel award to Thomas Cech and Sidney Altman. In 1990, it was found in Petunia that introduced genes can silence similar genes of the plant’s own, now known to be a result of RNA interference. At about the same time, 22 nt long RNAs, now called microRNAs, were found to have a role in the development of C. elegans. Studies on RNA interference gleaned a Nobel Prize for Andrew Fire and Craig Mello in 2006, and another Nobel was awarded for studies on the transcription of RNA to Roger Kornberg in the same year. The discovery of gene regulatory RNAs has led to attempts to develop drugs made of RNA, such as siRNA, to silence genes. Adding to the Nobel prizes awarded for research on RNA in 2009 it was awarded for the elucidation of the atomic structure of the ribosome to Venki Ramakrishnan, Tom Steitz, and Ada Yonath. In 1967, Carl Woese hypothesized that RNA might be catalytic and suggested that the earliest forms of life (self-replicating molecules) could have relied on RNA both to carry genetic information and to catalyze biochemical reactions—an RNA world. 9.6 Gene Expression Gene expression is the process by which information from a gene is used in the synthesis of a functional gene product. These products are often proteins, but in non-protein-coding genes such as transfer RNA (tRNA) or small nuclear RNA (snRNA) genes, the product is a functional RNA. Gene expression is summarized in the Central Dogma first formulated by Francis Crick in 1958, further developed in his 1970 article, and expanded by the subsequent discoveries of reverse transcription and RNA replication. The process of gene expression is used by all known life—eukaryotes (including multicellular organisms), prokaryotes (bacteria and archaea), and utilized by viruses—to generate the macromolecular machinery for life. In genetics, gene expression is the most fundamental level at which the genotype gives rise to the phenotype, i.e. observable trait. The genetic information stored in DNA represents the genotype, whereas the phenotype results from the “interpretation” of that information. Such phenotypes are often expressed by the synthesis of proteins that control the organism’s structure and development, or that act as enzymes catalyzing specific metabolic pathways. All steps in the gene expression process may be modulated (regulated), including the transcription, RNA splicing, translation, and post-translational modification of a protein. Regulation of gene expression gives control over the timing, location, and amount of a given gene product (protein or ncRNA) present in a cell and can have a profound effect on the cellular structure and function. Regulation of gene expression is the basis for cellular differentiation, development, morphogenesis and the versatility and adaptability of any organism. Gene regulation may therefore serve as a substrate for evolutionary change. 9.6.1 Transcription And RNA Processing Transcription is the first of several steps of DNA based gene expression, in which a particular segment of DNA is copied into RNA (especially mRNA) by the enzyme RNA polymerase. During transcription, a DNA sequence is read by an RNA polymerase, which produces a complementary, antiparallel RNA strand called a primary transcript. Transcription proceeds in the following general steps: RNA polymerase, together with one or more general transcription factors, binds to promoter DNA. RNA polymerase creates a transcription bubble, which separates the two strands of the DNA helix. This is done by breaking the hydrogen bonds between complementary DNA nucleotides. RNA polymerase adds RNA nucleotides (which are complementary to the nucleotides of one DNA strand). RNA sugar-phosphate backbone forms with assistance from RNA polymerase to form an RNA strand. Hydrogen bonds of the RNA–DNA helix break, freeing the newly synthesized RNA strand. If the cell has a nucleus, the RNA may be further processed. This may include polyadenylation, capping, and splicing. The RNA may remain in the nucleus or exit to the cytoplasm through the nuclear pore complex. The stretch of DNA transcribed into an RNA molecule is called a transcription unit. If the DNA encodes a protein, the transcription produces messenger RNA (mRNA); the mRNA, in turn, serves as a template for the protein’s synthesis through translation. Alternatively, the transcribed DNA may encode for non-coding RNA such as microRNA, ribosomal RNA (rRNA), transfer RNA (tRNA), or enzymatic RNA molecules called ribozymes. A DNA transcription unit encoding for a protein may contain both a coding sequence, which will be translated into the protein, and regulatory sequences, which direct and regulate the synthesis of that protein. The regulatory sequence before (“upstream” from) the coding sequence is called the five prime untranslated region (5’UTR); the sequence after (“downstream” from) the coding sequence is called the three prime untranslated region (3’UTR). As opposed to DNA replication, transcription results in an RNA complement that includes the nucleotide uracil (U) in all instances where thymine (T) would have occurred in a DNA complement. Only one of the two DNA strands serve as a template for transcription. The antisense strand of DNA is read by RNA polymerase from the 3’ end to the 5’ end during transcription (3’ → 5’). The complementary RNA is created in the opposite direction, in the 5’ → 3’ direction, matching the sequence of the sense strand with the exception of switching uracil for thymine. This directionality is because RNA polymerase can only add nucleotides to the 3’ end of the growing mRNA chain. This use of only the 3’ → 5’ DNA strand eliminates the need for the Okazaki fragments that are seen in DNA replication. This also removes the need for an RNA primer to initiate RNA synthesis, as is the case in DNA replication. The non-template (sense) strand of DNA is called the coding strand, because its sequence is the same as the newly created RNA transcript (except for the substitution of uracil for thymine). This is the strand that is used by convention when presenting a DNA sequence. Transcription has some proofreading mechanisms, but they are fewer and less effective than the controls for copying DNA. As a result, transcription has a lower copying fidelity than DNA replication. Transcription is divided into initiation, promoter escape, elongation, and termination. 9.6.2 Initiation Transcription begins with the binding of RNA polymerase, together with one or more general transcription factors, to a specific DNA sequence referred to as a “promoter” to form an RNA polymerase-promoter “closed complex”. In the “closed complex” the promoter DNA is still fully double-stranded. RNA polymerase, assisted by one or more general transcription factors, then unwinds approximately 14 base pairs of DNA to form an RNA polymerase-promoter “open complex”. In the “open complex” the promoter DNA is partly unwound and single-stranded. The exposed, single-stranded DNA is referred to as the “transcription bubble.” RNA polymerase, assisted by one or more general transcription factors, then selects a transcription start site in the transcription bubble, binds to an initiating NTP and an extending NTP (or a short RNA primer and an extending NTP) complementary to the transcription start site sequence, and catalyzes bond formation to yield an initial RNA product. In bacteria, RNA polymerase holoenzyme consists of five subunits: 2 α subunits, 1 β subunit, 1 β’ subunit, and 1 ω subunit. In bacteria, there is one general RNA transcription factor known as a sigma factor. RNA polymerase core enzyme binds to the bacterial general transcription (sigma) factor to form RNA polymerase holoenzyme and then binds to a promoter. (RNA polymerase is called a holoenzyme when sigma subunit is attached to the core enzyme which is consist of 2 α subunits, 1 β subunit, 1 β’ subunit only). In archaea and eukaryotes, RNA polymerase contains subunits homologous to each of the five RNA polymerase subunits in bacteria and also contains additional subunits. In archaea and eukaryotes, the functions of the bacterial general transcription factor sigma are performed by multiple general transcription factors that work together. In archaea, there are three general transcription factors: TBP, TFB, and TFE. In eukaryotes, in RNA polymerase II-dependent transcription, there are six general transcription factors: TFIIA, TFIIB (an ortholog of archaeal TFB), TFIID (a multisubunit factor in which the key subunit, TBP, is an ortholog of archaeal TBP), TFIIE (an ortholog of archaeal TFE), TFIIF, and TFIIH. The TFIID is the first component to bind to DNA due to binding of TBP, while TFIIH is the last component to be recruited. In archaea and eukaryotes, the RNA polymerase-promoter closed complex is usually referred to as the “preinitiation complex.” Transcription initiation is regulated by additional proteins, known as activators and repressors, and, in some cases, associated coactivators or corepressors, which modulate formation and function of the transcription initiation complex. After the first bond is synthesized, the RNA polymerase must escape the promoter. During this time there is a tendency to release the RNA transcript and produce truncated transcripts. This is called abortive initiation, and is common for both eukaryotes and prokaryotes. Abortive initiation continues to occur until an RNA product of a threshold length of approximately 10 nucleotides is synthesized, at which point promoter escape occurs and a transcription elongation complex is formed. Mechanistically, promoter escape occurs through DNA scrunching, providing the energy needed to break interactions between RNA polymerase holoenzyme and the promoter. In eukaryotes, at an RNA polymerase II-dependent promoter, upon promoter clearance, TFIIH phosphorylates serine 5 on the carboxy terminal domain of RNA polymerase II, leading to the recruitment of capping enzyme (CE). The exact mechanism of how CE induces promoter clearance in eukaryotes is not yet known. 9.6.3 Elongation One strand of the DNA, the template strand (or noncoding strand), is used as a template for RNA synthesis. As transcription proceeds, RNA polymerase traverses the template strand and uses base pairing complementarity with the DNA template to create an RNA copy (which elongates during the traversal). Although RNA polymerase traverses the template strand from 3’ → 5’, the coding (non-template) strand and newly formed RNA can also be used as reference points, so transcription can be described as occurring 5’ → 3’. This produces an RNA molecule from 5’ → 3’, an exact copy of the coding strand (except that thymines are replaced with uracils, and the nucleotides are composed of a ribose (5-carbon) sugar where DNA has deoxyribose (one fewer oxygen atom) in its sugar-phosphate backbone). Figure 9.14: RNA polymerase (RNAP) at work. Note the coding and template strands. The resulting RNA is a synthesized from the template strand and identical in sequence to the coding strand. mRNA transcription can involve multiple RNA polymerases on a single DNA template and multiple rounds of transcription (amplification of particular mRNA), so many mRNA molecules can be rapidly produced from a single copy of a gene. The characteristic elongation rates in prokaryotes and eukaryotes are about 10-100 nts/sec. In eukaryotes, however, nucleosomes act as major barriers to transcribing polymerases during transcription elongation. In these organisms, the pausing induced by nucleosomes can be regulated by transcription elongation factors such as TFIIS. Elongation also involves a proofreading mechanism that can replace incorrectly incorporated bases. In eukaryotes, this may correspond with short pauses during transcription that allow appropriate RNA editing factors to bind. These pauses may be intrinsic to the RNA polymerase or due to chromatin structure. 9.6.4 Termination Bacteria use two different strategies for transcription termination – Rho-independent termination and Rho-dependent termination. In Rho-independent transcription termination, RNA transcription stops when the newly synthesized RNA molecule forms a G-C-rich hairpin loop followed by a run of Us. When the hairpin forms, the mechanical stress breaks the weak rU-dA bonds, now filling the DNA–RNA hybrid. This pulls the poly-U transcript out of the active site of the RNA polymerase, terminating transcription. In the “Rho-dependent” type of termination, a protein factor called “Rho” destabilizes the interaction between the template and the mRNA, thus releasing the newl synthesized mRNA from the elongation complex. Transcription termination in eukaryotes is less well understood than in bacteria, but involves cleavage of the new transcript followed by template-independent addition of adenines at its new 3’ end, in a process called polyadenylation. 9.6.5 Inhibitors Of Transcription Transcription inhibitors can be used as antibiotics against, for example, pathogenic bacteria (antibacterials) and fungi (antifungals). An example of such an antibacterial is rifampicin, which inhibits bacterial transcription of DNA into mRNA by inhibiting DNA-dependent RNA polymerase by binding its beta-subunit, while 8-hydroxyquinoline is an antifungal transcription inhibitor. The effects of histone methylation may also work to inhibit the action of transcription. In vertebrates, the majority of gene promoters contain a CpG island with numerous CpG sites. When many of a gene’s promoter CpG sites are methylated the gene becomes inhibited (silenced). 9.6.6 Transcription Factors Active transcription units are clustered in the nucleus, in discrete sites called transcription factories or euchromatin. Such sites can be visualized by allowing engaged polymerases to extend their transcripts in tagged precursors (Br-UTP or Br-U) and immuno-labeling the tagged nascent RNA. Transcription factories can also be localized using fluorescence in situ hybridization or marked by antibodies directed against polymerases. There are ~10,000 factories in the nucleoplasm of a HeLa cell, among which are ~8,000 polymerase II factories and ~2,000 polymerase III factories. Each polymerase II factory contains ~8 polymerases. As most active transcription units are associated with only one polymerase, each factory usually contains ~8 different transcription units. These units might be associated through promoters and/or enhancers, with loops forming a “cloud” around the factor. A molecule that allows the genetic material to be realized as a protein was first hypothesized by François Jacob and Jacques Monod. Severo Ochoa won a Nobel Prize in Physiology or Medicine in 1959 for developing a process for synthesizing RNA in vitro with polynucleotide phosphorylase, which was useful for cracking the genetic code. RNA synthesis by RNA polymerase was established in vitro by several laboratories by 1965. Roger D. Kornberg won the 2006 Nobel Prize in Chemistry “for his studies of the molecular basis of eukaryotic transcription”. 9.6.7 RNA Processing Post-transcriptional modification or co-transcriptional modification is a set of biological processes common to most eukaryotic cells by which an RNA primary transcript is chemically altered following transcription from a gene to produce a mature, functional RNA molecule that can then leave the nucleus and perform any of a variety of different functions in the cell. There are many types of post-transcriptional modifications achieved through a diverse class of molecular mechanisms. Perhaps the most notable example is the conversion of precursor messenger RNA transcripts into mature messenger RNA that is subsequently capable of being translated into protein. This process includes three major steps that significantly modify the chemical structure of the RNA molecule: the addition of a 5’ cap, the addition of a 3’ polyadenylated tail, and RNA splicing. Such processing is vital for the correct translation of eukaryotic genomes because the initial precursor mRNA produced by transcription often contains both exons (coding sequences) and introns (non-coding sequences); splicing removes the introns and links the exons directly, while the cap and tail facilitate the transport of the mRNA to a ribosome and protect it from molecular degradation. Post-transcriptional modifications may also occur during the processing of other transcripts which ultimately become transfer RNA, ribosomal RNA, or any of the other types of RNA used by the cell. 9.6.8 mRNA Processing The pre-mRNA molecule undergoes three main modifications. These modifications are 5’ capping, 3’ polyadenylation, and RNA splicing, which occur in the cell nucleus before the RNA is translated. 9.6.9 5’ Processing Capping of the pre-mRNA involves the addition of 7-methylguanosine (m7G) to the 5’ end. To achieve this, the terminal 5’ phosphate requires removal, which is done with the aid of a phosphatase enzyme. The enzyme guanosyl transferase then catalyses the reaction, which produces the diphosphate 5’ end. The diphosphate 5’ end then attacks the alpha phosphorus atom of a GTP molecule in order to add the guanine residue in a 5’5’ triphosphate link. The enzyme (guanine-N7-)-methyltransferase (“cap MTase”) transfers a methyl group from S-adenosyl methionine to the guanine ring. This type of cap, with just the (m7G) in position is called a cap 0 structure. The ribose of the adjacent nucleotide may also be methylated to give a cap 1. Methylation of nucleotides downstream of the RNA molecule produce cap 2, cap 3 structures and so on. In these cases the methyl groups are added to the 2’ OH groups of the ribose sugar. The cap protects the 5’ end of the primary RNA transcript from attack by ribonucleases that have specificity to the 3’5’ phosphodiester bonds. 9.6.10 3’ Processing The pre-mRNA processing at the 3’ end of the RNA molecule involves cleavage of its 3’ end and then the addition of about 250 adenine residues to form a poly(A) tail. The cleavage and adenylation reactions occur primarily if a polyadenylation signal sequence (5’- AAUAAA-3’) is located near the 3’ end of the pre-mRNA molecule, which is followed by another sequence, which is usually (5’-CA-3’) and is the site of cleavage. A GU-rich sequence is also usually present further downstream on the pre-mRNA molecule. More recently, it has been demonstrated that alternate signal sequences such as UGUA upstream off the cleavage site can also direct cleavage and polyadenylation in the absence of the AAUAAA signal. It is important to understand that these two signals are not mutually independent and often coexist. After the synthesis of the sequence elements, several multi-subunit proteins are transferred to the RNA molecule. The transfer of these sequence specific binding proteins cleavage and polyadenylation specificity factor (CPSF), Cleavage Factor I (CF I) and cleavage stimulation factor (CStF) occurs from RNA Polymerase II. The three factors bind to the sequence elements. The AAUAAA signal is directly bound by CPSF. For UGUA dependent processing sites, binding of the multi protein complex is done by Cleavage Factor I (CF I). The resultant protein complex formed contains additional cleavage factors and the enzyme Polyadenylate Polymerase (PAP). This complex cleaves the RNA between the polyadenylation sequence and the GU-rich sequence at the cleavage site marked by the (5’-CA-3’) sequences. Poly(A) polymerase then adds about 200 adenine units to the new 3’ end of the RNA molecule using ATP as a precursor. As the poly(A) tail is synthesised, it binds multiple copies of poly(A) binding protein, which protects the 3’end from ribonuclease digestion. 9.6.11 Intron Splicing RNA splicing is the process by which introns, regions of RNA that do not code for proteins, are removed from the pre-mRNA and the remaining exons connected to re-form a single continuous molecule. Exons are sections of mRNA which become “expressed” or translated into a protein. They are the coding portions of a mRNA molecule. Although most RNA splicing occurs after the complete synthesis and end-capping of the pre-mRNA, transcripts with many exons can be spliced co-transcriptionally. The splicing reaction is catalyzed by a large protein complex called the spliceosome assembled from proteins and small nuclear RNA molecules that recognize splice sites in the pre-mRNA sequence. Many pre-mRNAs, including those encoding antibodies, can be spliced in multiple ways to produce different mature mRNAs that encode different protein sequences. This process is known as alternative splicing, and allows production of a large variety of proteins from a limited amount of DNA. 9.6.12 Reverse Transcription Some viruses (such as HIV, the cause of AIDS), have the ability to transcribe RNA into DNA. HIV has an RNA genome that is reverse transcribed into DNA. The resulting DNA can be merged with the DNA genome of the host cell. The main enzyme responsible for synthesis of DNA from an RNA template is called reverse transcriptase. In the case of HIV, reverse transcriptase is responsible for synthesizing a complementary DNA strand (cDNA) to the viral RNA genome. The enzyme ribonuclease H then digests the RNA strand, and reverse transcriptase synthesises a complementary strand of DNA to form a double helix DNA structure (“cDNA”). The cDNA is integrated into the host cell’s genome by the enzyme integrase, which causes the host cell to generate viral proteins that reassemble into new viral particles. In HIV, subsequent to this, the host cell undergoes programmed cell death, or apoptosis of T cells. However, in other retroviruses, the host cell remains intact as the virus buds out of the cell. Some eukaryotic cells contain an enzyme with reverse transcription activity called telomerase. Telomerase is a reverse transcriptase that lengthens the ends of linear chromosomes. Telomerase carries an RNA template from which it synthesizes a repeating sequence of DNA, or “junk” DNA. This repeated sequence of DNA is called a telomere and can be thought of as a “cap” for a chromosome. It is important because every time a linear chromosome is duplicated, it is shortened. With this “junk” DNA or “cap” at the ends of chromosomes, the shortening eliminates some of the non-essential, repeated sequence rather than the protein-encoding DNA sequence, that is farther away from the chromosome end. Telomerase is often activated in cancer cells to enable cancer cells to duplicate their genomes indefinitely without losing important protein-coding DNA sequence. Activation of telomerase could be part of the process that allows cancer cells to become immortal. The immortalizing factor of cancer via telomere lengthening due to telomerase has been proven to occur in 90% of all carcinogenic tumors in vivo with the remaining 10% using an alternative telomere maintenance route called ALT or Alternative Lengthening of Telomeres. 9.6.13 RNA Export In eukaryotes most mature RNA must be exported to the cytoplasm from the nucleus. While some RNAs function in the nucleus, many RNAs are transported through the nuclear pores and into the cytosol. Export of RNAs requires association with specific proteins known as exportins. Specific exportin molecules are responsible for the export of a given RNA type. mRNA transport also requires the correct association with Exon Junction Complex (EJC), which ensures that correct processing of the mRNA is completed before export. In some cases RNAs are additionally transported to a specific part of the cytoplasm, such as a synapse; they are then towed by motor proteins that bind through linker proteins to specific sequences (called “zipcodes”) on the RNA. 9.6.14 Transcription And RNA Processing Transcription is the first of several steps of DNA based gene expression, in which a particular segment of DNA is copied into RNA (especially mRNA) by the enzyme RNA polymerase. During transcription, a DNA sequence is read by an RNA polymerase, which produces a complementary, antiparallel RNA strand called a primary transcript. Transcription proceeds in the following general steps: RNA polymerase, together with one or more general transcription factors, binds to promoter DNA. RNA polymerase creates a transcription bubble, which separates the two strands of the DNA helix. This is done by breaking the hydrogen bonds between complementary DNA nucleotides. RNA polymerase adds RNA nucleotides (which are complementary to the nucleotides of one DNA strand). RNA sugar-phosphate backbone forms with assistance from RNA polymerase to form an RNA strand. Hydrogen bonds of the RNA–DNA helix break, freeing the newly synthesized RNA strand. If the cell has a nucleus, the RNA may be further processed. This may include polyadenylation, capping, and splicing. The RNA may remain in the nucleus or exit to the cytoplasm through the nuclear pore complex. The stretch of DNA transcribed into an RNA molecule is called a transcription unit. If the DNA encodes a protein, the transcription produces messenger RNA (mRNA); the mRNA, in turn, serves as a template for the protein’s synthesis through translation. Alternatively, the transcribed DNA may encode for non-coding RNA such as microRNA, ribosomal RNA (rRNA), transfer RNA (tRNA), or enzymatic RNA molecules called ribozymes. A DNA transcription unit encoding for a protein may contain both a coding sequence, which will be translated into the protein, and regulatory sequences, which direct and regulate the synthesis of that protein. The regulatory sequence before (“upstream” from) the coding sequence is called the five prime untranslated region (5’UTR); the sequence after (“downstream” from) the coding sequence is called the three prime untranslated region (3’UTR). As opposed to DNA replication, transcription results in an RNA complement that includes the nucleotide uracil (U) in all instances where thymine (T) would have occurred in a DNA complement. Only one of the two DNA strands serve as a template for transcription. The antisense strand of DNA is read by RNA polymerase from the 3’ end to the 5’ end during transcription (3’ → 5’). The complementary RNA is created in the opposite direction, in the 5’ → 3’ direction, matching the sequence of the sense strand with the exception of switching uracil for thymine. This directionality is because RNA polymerase can only add nucleotides to the 3’ end of the growing mRNA chain. This use of only the 3’ → 5’ DNA strand eliminates the need for the Okazaki fragments that are seen in DNA replication. This also removes the need for an RNA primer to initiate RNA synthesis, as is the case in DNA replication. The non-template (sense) strand of DNA is called the coding strand, because its sequence is the same as the newly created RNA transcript (except for the substitution of uracil for thymine). This is the strand that is used by convention when presenting a DNA sequence. Transcription has some proofreading mechanisms, but they are fewer and less effective than the controls for copying DNA. As a result, transcription has a lower copying fidelity than DNA replication. Transcription is divided into initiation, promoter escape, elongation, and termination. 9.6.15 Initiation Transcription begins with the binding of RNA polymerase, together with one or more general transcription factors, to a specific DNA sequence referred to as a “promoter” to form an RNA polymerase-promoter “closed complex”. In the “closed complex” the promoter DNA is still fully double-stranded. RNA polymerase, assisted by one or more general transcription factors, then unwinds approximately 14 base pairs of DNA to form an RNA polymerase-promoter “open complex”. In the “open complex” the promoter DNA is partly unwound and single-stranded. The exposed, single-stranded DNA is referred to as the “transcription bubble.” RNA polymerase, assisted by one or more general transcription factors, then selects a transcription start site in the transcription bubble, binds to an initiating NTP and an extending NTP (or a short RNA primer and an extending NTP) complementary to the transcription start site sequence, and catalyzes bond formation to yield an initial RNA product. In bacteria, RNA polymerase holoenzyme consists of five subunits: 2 α subunits, 1 β subunit, 1 β’ subunit, and 1 ω subunit. In bacteria, there is one general RNA transcription factor known as a sigma factor. RNA polymerase core enzyme binds to the bacterial general transcription (sigma) factor to form RNA polymerase holoenzyme and then binds to a promoter. (RNA polymerase is called a holoenzyme when sigma subunit is attached to the core enzyme which is consist of 2 α subunits, 1 β subunit, 1 β’ subunit only). In archaea and eukaryotes, RNA polymerase contains subunits homologous to each of the five RNA polymerase subunits in bacteria and also contains additional subunits. In archaea and eukaryotes, the functions of the bacterial general transcription factor sigma are performed by multiple general transcription factors that work together. In archaea, there are three general transcription factors: TBP, TFB, and TFE. In eukaryotes, in RNA polymerase II-dependent transcription, there are six general transcription factors: TFIIA, TFIIB (an ortholog of archaeal TFB), TFIID (a multisubunit factor in which the key subunit, TBP, is an ortholog of archaeal TBP), TFIIE (an ortholog of archaeal TFE), TFIIF, and TFIIH. The TFIID is the first component to bind to DNA due to binding of TBP, while TFIIH is the last component to be recruited. In archaea and eukaryotes, the RNA polymerase-promoter closed complex is usually referred to as the “preinitiation complex.” Transcription initiation is regulated by additional proteins, known as activators and repressors, and, in some cases, associated coactivators or corepressors, which modulate formation and function of the transcription initiation complex. After the first bond is synthesized, the RNA polymerase must escape the promoter. During this time there is a tendency to release the RNA transcript and produce truncated transcripts. This is called abortive initiation, and is common for both eukaryotes and prokaryotes. Abortive initiation continues to occur until an RNA product of a threshold length of approximately 10 nucleotides is synthesized, at which point promoter escape occurs and a transcription elongation complex is formed. Mechanistically, promoter escape occurs through DNA scrunching, providing the energy needed to break interactions between RNA polymerase holoenzyme and the promoter. In eukaryotes, at an RNA polymerase II-dependent promoter, upon promoter clearance, TFIIH phosphorylates serine 5 on the carboxy terminal domain of RNA polymerase II, leading to the recruitment of capping enzyme (CE). The exact mechanism of how CE induces promoter clearance in eukaryotes is not yet known. 9.6.16 Inhibitors of transcription Transcription inhibitors can be used as antibiotics against, for example, pathogenic bacteria (antibacterials) and fungi (antifungals). An example of such an antibacterial is rifampicin, which inhibits bacterial transcription of DNA into mRNA by inhibiting DNA-dependent RNA polymerase by binding its beta-subunit, while 8-hydroxyquinoline is an antifungal transcription inhibitor. The effects of histone methylation may also work to inhibit the action of transcription. In vertebrates, the majority of gene promoters contain a CpG island with numerous CpG sites. When many of a gene’s promoter CpG sites are methylated the gene becomes inhibited (silenced). 9.6.17 Transcription Factors Active transcription units are clustered in the nucleus, in discrete sites called transcription factories or euchromatin. Such sites can be visualized by allowing engaged polymerases to extend their transcripts in tagged precursors (Br-UTP or Br-U) and immuno-labeling the tagged nascent RNA. Transcription factories can also be localized using fluorescence in situ hybridization or marked by antibodies directed against polymerases. There are ~10,000 factories in the nucleoplasm of a HeLa cell, among which are ~8,000 polymerase II factories and ~2,000 polymerase III factories. Each polymerase II factory contains ~8 polymerases. As most active transcription units are associated with only one polymerase, each factory usually contains ~8 different transcription units. These units might be associated through promoters and/or enhancers, with loops forming a “cloud” around the factor. A molecule that allows the genetic material to be realized as a protein was first hypothesized by François Jacob and Jacques Monod. Severo Ochoa won a Nobel Prize in Physiology or Medicine in 1959 for developing a process for synthesizing RNA in vitro with polynucleotide phosphorylase, which was useful for cracking the genetic code. RNA synthesis by RNA polymerase was established in vitro by several laboratories by 1965. Roger D. Kornberg won the 2006 Nobel Prize in Chemistry “for his studies of the molecular basis of eukaryotic transcription”. 9.6.18 RNA Processing Post-transcriptional modification or co-transcriptional modification is a set of biological processes common to most eukaryotic cells by which an RNA primary transcript is chemically altered following transcription from a gene to produce a mature, functional RNA molecule that can then leave the nucleus and perform any of a variety of different functions in the cell. There are many types of post-transcriptional modifications achieved through a diverse class of molecular mechanisms. Perhaps the most notable example is the conversion of precursor messenger RNA transcripts into mature messenger RNA that is subsequently capable of being translated into protein. This process includes three major steps that significantly modify the chemical structure of the RNA molecule: the addition of a 5’ cap, the addition of a 3’ polyadenylated tail, and RNA splicing. Such processing is vital for the correct translation of eukaryotic genomes because the initial precursor mRNA produced by transcription often contains both exons (coding sequences) and introns (non-coding sequences); splicing removes the introns and links the exons directly, while the cap and tail facilitate the transport of the mRNA to a ribosome and protect it from molecular degradation. Post-transcriptional modifications may also occur during the processing of other transcripts which ultimately become transfer RNA, ribosomal RNA, or any of the other types of RNA used by the cell. 9.6.19 mRNA Processing The pre-mRNA molecule undergoes three main modifications. These modifications are 5’ capping, 3’ polyadenylation, and RNA splicing, which occur in the cell nucleus before the RNA is translated. 9.6.20 5’ Processing Capping of the pre-mRNA involves the addition of 7-methylguanosine (m7G) to the 5’ end. To achieve this, the terminal 5’ phosphate requires removal, which is done with the aid of a phosphatase enzyme. The enzyme guanosyl transferase then catalyses the reaction, which produces the diphosphate 5’ end. The diphosphate 5’ end then attacks the alpha phosphorus atom of a GTP molecule in order to add the guanine residue in a 5’5’ triphosphate link. The enzyme (guanine-N7-)-methyltransferase (“cap MTase”) transfers a methyl group from S-adenosyl methionine to the guanine ring. This type of cap, with just the (m7G) in position is called a cap 0 structure. The ribose of the adjacent nucleotide may also be methylated to give a cap 1. Methylation of nucleotides downstream of the RNA molecule produce cap 2, cap 3 structures and so on. In these cases the methyl groups are added to the 2’ OH groups of the ribose sugar. The cap protects the 5’ end of the primary RNA transcript from attack by ribonucleases that have specificity to the 3’5’ phosphodiester bonds. 9.6.21 3’ Processing The pre-mRNA processing at the 3’ end of the RNA molecule involves cleavage of its 3’ end and then the addition of about 250 adenine residues to form a poly(A) tail. The cleavage and adenylation reactions occur primarily if a polyadenylation signal sequence (5’- AAUAAA-3’) is located near the 3’ end of the pre-mRNA molecule, which is followed by another sequence, which is usually (5’-CA-3’) and is the site of cleavage. A GU-rich sequence is also usually present further downstream on the pre-mRNA molecule. More recently, it has been demonstrated that alternate signal sequences such as UGUA upstream off the cleavage site can also direct cleavage and polyadenylation in the absence of the AAUAAA signal. It is important to understand that these two signals are not mutually independent and often coexist. After the synthesis of the sequence elements, several multi-subunit proteins are transferred to the RNA molecule. The transfer of these sequence specific binding proteins cleavage and polyadenylation specificity factor (CPSF), Cleavage Factor I (CF I) and cleavage stimulation factor (CStF) occurs from RNA Polymerase II. The three factors bind to the sequence elements. The AAUAAA signal is directly bound by CPSF. For UGUA dependent processing sites, binding of the multi protein complex is done by Cleavage Factor I (CF I). The resultant protein complex formed contains additional cleavage factors and the enzyme Polyadenylate Polymerase (PAP). This complex cleaves the RNA between the polyadenylation sequence and the GU-rich sequence at the cleavage site marked by the (5’-CA-3’) sequences. Poly(A) polymerase then adds about 200 adenine units to the new 3’ end of the RNA molecule using ATP as a precursor. As the poly(A) tail is synthesised, it binds multiple copies of poly(A) binding protein, which protects the 3’end from ribonuclease digestion. 9.6.22 Intron Splicing RNA splicing is the process by which introns, regions of RNA that do not code for proteins, are removed from the pre-mRNA and the remaining exons connected to re-form a single continuous molecule. Exons are sections of mRNA which become “expressed” or translated into a protein. They are the coding portions of a mRNA molecule. Although most RNA splicing occurs after the complete synthesis and end-capping of the pre-mRNA, transcripts with many exons can be spliced co-transcriptionally. The splicing reaction is catalyzed by a large protein complex called the spliceosome assembled from proteins and small nuclear RNA molecules that recognize splice sites in the pre-mRNA sequence. Many pre-mRNAs, including those encoding antibodies, can be spliced in multiple ways to produce different mature mRNAs that encode different protein sequences. This process is known as alternative splicing, and allows production of a large variety of proteins from a limited amount of DNA. 9.6.23 Reverse Transcription Some viruses (such as HIV, the cause of AIDS), have the ability to transcribe RNA into DNA. HIV has an RNA genome that is reverse transcribed into DNA. The resulting DNA can be merged with the DNA genome of the host cell. The main enzyme responsible for synthesis of DNA from an RNA template is called reverse transcriptase. In the case of HIV, reverse transcriptase is responsible for synthesizing a complementary DNA strand (cDNA) to the viral RNA genome. The enzyme ribonuclease H then digests the RNA strand, and reverse transcriptase synthesises a complementary strand of DNA to form a double helix DNA structure (“cDNA”). The cDNA is integrated into the host cell’s genome by the enzyme integrase, which causes the host cell to generate viral proteins that reassemble into new viral particles. In HIV, subsequent to this, the host cell undergoes programmed cell death, or apoptosis of T cells. However, in other retroviruses, the host cell remains intact as the virus buds out of the cell. Some eukaryotic cells contain an enzyme with reverse transcription activity called telomerase. Telomerase is a reverse transcriptase that lengthens the ends of linear chromosomes. Telomerase carries an RNA template from which it synthesizes a repeating sequence of DNA, or “junk” DNA. This repeated sequence of DNA is called a telomere and can be thought of as a “cap” for a chromosome. It is important because every time a linear chromosome is duplicated, it is shortened. With this “junk” DNA or “cap” at the ends of chromosomes, the shortening eliminates some of the non-essential, repeated sequence rather than the protein-encoding DNA sequence, that is farther away from the chromosome end. Telomerase is often activated in cancer cells to enable cancer cells to duplicate their genomes indefinitely without losing important protein-coding DNA sequence. Activation of telomerase could be part of the process that allows cancer cells to become immortal. The immortalizing factor of cancer via telomere lengthening due to telomerase has been proven to occur in 90% of all carcinogenic tumors in vivo with the remaining 10% using an alternative telomere maintenance route called ALT or Alternative Lengthening of Telomeres. 9.6.24 Translation And The Genetic Code In molecular biology and genetics, translation is the process in which ribosomes in the cytoplasm or endoplasmic reticulum (ER) synthesize proteins after the process of transcription of DNA to RNA in the cell’s nucleus. The entire process is called gene expression. 9.6.25 Ribosomes Ribosomes are complex macromolecular machines, found within all living cells, that serves as the site of biological protein synthesis. Ribosomes link amino acids together in the order specified by messenger RNA (RNA) molecules. Ribosomes consist of two major components: the small ribosomal subunits, which read the mRNA, and the large subunits, which join amino acids to form a polypeptide chain. Each subunit consists of one or more ribosomal RNA (rRNA) molecules and a variety of ribosomal proteins. The ribosomes and associated molecules are also known as the translational apparatus. The sequence of DNA, which encodes the sequence of the amino acids in a protein, is copied into a messenger RNA chain. It may be copied many times into RNA chains. Ribosomes can bind to a messenger RNA chain and use its sequence for determining the correct sequence of amino acids for generating a given protein. Amino acids are selected and collected and carried to the ribosome by transfer RNA (tRNA) molecules, which enter one part of the ribosome and bind to the messenger RNA chain. It is during this binding that the correct translation of nucleic acid sequence to amino acid sequence occurs. For each coding triplet in the messenger RNA there is a distinct transfer RNA that matches and which carries the correct amino acid for that coding triplet. The attached amino acids are then linked together by another part of the ribosome. Once the protein is produced, it can then fold to produce a specific functional three-dimensional structure although during synthesis some proteins start folding into their correct form. A ribosome is made from complexes of RNAs and proteins and is therefore a ribonucleoprotein. Each ribosome is divided into two subunits: a smaller subunit which binds to a larger subunit and the mRNA pattern, and a larger subunit which binds to the tRNA, the amino acids, and the smaller subunit. When a ribosome finishes reading an mRNA molecule, these two subunits split apart. Ribosomes are ribozymes, because the catalytic peptidyl transferase activity that links amino acids together is performed by the ribosomal RNA. Ribosomes are often associated with the intracellular membranes that make up the rough endoplasmic reticulum. Ribosomes from bacteria, archaea and eukaryotes in the three-domain system, resemble each other to a remarkable degree, evidence of a common origin. They differ in their size, sequence, structure, and the ratio of protein to RNA. The differences in structure allow some antibiotics to kill bacteria by inhibiting their ribosomes, while leaving human ribosomes unaffected. In bacteria and archaea, more than one ribosome may move along a single mRNA chain at one time, each “reading” its sequence and producing a corresponding protein molecule. The mitochondrial ribosomes of eukaryotic cells, are produced from mitochondrial genes, and functionally resemble many features of those in bacteria, reflecting the likely evolutionary origin of mitochondria. Ribosomes were first observed in the mid-1950s by Romanian-American cell biologist George Emil Palade, using an electron microscope, as dense particles or granules. The term “ribosome” was proposed by scientist Richard B. Roberts in the end of 1950s. Albert Claude, Christian de Duve, and George Emil Palade were jointly awarded the Nobel Prize in Physiology or Medicine, in 1974, for the discovery of the ribosome. The Nobel Prize in Chemistry 2009 was awarded to Venkatraman Ramakrishnan, Thomas A. Steitz and Ada E. Yonath for determining the detailed structure and mechanism of the ribosome. 9.6.26 Bacterial Ribosomes Prokaryotic ribosomes are around 20 nm (200 Å) in diameter and are composed of 65% rRNA and 35% ribosomal proteins. Eukaryotic ribosomes are between 25 and 30 nm (250–300 Å) in diameter with an rRNA-to-protein ratio that is close to 1. Crystallographic work has shown that there are no ribosomal proteins close to the reaction site for polypeptide synthesis. This suggests that the protein components of ribosomes do not directly participate in peptide bond formation catalysis, but rather that these proteins act as a scaffold that may enhance the ability of rRNA to synthesize protein Figure 9.15: Crystal structure of the bacterial 70S ribosome of the bacterium Thermus thermophilus. The 30S (small) ribosomal subunit proteins are colored in green, the 50S (large) subunit proteins are colored in blue, the ribosomal RNA is colored orange. The 30S subunits contains 3 tRNA molecules (based on atomic coordinates of PDB 1JGQ and PDB 1GIY rendered with open source molecular visualization tool PyMol.) The unit of measurement used to describe the ribosomal subunits and the rRNA fragments is the Svedberg unit, a measure of the rate of sedimentation in centrifugation rather than size. This accounts for why fragment names do not add up: for example, bacterial 70S ribosomes are made of 50S and 30S subunits. Bacteria have 70S ribosomes, each consisting of a small (30S) and a large (50S) subunit. Escherichia coli, for example, has a 16S RNA subunit (consisting of 1540 nucleotides) that is bound to 21 proteins. The large subunit is composed of a 5S RNA subunit (120 nucleotides), a 23S RNA subunit (2900 nucleotides) and 31 proteins. 9.6.27 Eukaryotic Ribosomes Eukaryotes have 80S ribosomes located in their cytosol, each consisting of a small (40S) and large (60S) subunit. Their 40S subunit has an 18S RNA (1900 nucleotides) and 33 proteins. The large subunit is composed of a 5S RNA (120 nucleotides), 28S RNA (4700 nucleotides), a 5.8S RNA (160 nucleotides) subunits and 46 proteins. Figure 9.16: Crystal structure of the human 80S ribosome (based on atomic coordinates of PDB 4V6X rendered with open source molecular visualization tool PyMol). The 40S (small) ribosomal subunit proteins are shown in lightblue, the 60S (large) subunit proteins in palegreen, the ribosomal RNA in orange. The differences between the bacterial and eukaryotic ribosomes are exploited by pharmaceutical chemists to create antibiotics that can kill bacteria without harming eukaryotic cells. Due to the differences in their structures, the bacterial 70S ribosomes are vulnerable to these antibiotics while the eukaryotic 80S ribosomes are not. The various ribosomes share a core structure, which is quite similar despite the large differences in size. Much of the RNA is highly organized into various tertiary structural motifs, for example pseudoknots that exhibit coaxial stacking. The extra RNA in the larger ribosomes is in several long continuous insertions, such that they form loops out of the core structure without disrupting or changing it. All of the catalytic activity of the ribosome is carried out by the RNA; the proteins reside on the surface and seem to stabilize the structure. Figure 9.17: Tertiary structure of tRNA (based on atomic coordinates of PDB 1ehz rendered with open source molecular visualization tool PyMol.) Aminoacyl tRNA synthetases (enzymes) catalyze the bonding between specific tRNAs and the amino acids that their anticodon sequences call for. The product of this reaction is an aminoacyl-tRNA. In prokaryotes, this aminoacyl-tRNA is carried to the ribosome by EF-Tu, where mRNA codons are matched through complementary base pairing to specific tRNA anticodons. The ribosome has three sites for tRNA to bind. They are the aminoacyl site (abbreviated A), the peptidyl site (abbreviated P) and the exit site (abbreviated E). With respect to the mRNA, the three sites are oriented 5’ to 3’ E-P-A, because ribosomes move toward the 3’ end of mRNA. The A-site binds the incoming tRNA with the complementary codon on the mRNA. The P-site holds the tRNA with the growing polypeptide chain. The E-site holds the tRNA without its amino acid, and the tRNA is then released. When an aminoacyl-tRNA initially binds to its corresponding codon on the mRNA, it is in the A site. Then, a peptide bond forms between the amino acid of the tRNA in the A site and the amino acid of the charged tRNA in the P site. The growing polypeptide chain is transferred to the tRNA in the A site. Translocation occurs, moving the tRNA in the P site, now without an amino acid, to the E site; the tRNA that was in the A site, now charged with the polypeptide chain, is moved to the P site. The tRNA in the E site leaves and another aminoacyl-tRNA enters the A site to repeat the process. After the new amino acid is added to the chain, and after the mRNA is released out of the nucleus and into the ribosome’s core, the energy provided by the hydrolysis of an ATP bound to the translocase EF-G (in prokaryotes) and eEF-2 (in eukaryotes) moves the ribosome down one codon towards the 3’ end. The energy required for translation of proteins is significant. For a protein containing n amino acids, the number of high-energy phosphate bonds required to translate it is 4n+1. The rate of translation varies; it is significantly higher in prokaryotic cells (up to 17-21 amino acid residues per second) than in eukaryotic cells (up to 6-9 amino acid residues per second). Even though the ribosomes are usually considered accurate, processive machines, the translation process is subject to errors that can lead either to the synthesis of erroneous proteins or to the premature abandonment of translation. The rate of error in synthesizing proteins has been estimated to be between 1/105 and 1/103 misincorporated amino acids, depending on the experimental conditions. The rate of premature translation abandonment, instead, has been estimated to be of the order of magnitude of 10−4 events per translated codon. The correct amino acid is covalently bonded to the correct transfer RNA (tRNA) by amino acyl transferases. The amino acid is joined by its carboxyl group to the 3’ OH of the tRNA by an ester bond. When the tRNA has an amino acid linked to it, the tRNA is termed “charged”. Initiation involves the small subunit of the ribosome binding to the 5’ end of mRNA with the help of initiation factors (IF). In prokaryotes, initiation of protein synthesis involves the recognition of a purine-rich initiation sequence on the mRNA called the Shine-Dalgarno sequence. The Shine-Dalgarno sequence binds to a complementary pyrimidine-rich sequence on the 3’ end of the 16S rRNA part of the 30S ribosomal subunit. The binding of these complementary sequences ensures that the 30S ribosomal subunit is bound to the mRNA and is aligned such that the initiation codon is placed in the 30S portion of the P-site. Once the mRNA and 30S subunit are properly bound, an initiation factor brings the initiator tRNA-amino acid complex, f-Met-tRNA, to the 30S P site. The initiation phase is completed once a 50S subunit joins the 30 subunit, forming an active 70S ribosome. Termination of the polypeptide occurs when the A site of the ribosome is occupied by a stop codon (UAA, UAG, or UGA) on the mRNA. mRNA usually cannot recognize or bind to stop codons. Instead, the stop codon induces the binding of a release factor protein (RF1 &amp; RF2) that prompts the disassembly of the entire ribosome/mRNA complex by the hydrolysis of the polypeptide chain from the peptidyl transferase center of the ribosome. Drugs or special sequence motifs on the mRNA can change the ribosomal structure so that near-cognate tRNAs are bound to the stop codon instead of the release factors. In such cases of ‘translational readthrough’, translation continues until the ribosome encounters the next stop codon. The process of translation is highly regulated in prokaryotic and eukaryotic organisms. Regulation of translation can impact the global rate of protein synthesis which is closely coupled to the metabolic and proliferative state of a cell. In addition, recent work has revealed that genetic differences and their subsequent expression as mRNAs can also impact translation rate in an RNA-specific manner. 9.6.28 Translation In translation, messenger RNA (mRNA) is decoded in the ribosome decoding center to produce a specific amino acid chain, or polypeptide. The polypeptide later folds into an active protein and performs its functions in the cell. The ribosome facilitates decoding by inducing the binding of complementary tRNA anticodon sequences to mRNA codons. The tRNAs carry specific amino acids that are chained together into a polypeptide a the mRNA passes through and is read by the ribosome. Translation proceeds in three phases: Initiation: The ribosome assembles around the target mRNA. The first tRNA is attached at the start codon. Elongation: The tRNA transfers an amino acid to the tRNA corresponding to the next codon. The ribosome then moves (translocates) to the next mRNA codon to continue the process, creating an amino acid chain. Termination: When a peptidyl tRNA encounters a stop codon, the ribosome detaches. Figure 9.18: Diagram showing the translation of mRNA and the synthesis of proteins by a ribosome. In prokaryotes, translation occurs in the cytosol, where the medium and small subunits of the ribosome bind to the tRNA. In eukaryotes, translation occurs in the cytosol or across the membrane of the endoplasmic reticulum in a process called co-translational translocation. In co-translational translocation, the entire ribosome/mRNA complex binds to the outer membrane of the rough endoplasmic reticulum (ER) and the new protein is synthesized and released into the ER. Many types of transcribed RNA, such as transfer RNA, ribosomal RNA, and small nuclear RNA, do not undergo translation into proteins. A number of antibiotics act by inhibiting translation. These include clindamycin, anisomycin, cycloheximide, chloramphenicol, tetracycline, streptomycin, erythromycin, and puromycin. Prokaryotic ribosomes have a different structure from that of eukaryotic ribosomes, and thus antibiotics can specifically target bacterial infections without any harm to a eukaryotic host’s cells. In 1954, Zamecnik and Hoagland discovered tRNA. In 1955, George E. Palade discovered ribosomes. 9.6.29 Eukaryotic Translation 9.6.30 Initiation Initiation of translation usually involves the interaction of certain key proteins, the initiation factors, with a special tag bound to the 5’-end of an mRNA molecule, the 5’ cap, as well as with the 5’ UTR. These proteins bind the small (40S) ribosomal subunit and hold the mRNA in place. eIF3 is associated with the 40S ribosomal subunit and plays a role in keeping the large (60S) ribosomal subunit from prematurely binding. eIF3 also interacts with the eIF4F complex, which consists of three other initiation factors: eIF4A, eIF4E, and eIF4G. eIF4G is a scaffolding protein that directly associates with both eIF3 and the other two components. eIF4E is the cap-binding protein. Binding of the cap by eIF4E is often considered the rate-limiting step of cap-dependent initiation, and the concentration of eIF4E is a regulatory nexus of translational control. Certain viruses cleave a portion of eIF4G that binds eIF4E, thus preventing cap-dependent translation to hijack the host machinery in favor of the viral (cap-independent) messages. eIF4A is an ATP-dependent RNA helicase that aids the ribosome by resolving certain secondary structures formed along the mRNA transcript. The poly(A)-binding protein (PABP) also associates with the eIF4F complex via eIF4G, and binds the poly-A tail of most eukaryotic mRNA molecules. This 43S preinitiation complex (43S PIC) accompanied by the protein factors moves along the mRNA chain toward its 3’-end, in a process known as ‘scanning’, to reach the start codon (typically AUG). In eukaryotes and archaea, the amino acid encoded by the start codon is methionine. The Met-charged initiator tRNA (Met-tRNAiMet) is brought to the P-site of the small ribosomal subunit by eukaryotic initiation factor 2 (eIF2). It hydrolyzes GTP, and signals for the dissociation of several factors from the small ribosomal subunit, eventually leading to the association of the large subunit (or the 60S subunit). The complete ribosome (80S) then commences translation elongation. Regulation of protein synthesis is partly influenced by phosphorylation of eIF2 (via the α subunit), which is a part of the eIF2-GTP-Met-tRNAiMet ternary complex (eIF2-TC). When large numbers of eIF2 are phosphorylated, protein synthesis is inhibited. This occurs under amino acid starvation or after viral infection. However, a small fraction of this initiation factor is naturally phosphorylated. Another regulator is 4EBP, which binds to the initiation factor eIF4E and inhibits its interactions with eIF4G, thus preventing cap-dependent initiation. To oppose the effects of 4EBP, growth factors phosphorylate 4EBP, reducing its affinity for eIF4E and permitting protein synthesis. While protein synthesis is globally regulated by modulating the expression of key initiation factors as well as the number of ribosomes, individual mRNAs can have different translation rates due to the presence of regulatory sequence elements. This has been shown to be important in a variety of settings including yeast meiosis and ethylene response in plants. In addition, recent work in yeast and humans suggest that evolutionary divergence in cis-regulatory sequences can impact translation regulation. Additionally, RNA helicases such as DHX29 and Ded1/DDX3 may participate in the process of translation initiation, especially for mRNAs with structured 5’UTRs. Cap-independent initiation The best-studied example of cap-independent translation initiation in eukaryotes is that by the Internal ribosome entry site (IRES). What differentiates cap-independent translation from cap-dependent translation is that cap-independent translation does not require the 5’ cap to initiate scanning from the 5’ end of the mRNA until the start codon. The ribosome can be trafficked to the start site by direct binding, initiation factors, and/or ITAFs (IRES trans-acting factors) bypassing the need to scan the entire 5’ UTR. This method of translation has been found important in conditions that require the translation of specific mRNAs during cellular stress, when overall translation is reduced. Examples include factors responding to apoptosis and stress-induced responses. 9.6.31 Elongation Elongation depends on eukaryotic elongation factors. At the end of the initiation step, the mRNA is positioned so that the next codon can be translated during the elongation stage of protein synthesis. The initiator tRNA occupies the P site in the ribosome, and the A site is ready to receive an aminoacyl-tRNA. During chain elongation, each additional amino acid is added to the nascent polypeptide chain in a three-step microcycle. The steps in this microcycle are (1) positioning the correct aminoacyl-tRNA in the A site of the ribosome, (2) forming the peptide bond and (3) shifting the mRNA by one codon relative to the ribosome. Unlike bacteria, in which translation initiation occurs as soon as the 5’ end of an mRNA is synthesized, in eukaryotes such tight coupling between transcription and translation is not possible because transcription and translation are carried out in separate compartments of the cell (the nucleus and cytoplasm). Eukaryotic mRNA precursors must be processed in the nucleus (e.g., capping, polyadenylation, splicing) before they are exported to the cytoplasm for translation. 9.6.32 Termination Termination of elongation depends on eukaryotic release factors. The process is similar to that of prokaryotic termination, but unlike prokaryotic termination, there is a universal release factor, eRF1, that recognizes all three stop codons. Upon termination, the ribosome is disassembled and the completed polypeptide is released. eRF3 is a ribosome-dependent GTPase that helps eRF1 release the completed polypeptide. "],["genetic-engineering-1.html", "10 Genetic Engineering 10.1 Genetically Modified Organisms 10.2 Gene therapy 10.3 Recombinant DNA Technology 10.4 Human Germline Modification 10.5 Gain-of-function Research 10.6 Genomics 10.7 Genetic Testing", " 10 Genetic Engineering Genetic engineering, also called genetic modification or genetic manipulation, is the direct manipulation of an organism’s genes using biotechnology. It is a set of technologies used to change the genetic makeup of cells, including the transfer of genes within and across species boundaries to produce improved or novel organisms. New DNA is obtained by either isolating and copying the genetic material of interest using recombinant DNA methods or by artificially synthesising the DNA. A construct is usually created and used to insert this DNA into the host organism. The first recombinant DNA molecule was made by Paul Berg in 1972 by combining DNA from the monkey virus SV40 with the lambda virus. As well as inserting genes, the process can be used to remove, or “knock out”, genes. The new DNA can be inserted randomly, or targeted to a specific part of the genome. An organism that is generated through genetic engineering is considered to be genetically modified (GM) and the resulting entity is a genetically modified organism (GMO). The first GMO was a bacterium generated by Herbert Boyer and Stanley Cohen in 1973. Rudolf Jaenisch created the first GM animal when he inserted foreign DNA into a mouse in 1974. The first company to focus on genetic engineering, Genentech, was founded in 1976 and started the production of human proteins. Genetically engineered human insulin was produced in 1978 and insulin-producing bacteria were commercialised in 1982. Genetically modified food has been sold since 1994, with the release of the Flavr Savr tomato. The Flavr Savr was engineered to have a longer shelf life, but most current GM crops are modified to increase resistance to insects and herbicides. GloFish, the first GMO designed as a pet, was sold in the United States in December 2003. In 2016 salmon modified with a growth hormone were sold. Genetic engineering has been applied in numerous fields including research, medicine, industrial biotechnology and agriculture. In research GMOs are used to study gene function and expression through loss of function, gain of function, tracking and expression experiments. By knocking out genes responsible for certain conditions it is possible to create animal model organisms of human diseases. As well as producing hormones, vaccines and other drugs, genetic engineering has the potential to cure genetic diseases through gene therapy. The same techniques that are used to produce drugs can also have industrial applications such as producing enzymes for laundry detergent, cheeses and other products. The rise of commercialised genetically modified crops has provided economic benefit to farmers in many different countries, but has also been the source of most of the controversy surrounding the technology. This has been present since its early use; the first field trials were destroyed by anti-GM activists. Although there is a scientific consensus that currently available food derived from GM crops poses no greater risk to human health than conventional food, GM food safety is a leading concern with critics. Gene flow, impact on non-target organisms, control of the food supply and intellectual property rights have also been raised as potential issues. These concerns have led to the development of a regulatory framework, which started in 1975. It has led to an international treaty, the Cartagena Protocol on Biosafety, that was adopted in 2000. Individual countries have developed their own regulatory systems regarding GMOs, with the most marked differences occurring between the US and Europe. Comparison of conventional plant breeding with transgenic and cisgenic genetic modification Genetic engineering is a process that alters the genetic structure of an organism by either removing or introducing DNA. Unlike traditional animal and plant breeding, which involves doing multiple crosses and then selecting for the organism with the desired phenotype, genetic engineering takes the gene directly from one organism and delivers it to the other. This is much faster, can be used to insert any genes from any organism (even ones from different domains) and prevents other undesirable genes from also being added. Genetic engineering could potentially fix severe genetic disorders in humans by replacing the defective gene with a functioning one. It is an important tool in research that allows the function of specific genes to be studied. Drugs, vaccines and other products have been harvested from organisms engineered to produce them. Crops have been developed that aid food security by increasing yield, nutritional value and tolerance to environmental stresses. The DNA can be introduced directly into the host organism or into a cell that is then fused or hybridised with the host. This relies on recombinant nucleic acid techniques to form new combinations of heritable genetic material followed by the incorporation of that material either indirectly through a vector system or directly through micro-injection, macro-injection or micro-encapsulation. Genetic engineering does not normally include traditional breeding, in vitro fertilisation, induction of polyploidy, mutagenesis and cell fusion techniques that do not use recombinant nucleic acids or a genetically modified organism in the process. However, some broad definitions of genetic engineering include selective breeding. Cloning and stem cell research, although not considered genetic engineering, are closely related and genetic engineering can be used within them. Synthetic biology is an emerging discipline that takes genetic engineering a step further by introducing artificially synthesised material into an organism. Such synthetic DNA as Artificially Expanded Genetic Information System and Hachimoji DNA is made in this new field. Plants, animals or microorganisms that have been changed through genetic engineering are termed genetically modified organisms or GMOs. If genetic material from another species is added to the host, the resulting organism is called transgenic. If genetic material from the same species or a species that can naturally breed with the host is used the resulting organism is called cisgenic. If genetic engineering is used to remove genetic material from the target organism the resulting organism is termed a knockout organism. In Europe genetic modification is synonymous with genetic engineering while within the United States of America and Canada genetic modification can also be used to refer to more conventional breeding methods.u Genetic engineering is a process that alters the genetic structure of an organism by either removing or introducing DNA. Unlike traditional animal and plant breeding, which involves doing multiple crosses and then selecting for the organism with the desired phenotype, genetic engineering takes the gene directly from one organism and delivers it to the other. This is much faster, can be used to insert any genes from any organism (even ones from different domains) and prevents other undesirable genes from also being added. Genetic engineering could potentially fix severe genetic disorders in humans by replacing the defective gene with a functioning one. It is an important tool in research that allows the function of specific genes to be studied. Drugs, vaccines and other products have been harvested from organisms engineered to produce them. Crops have been developed that aid food security by increasing yield, nutritional value and tolerance to environmental stresses. The DNA can be introduced directly into the host organism or into a cell that is then fused or hybridised with the host. This relies on recombinant nucleic acid techniques to form new combinations of heritable genetic material followed by the incorporation of that material either indirectly through a vector system or directly through micro-injection, macro-injection or micro-encapsulation. Genetic engineering does not normally include traditional breeding, in vitro fertilisation, induction of polyploidy, mutagenesis and cell fusion techniques that do not use recombinant nucleic acids or a genetically modified organism in the process. However, some broad definitions of genetic engineering include selective breeding. Cloning and stem cell research, although not considered genetic engineering, are closely related and genetic engineering can be used within them. Synthetic biology is an emerging discipline that takes genetic engineering a step further by introducing artificially synthesised material into an organism. Such synthetic DNA as Artificially Expanded Genetic Information System and Hachimoji DNA is made in this new field. Plants, animals or microorganisms that have been changed through genetic engineering are termed genetically modified organisms or GMOs. If genetic material from another species is added to the host, the resulting organism is called transgenic. If genetic material from the same species or a species that can naturally breed with the host is used the resulting organism is called cisgenic. If genetic engineering is used to remove genetic material from the target organism the resulting organism is termed a knockout organism. In Europe genetic modification is synonymous with genetic engineering while within the United States of America and Canada genetic modification can also be used to refer to more conventional breeding methods. Humans have altered the genomes of species for thousands of years through selective breeding, or artificial selection:1:1 as contrasted with natural selection. More recently, mutation breeding has used exposure to chemicals or radiation to produce a high frequency of random mutations, for selective breeding purposes. Genetic engineering as the direct manipulation of DNA by humans outside breeding and mutations has only existed since the 1970s. The term “genetic engineering” was first coined by Jack Williamson in his science fiction novel Dragon’s Island, published in 1951 – one year before DNA’s role in heredity was confirmed by Alfred Hershey and Martha Chase, and two years before James Watson and Francis Crick showed that the DNA molecule has a double-helix structure – though the general concept of direct genetic manipulation was explored in rudimentary form in Stanley G. Weinbaum’s 1936 science fiction story Proteus Island. In 1972, Paul Berg created the first recombinant DNA molecules by combining DNA from the monkey virus SV40 with that of the lambda virus. In 1973 Herbert Boyer and Stanley Cohen created the first transgenic organism by inserting antibiotic resistance genes into the plasmid of an Escherichia coli bacterium. A year later Rudolf Jaenisch created a transgenic mouse by introducing foreign DNA into its embryo, making it the world’s first transgenic animal These achievements led to concerns in the scientific community about potential risks from genetic engineering, which were first discussed in depth at the Asilomar Conference in 1975. One of the main recommendations from this meeting was that government oversight of recombinant DNA research should be established until the technology was deemed safe. In 1976 Genentech, the first genetic engineering company, was founded by Herbert Boyer and Robert Swanson and a year later the company produced a human protein (somatostatin) in E.coli. Genentech announced the production of genetically engineered human insulin in 1978. In 1980, the U.S. Supreme Court in the Diamond v. Chakrabarty case ruled that genetically altered life could be patented. The insulin produced by bacteria was approved for release by the Food and Drug Administration (FDA) in 1982. In 1983, a biotech company, Advanced Genetic Sciences (AGS) applied for U.S. government authorisation to perform field tests with the ice-minus strain of Pseudomonas syringae to protect crops from frost, but environmental groups and protestors delayed the field tests for four years with legal challenges. In 1987, the ice-minus strain of P. syringae became the first genetically modified organism (GMO) to be released into the environment when a strawberry field and a potato field in California were sprayed with it. Both test fields were attacked by activist groups the night before the tests occurred: “The world’s first trial site attracted the world’s first field trasher”. The first field trials of genetically engineered plants occurred in France and the US in 1986, tobacco plants were engineered to be resistant to herbicides. The People’s Republic of China was the first country to commercialise transgenic plants, introducing a virus-resistant tobacco in 1992. In 1994 Calgene attained approval to commercially release the first genetically modified food, the Flavr Savr, a tomato engineered to have a longer shelf life. In 1994, the European Union approved tobacco engineered to be resistant to the herbicide bromoxynil, making it the first genetically engineered crop commercialised in Europe. In 1995, Bt Potato was approved safe by the Environmental Protection Agency, after having been approved by the FDA, making it the first pesticide producing crop to be approved in the US. In 2009 11 transgenic crops were grown commercially in 25 countries, the largest of which by area grown were the US, Brazil, Argentina, India, Canada, China, Paraguay and South Africa. In 2010, scientists at the J. Craig Venter Institute created the first synthetic genome and inserted it into an empty bacterial cell. The resulting bacterium, named Mycoplasma laboratorium, could replicate and produce proteins. Four years later this was taken a step further when a bacterium was developed that replicated a plasmid containing a unique base pair, creating the first organism engineered to use an expanded genetic alphabet. In 2012, Jennifer Doudna and Emmanuelle Charpentier collaborated to develop the CRISPR/Cas9 system, a technique which can be used to easily and specifically alter the genome of almost any organism. 10.1 Genetically Modified Organisms A genetically modified organism (GMO) is any organism whose genetic material has been altered using genetic engineering techniques. The exact definition of a genetically modified organism and what constitutes genetic engineering varies, with the most common being an organism altered in a way that “does not occur naturally by mating and/or natural recombination”. A wide variety of organisms have been genetically modified (GM), from animals to plants and microorganisms. Genes have been transferred within the same species, across species (creating transgenic organisms) and even across kingdoms. New genes can be introduced, or endogenous genes can be enhanced, altered or knocked out. Herbert Boyer and Stanley Cohen made the first genetically modified organism in 1973, a bacteria resistant to the antibiotic kanamycin. The first genetically modified animal, a mouse, was created in 1974 by Rudolf Jaenisch, and the first plant was produced in 1983. In 1994 the Flavr Savr tomato was released, the first commercialized genetically modified food. The first genetically modified animal to be commercialized was the GloFish (2003) and the first genetically modified animal to be approved for food use was the AquAdvantage salmon in 2015. Bacteria are the easiest organisms to engineer and have been used for research, food production, industrial protein purification (including drugs), agriculture, and art. There is potential to use them for environmental, purposes or as medicine. Fungi have been engineered with much the same goals. Viruses play an important role as vectors for inserting genetic information into other organisms. This use is especially relevant to human gene therapy. There are proposals to remove the virulent genes from viruses to create vaccines. Plants have been engineered for scientific research, to create new colors in plants, deliver vaccines and to create enhanced crops. Genetically modified crops are publicly the most controversial GMOs. The majority are engineered for herbicide tolerance or insect resistance. Golden rice has been engineered with three genes that increase its nutritional value. Other prospects for GM crops are as bioreactors for the production of biopharmaceuticals, biofuels or medicines. Animals are generally much harder to transform and the vast majority are still at the research stage. Mammals are the best model organisms for humans, making ones genetically engineered to resemble serious human diseases important to the discovery and development of treatments. Human proteins expressed in mammals are more likely to be similar to their natural counterparts than those expressed in plants or microorganisms. Livestock are modified with the intention of improving economically important traits such as growth-rate, quality of meat, milk composition, disease resistance and survival. Genetically modified fish are used for scientific research, as pets and as a food source. Genetic engineering has been proposed as a way to control mosquitos, a vector for many deadly diseases. Although human gene therapy is still relatively new, it has been used to treat genetic disorders such as severe combined immunodeficiency, and Leber’s congenital amaurosis. Many objections have been raised over the development of GMO’s, particularly their commercialization. Many of these involve GM crops and whether food produced from them is safe and what impact growing them will have on the environment. Other concerns are the objectivity and rigor of regulatory authorities, contamination of non-genetically modified food, control of the food supply, patenting of life and the use of intellectual property rights. Although there is a scientific consensus that currently available food derived from GM crops poses no greater risk to human health than conventional food, GM food safety is a leading issue with critics. Gene flow, impact on non-target organisms and escape are the major environmental concerns. Countries have adopted regulatory measures to deal with these concerns. There are differences in the regulation for the release of GMOs between countries, with some of the most marked differences occurring between the US and Europe. One of the key issues concerning regulators is whether GM food should be labeled and the status of gene edited organisms. What constitutes a genetically modified organism (GMO) is not always clear and can vary widely. At its broadest it can include anything that has had its genes altered, including by nature. Taking a less broad view it can encompass every organism that has had its genes altered by humans, which would include all crops and livestock. In 1993 the Encyclopedia Britannica defined genetic engineering as “any of a wide range of techniques … among them artificial insemination, in vitro fertilization (e.g.,”test-tube\" babies), sperm banks, cloning, and gene manipulation.\" The European Union (EU) included a similarly broad definition in early revies, specifically mentioning GMOs being produced by “selective breeding and other means of artificial selection.” They later excluded traditional breeding, in vitro fertilization, induction of polyploidy, mutagenesis and cell fusion techniques that do not use recombinant nucleic acids or a genetically modified organism in the process. A narrower definition provided by the Food and Agriculture Organization, the World Health Organization and the European Commission says that the organisms must be altered in a way that does “not occur naturally by mating and/or natural recombination”. There are examples of crops that fit this definition, but are not normally considered GMOs. For example, the grain crop triticale was fully developed in a laboratory in 1930 using various techniques to alter its genome. The Cartagena Protocol on Biosafety in 2000 used the synonym living modified organism (LMO) and defined it as “any living organism that possesses a novel combination of genetic material obtained through the use of modern biotechnology.” Modern biotechnology is further defined as “In vitro nucleic acid techniques, including recombinant deoxyribonucleic acid (DNA) and direct injection of nucleic acid into cells or organelles, or fusion of cells beyond the taxonomic family.” Genetically engineered organism (GEO) can be considered a more precise term compared to GMO when describing organisms’ genomes that have been directly manipulated with biotechnology. The term GMO originally was not typically used by scientists to describe genetically engineered organisms until after usage of GMO became common in popular media. The United States Department of Agriculture (USDA) considers GMOs to be plants or animals with heritable changes introduced by genetic engineering or traditional methods, while GEO specifically refers to organisms with genes introduced, eliminated, or rearranged using molecular biology, particularly recombinant DNA techniques, such as transgenesis. The definitions focus on the process more than the product, which means there could be GMOS and non-GMOs with very similar genotypes and phenotypes. This has led scientists to label it as a scientifically meaningless category, saying that it is impossible to group all the different types of GMOs under one common definition. It has also caused issues for organic institutions and groups looking to ban GMOs. It also poses problems as new processes are developed. The current definitions came in before genome editing became popular and there is some confusion as to whether they are GMOs. The EU has adjudged that they are changing their GMO definition to include “organisms obtained by mutagenesis”. In contrast the USDA has ruled that gene edited organisms are not considered GMOs. 10.1.1 Production Creating a genetically modified organism (GMO) is a multi-step process. Genetic engineers must isolate the gene they wish to insert into the host organism. This gene can be taken from a cell or artificially synthesized. If the chosen gene or the donor organism’s genome has been well studied it may already be accessible from a genetic library. The gene is then combined with other genetic elements, including a promoter and terminator region and a selectable marker. A number of techniques are available for inserting the isolated gene into the host genome. Bacteria can be induced to take up foreign DNA, usually by exposed heat shock or electroporation. DNA is generally inserted into animal cells using microinjection, where it can be injected through the cell’s nuclear envelope directly into the nucleus, or through the use of viral vectors. In plants the DNA is often inserted using Agrobacterium-mediated recombination, biolistics or electroporation. As only a single cell is transformed with genetic material, the organism must be regenerated from that single cell. In plants this is accomplished through tissue culture. In animals it is necessary to ensure that the inserted DNA is present in the embryonic stem cells. Further testing using PCR, Southern hybridization, and DNA sequencing is conducted to confirm that an organism contains the new gene. Traditionally the new genetic material was inserted randomly within the host genome. Gene targeting techniques, which creates double-stranded breaks and takes advantage on the cells natural homologous recombination repair systems, have been developed to target insertion to exact locations. Genome editing uses artificially engineered nucleases that create breaks at specific points. There are four families of engineered nucleases: meganucleases, zinc finger nucleases, transcription activator-like effector nucleases (TALENs), and the Cas9-guideRNA system (adapted from CRISPR) TALEN and CRISPR are the two most commonly used and each has its own advantages. TALENs have greater target specificity, while CRISPR is easier to design and more efficient. Humans have domesticated plants and animals since around 12,000 BCE, using selective breeding or artificial selection (as contrasted with natural selection). The process of selective breeding, in which organisms with desired traits (and thus with the desired genes) are used to breed the next generation and organisms lacking the trait are not bred, is a precursor to the modern concept of genetic modification.:1:1 Various advancements in genetics allowed humans to directly alter the DNA and therefore genes of organisms. In 1972 Paul Berg created the first recombinant DNA molecule when he combined DNA from a monkey virus with that of the lambda virs. Herbert Boyer and Stanley Cohen made the first genetically modified organism in 1973. They took a gene from a bacterium that provided resistance to the antibiotic kanamycin, inserted it into a plasmid and then induced other bacteria to incorporate the plasmid. The bacteria that had successfully incorporated the plasmid was then able to survive in the presence of kanamycin. Boyer and Cohen expressed other genes in bacteria. This included genes from the toad Xenopus laevis in 1974, creating the first GMO expressing a gene from an organism of a different kingdom. In 1974, Rudolf Jaenisch created a transgenic mouse by introducing foreign DNA into its embryo, making it the world’s first transgenic animal. However it took another eight years before transgenic mice were developed that passed the transgene to their offspring. Genetically modified mice were created in 1984 that carried cloned oncogenes, predisposing them to developing cancer. Mice with genes removed (termed a knockout mouse) were created in 1989. The first transgenic livestock were produced in 1985 and the first animal to synthesize transgenic proteins in their milk were mice in 1987. The mice were engineered to produce human tissue plasminogen activator, a protein involved in breaking down blood clots. In 1983 the first genetically engineered plant was developed by Michael W. Bevan, Richard B. Flavell and Mary-Dell Chilton. They infected tobacco with Agrobacterium transformed with an antibiotic resistance gene and through tissue culture techniques were able to grow a new plant containing the resistance gene. The gene gun was invented in 1987, allowing transformation of plants not susceptible to Agrobacterium infection. In 2000, Vitamin A-enriched golden rice was the first plant developed with increased nutrient value. In 1976 Genentech, the first genetic engineering company was founded by Herbert Boyer and Robert Swanson; a year later, the company produced a human protein (somatostatin) in E.coli. Genentech announced the production of genetically engineered human insulin in 1978. The insulin produced by bacteria, branded humulin, was approved for release by the Food and Drug Administration in 1982. In 1988 the first human antibodies were produced in plants. In 1987, a strain of Pseudomonas syringae became the first genetically modified organism to be released into the environment when a strawberry and potato field in California were sprayed with it. The first genetically modified crop, an antibiotic-resistant tobacco plant, was produced in 1982. China was the first country to commercialize transgenic plants, introducing a virus-resistant tobacco in 1992. In 1994 Calgene attained approval to commercially release the Flavr Savr tomato, the first genetically modified food. Also in 1994, the European Union approved tobacco engineered to be resistant to the herbicide bromoxynil, making it the first genetically engineered crop commercialized in Europe. An insect resistant Potato was approved for release in the US in 1995, and by 1996 approval had been granted to commercially grow 8 transgenic crops and one flower crop (carnation) in 6 countries plus the EU. In 2010, scientists at the J. Craig Venter Institute announced that they had created the first synthetic bacterial genome. The first genetically modified animal to be commercialized was the GloFish, a Zebra fish with a fluorescent gene added that allows it to glow in the dark under ultraviolet light. It was released to the US market in 2003. In 2015 AquAdvantage salmon became the first genetically modified animal to be approved for food use. Approval is for fish raised in Panama and sold in the US. The salmon were transformed with a growth hormone-regulating gene from a Pacific Chinook salmon and a promoter from an ocean pout enabling it to grow year-round instead of only during spring and summer. 10.1.2 Bacteria Bacteria were the first organisms to be genetically modified in the laboratory, due to the relative ease of modifying their chromosomes. This ease made them important tools for the creation of other GMOs. Genes and other genetic information from a wide range of organisms can be added to a plasmid and inserted into bacteria for storage and modification. Bacteria are cheap, easy to grow, clonal, multiply quickly and can be stored at −80 °C almost indefinitely. Once a gene is isolated it can be stored inside the bacteria, providing an unlimited supply for research. A large number of custom plasmids make manipulating DNA extracted from bacteria relatively easy. Their ease of use has made them great tools for scientists looking to study gene function and evolution. The simplest model organisms come from bacteria, with most of our early understanding of molecular biology coming from studying Escherichia coli. Scientists can easily manipulate and combine genes within the bacteria to create novel or disrupted proteins and observe the effect this has on various molecular systems. Researchers have combined the genes from bacteria and archaea, leading to insights on how these two diverged in the past. In the field of synthetic biology, they have been used to test various synthetic approaches, from synthesising genomes tocreating novel nucleotides. Bacteria have been used in the production of food for a long time, and specific strains have been developed and selected for that work on an industrial scale. They can be used to produce enzymes, amino acids, flavourings, and other compounds used in food production. With the advent of genetic engineering, new genetic changes can easily be introduced into these bacteria. Most food-producing bacteria are lactic acid bacteria, and this is where the majority of research into genetically engineering food-producing bacteria has gone. The bacteria can be modified to operate more efficiently, reduce toxic byproduct production, increase output, create improved compounds, and remove unnecessary pathways. Food products from genetically modified bacteria include alpha-amylase, which converts starch to simple sugars, chymosin, which clots milk protein for cheese making, and pectinesterase, which improves fruit juice clarity. The majority are produced in the US and even though regulations are in place to allow production in Europe, as of 2015 no food products derived from bacteria are currently available there. Genetically modified bacteria are used to produce large amounts of proteins for industrial use. Generally the bacteria are grown to a large volume before the gene encoding the protein is activated. The bacteria are then harvested and the desired protein purified from them. The high cost of extraction and purification has meant that only high value products have been produced at an industrial scale. The majority of these products are human proteins for use in medicine. Many of these proteins are impossible or difficult to obtain via natural methods and they are less likely to be contaminated with pathogens, making them safer. The first medicinal use of GM bacteria was to produce the protein insulin to treat diabetes. Other medicines produced include clotting factors to treat haemophilia, human growth hormone to treat various forms of dwarfism, interferon to treat some cancers, erythropoietin for anemic patients, and tissue plasminogen activator which dissolves blood clots. Outside of medicine they have been used to produce biofuels. There is interest in developing an extracellular expression system within the bacteria to reduce costs and make the production of more products economical. With greater understanding of the role that the microbiome plays in human health, there is the potential to treat diseases by genetically altering the bacteria to, themselves, be therapeutic agents. Ideas include altering gut bacteria so they destroy harmful bacteria, or using bacteria to replace or increase deficient enzymes or proteins. One research focus is to modify Lactobacillus, bacteria that naturally provide some protection against HIV, with genes that will further enhance this protection. If the bacteria do not form colonies inside the patient, the person must repeatedly ingest the modified bacteria in order to get the required doses. Enabling the bacteria to form a colony could provide a more long-term solution, but could also raise safety concerns as interactions between bacteria and the human body are less well understood than with traditional drugs. There are concerns that horizontal gene transfer to other bacteria could have unknown effects. As of 2018 there are clinical trials underway testing the efficacy and safety of these treatments. For over a century bacteria have been used in agriculture. Crops have been inoculated with Rhizobia (and more recently Azospirillum) to increase their production or to allow them to be grown outside their original habitat. Application of Bacillus thuringiensis (Bt) and other bacteria can help protect crops from insect infestation and plant diseases. With advances in genetic engineering, these bacteria have been manipulated for increased efficiency and expanded host range. Markers have also been added to aid in tracing the spread of the bacteria. The bacteria that naturally colonize certain crops have also been modified, in some cases to express the Bt genes responsible for pest resistance. Pseudomonas strains of bacteria cause frost damage by nucleating water into ice crystals around themselves. This led to the development of ice-minus bacteria, that have the ice-forming genes removed. When applied to crops they can compete with the non-modified bacteria and confer some frost resistance. Other uses for genetically modified bacteria include bioremediation, where the bacteria are used to convert pollutants into a less toxic form. Genetic engineering can increase the levels of the enzymes used to degrade a toxin or to make the bacteria more stable under environmental conditions. Bioart has also been created using genetically modified bacteria. In the 1980s artist Jon Davis and geneticist Dana Boyd converted the Germanic symbol for femininity (ᛉ) into binary code and then into a DNA sequence, which was then expressed in Escherichia coli. This was taken a step further in 2012, when a whole book was encoded onto DNA. Paintings have alo been produced using bacteria transformed with fluorescent proteins. 10.1.3 Viruses Viruses are often modified so they can be used as vectors for inserting genetic information into other organisms. This process is called transduction and if successful the recipient of the introduced DNA becomes a GMO. Different viruses have different efficiencies and capabilities. Researchers can use this to control for various factors; including the target location, insert size and duration of gene expression. Any dangerous sequences inherent in the virus must be removed, while those that allow the gene to be delivered effectively are retained. While viral vectors can be used to insert DNA into almost any organism it is especially relevant for its potential in treating human disease. Although primarily still at trial stages, there has been some successes using gene therapy to replace defective genes. This is most evident in curing patients with severe combined immunodeficiency rising from adenosine deaminase deficiency (ADA-SCID), although the development of leukemia in some ADA-SCID patients along with the death of Jesse Gelsinger in a 1999 trial set back the development of this approach for many years. In 2009 another breakthrough was achieved when an eight-year-old boy with Leber’s congenital amaurosis regained normal eyesight and in 2016 GlaxoSmithKline gained approval to commercialize a gene therapy treatment for ADA-SCID. As of 2018, there are a substantial number of clinical trials underway, including treatments for hemophilia, glioblastoma, chronic granulomatous disease, cystic fibrosis and various cancers. The most common virus used for gene delivery come from adenoviruses as they can carry up to 7.5 kb of foreign DNA and infect a relatively broad range of host cells, although they have been know to elicit immune responses in the host and only provide short term expression. Other common vectors are adeno-associated viruses, which have lower toxicity and longer term expression, but can only carry about 4kb of DNA. Herpes simplex viruses make promising vectors, having a carrying capacity of over 30kb and providing long term expression, although they are less efficient at gene delivery than other vectors. The best vectors for long term integration of the gene into the host genome are retroviruses, but their propensity for random integration is problematic. Lentiviruses are a part of the same family as retroviruses with the advantage of infecting both dividing and non-dividing cells, whereas retroviruses only target dividing cells. Other viruses that have been used as vectors include alphaviruses, flaviviruses, measles viruses, rhabdoviruses, Newcastle disease virus, poxviruses, and picornaviruses. Most vaccines consist of viruses that have been attenuated, disabled, weakened or killed in some way so that their virulent properties are no longer effective. Genetic engineering could theoretically be used to create viruses with the virulent genes removed. This does not affect the viruses infectivity, invokes a natural immune response and there is no chance that they will regain their virulence function, which can occur with some other vaccines. As such they are generally considered safer and more efficient than conventional vaccines, although concerns remain over non-target infection, potential side effects and horizontal gene transfer to other viruses. Another potential approach is to use vectors to create novel vaccines for diseases that have no vaccines available or the vaccines that do not work effectively, such as AIDS, malaria, and tuberculosis. The most effective vaccine against Tuberculosis, the Bacillus Calmette–Guérin (BCG) vaccine, only provides partial protection. A modified vaccine expressing a M tuberculosis antigen is able to enhance BCG protection. It has been shown to be safe to use at phase II trials, although not as effective as initially hoped. Other vector-based vaccines have already been approved and many more are being developed. Another potential use of genetically modified viruses is to alter them so they can directly treat diseases. This can be through expression of protective proteins or by directly targeting infected cells. In 2004, researchers reported that a genetically modified virus that exploits the selfish behaviour of cancer cells might offer an alternative way of killing tumours. Since then, several researchers have developed genetically modified oncolytic viruses that show promise as treatments for various types of cancer. In 2017 researchers genetically modified a virus to express spinach defensin proteins. The virus was injected into orange trees to combat citrus greening disease that had reduced orange production by 70% since 2005. Natural viral diseases, such as myxomatosis and rabbit haemorrhagic disease, have been used to help control pest populations. Over time the surviving pests become resistant, leading researchers to look at alternative methods. Genetically modified viruses that make the target animals infertile through immunocontraception have been created in the laboratory as well as others that target the developmental stage of the animal. There are concerns with using this approach regarding virus containment and cross species infection. Sometimes the same virus can be modified for contrasting purposes. Genetic modification of the myxoma virus has been proposed to conserve European wild rabbits in the Iberian peninsula and to help regulate them in Australia. To protect the Iberian species from viral diseases, the myxoma virus was genetically modified to immunize the rabbits, while in Australia the same myxoma virus was genetically modified to lower fertility in the Australian rabbit population. Outside of biology scientists have used a genetically modified virus to construct a lithium-ion battery and other nanostructured materials. It is possible to engineer bacteriophages to express modified proteins on their surface and join them up in specific patterns (a technique called phage display). These structures have potential uses for energy storage and generation, biosensing and tissue regeneration with some new materials currently produced including quantum dots, liquid crystals, nanorings and nanofibres. The battery was made by engineering M13 bacteriaophages so they would coat themselves in iron phosphate and then assemble themselves along a carbon nanotube. This created a highly conductive medium for use in a cathode, allowing energy to be transferred quickly. They could be constructed at lower temperatures with non-toxic chemicals, making them more environmentally friendly. 10.1.4 Fungi Fungi can be used for many of the same processes as bacteria. For industrial applications, yeasts combines the bacterial advantages of being a single celled organism that is easy to manipulate and grow with the advanced protein modifications found in eukaryotes. They can be used to produce large complex molecules for use in food, pharmaceuticals, hormones and steroids. Yeast is important for wine production and as of 2016 two genetically modified yeasts involved in the fermentation of wine have been commercialized in the United States and Canada. One has increased malolactic fermentation efficiency, while the other prevents the production of dangerous ethyl carbamate compounds during fermentation. There have also been advances in the production of biofuel from genetically modified fungi. Fungi, being the most common pathogens of insects, make attractive biopesticides. Unlike bacteria and viruses they have the advantage of infecting the insects by contact alone, although they are out competed in efficiency by chemical pesticides. Genetic engineering can improve virulence, usually by adding more virulent proteins, increasing infection rate or enhancing spore persistence. Many of the disease carrying vectors are susceptible to entomopathogenic fungi. An attractive target for biological control are mosquitos, vectors for a range of deadly diseases, including malaria, yellow fever and dengue fever. Mosquitos can evolve quickly so it becomes a balancing act of killing them before the Plasmodium they carry becomes the infectious disease, but not so fast that they become resistant to the fungi. By genetically engineering fungi like Metarhizium anisopliae and Beauveria bassiana to delay the development of mosquito infectiousness the selection pressure to evolve resistance is reduced. Another strategy is to add proteins to the fungi that block transmission of malaria or remove the Plasmodium altogether. A mushroom has been gene edited to resist browning, giving it a longer shelf life. The process used CRISPR to knock out a gene that encodes polyphenol oxidase. As it didn’t introduce any foreign DNA into the organism it was not deemed to be regulated under existing GMO frameworks and as such is the first CRISPR-edited organism to be approved for release. This has intensified debates as to whether gene-edited organisms should be considered genetically modified organisms and how they should be regulated. 10.1.5 Plants Plants have been engineered for scientific research, to display new flower colors, deliver vaccines and to create enhanced crops. Many plants are pluripotent, meaning that a single cell from a mature plant can be harvested and under the right conditions can develop into a new plant. This ability can be taken advantage of by genetic engineers; by selecting for cells that have been successfully transformed in an adult plant a new plant can then be grown that contains the transgene in every cell through a process known as tissue culture. Much of the advances in the field of genetic engineering has come from experimentation with tobacco. Major advances in tissue culture and plant cellular mechanisms for a wide range of plants has originated from systems developed in tobacco. It was the first plant to be altered using genetic engineering and is considered a model organism for not only genetic engineering, but a range of other fields. As such the transgenic tools and procedures are well established making tobacco one of the easiest plants to transform. Another major model organism relevant to genetic engineering is Arabidopsis thaliana. Its small genome and short life cycle makes it easy to manipulate and it contains many homologues to important crop species. It was the first plant sequenced, has a host of online resources available and can be transformed by simply dipping a flower in a transformed Agrobacterium solution. In research, plants are engineered to help discover the functions of certain genes. The simplest way to do this is to remove the gene and see what phenotype develops compared to the wild type form. Any differences are possibly the result of the missing gene. Unlike mutagenisis, genetic engineering allows targeted removal without disrupting other genes in the organism. Some genes are only expressed in certain tissue, so reporter genes, like GUS, can be attached to the gene of interest allowing visualization of the location. Other ways to test a gene is to alter it slightly and then return it to the plant and see if it still has the same effect on phenotype. Other strategies include attaching the gene to a strong promoter and see what happens when it is over expressed, forcing a gene to be expressed in a different location or at different developmental stages. Some genetically modified plants are purely ornamental. They are modified for flower color, fragrance, flower shape and plant architecture. The first genetically modified ornamentals commercialized altered color. Carnations were released in 1997, with the most popular genetically modified organism, a blue rose (actually lavender or mauve) created in 2004. The roses are sold in Japan, the United States, and Canada. Other genetically modified ornamentals include Chrysanthemum and Petunia. As well as increasing aesthetic value there are plans to develop ornamentals that use less water or are resistant to the cold, which would allow them to be grown outside their natural environments. It has been proposed to genetically modify some plant species threatened by extinction to be resistant to invasive plants and diseases, such as the emerald ash borer in North American and the fungal disease, Ceratocystis platani, in European plane trees. The papaya ringspot virus devastated papaya trees in Hawaii in the twentieth century until transgenic papaya plants were given pathogen-derived resistance. However, genetic modification for conservation in plants remains mainly speculative. A unique concern is that a transgenic species may no longer bear enough resemblance to the original species to truly claim that the original species is being conserved. Instead, the transgenic species may be genetically different enough to be considered a new species, thus diminishing the conservation worth of genetic modification. 10.1.6 Crops Genetically modified crops are genetically modified plants that are used in agriculture. The first crops developed were used for animal or human food and provide resistance to certain pests, diseases, environmental conditions, spoilage or chemical treatments (e.g. resistance to a herbicide). The second generation of crops aimed to improve the quality, often by altering the nutrient profile. Third generation genetically modified crops could be used for non-food purposes, including the production of pharmaceutical agents, biofuels, and other industrially useful goods, as well as for bioremediation. There are three main aims to agricultural advancement; increased production, improved conditions for agricultural workers and sustainability. GM crops contribute by improving harvests through reducing insect pressure, increasing nutrient value and tolerating different abiotic stresses. Despite this potential, as of 2018, the commercialized crops are limited mostly to cash crops like cotton, soybean, maize and canola and the vast majority of the introduced traits provide either herbicide tolerance or insect resistance. Soybeans accounted for half of all genetically modified crops planted in 2014. Adoption by farmers has been rapid, between 1996 and 2013, the total surface area of land cultivated with GM crops increased by a factor of 100. Geographically though the spread has been uneven, with strong growth in the Americas and parts of Asia and little in Europe and Africa. Its socioeconomic spread has been more even, with approximately 54% of worldwide GM crops grown in developing countries in 2013. Although doubts have been raised, most studies have found growing GM crops to be beneficial to farmers through decreased pesticide use as well as increased crop yield and farm profit. The majority of GM crops have been modified to be resistant to selected herbicides, usually a glyphosate or glufosinate based one. Genetically modified crops engineered to resist herbicides are now more available than conventionally bred resistant varieties; in the USA 93% of soybeans and most of the GM maize grown is glyphosate tolerant. Most currently available genes used to engineer insect resistance come from the Bacillus thuringiensis bacterium and code for delta endotoxins. A few use the genes that encode for vegetative insecticidal proteins. The only gene commercially used to provide insect protection that does not originate from B. thuringiensis is the Cowpea trypsin inhibitor (CpTI). CpTI was first approved for use cotton in 1999 and is currently undergoing trials in rice. Less than one percent of GM crops contained other traits, which include providing virus resistance, delaying senescence and altering the plants composition. Golden rice is the most well known GM crop that is aimed at increasing nutrient value. It has been engineered with three genes that biosynthesise beta-carotene, a precursor of vitamin A, in the edible parts of rice. It is intended to produce a fortified food to be grown and consumed in areas with a shortage of dietary vitamin A, a deficiency which each year is estimated to kill 670,000 children under the age of 5 and cause an additional 500,000 cases of irreversible childhood blindness. The original golden rice produced 1.6μg/g of the carotenoids, with further development increasing this 23 times. In 2018 it gained its first approvals for use as food. Plants and plant cells have been genetically engineered for production of biopharmaceuticals in bioreactors, a process known as pharming. Work has been done with duckweed Lemna minor, the algae Chlamydomonas reinhardtii and the moss Physcomitrella patens. Biopharmaceuticals produced include cytokines, hormones, antibodies, enzymes and vaccines, most of which are accumulated in the plant seeds. Many drugs also contain natural plant ingredients and the pathways that lead to their production have been genetically altered or transferred to other plant species to produce greater volume. Other options for bioreactors are biopolymers and biofuels. Unlike bacteria, plants can modify the proteins post-translationally, allowing them to make more complex molecules. They also pose less risk of being contaminated. Therapeutics have been cultured in transgenic carrot and tobacco cells, including a drug treatment for Gaucher’s disease. Vaccine production and storage has great potential in transgenic plants. Vaccines are expensive to produce, transport and administer, so having a system that could produce them locally would allow greater access to poorer and developing areas. As well as purifying vaccines expressed in plants it is also possible to produce edible vaccines in plants. Edible vaccines stimulate the immune system when ingested to protect against certain diseases. Being stored in plants reduces the long-term cost as they can be disseminated without the need for cold storage, don’t need to be purified and have long term stability. Also being housed within plant cells provides some protection from the gut acids upon digestion. However the cost of developing, regulating and containing transgenic plants is high, leading to most current plant-based vaccine development being applied to veterinary medicine, where the controls are not as strict. 10.1.7 Animals The vast majority of genetically modified animals are at the research stage with the number close to entering the market remaining small. As of 2018 only three genetically modified animals have been approved, all in the USA. A goat and a chicken have been engineered to produce medicines and a salmon that has increased growth. Despite the differences and difficulties in modifying them, the end aims are much the same as for plants. GM animals are created for research purposes, production of industrial or therapeutic products, agricultural uses or improving their health. There is also a market for creating genetically modified pets. The process of genetically engineering mammals is slow, tedious, and expensive. However, new technologies are making genetic modifications easier and more precise. The first transgenic mammals were produced by injecting viral DNA into embryos and then implanting the embryos in females. The embryo would develop and it would be hoped that some of the genetic material would be incorporated into the reproductive cells. Then researchers would have to wait until the animal reached breeding age and then offspring would be screened for presence of the gene in every cell. The development of the CRISPR-Cas9 gene editing system as a cheap and fast way of directly modifying germ cells, effectively halving the amount of time needed to develop genetically modified mammals. Mammals are the best models for human disease, making genetic engineered ones vital to the discovery and development of cures and treatments for many serious diseases. Knocking out genes responsible for human genetic disorders allows researchers to study the mechanism of the disease and to test possible cures. Genetically modified mice have been the most common mammals used in biomedical research, as they are cheap and easy to manipulate. Pigs are also a good target as they have a similar body size and anatomical features, physiology, pathophysiological response and diet. Nonhuman primates are the most similar model organisms to humans, but there is less ublic acceptance towards using them as research animals. In 2009, scientists announced that they had successfully transferred a gene into a primate species (marmosets) for the first time. Their first research target for these marmosets was Parkinson’s disease, but they were also considering amyotrophic lateral sclerosis and Huntington’s disease. Human proteins expressed in mammals are more likely to be similar to their natural counterparts than those expressed in plants or microorganisms. Stable expression has been accomplished in sheep, pigs, rats and other animals. In 2009 the first human biological drug produced from such an animal, a goat, was approved. The drug, ATryn, is an anticoagulant which reduces the probability of blood clots during surgery or childbirth and is extracted from the goat’s milk. Human alpha-1-antitrypsin is another protein that has been produced from goats and is used in treating humans with this deficiency. Another medicinal area is in creating pigs with greater capacity for human organ transplants (xenotransplantation). Pigs have been genetically modified so that their organs can no longer carry retroviruses or have modifications to reduce the chance of rejection. Pig lungs from genetically modified pigs are being considered for transplantation into humans. There is even potential to create chimeric pigs that can carry human organs. Livestock are modified with the intention of improving economically important traits such as growth-rate, quality of meat, milk composition, disease resistance and survival. Animals have been engineered to grow faster, be healthier and resist diseases. Modifications have also improved the wool production of sheep and udder health of cows. Goats have been genetically engineered to produce milk with strong spiderweb-like silk proteins in their milk. A GM pig called Enviropig was created with the capability of digesting plant phosphorus more efficiently than conventional pigs. They could reduce water pollution since they excrete 30 to 70% less phosphorus in manure. Dairy cows have been genetically engineered to produce milk that would be the same as human breast milk. This could potentially benefit mothers who cannot produce breast milk but want their children to have breast milk rather than formula. Researchers have also developed a genetically engineered cow that produces allergy-free milk. Scientists have genetically engineered several organisms, including some mammals, to include green fluorescent protein (GFP), for research purposes. GFP and other similar reporting genes allow easy visualization and localization of the products of the genetic modification. Fluorescent pigs have been bred to study human organ transplants, regenerating ocular photoreceptor cells, and other topics. In 2011 green-fluorescent cats were created to help find therapies for HIV/AIDS and other diseases as feline immunodeficiency virus is related to HIV. There have been suggestions that genetic engineering could be used to bring animals back from extinction. It involves changing the genome of a close living relative to resemble the extinct one and is currently being attempted with the passenger pigeon. Genes associated with the woolly mammoth have been added to the genome of an African Elephant, although the lead researcher says he has no intention of creating live elephants and transferring all the genes and reversing years of genetic evolution is a long way from being feasible. It is more likely that scientists could use this technology to conserve endangered animals by bringing back lost diversity or transferring evolved genetic advantages from adapted organisms to those that are struggling. Gene therapy uses genetically modified viruses to deliver genes which can cure disease in humans. Although gene therapy is still relatively new, it has had some successes. It has been used to treat genetic disorders such as severe combined immunodeficiency, and Leber’s congenital amaurosis. Treatments are also being developed for a range of other currently incurable diseases, such as cystic fibrosis, sickle cell anemia, Parkinson’s disease, cancer, diabetes, heart disease and muscular dystrophy. These treatments only effect somatic cells, meaning any changes would not be inheritable. Germline gene therapy results in any change being inheritable, which has raised concerns within the scientific community. In 2015, CRISPR was used to edit the DNA of non-viable human embryos. In November 2018, He Jiankui announced that he had edited the genomes of two human embryos, in an attempt to disable the CCR5 gene, which codes for a receptor that HIV uses to enter cells. He said that twin girls, Lulu and Nana, had been born a few weeks earlier and that they carried functional copies of CCR5 along with disabled CCR5 (mosaicism) and were still vulnerable to HIV. The work was widely condemned as unethical, dangerous, and premature. 10.1.8 Laws and regulations Genetically modified organisms are regulated by government agencies. This applies to research as well as the release of genetically modified organisms, including crops and food. The development of a regulatory framework concerning genetic engineering began in 1975, at Asilomar, California. The Asilomar meeting recommended a set of guidelines regarding the cautious use of recombinant technology and any products resulting from that technology. The Cartagena Protocol on Biosafety was adopted on 29 January 2000 and entered into force on 11 September 2003. It is an international treaty that governs the transfer, handling, and use of genetically modified organisms. One hundred and fifty-seven countries are members of the Protocol and many use it as a reference point for their own regulations. Universities and research institutes generally have a special committee that is responsible for approving any experiments that involve genetic engineering. Many experiments also need permission from a national regulatory group or legislation. All staff must be trained in the use of GMOs and all laboratories must gain approval from their regulatory agency to work with GMOs. The legislation covering GMOs are often derived from regulations and guidelines in place for the non-GMO version of the organism, although they are more severe. There is a near universal system for assessing the relative risks associated with GMOs and other agents to laboratory staff and the community. They are assigned to one of four risk categories based on their virulence, the severity of disease, the mode of transmission, and the availability of preventive measures or treatments. There are four biosafety levels that a laboratory can fall into, ranging from level 1 (which is suitable for working with agents not associated with disease) to level 4 (working with life-threatening agents). Different countries use different nomenclature to describe the levels and can have different requirements for what can be done at each level. There are differences in the regulation for the release of GMOs between countries, with some of the most marked differences occurring between the US and Europe. Regulation varies in a given country depending on the intended use of the products of the genetic engineering. For example, a crop not intended for food use is generally not reviewed by authorities responsible for food safety. Some nations have banned the release of GMOs or restricted their use, and others permit them with widely differing degrees of regulation. In 2016 thirty eight countries officially ban or prohibit the cultivation of GMOs and nine (Algeria, Bhutan, Kenya, Kyrgyzstan, Madagascar, Peru, Russia, Venezuela and Zimbabwe) ban their importation. Most countries that do not allow GMO cultivation do permit research using GMOs. The European Union (EU) differentiates between approval for cultivation within the EU and approval for import and processing. While only a few GMOs have been approved for cultivation in the EU a number of GMOs have been approved for import and processing. The cultivation of GMOs has triggered a debate about the market for GMOs in Europe. Depending on the coexistence regulations, incentives for cultivation of GM crops differ. The US policy does not focus on the process as much as other countries, looks at verifiable scientific risks and uses the concept of substantial equivalence. Whether gene edited organisms should be regulated the same as genetically modified organism is debated. USA regulations sees them as separate and does not regulate them under the same conditions, while in Europe a GMO is any organism created using genetic engineering techniques. One of the key issues concerning regulators is whether GM products should be labeled. The European Commission says that mandatory labeling and traceability are needed to allow for informed choice, avoid potential false advertising and facilitate the withdrawal of products if adverse effects on health or the environment are discovered. The American Medical Association and the American Association for the Advancement of Science say that absent scientific evidence of harm even voluntary labeling is misleading and will falsely alarm consumers. Labeling of GMO products in the marketplace is required in 64 countries. Labeling can be mandatory up to a threshold GM content level (which varies between countries) or voluntary. In Canada and the US labeling of GM food is voluntary, while in Europe all food (including processed food) or feed which contains greater than 0.9% of approved GMOs must be labelled. In 2014, sales of products that had been labeled as non-GMO grew 30 percent to US$ 1.1 billion. There is controversy over GMOs, especially with regard to their release outside laboratory environments. The dispute involves consumers, producers, biotechnology companies, governmental regulators, nongovernmental organizations, and scientists. Many of these concerns involve GM crops and whether food produced from them is safe and what impact growing them will have on the environment. These controversies have led to litigation, international trade disputes, and protests, and to restrictive regulation of commercial products in some countries. Most concerns are around the health and environmental effects of GMOs. These include whether they may provoke an allergic reaction, whether the transgenes could transfer to human cells and whether genes not approved for human consumption could outcross into the food supply. There is a scientific consensus that currently available food derived from GM crops poses no greater risk to human health than conventional food, but that each GM food needs to be tested on a case-by-case basis before introduction. Nonetheless, members of the public are much less likely than scientists to perceive GM foods as safe. The legal and regulatory status of GM foods varies by country, with some nations banning or restricting them, and others permitting them with widely differing degrees of regulation. Gene flow between GM crops and compatible plants, along with increased use of broad-spectrum herbicides, can increase the risk of herbicide resistant weed populations. Debate over the extent and consequences of gene flow intensified in 2001 when a paper was published showing transgenes had been found in landrace maize in Mexico, the crops center of diversity. Gene flow from GM crops to other organisms has been found to generally be lower than what would occur naturally. In order to address some of these concerns some GMOs have been developed with traits to help control their spread. To prevent the genetically modified salmon inadvertently breeding with wild salmon, all the fish raised for food are females, triploid, 99% are reproductively sterile, and raised in areas where escaped salmon could not survive. Bacteria have also been modified to depend on nutrients that cannot be found in nature, and genetic use restriction technology has been developed, though not yet marketed, that causes the second generation of GM plants to be sterile. Other environmental and agronomic concerns include a decrease in biodiversity, an increase in secondary pests (non-targeted pests) and evolution of resistant insect pests. In the areas of China and the US with Bt crops the overall biodiversity of insects has increased and the impact of secondary pests has been minimal. Resistance was found to be slow to evolve when best practice strategies were followed. The impact of Bt crops on beneficial non-target organisms became a public issue after a 1999 paper suggested they could be toxic to monarch butterflies. Follow up studies have since shown that the toxicity levels encountered in the field were not high enough to harm the larvae. Accusations that scientists are “playing God” and other religious issues have been ascribed to the technology from the beginning. With the ability to genetically engineer humans now possible there are ethical concerns over how far this technology should go, or if it should be used at all. Much debate revolves around where the line between treatment and enhancement is and whether the modifications should be inheritable. Other concerns include contamination of the non-genetically modified food supply, the rigor of the regulatory process, consolidation of control of the food supply in companies that make and sell GMOs, exaggeration of the benefits of genetic modification, or concerns over the use of herbicides with glyphosate. Other issues raised include the patenting of life and the use of intellectual property rights. There are large differences in consumer acceptance of GMOs, with Europeans more likely to view GM food negatively than North Americans. GMOs arrived on the scene as the public confidence in food safety, attributed to recent food scares such as Bovine spongiform encephalopathy and other scandals involving government regulation of products in Europe, was low. This along with campaigns run by various non-governmental organizations (NGO) have been very successful in blocking or limiting the use of GM crops. NGOs like the Organic Consumers Association, the Union of Concerned Scientists, Greenpeace and other groups have said that risks have not been adequately identified and managed and that there are unanswered questions regarding the potential long-term impact on human health from food derived from GMOs. They propose mandatory labeling or a moratorium on such products. 10.2 Gene therapy Gene therapy (also called human gene transfer) is a medical field which focuses on the utilization of the therapeutic delivery of nucleic acid into a patient’s cells as a drug to treat disease. The first attempt at modifying human DNA was performed in 1980 by Martin Cline, but the first successful nuclear gene transfer in humans, approved by the National Institutes of Health, was performed in May 1989. The first therapeutic use of gene transfer as well as the first direct insertion of human DNA into the nuclear genome was performed by French Anderson in a trial starting in September 1990. It is thought to be able to cure many genetic disorders or treat them over time. Between 1989 and December 2018, over 2,900 clinical trials were conducted, with more than half of them in phase I. As of 2017, Spark Therapeutics’ Luxturna (RPE65 mutation-induced blindness) and Novartis’ Kymriah (Chimeric antigen receptor T cell therapy) are the FDA’s first approved gene therapies to enter the market. Since that time, drugs such as Novartis’ Zolgensma and Alnylam’s Patisiran have also received FDA approval, in addition to other companies’ gene therapy drugs. Most of these approaches utilize adeno-associated viruses (AAVs) and lentiviruses for performing gene insertions, in vivo and ex vivo, respectively. ASO / siRNA approaches such as those conducted by Alnylam and Ionis Pharmaceuticals require non-viral delivery systems, and utilize alternative mechanisms for trafficking to liver cells by way of GalNAc transporters. The introduction of CRISPR gene editing has opened new doors for its application and utilization in gene therapy. Solutions to medical hurdles, such as the eradication of latent human immunodeficiency virus (HIV) reservoirs, may soon become a tangible reality. Not all medical procedures that introduce alterations to a patient’s genetic makeup can be considered gene therapy. Bone marrow transplantation and organ transplants in general have been found to introduce foreign DNA into patients. Gene therapy is defined by the precision of the procedure and the intention of direct therapeutic effect. After extensive research on animals throughout the 1980s and a 1989 bacterial gene tagging trial on humans, the first gene therapy widely accepted as a success was demonstrated in a trial that started on 14 September 1990, when Ashi DeSilva was treated for ADA-SCID (Adenosine deaminase deficiency), an autosomal recessive metabolic disorder that causes immunodeficiency. It occurs in fewer than one in 100,000 live births worldwide. The first somatic treatment that produced a permanent genetic change was initiated in 1993. The goal was to cure malignant brain tumors by using recombinant DNA to transfer a gene making the tumor cells sensitive to a drug that in turn would cause the tumor cells to die. Gene therapy is a way to fix a genetic problem at its source. The polymers are either translated into proteins, interfere with target gene expression, or possibly correct genetic mutations. The most common form uses DNA that encodes a functional, therapeutic gene to replace a mutated gene. The polymer molecule is packaged within a “vector”, which carries the molecule inside cells. Early clinical failures led to dismissals of gene therapy. Clinical successes since 2006 regained researchers’ attention, although as of 2014, it was still largely an experimental technique. These include treatment of retinal diseases Leber’s congenital amaurosis and choroideremia, X-linked SCID, ADA-SCID, adrenoleukodystrophy, chronic lymphocytic leukemia (CLL), acute lymphocytic leukemia (ALL), multiple myeloma, haemophilia, and Parkinson’s disease. Between 2013 and April 2014, US companies invested over US$ 600 million in the field. The first commercial gene therapy, Gendicine, was approved in China in 2003 for the treatment of certain cancers. In 2011 Neovasculgen was registered in Russia as the first-in-class gene-therapy drug for treatment of peripheral artery disease, including critical limb ischemia. In 2012 Glybera, a treatment for a rare inherited disorder, lipoprotein lipase deficiency became the first treatment to be approved for clinical use in either Europe or the United States after its endorsement by the European Commission. Following early advances in genetic engineering of bacteria, cells, and small animals, scientists started considering how to apply it to medicine. Two main approaches were considered – replacing or disrupting defective genes. Scientists focused on diseases caused by single-gene defects, such as cystic fibrosis, haemophilia, muscular dystrophy, thalassemia, and sickle cell anemia. Glybera treats one such disease, caused by a defect in lipoprotein lipase. DNA must be administered, reach the damaged cells, enter the cell and either express or disrupt a protein. Multiple delivery techniques have been explored. The initial approach incorporated DNA into an engineered virus to deliver the DNA into a chromosome. Naked DNA approaches have also been explored, especially in the context of vaccine development. Generally, efforts focused on administering a gene that causes a needed protein to be expressed. More recently, increased understanding of nuclease function has led to more direct DNA editing, using techniques such as zinc finger nucleases and CRISPR. The vector incorporates genes into chromosomes. The expressed nucleases then knock out and replace genes in the chromosome. As of 2014 these approaches involve removing cells from patients, editing a chromosome and returning the transformed cells to patients. Gene editing is a potential approach to alter the human genome to treat genetic diseases, viral diseases, and cancer. As of 2016 these approaches were still years from being medicine. Gene therapy may be classified into two types: Somatic: in somatic cell gene therapy (SCGT), the therapeutic genes are transferred into any cell other than a gamete, germ cell, gametocyte, or undifferentiated stem cell. Any such modifications affect the individual patient only, and are not inherited by offspring. Somatic gene therapy represents mainstream basic and clinical research, in which therapeutic DNA (either integrated in the genome or as an external episome or plasmid) is used to treat disease. Over 600 clinical trials utilizing SCGT are underway[when?] in the US. Most focus on severe genetic disorders, including immunodeficiencies, haemophilia thalassaemia, and cystic fibrosis. Such single gene disorders are good candidates for somatic cell therapy. The complete correction of a genetic disorder or the replacement of multiple genes is not yet possible. Only a few of the trials are in the advanced stages. [needs update] Germline: in germline gene therapy (GGT), germ cells (sperm or egg cells) are modified by the introduction of functional genes into their genomes. Modifying a germ cell causes all the organism’s cells to contain the modified gene. The change is therefore heritable and passed on to later generations. Australia, Canada, Germany, Israel, Switzerland, and the Netherlands prohibit GGT for application in human beings, for technical and ethical reasons, including insufficient knowledge about possible risks to future generations and higher risks versus SCGT. The US has no federal controls specifically addressing human genetic modification (beyond FDA regulations for therapies in general). The delivery of DNA into cells can be accomplished by multiple methods. The two major classes are recombinant viruses (sometimes called biological nanoparticles or viral vectors) and naked DNA or DNA complexes (non-viral methods). In order to replicate, viruses introduce their genetic material into the host cell, tricking the host’s cellular machinery into using it as blueprints for viral proteins. Retroviruses go a stage further by having their genetic material copied into the genome of the host cell. Scientists exploit this by substituting a virus’s genetic material with therapeutic DNA. (The term ‘DNA’ may be an oversimplification, as some viruses contain RNA, and gene therapy could take this form as well.) A number of viruses have been used for human gene therapy, including retroviruses, adenoviruses, herpes simplex, vaccinia, and adeno-associated virus. Like the genetic material (DNA or RNA) in viruses, therapeutic DNA can be designed to simply serve as a temporary blueprint that is degraded naturally or (at least theoretically) to enter the host’s genome, becoming a permanent part of the host’s DNA in infected cells. Non-viral methods present certain advantages over viral methods, such as large scale production and low host immunogenicity. However, non-viral methods initially produced lower levels of transfection and gene expression, and thus lower therapeutic efficacy. Newer technologies offer promise of solving these problems, with the advent of increased cell-specific targeting and subcellular trafficking control. Methods for non-viral gene therapy include the injection of naked DNA, electroporation, the gene gun, sonoporation, magnetofection, the use of oligonucleotides, lipoplexes, dendrimers, and inorganic nanoparticles. More recent approaches, such as those performed by companies such as Ligandal, offer the possibility of creating cell-specific targeting technologies for a variety of gene therapy modalities, including RNA, DNA and gene editing tools such as CRISPR. Other companies, such as Arbutus Biopharma and Arcturus Therapeutics, offer non-viral, non-cell-targeted approaches that mainly exhibit liver trophism. In more recent years, startups such as Sixfold Bio, GenEdit, and Spotlight Therapeutics have begun to solve the non-viral gene delivery problem. Non-viral techniques offer the possibility of repeat dosing and greater tailorability of genetic payloads, which in the future will be more likely to take over viral-based delivery systems. Some of the unsolved problems include: Short-lived nature – Before gene therapy can become a permanent cure for a condition, the therapeutic DNA introduced into target cells must remain functional and the cells containing the therapeutic DNA must be stable. Problems with integrating therapeutic DNA into the genome and the rapidly dividing nature of many cells prevent it from achieving long-term benefits. Patients require multiple treatments. Immune response – Any time a foreign object is introduced into human tissues, the immune system is stimulated to attack the invader. Stimulating the immune system in a way that reduces gene therapy effectiveness is possible. The immune system’s enhanced response to viruses that it has seen before reduces the effectiveness to repeated treatments. Problems with viral vectors – Viral vectors carry the risks of toxicity, inflammatory responses, and gene control and targeting issues. Multigene disorders – Some commonly occurring disorders, such as heart disease, high blood pressure, Alzheimer’s disease, arthritis, and diabetes, are affected by variations in multiple genes, which complicate gene therapy. Some therapies may breach the Weismann barrier (between soma and germ-line) protecting the testes, potentially modifying the germline, falling afoul of regulations in countries that prohibit the latter practice. Insertional mutagenesis – If the DNA is integrated in a sensitive spot in the genome, for example in a tumor suppressor gene, the therapy could induce a tumor. This has occurred in clinical trials for X-linked severe combined immunodeficiency (X-SCID) patients, in which hematopoietic stem cells were transduced with a corrective transgene using a retrovirus, and this led to the development of T cell leukemia in 3 of 20 patients. One possible solution is to add a functional tumor suppressor gene to the DNA to be integrated. This may be problematic since the longer the DNA is, the harder it is to integrate into cell genomes. CRISPR technology allows researchers to make much more precise genome changes at exact locations. Cost – Alipogene tiparvovec or Glybera, for example, at a cost of US$ 1.6 million per patient, was reported in 2013 to be the world’s most expensive drug. Deaths Three patients’ deaths have been reported in gene therapy trials, putting the field under close scrutiny. The first was that of Jesse Gelsinger, who died in 1999 because of immune rejection response. One X-SCID patient died of leukemia in 2003. An 18-year-old male died of systemic inflammatory response syndrome following adenovirus gene therapy in 2003. In 2007, a rheumatoid arthritis patient died from an infection; the subsequent investigation concluded that the death was not related to gene therapy. However it is always important to remember that although deaths are rare they can still occur and it is very possible that certain types of gene therapy can cause certain cancers. 10.2.1 Laws and regulations Regulations covering genetic modification are part of general guidelines about human-involved biomedical research. There are no international treaties which are legally binding in this area, but there are recommendations for national laws from various bodies. The Helsinki Declaration (Ethical Principles for Medical Research Involving Human Subjects) was amended by the World Medical Association’s General Assembly in 2008. This document provides principles physicians and researchers must consider when involving humans as research subjects. The Statement on Gene Therapy Research initiated by the Human Genome Organization (HUGO) in 2001 providesa legal baseline for all countries. HUGO’s document emphasizes human freedom and adherence to human rights, and offers recommendations for somatic gene therapy, including the importance of recognizing public concerns about such research. No federal legislation lays out protocols or restrictions about human genetic engineering in the USA. This subject is governed by overlapping regulations from local and federal agencies, including the Department of Health and Human Services, the FDA and NIH’s Recombinant DNA Advisory Committee. Researchers seeking federal funds for an investigational new drug application, (commonly the case for somatic human genetic engineering,) must obey international and federal guidelines for the protection of human subjects. NIH serves as the main gene therapy regulator for federally funded research. Privately funded research is advised to follow these regulations. NIH provides funding for research that develops or enhances genetic engineering techniques and to evaluate the ethics and quality in current research. The NIH maintains a mandatory registry of human genetic engineering research protocols that includes all federally funded projects. An NIH advisory committee published a set of guidelines on gene manipulation. The guidelines discuss lab safety as well as human test subjects and various experimental types that involve genetic changes. Several sections specifically pertain to human genetic engineering, including Section III-C-1. This section describes required review processes and other aspects when seeking approval to begin clinical research involving genetic transfer into a human patient. The protocol for a gene therapy clinical trial must be approved by the NIH’s Recombinant DNA Advisory Committee prior to any clinical trial beginning; this is different from any other kind of clinical trial. As with other kinds of drugs, the FDA regulates the quality and safety of gene therapy products and supervises how these products are used clinically. Therapeutic alteration of the human genome falls under the same regulatory requirements as any other medical treatment. Research involving human subjects, such as clinical trials, must be reviewed and approved by the FDA and an Institutional Review Board. ## Creating A Genetically Modified Organism (GMO) Creating a GMO is a multi-step process. Genetic engineers must first choose what gene they wish to insert into the organism. This is driven by what the aim is for the resultant organism and is built on earlier research. Genetic screens can be carried out to determine potential genes and further tests then used to identify the best candidates. The development of microarrays, transcriptomics and genome sequencing has made it much easier to find suitable genes. Luck also plays its part; the round-up ready gene was discovered after scientists noticed a bacterium thriving in the presence of the herbicide. 10.2.2 Gene Isolation And Cloning The next step is to isolate the candidate gene. The cell containing the gene is opened and the DNA is purified. The gene is separated by using restriction enzymes to cut the DNA into fragments or polymerase chain reaction (PCR) to amplify up the gene segment. These segments can then be extracted through gel electrophoresis. If the chosen gene or the donor organism’s genome has been well studied it may already be accessible from a genetic library. If the DNA sequence is known, but no copies of the gene are available, it can also be artificially synthesised. Once isolated the gene is ligated into a plasmid that is then inserted into a bacterium. The plasmid is replicated when the bacteria divide, ensuring unlimited copies of the gene are available. Before the gene is inserted into the target organism it must be combined with other genetic elements. These include a promoter and terminator region, which initiate and end transcription. A selectable marker gene is added, which in most cases confers antibiotic resistance, so researchers can easily determine which cells have been successfully transformed. The gene can also be modified at this stage for better expression or effectiveness. These manipulations are carried out using recombinant DNA techniques, such as restriction digests, ligations and molecular cloning. 10.2.3 Inserting DNA Into The Host Genome There are a number of techniques used to insert genetic material into the host genome. Some bacteria can naturally take up foreign DNA. This ability can be induced in other bacteria via stress (e.g. thermal or electric shock), which increases the cell membrane’s permeability to DNA; up-taken DNA can either integrate with the genome or exist as extrachromosomal DNA. DNA is generally inserted into animal cells using microinjection, where it can be injected through the cell’s nuclear envelope directly into the nucleus, or through the use of viral vectors. Plant genomes can be engineered by physical methods or by use of Agrobacterium for the delivery of sequences hosted in T-DNA binary vectors. In plants the DNA is often inserted using Agrobacterium-mediated transformation, taking advantage of the Agrobacteriums T-DNA sequence that allows natural insertion of genetic material into plant cells. Other methods include biolistics, where particles of gold or tungsten are coated with DNA and then shot into young plant cells, and electroporation, which involves using an electric shock to make the cell membrane permeable to plasmid DNA. As only a single cell is transformed with genetic material, the organism must be regenerated from that single cell. In plants this is accomplished through the use of tissue culture. In animals it is necessary to ensure that the inserted DNA is present in the embryonic stem cells. Bacteria consist of a single cell and reproduce clonally so regeneration is not necessary. Selectable markers are used to easily differentiate transformed from untransformed cells. These markers are usually present in the transgenic organism, although a number of strategies have been developed that can remove the selectable marker from the mature transgenic plant. Further testing using PCR, Southern hybridization, and DNA sequencing is conducted to confirm that an organism contains the new gene. These tests can also confirm the chromosomal location and copy number of the inserted gene. The presence of the gene does not guarantee it will be expressed at appropriate levels in the target tissue so methods that look for and measure the gene products (RNA and protein) are also used. These include northern hybridisation, quantitative RT-PCR, Western blot, immunofluorescence, ELISA and phenotypic analysis. The new genetic material can be inserted randomly within the host genome or targeted to a specific location. The technique of gene targeting uses homologous recombination to make desired changes to a specific endogenous gene. This tends to occur at a relatively low frequency in plants and animals and generally requires the use of selectable markers. The frequency of gene targeting can be greatly enhanced through genome editing. Genome editing uses artificially engineered nucleases that create specific double-stranded breaks at desired locations in the genome, and use the cell’s endogenous mechanisms to repair the induced break by the natural processes of homologous recombination and nonhomologous end-joining. There are four families of engineered nucleases: meganucleases, zinc finger nucleases, transcription activator-like effector nucleases (TALENs), and the Cas9-guideRNA system (adapted from CRISPR). TALEN and CRISPR are the two most commonly used and each has its own advantages. TALENs have greater target specificity, while CRISPR is easier to design and more efficient. In addition to enhancing gene targeting, engineered nucleases can be used to introduce mutations at endogenous genes that generate a gene knockout. 10.2.4 Applications Of Genetic Editing Genetic engineering has applications in medicine, research, industry and agriculture and can be used on a wide range of plants, animals and microorganisms. Bacteria, the first organisms to be genetically modified, can have plasmid DNA inserted containing new genes that code for medicines or enzymes that process food and other substrates. Plants have been modified for insect protection, herbicide resistance, virus resistance, enhanced nutrition, tolerance to environmental pressures and the production of edible vaccines. Most commercialised GMOs are insect resistant or herbicide tolerant crop plants. Genetically modified animals have been used for research, model animals and the production of agricultural or pharmaceutical products. The genetically modified animals include animals with genes knocked out, increased susceptibility to disease, hormones for extra growth and the ability to express proteins in their milk. Genetic engineering has many applications to medicine that include the manufacturing of drugs, creation of model animals that mimic human conditions and gene therapy. One of the earliest uses of genetic engineering was to mass-produce human insulin in bacteria. This application has now been applied to human growth hormones, follicle stimulating hormones (for treating infertility), human albumin, monoclonal antibodies, antihemophilic factors, vaccines and many other drugs. Mouse hybridomas, cells fused together to create monoclonal antibodies, have been adapted through genetic engineering to create human monoclonal antibodies. In 2017, genetic engineering of chimeric antigen receptors on a patient’s own T-cells was approved by the U.S. FDA as a treatment for the cancer acute lymphoblastic leukemia. Genetically engineered viruses are being developed that can still confer immunity, but lack the infectious sequences. Genetic engineering is also used to create animal models of human diseases. Genetically modified mice are the most common genetically engineered animal model. They have been used to study and model cancer (the oncomouse), obesity, heart disease, diabetes, arthritis, substance abuse, anxiety, aging and Parkinson disease. Potential cures can be tested against these mouse models. Also genetically modified pigs have been bred with the aim of increasing the success of pig to human organ transplantation. Gene therapy is the genetic engineering of humans, generally by replacing defective genes with effective ones. Clinical research using somatic gene therapy has been conducted with several diseases, including X-linked SCID, chronic lymphocytic leukemia (CLL), and Parkinson’s disease. In 2012, Alipogene tiparvovec became the first gene therapy treatment to be approved for clinical use. In 2015 a virus was used to insert a healthy gene into the skin cells of a boy suffering from a rare skin disease, epidermolysis bullosa, in order to grow, and then graft healthy skin onto 80 percent of the boy’s body which was affected by the illness. Germline gene therapy would result in any change being inheritable, which has raised concerns within the scientific community. In 2015, CRISPR was used to edit the DNA of non-viable human embryos, leading scientists of major world academies to call for a moratorium on inheritable human genome edits. There are also concerns that the technology could be used not just for treatment, but for enhancement, modification or alteration of a human beings’ appearance, adaptability, intelligence, character or behavior. The distinction between cure and enhancement can also be difficult to establish. In November 2018, He Jiankui announced that he had edited the genomes of two human embryos, to attempt to disable the CCR5 gene, which codes for a receptor that HIV uses to enter cells. He said that twin girls, Lulu and Nana, had been born a few weeks earlier. He said that the girls still carried functional copies of CCR5 along with disabled CCR5 (mosaicism) and were still vulnerable to HIV. The work was widely condemned as unethical, dangerous, and premature. Currently, germline modification is banned in 40 countries. Scientists that do this type of research will often let embryos grow for a few days without allowing it to develop into a baby. Researchers are altering the genome of pigs to induce the growth of human organs to be used in transplants. Scientists are creating “gene drives”, changing the genomes of mosquitoes to make them immune to malaria, and then looking to spread the genetically altered mosquitoes throughout the mosquito population in the hopes of eliminating the disease. Genetic engineering is an important tool for natural scientists, with the creation of transgenic organisms one of the most important tools for analysis of gene function. Genes and other genetic information from a wide range of organisms can be inserted into bacteria for storage and modification, creating genetically modified bacteria in the process. Bacteria are cheap, easy to grow, clonal, multiply quickly, relatively easy to transform and can be stored at -80 °C almost indefinitely. Once a gene is isolated it can be stored inside the bacteria providing an unlimited supply for research. Organisms are genetically engineered to discover the functions of certain genes. This could be the effect on the phenotype of the organism, where the gene is expressed or what other genes it interacts with. These experiments generally involve loss of function, gain of function, tracking and expression. Loss of function experiments, such as in a gene knockout experiment, in which an organism is engineered to lack the activity of one or more genes. In a simple knockout a copy of the desired gene has been altered to make it non-functional. Embryonic stem cells incorporate the altered gene, which replaces the already present functional copy. These stem cells are injected into blastocysts, which are implanted into surrogate mothers. This allows the experimenter to analyse the defects caused by this mutation and thereby determine the role of particular genes. It is used especially frequently in developmental biology. When this is done by creating a library of genes with point mutations at every position in the area of interest, or even every position in the whole gene, this is called “scanning mutagenesis”. The simplest method, and the first to be used, is “alanine scanning”, where every position in turn is mutated to the unreactive amino acid alanine. Gain of function experiments, the logical counterpart of knockouts. These are sometimes performed in conjunction with knockout experiments to more finely establish the function of the desired gene. The process is much the same as that in knockout engineering, except that the construct is designed to increase the function of the gene, usually by providing extra copies of the gene or inducing synthesis of the protein more frequently. Gain of function is used to tell whether or not a protein is sufficient for a function, but does not always mean it’s required, especially when dealing with genetic or functional redundancy. Tracking experiments, which seek to gain information about the localisation and interaction of the desired protein. One way to do this is to replace the wild-type gene with a ‘fusion’ gene, which is a juxtaposition of the wild-type gene with a reporting element such as green fluorescent protein (GFP) that will allow easy visualisation of the products of the genetic modification. While this is a useful technique, the manipulation can destroy the function of the gene, creating secondary effects and possibly calling into question the results of the experiment. More sophisticated techniques are now in development that can track protein products without mitigating their function, such as the addition of small sequences that will serve as binding motifs to monoclonal antibodies. Expression studies aim to discover where and when specific proteins are produced. In these experiments, the DNA sequence before the DNA that codes for a protein, known as a gene’s promoter, is reintroduced into an organism with the protein coding region replaced by a reporter gene such as GFP or an enzyme that catalyses the production of a dye. Thus the time and place where a particular protein is produced can be observed. Expression studies can be taken a step further by altering the promoter to find which pieces are crucial for the proper expression of the gene and are actually bound by transcription factor proteins; this process is known as promoter bashing. Organisms can have their cells transformed with a gene coding for a useful protein, such as an enzyme, so that they will overexpress the desired protein. Mass quantities of the protein can then be manufactured by growing the transformed organism in bioreactor equipment using industrial fermentation, and then purifying the protein. Some genes do not work well in bacteria, so yeast, insect cells or mammalians cells can also be used. These techniques are used to produce medicines such as insulin, human growth hormone, and vaccines, supplements such as tryptophan, aid in the production of food (chymosin in cheese making) and fuels. Other applications with genetically engineered bacteria could involve making them perform tasks outside their natural cycle, such as making biofuels, cleaning up oil spills, carbon and other toxic waste and detecting arsenic in drinking water. Certain genetically modified microbes can also be used in biomining and bioremediation, due to their ability to extract heavy metals from their environment and incorporate them into compounds that are more easily recoverable. In materials science, a genetically modified virus has been used in a research laboratory as a scaffold for assembling a more environmentally friendly lithium-ion battery. Bacteria have also been engineered to function as sensors by expressing a fluorescent protein under certain environmental conditions. One of the best-known and controversial applications of genetic engineering is the creation and use of genetically modified crops or genetically modified livestock to produce genetically modified food. Crops have been developed to increase production, increase tolerance to abiotic stresses, alter the composition of the food, or to produce novel products. The first crops to be released commercially on a large scale provided protection from insect pests or tolerance to herbicides. Fungal and virus resistant crops have also been developed or are in development. This makes the insect and weed management of crops easier and can indirectly increase crop yield. GM crops that directly improve yield by accelerating growth or making the plant more hardy (by improving salt, cold or drought tolerance) are also under development. In 2016 Salmon have been genetically modified with growth hormones to reach normal adult size much faster. GMOs have been developed that modify the quality of produce by increasing the nutritional value or providing more industrially useful qualities or quantities. The Amflora potato produces a more industrially useful blend of starches. Soybeans and canola have been genetically modified to produce more healthy oils. The first commercialised GM food was a tomato that had delayed ripening, increasing its shelf life. Plants and animals have been engineered to produce materials they do not normally make. Pharming uses crops and animals as bioreactors to produce vaccines, drug intermediates, or the drugs themselves; the useful product is purified from the harvest and then used in the standard pharmaceutical production process. Cows and goats have been engineered to express drugs and other proteins in their milk, and in 2009 the FDA approved a drug produced in goat milk. Genetic engineering has potential applications in conservation and natural area management. Gene transfer through viral vectors has been proposed as a means of controlling invasive species as well as vaccinating threatened fauna from disease. Transgenic trees have been suggested as a way to confer resistance to pathogens in wild populations. With the increasing risks of maladaptation in organisms as a result of climate change and other perturbations, facilitated adaptation through gene tweaking could be one solution to reducing extinction risks. Applications of genetic engineering in conservation are thus far mostly theoretical and have yet to be put into practice. Genetic engineering is also being used to create microbial art. Some bacteria have been genetically engineered to create black and white photographs. Novelty items such as lavender-colored carnations, blue roses, and glowing fish have also been produced through genetic engineering. 10.2.5 Regulation Of Genetic Engineering The regulation of genetic engineering concerns the approaches taken by governments to assess and manage the risks associated with the development and release of GMOs. The development of a regulatory framework began in 1975, at Asilomar, California. The Asilomar meeting recommended a set of voluntary guidelines regarding the use of recombinant technology. As the technology improved the US established a committee at the Office of Science and Technology, which assigned regulatory approval of GM food to the USDA, FDA and EPA. The Cartagena Protocol on Biosafety, an international treaty that governs the transfer, handling, and use of GMOs, was adopted on 29 January 2000. One hundred and fifty-seven countries are members of the Protocol and many use it as a reference point for their own regulations. The legal and regulatory status of GM foods varies by country, with some nations banning or restricting them, and others permitting them with widely differing degrees of regulation. Some countries allow the import of GM food with authorisation, but either do not allow its cultivation (Russia, Norway, Israel) or have provisions for cultivation even though no GM products are yet produced (Japan, South Korea). Most countries that do not allow GMO cultivation do permit research. Some of the most marked differences occurring between the US and Europe. The US policy focuses on the product (not the process), only looks at verifiable scientific risks and uses the concept of substantial equivalence. The European Union by contrast has possibly the most stringent GMO regulations in the world. All GMOs, along with irradiated food, are considered “new food” and subject to extensive, case-by-case, science-based food evaluation by the European Food Safety Authority. The criteria for authorisation fall in four broad categories: “safety”, “freedom of choice”, “labelling”, and “traceability”. The level of regulation in other countries that cultivate GMOs lie in between Europe and the United States. One of the key issues concerning regulators is whether GM products should be labeled. The European Commission says that mandatory labeling and traceability are needed to allow for informed choice, avoid potential false advertising and facilitate the withdrawal of products if adverse effects on health or the environment are discovered. The American Medical Association and the American Association for the Advancement of Science say that absent scientific evidence of harm even voluntary labeling is misleading and will falsely alarm consumers. Labeling of GMO products in the marketplace is required in 64 countries. Labeling can be mandatory up to a threshold GM content level (which varies between countries) or voluntary. In Canada and the US labeling of GM food is voluntary, while in Europe all food (including processed food) or feed which contains greater than 0.9% of approved GMOs must be labelled. Critics have objected to the use of genetic engineering on several grounds, including ethical, ecological and economic concerns. Many of these concerns involve GM crops and whether food produced from them is safe and what impact growing them will have on the environment. These controversies have led to litigation, international trade disputes, and protests, and to restrictive regulation of commercial products in some countries. Accusations that scientists are “playing God” and other religious issues have been ascribed to the technology from the beginning. Other ethical issues raised include the patenting of life, the use of intellectual property rights, the level of labeling on products, control of the food supply and the objectivity of the regulatory process. Although doubts have been raised, economically most studies have found growing GM crops to be beneficial to farmers. Gene flow between GM crops and compatible plants, along with increased use of selective herbicides, can increase the risk of “superweeds” developing. Other environmental concerns involve potential impacts on non-target organisms, including soil microbes, and an increase in secondary and resistant insect pests. Many of the environmental impacts regarding GM crops may take many years to be understood and are also evident in conventional agriculture practices. With the commercialisation of genetically modified fish there are concerns over what the environmental consequences will be if they escape. There are three main concerns over the safety of genetically modified food: whether they may provoke an allergic reaction; whether the genes could transfer from the food into human cells; and whether the genes not approved for human consumption could outcross to other crops. There is a scientific consensus that currently available food derived from GM crops poses no greater risk to human health than conventional food, but that each GM food needs to be tested on a case-by-case basis before introduction. Nonetheless, members of the public are less likely than scientists to perceive GM foods as safe. 10.3 Recombinant DNA Technology Recombinant DNA (rDNA) molecules are DNA molecules formed by laboratory methods of genetic recombination (such as molecular cloning) to bring together genetic material from multiple sources, creating sequences that would not otherwise be found in the genome. Recombinant DNA is the general name for a piece of DNA that has been created by combining at least two strands. Recombinant DNA is possible because DNA molecules from all organisms share the same chemical structure, and differ only in the nucleotide sequence within that identical overall structure. Recombinant DNA molecules are sometimes called chimeric DNA, because they can be made of material from two different species, like the mythical chimera. R-DNA technology uses palindromic sequences and leads to the production of sticky and blunt ends. The DNA sequences used in the construction of recombinant DNA molecules can originate from any species. For example, plant DNA may be joined to bacterial DNA, or human DNA may be joined with fungal DNA. In addition, DNA sequences that do not occur anywhere in nature may be created by the chemical synthesis of DNA, and incorporated into recombinant molecules. Using recombinant DNA technology and synthetic DNA, literally any DNA sequence may be created and introduced into any of a very wide range of living organisms. Proteins that can result from the expression of recombinant DNA within living cells are termed recombinant proteins. When recombinant DNA encoding a protein is introduced into a host organism, the recombinant protein is not necessarily produced. Expression of foreign proteins requires the use of specialized expression vectors and often necessitates significant restructuring by foreign coding sequences. Recombinant DNA differs from genetic recombination in that the former results from artificial methods in the test tube, while the latter is a normal biological process that results in the remixing of existing DNA sequences in essentially all organisms. Molecular cloning is the laboratory process used to create recombinant DNA. It is one of two most widely used methods, along with polymerase chain reaction (PCR), used to direct the replication of any specific DNA sequence chosen by the experimentalist. There are two fundamental differences between the methods. One is that molecular cloning involves replication of the DNA within a living cell, while PCR replicates DNA in the test tube, free of living cells. The other difference is that cloning involves cutting and pasting DNA sequences, while PCR amplifies by copying an existing sequence. Formation of recombinant DNA requires a cloning vector, a DNA molecule that replicates within a living cell. Vectors are generally derived from plasmids or viruses, and represent relatively small segments of DNA that contain necessary genetic signals for replication, as well as additional elements for convenience in inserting foreign DNA, identifying cells that contain recombinant DNA, and, where appropriate, expressing the foreign DNA. The choice of vector for molecular cloning depends on the choice of host organism, the size of the DNA to be cloned, and whether and how the foreign DNA is to be expressed. The DNA segments can be combined by using a variety of methods, such as restriction enzyme/ligase cloning or Gibson assembly. In standard cloning protocols, the cloning of any DNA fragment essentially involves seven steps: (1) Choice of host organism and cloning vector, (2) Preparation of vector DNA, (3) Preparation of DNA to be cloned, (4) Creation of recombinant DNA, (5) Introduction of recombinant DNA into the host organism, (6) Selection of organisms containing recombinant DNA, and (7) Screening for clones with desired DNA inserts and biological properties. Following transplantation into the host organism, the foreign DNA contained within the recombinant DNA construct may or may not be expressed. That is, the DNA may simply be replicated without expression, or it may be transcribed and translated and a recombinant protein is produced. Generally speaking, expression of a foreign gene requires restructuring the gene to include sequences that are required for producing an mRNA molecule that can be used by the host’s translational apparatus (e.g. promoter, translational initiation signal, and transcriptional terminator). Specific changes to the host organism may be made to improve expression of the ectopic gene. In addition, changes may be needed to the coding sequences as well, to optimize translation, make the protein soluble, direct the recombinant protein to the proper cellular or extracellular location, and stabilize the protein from degradation. In most cases, organisms containing recombinant DNA have apparently normal phenotypes. That is, their appearance, behavior and metabolism are usually unchanged, and the only way to demonstrate the presence of recombinant sequences is to examine the DNA itself, typically using a polymerase chain reaction (PCR) test. Significant exceptions exist, and are discussed below. If the rDNA sequences encode a gene that is expressed, then the presence of RNA and/or protein products of the recombinant gene can be detected, typically using RT-PCR or western hybridization methods. Gross phenotypic changes are not the norm, unless the recombinant gene has been chosen and modified so as to generate biological activity in the host organism. Additional phenotypes that are encountered include toxicity to the host organism induced by the recombinant gene product, especially if it is over-expressed or expressed within inappropriate cells or tissues. In some cases, recombinant DNA can have deleterious effects even if it is not expressed. One mechanism by which this happens is insertional inactivation, in which the rDNA becomes inserted into a host cell’s gene. In some cases, researchers use this phenomenon to “knock out” genes to determine their biological function and importance. Another mechanism by which rDNA insertion into chromosomal DNA can affect gene expression is by inappropriate activation of previously unexpressed host cell genes. This can happen, for example, when a recombinant DNA fragment containing an active promoter becomes located next to a previously silent host cell gene, or when a host cell gene that functions to restrain gene expression undergoes insertional inactivation by recombinant DNA. Recombinant DNA is widely used in biotechnology, medicine and research. Today, recombinant proteins and other products that result from the use of DNA technology are found in essentially every western pharmacy, physician or veterinarian office, medical testing laboratory, and biological research laboratory. In addition, organisms that have been manipulated using recombinant DNA technology, as well as products derived from those organisms, have found their way into many farms, supermarkets, home medicine cabinets, and even pet shops, such as those that sell GloFish and other genetically modified animals. The most common application of recombinant DNA is in basic research, in which the technology is important to most current work in the biological and biomedical sciences. Recombinant DNA is used to identify, map and sequence genes, and to determine their function. rDNA probes are employed in analyzing gene expression within individual cells, and throughout the tissues of whole organisms. Recombinant proteins are widely used as reagents in laboratory experiments and to generate antibody probes for examining protein synthesis within cells and organisms. Many additional practical applications of recombinant DNA are found in industry, food production, human and veterinary medicine, agriculture, and bioengineering. Some specific examples are: Recombinant human insulin: almost completely replaced insulin obtained from animal sources (e.g. pigs and cattle) for the treatment of insulin-dependent diabetes. A variety of different recombinant insulin preparations are in widespread use. Recombinant insulin is synthesized by inserting the human insulin gene into E. coli, or yeast (Saccharomyces cerevisiae) which then produces insulin for human use. Administered to patients whose pituitary glands generate insufficient quantities to support normal growth and development. Before recombinant HGH became available, HGH for therapeutic use was obtained from pituitary glands of cadavers. This unsafe practice led to some patients developing Creutzfeldt–Jakob disease. Recombinant HGH eliminated this problem, and is now used therapeutically. It has also been misused as a performance-enhancing drug by athletes and others. DrugBank entry Recombinant blood clotting factor VIII: a blood-clotting protein that is administered to patients with forms of the bleeding disorder hemophilia, who are unable to produce factor VIII in quantities sufficient to support normal blood coagulation. Before the development of recombinant factor VIII, the protein was obtained by processing large quantities of human blood from multiple donors, which carried a very high risk of transmission of blood borne infectious diseases, for example HIV and hepatitis B. DrugBank entry Recombinant hepatitis B vaccine: Hepatitis B infection is controlled through the use of a recombinant hepatitis B vaccine, which contains a form of the hepatitis B virus surface antigen that is produced in yeast cells. The development of the recombinant subunit vaccine was an important and necessary development because hepatitis B virus, unlike other common viruses such as polio virus, cannot be grown in vitro. Vaccine information from Hepatitis B Foundation Diagnosis of infection with HIV: each of the three widely used methods for diagnosing HIV infection has been developed using recombinant DNA. The antibody test (ELISA or western blot) uses a recombinant HIV protein to test for the presence of antibodies that the body has produced in response to an HIV infection. The DNA test looks for the presence of HIV genetic material using reverse transcription polymerase chain reaction (RT-PCR). Development of the RT-PCR test was made possible by the molecular cloning and sequence analysis of HIV genomes. HIV testing page from US Centers for Disease Control (CDC) Golden rice: a recombinant variety of rice that has been engineered to express the enzymes responsible for β-carotene biosynthesis. This variety of rice holds substantial promise for reducing the incidence of vitamin A deficiency in the world’s population. Golden rice is not currently in use, pending the resolution of regulatory and intellectual property issues. Herbicide-resistant crops: commercial varieties of important agricultural crops (including soy, maize/corn, sorghum, canola, alfalfa and cotton) have been developed that incorporate a recombinant gene that results in resistance to the herbicide glyphosate (trade name Roundup), and simplifies weed control by glyphosate application. These crops are in common commercial use in several countries. Insect-resistant crops: bacillus thuringeiensis is a bacterium that naturally produces a protein (Bt toxin) with insecticidal properties. The bacterium has been applied to crops as an insect-control strategy for many years, and this practice has been widely adopted in agriculture and gardening. Recently, plants have been developed that express a recombinant form of the bacterial protein, which may effectively control some insect predators. Environmental issues associated with the use of these transgenic crops have not been fully resolved. The first publications describing the successful production and intracellular replication of recombinant DNA appeared in 1972 and 1973, from Stanford and UCSF. In 1980, Paul Berg, a professor in the Biochemistry Department at Stanford and an author on one of the first papers was awarded the Nobel Prize in Chemistry for his work on nucleic acids “with particular regard to recombinant DNA”. Werner Arber, Hamilton Smith, and Daniel Nathans shared the 1978 Nobel Prize in Physiology or Medicine for the discovery of restriction endonucleases which are used rDNA technology. Stanford University applied for a US patent on recombinant DNA in 1974, listing the inventors as Herbert W. Boyer and Stanley N. Cohen; this patent was awarded in 1980. The first licensed drug generated using recombinant DNA technology was human insulin, developed by Genentech and licensed by Eli Lilly and Company. Scientists associated with the initial development of recombinant DNA methods recognized that the potential existed for organisms containing recombinant DNA to have undesirable or dangerous properties. At the 1975 Asilomar Conference on Recombinant DNA, these concerns were discussed and a voluntary moratorium on recombinant DNA research was initiated for experiments that were considered particularly risky. This moratorium was widely observed until the National Institutes of Health (USA) developed and issued formal guidelines for rDNA work. Today, recombinant DNA molecules and recombinant proteins are usually not regarded as dangerous. However, concerns remain about some organisms that express recombinant DNA, particularly when they leave the laboratory and are introduced into the environment or food chain. 10.3.1 Molecular Cloning Molecular cloning is a set of experimental methods in molecular biology that are used to assemble recombinant DNA molecules and to direct their replication within host organisms. The use of the word cloning refers to the fact that the method involves the replication of one molecule to produce a population of cells with identical DNA molecules. Molecular cloning generally uses DNA sequences from two different organisms: the species that is the source of the DNA to be cloned, and the species that will serve as the living host for replication of the recombinant DNA. Molecular cloning methods are central to many contemporary areas of modern biology and medicine. Figure 10.1: Diagram of molecular cloning using bacteria and plasmids. In a conventional molecular cloning experiment, the DNA to be cloned is obtained from an organism of interest, then treated with enzymes in the test tube to generate smaller DNA fragments. Subsequently, these fragments are then combined with vector DNA to generate recombinant DNA molecules. The recombinant DNA is then introduced into a host organism (typically an easy-to-grow, benign, laboratory strain of E. coli bacteria). This will generate a population of organisms in which recombinant DNA molecules are replicated along with the host DNA. Because they contain foreign DNA fragments, these are transgenic or genetically modified microorganisms (GMO). This process takes advantage of the fact that a single bacterial cell can be induced to take up and replicate a single recombinant DNA molecule. This single cell can then be expanded exponentially to generate a large amount of bacteria, each of which contain copies of the original recombinant molecule. Thus, both the resulting bacterial population, and the recombinant DNA molecule, are commonly referred to as “clones”. Strictly speaking, recombinant DNA refers to DNA molecules, while molecular cloning refers to the experimental methods used to assemble them. The idea arose that different DNA sequences could be inserted into a plasmid and that these foreign sequences would be carried into bacteria and digested as part of the plasmid. That is, these plasmids could serve as cloning vectors to carry genes. Virtually any DNA sequence can be cloned and amplified, but there are some factors that might limit the success of the process. Examples of the DNA sequences that are difficult to clone are inverted repeats, origins of replication, centromeres and telomeres. Another characteristic that limits chances of success is large size of DNA sequence. Inserts larger than 10kbp have very limited success, but bacteriophages such as bacteriophage λ can be modified to successfully insert a sequence up to 40 kbp. Prior to the 1970s, the understanding of genetics and molecular biology was severely hampered by an inability to isolate and study individual genes from complex organisms. This changed dramatically with the advent of molecular cloning methods. Microbiologists, seeking to understand the molecular mechanisms through which bacteria restricted the growth of bacteriophage, isolated restriction endonucleases, enzymes that could cleave DNA molecules only when specific DNA sequences were encountered. They showed that restriction enzymes cleaved chromosome-length DNA molecules at specific locations, and that specific sections of the larger molecule could be purified by size fractionation. Using a second enzyme, DNA ligase, fragments generated by restriction enzymes could be joined in new combinations, termed recombinant DNA. By recombining DNA segments of interest with vector DNA, such as bacteriophage or plasmids, which naturally replicate inside bacteria, large quantities of purified recombinant DNA molecules could be produced in bacterial cultures. The first recombinant DNA molecules were generated and studied in 1972. Molecular cloning takes advantage of the fact that the chemical structure of DNA is fundamentally the same in all living organisms. Therefore, if any segment of DNA from any organism is inserted into a DNA segment containing the molecular sequences required for DNA replication, and the resulting recombinant DNA is introduced into the organism from which the replication sequences were obtained, then the foreign DNA will be replicated along with the host cell’s DNA in the transgenic organism. The polymerase chain reaction (PCR) is a rapid version of molecular cloning without the need for replication of the DNA in a living microorganism, as PCR replicates DNA in an in vitro solution, free of living cells. 10.3.2 Procedures In standard molecular cloning experiments, the cloning of any DNA fragment essentially involves seven steps: (1) Choice of host organism and cloning vector, (2) Preparation of vector DNA, (3) Preparation of DNA to be cloned, (4) Creation of recombinant DNA, (5) Introduction of recombinant DNA into host organism, (6) Selection of organisms containing recombinant DNA, (7) Screening for clones with desired DNA inserts and biological properties. Although a very large number of host organisms and molecular cloning vectors are in use, the great majority of molecular cloning experiments begin with a laboratory strain of the bacterium Escherichia coli (E. coli) and a plasmid cloning vector. E. coli and plasmid vectors are in common use because they are technically sophisticated, versatile, widely available, and offer rapid growth of recombinant organisms with minimal equipment. If the DNA to be cloned is exceptionally large (hundreds of thousands to millions of base pairs), then a bacterial artificial chromosome or yeast artificial chromosome vector is often chosen. Specialized applications may call for specialized host-vector systems. For example, if the experimentalists wish to harvest a particular protein from the recombinant organism, then an expression vector is chosen that contains appropriate signals for transcription and translation in the desired host organism. Alternatively, if replication of the DNA in different species is desired (for example, transfer of DNA from bacteria to plants), then a multiple host range vector (also termed shuttle vector) may be selected. In practice, however, specialized molecular cloning experiments usually begin with cloning into a bacterial plasmid, followed by subcloning into a specialized vector. Whatever combination of host and vector are used, the vector almost always contains four DNA segments that are critically important to its function and experimental utility: DNA replication origin is necessary for the vector (and its linked recombinant sequences) to replicate inside the host organism one or more unique restriction endonuclease recognition sites to serves as sites where foreign DNA may be introduced a selectable genetic marker gene that can be used to enable the survival of cells that have taken up vector sequences a tag gene that can be used to screen for cells containing the foreign DNA The cloning vector is treated with a restriction endonuclease to cleave the DNA at the site where foreign DNA will be inserted. The restriction enzyme is chosen to generate a configuration at the cleavage site that is compatible with the ends of the foreign DNA (see DNA end). Typically, this is done by cleaving the vector DNA and foreign DNA with the same restriction enzyme, for example EcoRI. Most modern vectors contain a variety of convenient cleavage sites that are unique within the vector molecule (so that the vector can only be cleaved at a single site) and are located within a gene (frequently beta-galactosidase) whose inativation can be used to distinguish recombinant from non-recombinant organisms at a later step in the process. To improve the ratio of recombinant to non-recombinant organisms, the cleaved vector may be treated with an enzyme (alkaline phosphatase) that dephosphorylates the vector ends. Vector molecules with dephosphorylated ends are unable to replicate, and replication can only be restored if foreign DNA is integrated into the cleavage site. For cloning of genomic DNA, the DNA to be cloned is extracted from the organism of interest. Virtually any tissue source can be used (even tissues from extinct animals), as long as the DNA is not extensively degraded. The DNA is then purified using simple methods to remove contaminating proteins (extraction with phenol), RNA (ribonuclease) and smaller molecules (precipitation and/or chromatography). Polymerase chain reaction (PCR) methods are often used for amplification of specific DNA or RNA (RT-PCR) sequences prior to molecular cloning. DNA for cloning experiments may also be obtained from RNA using reverse transcriptase (complementary DNA or cDNA cloning), or in the form of synthetic DNA (artificial gene synthesis). cDNA cloning is usually used to obtain clones representative of the mRNA population of the cells of interest, while synthetic DNA is used to obtain any precise sequence defined by the designer. Such a designed sequence may be required when moving genes across genetic codes (for example, from the mitochrondria to the nucleus) or simply for increasing expression via codon optimization. The purified DNA is then treated with a restriction enzyme to generate fragments with ends capable of being linked to those of the vector. If necessary, short double-stranded segments of DNA (linkers) containing desired restriction sites may be added to create end structures that are compatible with the vector. The creation of recombinant DNA is in many ways the simplest step of the molecular cloning process. DNA prepared from the vector and foreign source are simply mixed together at appropriate concentrations and exposed to an enzyme (DNA ligase) that covalently links the ends together. This joining reaction is often termed ligation. The resulting DNA mixture containing randomly joined ends is then ready for introduction into the host organism. DNA ligase only recognizes and acts on the ends of linear DNA molecules, usually resulting in a complex mixture of DNA molecules with randomly joined ends. The desired products (vector DNA covalently linked to foreign DNA) will be present, but other sequences (e.g. foreign DNA linked to itself, vector DNA linked to itself and higher-order combinations of vector and foreign DNA) are also usually present. This complex mixture is sorted out in subsequent steps of the cloning process, after the DNA mixture is introduced into cells. The DNA mixture, previously manipulated in vitro, is moved back into a living cell, referred to as the host organism. The methods used to get DNA into cells are varied, and the name applied to this step in the molecular cloning process will often depend upon the experimental method that is chosen (e.g. transformation, transduction, transfection, electroporation). When microorganisms are able to take up and replicate DNA from their local environment, the process is termed transformation, and cells that are in a physiological state such that they can take up DNA are said to be competent. In mammalian cell culture, the analogous process of introducing DNA into cells is commonly termed transfection. Both transformation and transfection usually require preparation of the cells through a special growth regime and chemical treatment process that will vary with the specific species and cell types that are used. Electroporation uses high voltage electrical pulses to translocate DNA across the cell membrane (and cell wall, if present). In contrast, transduction involves the packaging of DNA into virus-derived particles, and using these virus-like particles to introduce the encapsulated DNA into the cell through a process resembling viral infection. Although electroporation and transduction are highly specialized methods, they may be the most efficient methods to move DNA into cells. Whichever method is used, the introduction of recombinant DNA into the chosen host organism is usually a low efficiency process; that is, only a small fraction of the cells will actually take up DNA. Experimental scientists deal with this issue through a step of artificial genetic selection, in which cells that have not taken up DNA are selectively killed, and only those cells that can actively replicate DNA containing the selectable marker gene encoded by the vector are able to survive. When bacterial cells are used as host organisms, the selectable marker is usually a gene that confers resistance to an antibiotic that would otherwise kill the cells, typically ampicillin. Cells harboring the plasmid will survive when exposed to the antibiotic, while those that have failed to take up plasmid sequences will die. When mammalian cells (e.g. human or mouse cells) are used, a similar strategy is used, except that the marker gene (in this case typically encoded as part of the kanMX cassette) confers resistance to the antibiotic Geneticin. Modern bacterial cloning vectors (e.g. pUC19 and later derivatives including the pGEM vectors) use the blue-white screening system to distinguish colonies (clones) of transgenic cells from those that contain the parental vector (i.e. vector DNA with no recombinant sequence inserted). In these vectors, foreign DNA is inserted into a sequence that encodes an essential part of beta-galactosidase, an enzyme whose activity results in formation of a blue-colored colony on the culture medium that is used for this work. Insertion of the foreign DNA into the beta-galactosidase coding sequence disables the function of the enzyme, so that colonies containing transformed DNA remain colorless (white). Therefore, experimentalists are easily able to identify and conduct further studies on transgenic bacterial clones, while ignoring those that do not contain recombinant DNA. The total population of individual clones obtained in a molecular cloning experiment is often termed a DNA library. Libraries may be highly complex (as when cloning complete genomic DNA from an organism) or relatively simple (as when moving a previously cloned DNA fragment into a different plasmid), but it is almost always necessary to examine a number of different clones to be sure that the desired DNA construct is obtained. This may be accomplished through a very wide range of experimental methods, including the use of nucleic acid hybridizations, antibody probes, polymerase chain reaction, restriction fragment analysis and/or DNA sequencing. 10.3.3 Mutagenesis In molecular biology, mutagenesis is an important laboratory technique whereby DNA mutations are deliberately engineered to produce mutant genes, proteins, strains of bacteria, or other genetically modified organisms. The various constituents of a gene, as well as its regulatory elements and its gene products, may be mutated so that the functioning of a genetic locus, process, or product can be examined in detail. The mutation may produce mutant proteins with interesting properties or enhanced or novel functions that may be of commercial use. Mutant strains may also be produced that have practical application or allow the molecular basis of a particular cell function to be investigated. A large number of methods for achieving experimental mutagenesis have been developed. Initially, the kind of mutations artificially induced in the laboratory were entirely random; methods allowing for more specific site-directed mutagenesis were introduced later. Since 2013, development of the CRISPR/Cas9 technology, based on a prokaryotic viral defense system, has allowed for the editing or mutagenesis of a genome in vivo. 10.3.4 Random Mutagenesis Early approaches to mutagenesis relied on methods which produced entirely random mutations. In such methods, cells or organisms are exposed to mutagens such as UV radiation or mutagenic chemicals, and mutants with desired characteristics are then selected. Hermann Muller discovered in 1927 that X-rays can cause genetic mutations in fruit flies, and went on to use the mutants he created for his studies in genetics. For Escherichia coli, mutants may be selected first by exposure to UV radiation, then plated onto an agar medium. The colonies formed are then replica-plated, one in a rich medium, another in a minimal medium, and mutants that have specific nutritional requirements can then be identified by their inability to grow in the minimal medium. Similar procedures may be repeated with other types of cells and with different media for selection. A number of methods for generating random mutations in specific proteins were later developed to screen for mutants with interesting or improved properties. These methods may involve the use of doped nucleotides in oligonucleotide synthesis, or conducting a PCR reaction in conditions that enhance misincorporation of nucleotides (error-prone PCR), for example by reducing the fidelity of replication or using nucleotide analogues. A variation of this method for integrating non-biased mutations in a gene is sequence saturation mutagenesis. PCR products which contain mutation(s) are then cloned into an expression vector and the mutant proteins produced can then be characterised. In animal studies, alkylating agents such as N-ethyl-N-nitrosourea (ENU) have been used to generate mutant mice. Ethyl methanesulfonate (EMS) is also often used to generate animal and plant mutants. In a European Union law (as 2001/18 directive), this kind of mutagenesis may be used to produce GMOs but the products are exempted from regulation: no labeling, no evaluation. 10.3.5 Site-Directed Mutagenesis Many researchers seek to introduce selected changes to DNA in a precise, site-specific manner. Analogs of nucleotides and other chemicals were first used to generate localized point mutations. Such chemicals include aminopurine, which induces an AT to GC transition, while nitrosoguanidine, bisulfite, and N4-hydroxycytidine may induce a GC to AT transition. These techniques allow specific mutations to be engineered into a protein; however, they are not flexible with respect to the kinds of mutants generated, nor are they as specific as later methods of site-directed mutagenesis and therefore have some degree of randomness. Current techniques for site-specific mutation commonly involve using pre-fabricated mutagenic oligonucleotides in a primer extension reaction with DNA polymerase. This methods allows for point mutation or deletion or insertion of small stretches of DNA at specific sites. Advances in methodology have made such mutagenesis now a relatively simple and efficient process. The site-directed approach may be done systematically in such techniques as alanine scanning mutagenesis, whereby residues are systematically mutated to alanine in order to identify residues important to the structure or function of a protein. 10.3.6 Gene Synthesis As the cost of DNA oligonucleotide synthesis falls, artificial synthesis of a complete gene is now a viable method for introducing mutations into a gene. This method allows for extensive mutation at multiple sites, including the complete redesign of the codon usage of a gene to optimise it for a particular organism. 10.3.7 Gene Knockout A gene knockout (abbreviation: KO) is a genetic technique in which one of an organism’s genes is made inoperative (“knocked out” of the organism). However, KO can also refer to the gene that is knocked out or the organism that carries the gene knockout. Knockout organisms or simply knockouts are used to study gene function, usually by investigating the effect of gene loss. Researchers draw inferences from the difference between the knockout organism and normal individuals. The KO technique is essentially the opposite of a gene knock-in. Knocking out two genes simultaneously in an organism is known as a double knockout (DKO). Similarly the terms triple knockout (TKO) and quadruple knockouts (QKO) are used to describe three or four knocked out genes, respectively. However, one needs to distinguish between heterozygous and homozygous KOs. In the former, only one of two gene copies (alleles) is knocked out, in the latter both are knocked out. Knockouts are accomplished through a variety of techniques. Originally, naturally occurring mutations were identified and then gene loss or inactivation had to be established by DNA sequencing or other methods. Traditionally, homologous recombination was the main method for causing a gene knockout. This method involves creating a DNA construct containing the desired mutation. For knockout purposes, this typically involves a drug resistance marker in place of the desired knockout gene. The construct will also contain a minimum of 2kb of homology to the target sequence. The construct can be delivered to stem cells either through microinjection or electroporation. This method then relies on the cell’s own repair mechanisms to recombine the DNA construct into the existing DNA. This results in the sequence of the gene being altered, and most cases the gene will b translated into a nonfunctional protein, if it is translated at all. However, this is an inefficient process, as homologous recombination accounts for only 10−2 to 10-3 of DNA integrations. Often, the drug selection marker on the construct is used to select for cells in which the recombination event has occurred.e These stem cells now lacking the gene could be used in vivo, for instance in mice, by inserting them into early embryos. If the resulting chimeric mouse contained the genetic change in their germline, this could then be passed on offspring. In diploid organisms, which contain two alleles for most genes, and may as well contain several related genes that collaborate in the same role, additional rounds of transformation and selection are performed until every targeted gene is knocked out. Selective breeding may be required to produce homozygous knockout animals. There are currently three methods in use that involve precisely targeting a DNA sequence in order to introduce a double-stranded break. Once this occurs, the cell’s repair mechanisms will attempt to repair this double stranded break, often through non-homologous end joining (NHEJ), which involves directly ligating the two cut ends together. This may be done imperfectly, therefore sometimes causing insertions or deletions of base pairs, which cause frameshift mutations. These mutations can render the gene in which they occur nonfunctional, thus creating a knockout of that gene. This process is more efficient than homologous recombination, and therefore can be more easily used to create biallelic knockouts. Zinc-finger nucleases consist of DNA binding domains that can precisely target a DNA sequence. Each zinc finger can recognize codons of a desired DNA sequence, and therefore can be modularly assembled to bind to a particular sequence. These binding domains are coupled with a restriction endonuclease that can cause a double stranded break (DSB) in the DNA. Repair processes may introduce mutations that destroy functionality of the gene. Transcription activator-like effector nucleases (TALENs) also contain a DNA binding domain and a nuclease that can cleave DNA. The DNA binding region consists of amino acid repeats that each recognize a single base pair of the desired targeted DNA sequence. If this cleavage is targeted to a gene coding region, and NHEJ-mediated repair introduces insertions and deletions, a frameshift mutation often results, thus disrupting function of the gene. Clustered regularly interspaced short palindromic repeats (CRISPR)/Cas9 is a method for genome editing that contains a guide RNA complexed with a Cas9 protein. The guide RNA can be engineered to match a desired DNA sequence through simple complementary base pairing, as opposed to the time consuming assembly of constructs required by zinc-fingers or TALENs. The coupled Cas9 will cause a double stranded break in the DNA. Following the same principle as zinc-fingers and TALENs, the attempts to repair these double stranded breaks often result in frameshift mutations that result in an nonfunctional gene. 10.3.8 Conditional Gene Knockout Conditional gene knockout is a technique used to eliminate a specific gene in a certain tissue, such as the liver. This technique is useful to study the role of individual genes in living organisms. It differs from traditional gene knockout because it targets specific genes at specific times rather than being deleted from beginning of life. Using the conditional gene knockout technique eliminates many of the side effects from traditional gene knockout. In traditional gene knockout, embryonic death from a gene mutation can occur, and this prevents scientists from studying the gene in adults. Some tissues cannot be studied properly in isolation, so the gene must be inactive in a certain tissue while remaining active in others. With this technology, scientists are able to knockout genes at a specific stage in development and study how the knockout of a gene in one tissue affects the same gene in other tissues. The most commonly used technique is the Cre-lox recombination system. The Cre recombinase enzyme specifically recognizes two lox (loci of recombination) sites within DNA and causes recombination between them. During recombination two strands of DNA exchange information. This recombination will cause a deletion or inversion of the genes between the two lox sites, depending on their orientation. An entire gene can be removed to inactivate it. This whole system is inducible so a chemical can be added to knock genes out at a specific time. Two of the most commonly used chemicals are tetracycline, which activates transcription of the Cre recombinase gene and tamoxifen, which activates transport of the Cre recombinase protein to the nucleus. Only a few cell types express Cre recombinase and no mammalian cells express it so there is no risk of accidental activation of lox sites when using conditional gene knockout in mammals. Figuring out how to express Cre-recombinase in an organism tends to be the most difficult part of this technique. Uses The conditional gene knockout method is often used to model human diseases in other mammals. It has increased scientists’ ability to study diseases, such as cancer, that develop in specific cell types or developmental stages. It is known that mutations in the BRCA1 gene are linked to breast cancer. Scientists used conditional gene knockout to delete the BRCA1 allele in mammary gland tissue in mice and found that it plays an important role in tumour suppression. Conditional gene knockouts in mice are often used to study human diseases because many genes produce similar phenotypes in both species. The goal of KOMP is to create knockout mutations in the embryonic stem cells for each of the 20,000 protein coding genes in mice. The genes are knocked out because this is the best way to study their function and learn more about their role in human diseases. Some alleles in this project cannot be knocked out using traditional methods and require the specificity of the conditional gene knockout technique. Other combinatorial methods are needed to knockout the last remaining alleles. Conditional gene knockout is a time-consuming procedure and there are additional projects focusing on knocking out the remaining mouse genes. The KOMP projected was started in 2006 and is still ongoing. 10.3.9 Gene Knock-In Gene knockin is similar to gene knockout, but it replaces a gene with another instead of deleting it. 10.3.10 RNA interference RNA interference (RNAi) is a biological process in which RNA molecules inhibit gene expression or translation, by neutralizing targeted mRNA molecules. The process of RNAi was referred to as “co-suppression” and “quelling” when observed prior to the knowledge of an RNA-related mechanism. The discovery of RNAi was preceded first by observations of transcriptional inhibition by antisense RNA expressed in transgenic plants, and more directly by reports of unexpected outcomes in experiments performed by plant scientists in the United States and the Netherlands in the early 1990s. The detailed study of each of these seemingly different processes elucidated that the identity of these phenomena were all actually RNAi. Andrew Fire and Craig C. Mello shared the 2006 Nobel Prize in Physiology or Medicine for their work on RNA interference in the nematode worm Caenorhabditis elegans, which they published in 1998. Since the discovery of RNAi and its regulatory potentials, it has become evident that RNAi has immense potential in suppression of desired genes. RNAi is now known as precise, efficient, stable and better than antisense technology for gene suppression. However, antisense RNA produced intracellularly by an expression vector may be developed and find utility as novel therapeutic agents. Two types of small ribonucleic acid (RNA) molecules – microRNA (miRNA) and small interfering RNA (siRNA) – are central to RNA interference. RNAs are the direct products of genes, and these small RNAs can direct enzyme complexes to degrade messenger RNA (mRNA) molecules and thus decrease their activity by preventing translation, via post-transcriptional gene silencing. Moreover, transcription can be inhibited via the pre-transcriptional silencing mechanism of RNA interference, through which an enzyme complex catalyzes DNA methylation at genomic positions complementary to complexed siRNA or miRNA. RNA interference has an important role in defending cells against parasitic nucleotide sequences – viruses and transposons. It also influences development. The RNAi pathway is found in many eukaryotes, including animals, and is initiated by the enzyme Dicer, which cleaves long double-stranded RNA (dsRNA) molecules into short double-stranded fragments of ~21 nucleotide siRNAs. Each siRNA is unwound into two single-stranded RNAs (ssRNAs), the passenger strand and the guide strand. The passenger strand is degraded and the guide strand is incorporated into the RNA-induced silencing complex (RISC). The most well-studied outcome is post-transcriptional gene silencing, which occurs when the guide strand pairs with a complementary sequence in a messenger RNA molecule and induces cleavage by Argonaute 2 (Ago2), the catalytic component of the RISC. In some organisms, this process spreads systemically, despite the initially limited molar concentrations of siRNA. Figure 10.2: Lentiviral delivery of designed shRNAs and the mechanism of RNA interference in mammalian cells. RNAi is a valuable research tool, both in cell culture and in living organisms, because synthetic dsRNA introduced into cells can selectively and robustly induce suppression of specific genes of interest. RNAi may be used for large-scale screens that systematically shut down each gene in the cell, which can help to identify the components necessary for a particular cellular process or an event such as cell division. The pathway is also used as a practical tool in biotechnology, medicine and insecticides. RNAi is an RNA-dependent gene silencing process that is controlled by the RNA-induced silencing complex (RISC) and is initiated by short double-stranded RNA molecules in a cell’s cytoplasm, where they interact with the catalytic RISC component argonaute. When the dsRNA is exogenous (coming from infection by a virus with an RNA genome or laboratory manipulations), the RNA is imported directly into the cytoplasm and cleaved to short fragments by Dicer. The initiating dsRNA can also be endogenous (originating in the cell), as in pre-microRNAs expressed from RNA-coding genes in the genome. The primary transcripts from such genes are first processed to form the characteristic stem-loop structure of pre-miRNA in the nucleus, then exported to the cytoplasm. Thus, the two dsRNA pathways, exogenous and endogenous, converge at the RISC. Exogenous dsRNA initiates RNAi by activating the ribonuclease protein Dicer, which binds and cleaves double-stranded RNAs (dsRNAs) in plants, or short hairpin RNAs (shRNAs) in humans, to produce double-stranded fragments of 20–25 base pairs with a 2-nucleotide overhang at the 3’ end. Bioinformatics studies on the genomes of multiple organisms suggest this length maximizes target-gene specificity and minimizes non-specific effects. These short double-stranded fragments are called small interfering RNAs (siRNAs). These siRNAs are then separated into single strands and integrated into an active RISC, by RISC-Loading Complex (RLC). RLC includes Dicer-2 and R2D2, and is crucial to unite Ago2 and RISC. TATA-binding protein-associated factor 11 (TAF11) assembles the RLC by facilitating Dcr-2-R2D2 tetramerization, which increases the binding affinity to siRNA by 10-fold. Association with TAF11 would convert the R2-D2-Initiator (RDI) complex into the RLC. R2D2 carries tandem double-stranded RNA-binding domains to recognize the thermodynamically stable terminus of siRNA duplexes, whereas Dicer-2 the other less stable extremity. Loading is asymmetric: the MID domain of Ago2 recognizes the thermodynamically stable end of the siRNA. Therefore, the “passenger” (sense) strand whose 5′ end is discarded by MID is ejected, while the saved “guide” (antisense) strand cooperates with AGO to form the RISC. After integration into the RISC, siRNAs base-pair to their target mRNA and cleave it, thereby preventing it from being used as a translation template. Differently from siRNA, a miRNA-loaded RISC complex scans cytoplasmic mRNAs for potential complementarity. Instead of destructive cleavage (by Ago2), miRNAs rather target the 3′ untranslated region (UTR) regions of mRNAs where they typically bind with imperfect complementarity, thus blocking the access of ribosomes for translation. Exogenous dsRNA is detected and bound by an effector protein, known as RDE-4 in C. elegans and R2D2 in Drosophila, that stimulates dicer activity. The mechanism producing this length specificity is unknown and this protein only binds long dsRNAs. In C. elegans this initiation response is amplified through the synthesis of a population of ‘secondary’ siRNAs during which the dicer-produced initiating or ‘primary’ siRNAs are used as templates. These ‘secondary’ siRNAs are structurally distinct from dicer-produced siRNAs and appear to be produced by an RNA-dependent RNA polymerase (RdRP). 10.3.11 MicroRNA MicroRNAs (miRNAs) are genomically encoded non-coding RNAs that help regulate gene expression, particularly during development. The phenomenon of RNA interference, broadly defined, includes the endogenously induced gene silencing effects of miRNAs as well as silencing triggered by foreign dsRNA. Mature miRNAs are structurally similar to siRNAs produced from exogenous dsRNA, but before reaching maturity, miRNAs must first undergo extensive post-transcriptional modification. A miRNA is expressed from a much longer RNA-coding gene as a primary transcript known as a pri-miRNA which is processed, in the cell nucleus, to a 70-nucleotide stem-loop structure called a pre-miRNA by the microprocessor complex. This complex consists of an RNase III enzyme called Drosha and a dsRNA-binding protein DGCR8. The dsRNA portion of this pre-miRNA is bound and cleaved by Dicer to produce the mature miRNA molecule that can be integrated into the RISC complex; thus, miRNA and siRNA share the same downstream cellular machinery. First, viral encoded miRNA was described in EBV. Thereafter, an increasing number of microRNAs have been described in viruses. VIRmiRNA is a comprehensive catalogue covering viral microRNA, their targets and anti-viral miRNAs (see also VIRmiRNA resource: http://crdd.osdd.net/servers/virmirna/). siRNAs derived from long dsRNA precursors differ from miRNAs in that miRNAs, especially those in animals, typically have incomplete base pairing to a target and inhibit the translation of many different mRNAs with similar sequences. In contrast, siRNAs typically base-pair perfectly and induce mRNA cleavage only in a single, specific target. In Drosophila and C. elegans, miRNA and siRNA are processed by distinct argonaute proteins and dicer enzymes. Three prime untranslated regions (3’UTRs) of messenger RNAs (mRNAs) often contain regulatory sequences that post-transcriptionally cause RNA interference. Such 3’-UTRs often contain both binding sites for microRNAs (miRNAs) as well as for regulatory proteins. By binding to specific sites within the 3’-UTR, miRNAs can decrease gene expression of various mRNAs by either inhibiting translation or directly causing degradation of the transcript. The 3’-UTR also may have silencer regions that bind repressor proteins that inhibit the expression of a mRNA. The 3’-UTR often contains microRNA response elements (MREs). MREs are sequences to which miRNAs bind. These are prevalent motifs within 3’-UTRs. Among all regulatory motifs within the 3’-UTRs (e.g. including silencer regions), MREs make up about half of the motifs. As of 2014, the miRBase web site, an archive of miRNA sequences and annotations, listed 28,645 entries in 233 biologic species. Of these, 1,881 miRNAs were in annotated human miRNA loci. miRNAs were predicted to have an average of about four hundred target mRNAs (affecting expression of several hundred genes). Friedman et al. estimate that &gt;45,000 miRNA target sites within human mRNA 3’UTRs are conserved above background levels, and &gt;60% of human protein-coding genes have been under selective pressure to maintain pairing to miRNAs. Direct experiments show that a single miRNA can reduce the stability of hundreds of unique mRNAs. Other experiments show that a single miRNA may repress the production of hundreds of proteins, but that this repression often is relatively mild (less than 2-fold). The effects of miRNA dysregulation of gene expression seem to be important in cancer. For instance, in gastrointestinal cancers, nine miRNAs have been identified as epigenetically altered and effective in down regulating DNA repair enzymes. The effects of miRNA dysregulation of gene expression also seem to be important in neuropsychiatric disorders, such as schizophrenia, bipolar disorder, major depression, Parkinson’s disease, Alzheimer’s disease and autism spectrum disorders. RISC activation and catalysis Exogenous dsRNA is detected and bound by an effector protein, known as RDE-4 in C. elegans and R2D2 in Drosophila, that stimulates dicer activity. This protein only binds long dsRNAs, but the mechanism producing this length specificity is unknown. This RNA-binding protein then facilitates the transfer of cleaved siRNAs to the RISC complex. In C. elegans this initiation response is amplified through the synthesis of a population of ‘secondary’ siRNAs during which the dicer-produced initiating or ‘primary’ siRNAs are used as templates. These ‘secondary’ siRNAs are structurally distinct from dicer-produced siRNAs and appear to be produced by an RNA-dependent RNA polymerase (RdRP). The active components of an RNA-induced silencing complex (RISC) are endonucleases called argonaute proteins, which cleave the target mRNA strand complementary to their bound siRNA. As the fragments produced by dicer are double-stranded, they could each in theory produce a functional siRNA. However, only one of the two strands, which is known as the guide strand, binds the argonaute protein and directs gene silencing. The other anti-guide strand or passenger strand is degraded during RISC activation. Although it was first believed that an ATP-dependent helicase separated these two strands, the process proved to be ATP-independent and performed directly by the protein components of RISC. However, an in vitro kinetic analysis of RNAi in the presence and absence of ATP showed that ATP may be required to unwind and remove the cleaved mRNA strand from the RISC complex after catalysis. The guide strand tends to be the one whose 5’ end is less stably paired to its complement, but strand selection is unaffected by the direction in which dicer cleaves the dsRNA before RISC incorporation. Instead, the R2D2 protein may serve as the differentiating factor by binding the more-stable 5’ end of the passenger strand. 10.3.12 Transcriptional Silencing Components of the RNAi pathway are used in many eukaryotes in the maintenance of the organization and structure of their genomes. Modification of histones and associated induction of heterochromatin formation serves to downregulate genes pre-transcriptionally; this process is referred to as RNA-induced transcriptional silencing (RITS), and is carried out by a complex of proteins called the RITS complex. In fission yeast this complex contains argonaute, a chromodomain protein Chp1, and a protein called Tas3 of unknown function. As a consequence, the induction and spread of heterochromatic regions requires the argonaute and RdRP proteins. Indeed, deletion of these genes in the fission yeast S. pombe disrupts histone methylation and centromere formation, causing slow or stalled anaphase during cell division. In some cases, similar processes associated with histone modification have been observed to transcriptionally upregulate genes. The type of RNA editing that is most prevalent in higher eukaryotes converts adenosine nucleotides into inosine in dsRNAs via the enzyme adenosine deaminase (ADAR). It was originally proposed in 2000 that the RNAi and A→I RNA editing pathways might compete for a common dsRNA substrate. Some pre-miRNAs do undergo A→I RNA editing and this mechanism may regulate the processing and expression of mature miRNAs. Furthermore, at least one mammalian ADAR can sequester siRNAs from RNAi pathway components. Further support for this model comes from studies on ADAR-null C. elegans strains indicating that A→I RNA editing may counteract RNAi silencing of endogenous genes and transgenes. 10.3.13 Gene Knockdown The RNA interference pathway is often exploited in experimental biology to study the function of genes in cell culture and in vivo in model organisms. Double-stranded RNA is synthesized with a sequence complementary to a gene of interest and introduced into a cell or organism, where it is recognized as exogenous genetic material and activates the RNAi pathway. Using this mechanism, researchers can cause a drastic decrease in the expression of a targeted gene. Studying the effects of this decrease can show the physiological role of the gene product. Since RNAi may not totally abolish expression of the gene, this technique is sometimes referred as a “knockdown”, to distinguish it from “knockout” procedures in which expression of a gene is entirely eliminated. In a recent study validation of RNAi silencing efficiency using gene array data showed 18.5% failure rate across 429 independent experiments. Extensive efforts in computational biology have been directed toward the design of successful dsRNA reagents that maximize gene knockdown but minimize “off-target” effects. Off-target effects arise when an introduced RNA has a base sequence that can pair with and thus reduce the expression of multiple genes. Such problems occur more frequently when the dsRNA contains repetitive sequences. It has been estimated from studying the genomes of humans, C. elegans and S. pombe that about 10% of possible siRNAs have substantial off-target effects. A multitude of software tools have been developed implementing algorithms for the design of general mammal-specific, and virus-specific siRNAs that are automatically checked for possible cross-reactivity. Depending on the organism and experimental system, the exogenous RNA may be a long strand designed to be cleaved by dicer, or short RNAs designed to serve as siRNA substrates. In most mammalian cells, shorter RNAs are used because long double-stranded RNA molecules induce the mammalian interferon response, a form of innate immunity that reacts nonspecifically to foreign genetic material. Mouse oocytes and cells from early mouse embryos lack this reaction to exogenous dsRNA and are therefore a common model system for studying mammalian gene-knockdown effects. Specialized laboratory techniques have also been developed to improve the utility of RNAi in mammalian systems by avoiding the direct introduction of siRNA, for example, by stable transfection with a plasmid encoding the appropriate sequence from which siRNAs can be transcribed, or by more elaborate lentiviral vector systems allowing the inducible activation or deactivation of transcription, known as conditional RNAi. Most functional genomics applications of RNAi in animals have used C. elegans and Drosophila, as these are the common model organisms in which RNAi is most effective. C. elegans is particularly useful for RNAi research for two reasons: firstly, the effects of gene silencing are generally heritable, and secondly because delivery of the dsRNA is extremely simple. Through a mechanism whose details are poorly understood, bacteria such as E. coli that carry the desired dsRNA can be fed to the worms and will transfer their RNA payload to the worm via the intestinal tract. This “delivery by feeding” is just as effective at inducing gene silencing as more costly and time-consuming delivery methods, such as soaking the worms in dsRNA solution and injecting dsRNA into the gonads. Although delivery is more difficult in most other organisms, efforts are also underway to undertake large-scale genomic screening applications in cell culture with mammalian cells. Functional genomics using RNAi is a particularly attractive technique for genomic mapping and annotation in plants because many plants are polyploid, which presents substantial challenges for more traditional genetic engineering methods. For example, RNAi has been successfully used for functional genomics studies in bread wheat (which is hexaploid) as well as more common plant model systems Arabidopsis and maize. 10.3.14 Cre-Lox Recombination Cre-Lox recombination is a site-specific recombinase technology, used to carry out deletions, insertions, translocations and inversions at specific sites in the DNA of cells. It allows the DNA modification to be targeted to a specific cell type or be triggered by a specific external stimulus. It is implemented both in eukaryotic and prokaryotic systems. The Cre-lox recombination system has been particularly useful to help neuroscientists to study the brain in which complex cell types and neural circuits come together to generate cognition and behaviors. NIH Blueprint for Neuroscience Research has created several hundreds of Cre driver mouse lines which are currently used by the worldwide neuroscience community. The system consists of a single enzyme, Cre recombinase, that recombines a pair of short target sequences called the Lox sequences. This system can be implemented without inserting any extra supporting proteins or sequences. The Cre enzyme and the original Lox site called the LoxP sequence are derived from bacteriophage P1. Placing Lox sequences appropriately allows genes to be activated, repressed, or exchanged for other genes. At a DNA level many types of manipulations can be carried out. The activity of the Cre enzyme can be controlled so that it is expressed in a particular cell type or triggered by an external stimulus like a chemical signal or a heat shock. These targeted DNA changes are useful in cell lineage tracing and when mutants are lethal if expressed globally. The Cre-Lox system is very similar in action and in usage to the FLP-FRT recombination system. Cre-Lox recombination involves the targeting of a specific sequence of DNA and splicing it with the help of an enzyme called Cre recombinase. Cre-Lox recombination is commonly used to circumvent embryonic lethality caused by systemic inactivation of many genes. In addition, Cre–Lox recombination provides the best experimental control that presently[when?] exists in transgenic animal modeling to link genotypes (alterations in genomic DNA) to phenotypes (the biological outcomes). The Cre-lox system is used as a genetic tool to control site specific recombination events in genomic DNA. This system has allowed researchers to manipulate a variety of genetically modified organisms to control gene expression, delete undesired DNA sequences and modify chromosome architecture. The Cre protein is a site-specific DNA recombinase that can catalyse the recombination of DNA between specific sites in a DNA molecule. These sites, known as loxP sequences, contain specific binding sites for Cre that surround a directional core sequence where recombination can occur. When cells that have loxP sites in their genome express Cre, a recombination event can occur between the loxP sites. Cre recombinase proteins bind to the first and last 13 bp regions of a lox site forming a dimer. This dimer then binds to a dimer on another lox site to form a tetramer. Lox sites are directional and the two sites joined by the tetramer are parallel in orientation. The double stranded DNA is cut at both loxP sites by the Cre protein. The strands are then rejoined with DNA ligase in a quick and efficient process. The result of recombination depends on the orientation of the loxP sites. For two lox sites on the same chromosome arm, inverted loxP sites will cause an inversion of the intervening DNA, while a direct repeat of loxP sites will cause a deletion event. If loxP sites are on different chromosomes it is possible for translocation events to be catalysed by Cre induced recombination. Two plasmids can be joined using the variant lox sites 71 and 66. The Cre protein (encoded by the locus originally named as “Causes recombination”, with “Cyclization recombinase” being found in some references) consists of 4 subunits and two domains: The larger carboxyl (C-terminal) domain, and smaller amino (N-terminal) domain. The total protein has 343 amino acids. The C domain is similar in structure to the domain in the Integrase family of enzymes isolated from lambda phage. This is also the catalytic site of the enzyme. loxP (locus of X-over P1) is a site on the bacteriophage P1 consisting of 34 bp. The site includes an asymmetric 8 bp sequence, variable except for the middle two bases, in between two sets of symmetric, 13 bp sequences. The exact sequence is given below; ‘N’ indicates bases which may vary, and lowercase letters indicate bases that have been mutated from the wild-type. The 13 bp sequences are palindromic but the 8 bp spacer is not, thus giving the loxP sequence a certain direction. Usually loxP sites come in pairs for genetic manipulation. If the two loxP sites are in the same orientation, the floxed sequence (sequence flanked by two loxP sites) is excised; however if the two loxP sites are in the opposite orientation, the floxed sequence is inverted. If there exists a floxed donor sequence, the donor sequence can be swapped with the original sequence. This technique is called recombinase-mediated cassette exchange and is a very convenient and time-saving way for genetic manipulation. The caveat, however, is that the recombination reaction can happen backwards, rendering cassette exchange inefficient. In addition, sequence excision can happen in trans instead of a in cis cassette exchange event. The loxP mutants are created to avoid these problems. The P1 phage is a temperate phage that causes either a lysogenic or lytic cycle when it infects a bacterium. In its lytic state, once its viral genome is injected into the host cell, viral proteins are produced, virions are assembled, and the host cell is lysed to release the phages, continuing the cycle. In the lysogenic cycle the phage genome replicates with the rest of the bacterial genome and is transmitted to daughter cells at each subsequent cell division. It can transition to the lytic cycle by a later event such as UV radiation or starvation. Phages like the lambda phage use their site specific recombinases to integrate their DNA into the host genome during lysogeny. P1 phage DNA on the other hand, exists as a plasmid in the host. The Cre-lox system serves several functions in the phage: it circularizes the phage DNA into a plasmid, separates interlinked plasmid rings so they are passed to both daughter bacteria equally and may help maintain copy numbers through an alternative means of replication. The P1 phage DNA when released into the host from the virion is in the form of a linear double stranded DNA molecule. The Cre enzyme targets loxP sites at the ends of this molecule and cyclises the genome. This can also take place in the absence of the Cre lox system with the help of other bacterial and viral proteins. The P1 plasmid is relatively large (≈90Kbp) and hence exists in a low copy number - usually one per cell. If the two daughter plasmids get interlinked one of the daughter cells of the host will lose the plasmid. The Cre-lox recombination system prevents these situations by unlinking the rings of DNA by carrying out two recombination events (linked rings -&gt; single fused ring -&gt; two unlinked rings). It is also proposed that rolling circle replication followed by recombination will allow the plasmid to increase its copy number when certain regulators (repA) are limiting. 10.3.15 CRISPR Gene Editing CRISPR gene editing is a method by which the genomes of living organisms may be edited. It is based on a simplified version of the bacterial CRISPR/Cas (CRISPR-Cas9) antiviral defense system. By delivering the Cas9 nuclease complexed with a synthetic guide RNA (gRNA) into a cell, the cell’s genome can be cut at a desired location, allowing existing genes to be removed and/or new ones added. Figure 10.3: Diagram of the CRISPR prokaryotic antiviral defense mechanism. While genomic editing in eukaryotic cells has been possible using various methods since the 1980s, the methods employed had proved to be inefficient and impractical to implement on a larger scale. Genomic editing leads to irreversible changes to the gene. Working like genetic scissors, the Cas9 nuclease opens both strands of the targeted sequence of DNA to introduce the modification by one of two methods. Knock-in mutations, facilitated via Homology Directed Repair (HDR), is the traditional pathway of targeted genomic editing approaches. This allows for the introduction of targeted DNA damage and repair. HDR employs the use of similar DNA sequences to drive the repair of the break via the incorporation of exogenous DNA to function as the repair template. This method relies on the periodic and isolated occurrence of DNA damage at the target site in order for a repair to commence. Knock-out mutations caused by CRISPR-Cas9 results in the repair of the double-strand break by means of NHEJ (Non-Homologous End Joining). NHEJ can often result in random deletions or insertions at the repair site disrupting or altering gene functionality. Therefore, genomic engineering by CRISPR-Cas9 allows researchers the ability to generate targeted random gene disruption. Because of this, the precision of genomic editing is a great concern. With the discovery of CRISPR and specifically the Cas9 nuclease molecule, efficient and highly selective editing is now a reality. Cas9 allows for a reliable method of creating a targeted break at a specific location as designated by the crRNA and tracrRna guide strands. Cas9 derived from Streptococcus pyogenes bacteria has facilitated the targeted genomic modification in eukaryotic cells. The ease with which researchers can insert Cas9 and template RNA in order to silence or cause point mutations on specific loci has proved invaluable to the quick and efficient mapping of genomic models and biological processes associated with various genes in a variety of eukaryotes. Newly engineered variants of the Cas9 nuclease have been developed that significantly reduce off-target activity. CRISPR-Cas9 genome editing techniques have many potential applications, including medicine and crop seed enhancement. The use of CRISPR-Cas9-gRNA complex for genome editing was the AAAS’s choice for breakthrough of the year in 2015. Bioethical concerns have been raised about the prospect of using CRISPR for germline editing. In the early 2000s, researchers developed zinc finger nucleases (ZFNs), synthetic proteins whose DNA-binding domains enable them to create double-stranded breaks in DNA at specific points. In 2010, synthetic nucleases called transcription activator-like effector nucleases (TALENs) provided an easier way to target a double-stranded break to a specific location on the DNA strand. Both zinc finger nucleases and TALENs require the creation of a custom protein for each targeted DNA sequence, which is a more difficult and time-consuming process than that for guide RNAs. CRISPRs are much easier to design because the process requires making only a short RNA sequence. Whereas RNA interference (RNAi) does not fully suppress gene function, CRISPR, ZFNs and TALENs provide full irreversible gene knockout. CRISPR can also target several DNA sites simultaneously by simply introducing different gRNAs. In addition, CRISPR costs are relatively low. CRISPR-Cas9 genome editing is carried out with a Type II CRISPR system. When utilized for genome editing, this system includes Cas9, crRNA, tracrRNA along with an optional section of DNA repair template that is utilized in either non-homologous end joining (NHEJ) or homology directed repair (HDR). CRISPR-Cas9 often employs a plasmid to transfect the target cells. The main components of this plasmid are displayed in the image and listed in the table. The crRNA needs to be designed for each application as this is the sequence that Cas9 uses to identify and directly bind to the cell’s DNA. The crRNA must bind only where editing is desired. The repair template is designed for each application, as it must overlap with the sequences on either side of the cut and code for the insertion sequence. Multiple crRNAs and the tracrRNA can be packaged together to form a single-guide RNA (sgRNA). This sgRNA can be joined together with the Cas9 gene and made into a plasmid in order to be transfected into cells. CRISPR-Cas9 offers a high degree of fidelity and relatively simple construction. It depends on two factors for its specificity: the target sequence and the PAM. The target sequence is 20 bases long as part of each CRISPR locus in the crRNA array. A typical crRNA array has multiple unique target sequences. Cas9 proteins select the correct location on the host’s genome by utilizing the sequence to bond with base pairs on the host DNA. The sequence is not part of the Cas9 protein and as a result is customizable and can be independently synthesized. The PAM sequence on the host genome is recognized by Cas9. Cas9 cannot be easily modified to recognize a different PAM sequence. However this is not too limiting as it is a short sequence and nonspecific (e.g. the SpCas9 PAM sequence is 5’-NGG-3’ and in the human genome occurs roughly every 8 to 12 base pairs). Once these have been assembled into a plasmid and transfected into cells the Cas9 protein with the help of the crRNA finds the correct sequence in the host cell’s DNA and – depending on the Cas9 variant – creates a single or double strand break in the DNA. Properly spaced single strand breaks in the host DNA can trigger homology directed repair, which is less error prone than the non-homologous end joining that typically follows a double strand break. Providing a DNA repair template allows for the insertion of a specific DNA sequence at an exact location within the genome. The repair template should extend 40 to 90 base pairs beyond the Cas9 induced DNA break. The goal is for the cell’s HDR process to utilize the provided repair template and thereby incorporate the new sequence into the genome. Once incorporated, this new sequence is now part of the cell’s genetic material and passes into its daughter cells. Many online tools are available to aid in designing effective sgRNA sequences. Delivery of Cas9, sgRNA, and associated complexes into cells can occur via viral and non-viral systems. Electroporation of DNA, RNA, or ribonucleocomplexes is a common technique, though it can result in harmful effects on the target cells. Chemical transfection techniques utilizing lipids have also been used to introduce sgRNA in complex with Cas9 into cells. Hard-to-transfect cells (e.g. stem cells, neurons, and hematopoietic cells) require more efficient delivery systems such as those based on lentivirus (LVs), adenovirus (AdV) and adeno-associated virus (AAV). Several variants of CRISPR-Cas9 allow gene activation or genome editing with an external trigger such as light or small molecules. These include photoactivatable CRISPR systems developed by fusing light-responsive protein partners with an activator domain and a dCas9 for gene activation, or fusing similar light responsive domains with two constructs of split-Cas9, or by incorporating caged unnatural amino acids into Cas9, or by modifying the guide RNAs with photocleavable complements for genome editing. Methods to control genome editing with small molecules include an allosteric Cas9, with no detectable background editing, that will activate binding and cleavage upon the addition of 4-hydroxytamoxifen (4-HT), 4-HT responsive intein-linked Cas9s or a Cas9 that is 4-HT responsive when fused to four ERT2 domains. Intein-inducible split-Cas9 allows dimerization of Cas9 fragments and Rapamycin-inducible split-Cas9 system developed by fusing two constructs of split Cas9 with FRB and FKBP fragments. Furthermore, other studies have shown to induce transcription of Cas9 with a small molecule, doxycycline. Small molecules can also be used to improve Homology Directed Repair (HDR), often by inhibiting the Non-Homologous End Joining (NHEJ) pathway. These systems allow conditional control of CRISPR activity for improved precision, efficiency and spatiotemporal control. Cas9 genomic modification has allowed for the quick and efficient generation of transgenic models within the field of genetics. Cas9 can be easily introduced into the target cells via plasmid transfection along with sgRNA in order to model the spread of diseases and the cell’s response and defense to infection. The ability of Cas9 to be introduced in vivo allows for the creation of more accurate models of gene function, mutation effects, all while avoiding the off-target mutations typically observed with older methods of genetic engineering. The CRISPR and Cas9 revolution in genomic modeling doesn’t only extend to mammals. Traditional genomic models such as Drosophila melanogaster, one of the first model species, have seen further refinement in their resolution with the use of Cas9. Cas9 uses celtimicrobial therapy and a strategy by which to manipulate bacterial populations. Recent studies suggested a correlation between the interfering of the CRISPR-Cas locus and acquisition of antibiotic resistance This system provides protection of bacteria against invading foreign DNA, such as transposons, bacteriophages and plasmids. This system was shown to be a strong selective pressure for the acquisition of antibiotic resistance and virulence factor in bacterial pathogens. The first clinical trial involving CRISPR started in 2016. It involved removing immune cells from people with lung cancer, using CRISPR to edit out the gene expressed PD-1, then administrating the altered cells back to the same person. 20 other trials were under way or nearly ready, mostly in China, as of 2017. In 2016, the United States Food and Drug Administration (FDA) approved a clinical trial in which CRISPR would be used to alter T cells extracted from people with different kinds of cancer and then administer those engineered T cells back to the same people. Using “dead” versions of Cas9 (dCas9) eliminates CRISPR’s DNA-cutting ability, while preserving its ability to target desirable sequences. Multiple groups added various regulatory factors to dCas9s, enabling them to turn almost any gene on or off or adjust its level of activity. Like RNAi, CRISPR interference (CRISPRi) turns off genes in a reversible fashion by targeting, but not cutting a site. The targeted site is methylated, epigenetically modifying the gene. This modification inhibits transcription. These precisely placed modifications may then be used to regulate the effects on gene expressions and DNA dynamics after the inhibition of certain genome sequences within DNA. Within the past few years, epigenetic marks in different human cells have been closely researched and certain patterns within the marks have been found to correlate with everything ranging from tumor growth to brain activity. Conversely, CRISPR-mediated activation (CRISPRa) promotes gene transcription. Cas9 is an effective way of targeting and silencing specific genes at the DNA level. In bacteria, the presence of Cas9 alone is enough to block transcription. For mammalian applications, a section of protein is added. Its guide RNA targets regulatory DNA sequences called promoters that immediately precede the target gene. Cas9 was used to carry synthetic transcription factors that activated specific human genes. The technique achieved a strong effect by targeting multiple CRISPR constructs to slightly different locations on the gene’s promoter. 10.3.16 Gene Drive A gene drive is a genetic engineering technology that propagates a particular suite of genes throughout a population by altering the probability that a specific allele will be transmitted to offspring from the natural 50% probability. Gene drives can arise through a variety of mechanisms. They have been proposed to provide an effective means of genetically modifying specific populations and entire species.,The technique can employ adding, deleting, disrupting, or modifying genes. Proposed applications include exterminating insects that carry pathogens (notably mosquitoes that transmit malaria, dengue, and zika pathogens), controlling invasive species or eliminating herbicide or pesticide resistance. In sexually-reproducing species, most genes are present in two copies (which can be the same or different alleles), either one of which has a 50% chance of passing to a descendant. By biasing the inheritance of particular altered genes, synthetic gene drives could spread alterations through a population. At the molecular level, an endonuclease gene drive works by cutting a chromosome at a specific site that does not encode the drive, inducing the cell to repair the damage by copying the drive sequence onto the damaged chromosome. The cell then has two copies of the drive sequence. The method derives from genome editing techniques and relies on the fact that double strand breaks are most frequently repaired by homologous recombination, (in the presence of a template), rather than non-homologous end joining. To achieve this behavior, endonuclease gene drives consist of two nested elements: either a homing endonuclease or a RNA-guided endonuclease (e.g., Cas9 or Cpf1) and its guide RNA, that cuts the target sequence in recipient cells a template sequence used by the DNA repair machinery after the target sequence is cut. To achieve the self-propagating nature of gene drives, this repair template contains at least the endonuclease sequence. Because the template must be used to repair a double-strand break at the cutting site, its sides are homologous to the sequences that are adjacent to the cutting site in the host genome. By targeting the gene drive to a gene coding sequence, this gene will be inactivated; additional sequences can be introduced in the gene drive to encode new functions. As a result, the gene drive insertion in the genome will re-occur in each organism that inherits one copy of the modification and one copy of the wild-type gene. If the gene drive is already present in the egg cell (e.g. when received from one parent), all the gametes of the individual will carry the gene drive (instead of 50% in the case of a normal gene). Since it can never more than double in frequency with each generation, a gene drive introduced in a single individual typically requires dozens of generations to affect a substantial fraction of a population. Alternatively, releasing drive-containing organisms in sufficient numbers can affect the rest within a few generations; for instance, by introducing it in every thousandth individual, it takes only 12–15 generations to be present in all individuals. Whether a gene drive will ultimately become fixed in a population and at which speed depends on its effect on individuals fitness, on the rate of allele conversion, and on the population structure. In a well mixed population and with realistic allele conversion frequencies (≈90%), population genetics predicts that gene drives get fixed for selection coefficient smaller than 0.3; in other words, gene drives can be used to spread modifications as long as reproductive success is not reduced by more than 30%. This is in contrast with normal genes, which can only spread across large populations if they increase fitness. 10.4 Human Germline Modification As of March 2015, multiple groups had announced ongoing research with the intention of laying the foundations for applying CRISPR to human embryos for human germline engineering, including labs in the US, China, and the UK, as well as US biotechnology company OvaScience. Scientists, including a CRISPR co-discoverer, urged a worldwide moratorium on applying CRISPR to the human germline, especially for clinical use. They said “scientists should avoid even attempting, in lax jurisdictions, germline genome modification for clinical application in humans” until the full implications “are discussed among scientific and governmental organizations”. These scientists support further low-level research on CRISPR and do not see CRISPR as developed enough for any clinical use in making heritable changes to humans. In April 2015, Chinese scientists reported results of an attempt to alter the DNA of non-viable human embryos using CRISPR to correct a mutation that causes beta thalassemia, a lethal heritable disorder. The study had previously been rejected by both Nature and Science in part because of ethical concerns. The experiments resulted in successfully changing only some of the intended genes, and had off-target effects on other genes. The researchers stated that CRISPR is not ready for clinical application in reproductive medicine. In April 2016, Chinese scientists were reported to have made a second unsuccessful attempt to alter the DNA of non-viable human embryos using CRISPR - this time to alter the CCR5 gene to make the embryo HIV resistant. In December 2015, an International Summit on Human Gene Editing took place in Washington under the guidance of David Baltimore. Members of national scientific academies of America, Britain and China discussed the ethics of germline modification. They agreed to support basic and clinical research under certain legal and ethical guidelines. A specific distinction was made between somatic cells, where the effects of edits are limited to a single individual, versus germline cells, where genome changes could be inherited by descendants. Heritable modifications could have unintended and far-reaching consequences for human evolution, genetically (e.g. gene/environment interactions) and culturally (e.g. Social Darwinism). Altering of gametocytes and embryos to generate inheritable changes in humans was defined to be irresponsible. The group agreed to initiate an international forum to address such concerns and harmonize regulations across countries. In November 2018, Jiankui He announced that he had edited two human embryos, to attempt to disable the gene for CCR5, which codes for a receptor that HIV uses to enter cells. He said that twin girls, Lulu and Nana, had been born a few weeks earlier. He said that the girls still carried functional copies of CCR5 along with disabled CCR5 (mosaicism) and were still vulnerable to HIV. The work was widely condemned as unethical, dangerous, and premature. An international group of scientists called for a global moratorium on genetically editing human embryos. Policy regulations for the CRISPR-Cas9 system vary around the globe. In February 2016, British scientists were given permission by regulators to genetically modify human embryos by using CRISPR-Cas9 and related techniques. However, researchers were forbidden from implanting the embryos and the embryos were to be destroyed after seven days. The US has an elaborate, interdepartmental regulatory system to evaluate new genetically modified foods and crops. For example, the Agriculture Risk Protection Act of 2000 gives the USDA the authority to oversee the detection, control, eradication, suppression, prevention, or retardation of the spread of plant pests or noxious weeds to protect the agriculture, environment and economy of the US. The act regulates any genetically modified organism that utilizes the genome of a predefined “plant pest” or any plant not previously categorized. In 2015, Yinong Yang successfully deactivated 16 specific genes in the white button mushroom, to make them non-browning. Since he had not added any foreign-species (transgenic) DNA to his organism, the mushroom could not be regulated by the USDA under Section 340.2. Yang’s white button mushroom was the first organism genetically modified with the CRISPR-Cas9 protein system to pass US regulation. In 2016, the USDA sponsored a committee to consider future regulatory policy for upcoming genetic modification techniques. With the help of the US National Academies of Sciences, Engineering and Medicine, special interests groups met on April 15 to contemplate the possible advancements in genetic engineering within the next five years and any new regulations that might be needed as a result. The FDA in 2017 proposed a rule that would classify genetic engineering modifications to animals as “animal drugs”, subjecting them to strict regulation if offered for sale, and reducing the ability for individuals and small businesses to make them profitably. 10.5 Gain-of-function Research Gain-of-function research (GoF research or GoFR) is medical research that genetically alters an organism in a way that may enhance the biological functions of gene products. This may include an altered pathogenesis, transmissibility, or host range, i.e. the types of hosts that a microorganism can infect. This research is intended to reveal targets to better predict emerging infectious diseases and to develop vaccines and therapeutics. For example, influenza B can only infect humans and harbor seals. Introducing a mutation that would allow influenza B to infect rabbits in a controlled laboratory situation would be considered a “gain of function” experiment as the virus did not previously have that function. That type of experiment could then help reveal which parts of the virus are responsible for its host range, enabling the creation of antiviral medicines which block this function. In virology, gain-of-function research is employed with the intention of better understanding current and future pandemics. In vaccine development, gain-of-function research is conducted in the hope of gaining a head start on a virus and being able to develop a vaccine or therapeutic before it emerges. The term “gain of function” is sometimes applied more narrowly to refer to “research which could enable a pandemic-potential pathogen to replicate more quickly or cause more harm in humans or other closely-related mammals.” Some forms of gain-of-function research (specifically work which involves certain select agent pathogens) carry inherent biosafety and biosecurity risks, and are thus also referred to as dual use research of concern (DURC). To mitigate these risks while allowing the benefits of such research, various governments have mandated that DURC experiments be regulated under additional oversight by institutions (so-called institutional “DURC” committees) and government agencies (such as the NIH’s recombinant DNA advisory committee). A mirrored approach can be seen in the European Union’s Dual Use Coordination Group (DUCG). Importantly, the US and EU regulations both mandate that an unaffiliated member of the public (or several) be “active participants” in the oversight process. Significant debate has taken place in the scientific community on how to assess the risks and benefit of gain-of-function research, how to publish such research responsibly, and how to engage the public in an open and honest review. As of January 2020, the United States is convening an expert panel to revisit the rules for gain-of-function research and provide more clarity in how such experiments are approved, and when they should be disclosed to the public. In early 2011, two groups were investigating how flu viruses specific to birds could possibly cross over and create pandemics in humans: one led by Yoshihiro Kawaoka at University of Wisconsin in Madison, Wisconsin and another led by Ron Fouchier at Erasmus University Medical Center in the Netherlands. Both groups had both serially passaged H5N1 avian influenza in ferrets, manually taking the virus from one ferret to another, until it was capable of spreading via respiratory droplets. The normally bird-specific virus, through replication over time in the ferrets’ lungs, had adopted several amino acid changes that enabled it to replicate in the mammalian lungs, which are a notably colder than those found in birds. This small change also allowed the virus to transmit via droplets in the air made when the ferrets’ coughed or sneezed. Proponents of the Kawaoka and Fouchier experiments cited several benefits: these answered the question of how a virus like H5N1 could possibly become airborne in humans, allowed other researchers to develop vaccines and therapeutics which specifically targeted these amino acid changes, and also demonstrated that there was a linkage between transmissibility in avian viruses and lethality: while the virus had become more transmissible, it had also become significantly less deadly. Various critics of the research (including members of Congress) responded to the publications with alarm. Others called the experiments an “engineered doomsday.” Questions were raised by other scientists including Marc Lipsitch of the T. H. Chan School of Public Health at Harvard University about the relative risks and benefits of this research. In May 2013, a group led by Hualan Chen, director of China’s National Avian Influenza Reference Laboratory, published several experiments they had conducted at the BSL3+ laboratory of the Harbin Veterinary Research Institute, investigating what would happen if a 2009 H1N1 circulating in humans infected the same cell as an avian influenza H5N1. Importantly, the experiments had been conducted before a research pause on H5N1 experiments had been agreed upon by the greater virologist community. They used these experiments to determine that certain genes, if reassorted in such a dual-infection scenario in the wild, would allow transmission of the H5N1 virus more easily in mammals (notably guinea pigs as a model organism for rodent species), proving that certain agricultural scenarios carry the risk of allowing H5N1 to cross over into mammals. As in the Fouchier and Kawaoka experiments above, the viruses in this study were also significantly less lethal after the modification. Critics of the 2013 Chen group study (including Simon Wain-Hobson of the Pasteur Institute and former Royal Society President Robert May) decried this as an unsafe experiment that was unnecessary to prove the intended conclusions, calling Chen’s work “appallingly irresponsible” and also raising concerns about the biosafety of the laboratory itself. Others (including the Director of the WHO Collaborating Centre on Influenza in Tokyo, Masato Tashiro) praised Chen’s laboratory as “state of the art.” Jeremy Farrar, director of the Oxford University Clinical Research Unit in Ho Chi Minh City, described the work as “remarkable” and said that it demonstrated the “very real threat” that “continued circulation of H5N1 strains in Asia and Egypt” poses. 10.6 Genomics Genomics is an interdisciplinary field of biology focusing on the structure, function, evolution, mapping, and editing of genomes. A genome is an organism’s complete set of DNA, including all of its genes. In contrast to genetics, which refers to the study of individual genes and their roles in inheritance, genomics aims at the collective characterization and quantification of all of an organism’s genes, their interrelations and influence on the organism. Genes may direct the production of proteins with the assistance of enzymes and messenger molecules. In turn, proteins make up body structures such as organs and tissues as well as control chemical reactions and carry signals between cells. Genomics also involves the sequencing and analysis of genomes through uses of high throughput DNA sequencing and bioinformatics to assemble and analyze the function and structure of entire genomes. Advances in genomics have triggered a revolution in discovery-based research and systems biology to facilitate understanding of even the most complex biological systems such as the brain. The field also includes studies of intragenomic (within the genome) phenomena such as epistasis (effect of one gene on another), pleiotropy (one gene affecting more than one trait), heterosis (hybrid vigour), and other interactions between loci and alleles within the genome. From the Greek ΓΕΝ gen, “gene”meaning “become, create, creation, birth”, and subsequent variants: genealogy, genesis, genetics, genic, genomere, genotype, genus etc. While the word genome (from the German Genom, attributed to Hans Winkler) was in use in English as early as 1926, the term genomics was coined by Tom Roderick, a geneticist at the Jackson Laboratory (Bar Harbor, Maine), over beer at a meeting held in Maryland on the mapping of the human genome in 1986. Following Rosalind Franklin’s confirmation of the helical structure of DNA, James D. Watson and Francis Crick’s publication of the structure of DNA in 1953 and Fred Sanger’s publication of the Amino acid sequence of insulin in 1955, nucleic acid sequencing became a major target of early molecular biologists. In 1964, Robert W. Holley and colleagues published the first nucleic acid sequence ever determined, the ribonucleotide sequence of alanine transfer RNA. Extending this work, Marshall Nirenberg and Philip Leder revealed the triplet nature of the genetic code and were able to determine the sequences of 54 out of 64 codons in their experiments. In 1972, Walter Fiers and his team at the Laboratory of Molecular Biology of the University of Ghent Ghent, Belgium) were the first to determine the sequence of a gene: the gene for Bacteriophage MS2 coat protein. Fiers’ group expanded on their MS2 coat protein work, determining the complete nucleotide-sequence of bacteriophage MS2-RNA (whose genome encodes just four genes in 3569 base pairs) and Simian virus 40 in 1976 and 1978, respectively. In addition to his seminal work on the amino acid sequence of insulin, Frederick Sanger and his colleagues played a key role in the development of DNA sequencing techniques that enabled the establishment of comprehensive genome sequencing projects. In 1975, he and Alan Coulson published a sequencing procedure using DNA polymerase with radiolabelled nucleotides that he called the Plus and Minus technique. This involved two closely related methods that generated short oligonucleotides with defined 3’ termini. These could be fractionated by electrophoresis on a polyacrylamide gel (called polyacrylamide gel electrophoresis) and visualised using autoradiography. The procedure could sequence up to 80 nucleotides in one go and was a big improvement, but was still very laborious. Nevertheless, in 1977 his group was able to sequence most of the 5,386 nucleotides of the single-stranded bacteriophage φX174, completing the first fully sequenced DNA-based genome. The refinement of the Plus and Minus method resulted in the chain-termination, or Sanger method (see below), which formed the basis of the techniques of DNA sequencing, genome mapping, data storage, and bioinformatic analysis most widely used in the following quarter-century of research. In the same year Walter Gilbert and Allan Maxam of Harvard University independently developed the Maxam-Gilbert method (also known as the chemical method) of DNA sequencing, involving the preferential cleavage of DNA at known bases, a less efficient method. For their groundbreaking work in the sequencing of nucleic acids, Gilbert and Sanger shared half the 1980 Nobel Prize in chemistry with Paul Berg (recombinant DNA). 10.6.1 Complete Genomes The advent of rapid and efficient DNA sequencing technologies resulted in a rapid intensification in the scope and speed of completion of genome sequencing projects. The first complete genome sequence of a eukaryotic organelle, the human mitochondrion (16,568 bp, about 16.6 kb [kilobase]), was reported in 1981, and the first chloroplast genomes followed in 1986. In 1992, the first eukaryotic chromosome, chromosome III of brewer’s yeast Saccharomyces cerevisiae (315 kb) was sequenced. The first free-living organism to be sequenced was that of Haemophilus influenzae (1.8 Mb [megabase]) in 1995. The following year a consortium of researchers from laboratories across North America, Europe, and Japan announced the completion of the first complete genome sequence of a eukaryote, S. cerevisiae (12.1 Mb), and since then genomes have continued being sequenced at an exponentially growing pace. As of October 2011, the complete sequences are available for: 2,719 viruses, 1,115 archaea and bacteria, and 36 eukaryotes, of which about half are fungi. Most of the microorganisms whose genomes have been completely sequenced are problematic pathogens, such as Haemophilus influenzae, which has resulted in a pronounced bias in their phylogenetic distribution compared to the breadth of microbial diversity. Of the other sequenced species, most were chosen because they were well-studied model organisms or promised to become good models. Yeast (Saccharomyces cerevisiae) has long been an important model organism for the eukaryotic cell, while the fruit fly Drosophila melanogaster has been a very important tool (notably in early pre-molecular genetics). The worm Caenorhabditis elegans is an often used simple model for multicellular organisms. The zebrafish Danio rerio is used for many developmental studies on the molecular level, and the plant Arabidopsis thaliana is a model organism for flowering plants. The Japanese pufferfish (Takifugu rubripes) and the spotted green pufferfish (Tetraodon nigroviridis) are interesting because of their small and compact genomes, which contain very little noncoding DNA compared to most species. The mammals dog (Canis familiaris), brown rat (Rattus norvegicus), mouse (Mus musculus), and chimpanzee (Pan troglodytes) are all important model animals in medical research. A rough draft of the human genome was completed by the Human Genome Project in early 2001, creating much fanfare. This project, completed in 2003, sequenced the entire genome for one specific person, and by 2007 this sequence was declared “finished” (less than one error in 20,000 bases and all chromosomes assembled). In the years since then, the genomes of many other individuals have been sequenced, partly under the auspices of the 1000 Genomes Project, which announced the sequencing of 1,092 genomes in October 2012. Completion of this project was made possible by the development of dramatically more efficient sequencing technologies and required the commitment of significant bioinformatics resources from a large international collaboration. The continued analysis of human genomic data has profound political and social repercussions for human societies. 10.6.2 The “Omics” Revolution The English-language neologism omics informally refers to a field of study in biology ending in -omics, such as genomics, proteomics or metabolomics. The related suffix -ome is used to address the objects of study of such fields, such as the genome, proteome or metabolome respectively. The suffix -ome as used in molecular biology refers to a totality of some sort; similarly omics has come to refer generally to the study of large, comprehensive biological data sets. While the growth in the use of the term has led some scientists (Jonathan Eisen, among others) to claim that it has been oversold, it reflects the change in orientation towards the quantitative analysis of complete or near-complete assortment of all the constituents of a system. In the study of symbioses, for example, researchers which were once limited to the study of a single gene product can now simultaneously compare the total complement of several types of biological molecules. 10.6.3 Genome Analysis After an organism has been selected, genome projects involve three components: the sequencing of DNA, the assembly of that sequence to create a representation of the original chromosome, and the annotation and analysis of that representation. Finished genomes are defined as having a single contiguous sequence with no ambiguities representing each replicon. 10.6.4 Genome Annotation The DNA sequence assembly alone is of little value without additional analysis. Genome annotation is the process of attaching biological information to sequences, and consists of three main steps: identifying portions of the genome that do not code for proteins identifying elements on the genome, a process called gene prediction, and attaching biological information to these elements. Automatic annotation tools try to perform these steps in silico, as opposed to manual annotation (a.k.a. curation) which involves human expertise and potential experimental verification. Ideally, these approaches co-exist and complement each other in the same annotation pipeline (also see below). Traditionally, the basic level of annotation is using BLAST for finding similarities, and then annotating genomes based on homologues. More recently, additional information is added to the annotation platform. The additional information allows manual annotators to deconvolute discrepancies between genes that are given the same annotation. Some databases use genome context information, similarity scores, experimental data, and integrations of other resources to provide genome annotations through their Subsystems approach. Other databases (e.g. Ensembl) rely on both curated data sources as well as a range of software tools in their automated genome annotation pipeline. Structural annotation consists of the identification of genomic elements, primarily ORFs and their localisation, or gene structure. Functional annotation consists of attaching biological information to genomic elements. 10.6.5 Functional Genomics Functional genomics is a field of molecular biology that attempts to make use of the vast wealth of data produced by genomic projects (such as genome sequencing projects) to describe gene (and protein) functions and interactions. Functional genomics focuses on the dynamic aspects such as gene transcription, translation, and protein–protein interactions, as opposed to the static aspects of the genomic information such as DNA sequence or structures. Functional genomics attempts to answer questions about the function of DNA at the levels of genes, RNA transcripts, and protein products. A key characteristic of functional genomics studies is their genome-wide approach to these questions, generally involving high-throughput methods rather than a more traditional “gene-by-gene” approach. A major branch of genomics is still concerned with sequencing the genomes of various organisms, but the knowledge of full genomes has created the possibility for the field of functional genomics, mainly concerned with patterns of gene expression during various conditions. The most important tools here are microarrays and bioinformatics. 10.6.6 Structural Genomics Structural genomics seeks to describe the 3-dimensional structure of every protein encoded by a given genome. This genome-based approach allows for a high-throughput method of structure determination by a combination of experimental and modeling approaches. The principal difference between structural genomics and traditional structural prediction is that structural genomics attempts to determine the structure of every protein encoded by the genome, rather than focusing on one particular protein. With full-genome sequences available, structure prediction can be done more quickly through a combination of experimental and modeling approaches, especially because the availability of large numbers of sequenced genomes and previously solved protein structures allow scientists to model protein structure on the structures of previously solved homologs. Structural genomics involves taking a large number of approaches to structure determination, including experimental methods using genomic sequences or modeling-based approaches based on sequence or structural homology to a protein of known structure or based on chemical and physical principles for a protein with no homology to any known structure. As opposed to traditional structural biology, the determination of a protein structure through a structural genomics effort often (but not always) comes before anything is known regarding the protein function. This raises new challenges in structural bioinformatics, i.e. determining protein function from its 3D structure. 10.6.7 Epigenomics Epigenomics is the study of the complete set of epigenetic modifications on the genetic material of a cell, known as the epigenome. Epigenetic modifications are reversible modifications on a cell’s DNA or histones that affect gene expression without altering the DNA sequence (Russell 2010 p. 475). Two of the most characterized epigenetic modifications are DNA methylation and histone modification. Epigenetic modifications play an important role in gene expression and regulation, and are involved in numerous cellular processes such as in differentiation/development and tumorigenesis. The study of epigenetics on a global level has been made possible only recently through the adaptation of genomic high-throughput assays. 10.6.8 Metagenomics Metagenomics is the study of metagenomes, genetic material recovered directly from environmental samples. The broad field may also be referred to as environmental genomics, ecogenomics or community genomics. While traditional microbiology and microbial genome sequencing rely upon cultivated clonal cultures, early environmental gene sequencing cloned specific genes (often the 16S rRNA gene) to produce a profile of diversity in a natural sample. Such work revealed that the vast majority of microbial biodiversity had been missed by cultivation-based methods. Recent studies use “shotgun” Sanger sequencing or massively parallel pyrosequencing to get largely unbiased samples of all genes from all the members of the sampled communities. Because of its power to reveal the previously hidden diversity of microscopic life, metagenomics offers a powerful lens for viewing the microbial world that has the potential to revolutionize understanding of the entire living world. 10.6.9 Applications Of Genomics Genomics has provided applications in many fields, including medicine, biotechnology, anthropology and other social sciences. 10.6.10 Genomic Medicine Next-generation genomic technologies allow clinicians and biomedical researchers to drastically increase the amount of genomic data collected on large study populations. When combined with new informatics approaches that integrate many kinds of data with genomic data in disease research, this allows researchers to better understand the genetic bases of drug response and disease. For example, the All of Us research program aims to collect genome sequence data from 1 million participants to become a critical component of the precision medicine research platform. 10.6.11 Synthetic Biology And Bioengineering The growth of genomic knowledge has enabled increasingly sophisticated applications of synthetic biology. In 2010 researchers at the J. Craig Venter Institute announced the creation of a partially synthetic species of bacterium, Mycoplasma laboratorium, derived from the genome of Mycoplasma genitalium. 10.6.12 Conservation Genomics Conservationists can use the information gathered by genomic sequencing in order to better evaluate genetic factors key to species conservation, such as the genetic diversity of a population or whether an individual is heterozygous for a recessive inherited genetic disorder. By using genomic data to evaluate the effects of evolutionary processes and to detect patterns in variation throughout a given population, conservationists can formulate plans to aid a given species without as many variables left unknown as those unaddressed by standard genetic approaches. 10.6.13 Genome-Wide Association Study In genetics, a genome-wide association study (GWA study, or GWAS), also known as whole genome association study (WGA study, or WGAS), is an observational study of a genome-wide set of genetic variants in different individuals to see if any variant is associated with a trait. GWASs typically focus on associations between single-nucleotide polymorphisms (SNPs) and traits like major human diseases, but can equally be applied to any other genetic variants and any other organisms. When applied to human data, GWA studies compare the DNA of participants having varying phenotypes for a particular trait or disease. These participants may be people with a disease (cases) and similar people without the disease (controls), or they may be people with different phenotypes for a particular trait, for example blood pressure. This approach is known as phenotype-first, in which the participants are classified first by their clinical manifestation(s), as opposed to genotype-first. Each person gives a sample of DNA, from which millions of genetic variants are read using SNP arrays. If one type of the variant (one allele) is more frequent in people with the disease, the variant is said to be associated with the disease. The associated SNPs are then considered to mark a region of the human genome that may influence the risk of disease. GWA studies investigate the entire genome, in contrast to methods that specifically test a small number of pre-specified genetic regions. Hence, GWAS is a non-candidate-driven approach, in contrast to gene-specific candidate-driven studies. GWA studies identify SNPs and other variants in DNA associated with a disease, but they cannot on their own specify which genes are causal. The first successful GWAS published in 2002 studied myocardial infarction. This study design was then implemented in the landmark GWA 2005 study investigating patients with age-related macular degeneration, and found two SNPs with significantly altered allele frequency compared to healthy controls. As of 2017, over 3,000 human GWA studies have examined over 1,800 diseases and traits, and thousands of SNP associations have been found. Except in the case of rare genetic diseases, these associations are very weak, but while they may not explain much of the risk, they provide insight into genes and pathways that can be important. Any two human genomes differ in millions of different ways. There are small variations in the individual nucleotides of the genomes (SNPs) as well as many larger variations, such as deletions, insertions and copy number variations. Any of these may cause alterations in an individual’s traits, or phenotype, which can be anything from disease risk to physical properties such as height. Around the year 2000, prior to the introduction of GWA studies, the primary method of investigation was through inheritance studies of genetic linkage in families. This approach had proven highly useful towards single gene disorders. However, for common and complex dseases the results of genetic linkage studies proved hard to reproduce. A suggested alternative to linkage studies was the genetic association study. This study type asks if the allele of a genetic variant is found more often than expected in individuals with the phenotype of interest (e.g. with the disease being studied). Early calculations on statistical power indicated that this approach could be better than linkage studies at detecting weak genetic effects. The most common approach of GWA studies is the case-control setup, which compares two large groups of individuals, one healthy control group and one case group affected by a disease. All individuals in each group are genotyped for the majority of common known SNPs. The exact number of SNPs depends on the genotyping technology, but are typically one million or more. For each of these SNPs it is then investigated if the allele frequency is significantly altered between the case and the control group. In such setups, the fundamental unit for reporting effect sizes is the odds ratio. The odds ratio is the ratio of two odds, which in the context of GWA studies are the odds of case for individuals having a specific allele and the odds of case for individuals who do not have that same allele. As an example, suppose that there are two alleles, T and C. The number of individuals in the case group having allele T is represented by ‘A’ and the number of individuals in the control group having allele T is represented by ‘B’. Similarly, the number of individuals in the case group having allele C is represented by ‘X’ and the number of individuals in the control group having allele C is represented by ‘Y’. In this case the odds ratio for allele T is A:B (meaning ‘A to B’, in standard odds terminology) divided by X:Y, which in mathematical notation is simply (A/B)/(X/Y). When the allele frequency in the case group is much higher than in the control group, the odds ratio is higher than 1, and vice versa for lower allele frequency. Additionally, a P-value for the significance of the odds ratio is typically calculated using a simple chi-squared test. Finding odds ratios that are significantly different from 1 is the objective of the GWA study because this shows that a SNP is associated with disease. Because so many variants are tested, it is standard practice to require the p-value to be lower than 5 x 10-8 to consider a variant significant. Attempts have been made at creating comprehensive catalogues of SNPs that have been identified from GWA studies. As of 2009, SNPs associated with diseases are numbered in the thousands. The first GWA study, conducted in 2005, compared 96 patients with age-related macular degeneration (ARMD) with 50 healthy controls. It identified two SNPs with significantly altered allele frequency between the two groups. These SNPs were located in the gene encoding complement factor H, which was an unexpected finding in the research of ARMD. The findings from these first GWA studies have subsequently prompted further functional research towards therapeutical manipulation of the complement system in ARMD. Another landmark publication in the history of GWA studies was the Wellcome Trust Case Control Consortium (WTCCC) study, the largest GWA study ever conducted at the time of its publication in 2007. The WTCCC included 14,000 cases of seven common diseases (~2,000 individuals for each of coronary heart disease, type 1 diabetes, type 2 diabetes, rheumatoid arthritis, Crohn’s disease, bipolar disorder, and hypertension) and 3,000 shared controls. This study was successful in uncovering many new disease genes underlying these diseases. 10.7 Genetic Testing Genetic testing, also known as DNA testing, is used to identify changes in DNA sequence or chromosome structure. Genetic testing can also include measuring the results of genetic changes, such as RNA analysis as an output of gene expression, or through biochemical analysis to measure specific protein output. In a medical setting, genetic testing can be used to diagnose or rule out suspected genetic disorders, predict risks for specific conditions, or gain information that can be used to customize medical treatments based on an individual’s genetic makeup. Genetic testing can also be used to determine biological relatives, such as a child’s parentage (genetic mother and father) through DNA paternity testing, or be used to broadly predict an individual’s ancestry. Genetic testing of plants and animals can be used for similar reasons as in humans (e.g. to assess relatedness/ancestry or predict/diagnose genetic disorders), to gain information used for selective breeding, or for efforts to boost genetic diversity in endangered populations. The variety of genetic tests has expanded throughout the years. Early forms of genetic testing which began in the 1950s involved counting the number of chromosomes per cell. Deviations from the expected number of chromosomes (46 in humans) could lead to a diagnosis of certain genetic conditions such as trisomy 21 (Down syndrome) or monosomy X (Turner syndrome). In the 1970s, a method to stain specific regions of chromosomes, called chromosome banding, was developed that allowed more detailed analysis of chromosome structure and diagnosis of genetic disorders that involved large structural rearrangements. In addition to analyzing whole chromosomes (cytogenetics), genetic testing has expanded to include the fields of molecular genetics and genomics which can identify changes at the level of individual genes, parts of genes, or even single nucleotide “letters” of DNA sequence. According to the National Institutes of Health, there are tests available for more than 2,000 genetic conditions, and one study estimated that as of 2017 there were more than 75,000 genetic tests on the market. There are a number of types of testing available, including: Cell-free fetal DNA (cffDNA) testing - a non-invasive (for the fetus) test. It is performed on a sample of venous blood from the mother, and can provide information about the fetus early in pregnancy. As of 2015 it is the most sensitive and specific screening test for Down syndrome. Newborn screening - used just after birth to identify genetic disorders that can be treated early in life. A blood sample is collected with a heel prick from the newborn 24–48 hours after birth and sent to the lab for analysis. In the United States, newborn screening procedure varies state by state, but all states by law test for at least 21 disorders. If abnormal results are obtained, it does not necessarily mean the child has the disorder. Diagnostic tests must follow the initial screening to confirm the disease. The routine testing of infants for certain disorders is the most widespread use of genetic testing—millions of babies are tested each year in the United States. All states currently test infants for phenylketonuria (a genetic disorder that causes mental illness if left untreated) and congenital hypothyroidism (a disorder of the thyroid gland). People with PKU do not have an enzyme needed to process the amino acid phenylalanine, which is responsible for normal growth in children and normal protein use throughout their lifetime. If there is a buildup of too much phenylalanine, brain tissue can be damaged, causing developmental delay. Newborn screening can detect the presence of PKU, allowing children to be placed on special diets to avoid the effects of the disorder. Diagnostic testing - used to diagnose or rule out a specific genetic or chromosomal condition. In many cases, genetic testing is used to confirm a diagnosis when a particular condition is suspected based on physical mutations and symptoms. Diagnostic testing can be performed at any time during a person’s life, but is not available for all genes or all genetic conditions. The results of a diagnostic test can influence a person’s choices about health care and the management of the disease. For example, people with a family history of polycystic kidney disease (PKD) who experience pain or tenderness in their abdomen, blood in their urine, frequent urination, pain in the sides, a urinary tract infection or kidney stones may decide to have their genes tested and the result could confirm the diagnosis of PKD. Carrier testing - used to identify people who carry one copy of a gene mutation that, when present in two copies, causes a genetic disorder. This type of testing is offered to individuals who have a family history of a genetic disorder and to people in ethnic groups with an increased risk of specific genetic conditions. If both parents are tested, the test can provide information about a couple’s risk of having a child with a genetic condition like cystic fibrosis. Preimplantation genetic diagnosis - performed on human embryos prior to the implantation as part of an in vitro fertilization procedure. Pre-implantation testing is used when individuals try to conceive a child through in vitro fertilization. Eggs from the woman and sperm from the man are removed and fertilized outside the body to create multiple embryos. The embryos are individually screened for abnormalities, and the ones without abnormalities are implanted in the uterus. Prenatal diagnosis - used to detect changes in a fetus’s genes or chromosomes before birth. This type of testing is offered to couples with an increased risk of having a baby with a genetic or chromosomal disorder. In some cases, prenatal testing can lessen a couple’s uncertainty or help them decide whether to abort the pregnancy. It cannot identify all possible inherited disorders and birth defects, however. One method of performing a prenatal genetic test involves an amniocentesis, which removes a sample of fluid from the mother’s amniotic sac 15 to 20 or more weeks into pregnancy. The fluid is then tested for chromosomal abnormalities such as Down syndrome (Trisomy 21) and Trisomy 18, which can result in neonatal or fetal death. Test results can be retrieved within 7–14 days after the test is done. This method is 99.4% accurate at detecting and diagnosing fetal chromosome abnormalities. Although there is a risk of miscarriage associated with an amniocentesis, the miscarriage rate is only 1/400. Another method of prenatal testing is Chorionic Villus Sampling (CVS). Chorionic villi are projections from the placenta that carry the same genetic makeup as the baby. During this method of prenatal testing, a sample of chorionic villi is removed from the placenta to be tested. This test is performed 10–13 weeks into pregnancy and results are ready 7–14 days after the test was done. Another test using blood taken from the fetal umbilical cord is percutaneous umbilical cord blood sampling. Predictive and presymptomatic testing - used to detect gene mutations associated with disorders that appear after birth, often later in life. These tests can be helpful to people who have a family member with a genetic disorder, but who have no features of the disorder themselves at the time of testing. Predictive testing can identify mutations that increase a person’s chances of developing disorders with a genetic basis, such as certain types of cancer. For example, an individual with a mutation in BRCA1 has a 65% cumulative risk of breast cancer. Hereditary breast cancer along with ovarian cancer syndrome are caused by gene alterations in the genes BRCA1 and BRCA2. Major cancer types related to mutations in these genes are female breast cancer, ovarian, prostate, pancreatic, and male breast cancer. Li-Fraumeni syndrome is caused by a gene alteration on the gene TP53. Cancer types associated with a mutation on this gene include breast cancer, soft tissue sarcoma, osteosarcoma (bone cancer), leukemia and brain tumors. In the Cowden syndrome there is a mutation on the PTEN gene, causing potential breast, thyroid or endometrial cancer. Presymptomatic testing can determine whether a person will develop a genetic disorder, such as hemochromatosis (an iron overload disorder), before any signs or symptoms appear. The results of predictive and presymptomatic testing can provide information about a person’s risk of developing a specific disorder, help with making decisions about medical care and provide a better prognosis. Pharmacogenomics - determines the influence of genetic variation on drug response. When a person has a disease or health condition, pharmacogenomics can examine an individual’s genetic makeup to determine what medicine and what dosage would be the safest and most beneficial to the patient. In the human population, there are approximately 11 million single nucleotide polymorphisms (SNPs) in people’s genomes, making them the most common variations in the human genome. SNPs reveal information about an individual’s response to certain drugs. This type of genetic testing can be used for cancer patients undergoing chemotherapy. A sample of the cancer tissue can be sent in for genetic analysis by a specialized lab. After analysis, information retrieved can identify mutations in the tumor which can be used to determine the best treatment option. Non-diagnostic testing includes: Forensic testing - uses DNA sequences to identify an individual for legal purposes. Unlike the tests described above, forensic testing is not used to detect gene mutations associated with disease. This type of testing can identify crime or catastrophe victims, rule out or implicate a crime suspect, or establish biological relationships between people (for example, paternity). Paternity testing - uses special DNA markers to identify the same or similar inheritance patterns between related individuals. Based on the fact that we all inherit half of our DNA from the father, and half from the mother, DNA scientists test individuals to find the match of DNA sequences at some highly differential markers to draw the conclusion of relatedness. Genealogical DNA test - used to determine ancestry or ethnic heritage for genetic genealogy. Research testing - includes finding unknown genes, learning how genes work and advancing understanding of genetic conditions. The results of testing done as part of a research study are usually not available to patients or their healthcare providers. Genetic testing is often done as part of a genetic consultation and as of mid-2008 there were more than 1,200 clinically applicable genetic tests available. Once a person decides to proceed with genetic testing, a medical geneticist, genetic counselor, primary care doctor, or specialist can order the test after obtaining informed consent. Genetic tests are performed on a sample of blood, hair, skin, amniotic fluid (the fluid that surrounds a fetus during pregnancy), or other tissue. For example, a medical procedure called a buccal smear uses a small brush or cotton swab to collect a sample of cells from the inside surface of the cheek. Alternatively, a small amount of saline mouthwash may be swished in the mouth to collect the cells. The sample is sent to a laboratory where technicians look for specific changes in chromosomes, DNA, or proteins, depending on the suspected disorders, often using DNA sequencing. The laboratory reports the test results in writing to a person’s doctor or genetic counselor. Routine newborn screening tests are done on a small blood sample obtained by pricking the baby’s heel with a lancet. The physical risks associated with most genetic tests are very small, particularly for those tests that require only a blood sample or buccal smear (a procedure that samples cells from the inside surface of the cheek). The procedures used for prenatal testing carry a small but non-negligible risk of losing the pregnancy (miscarriage) because they require a sample of amniotic fluid or tissue from around the fetus. Many of the risks associated with genetic testing involve the emotional, social, or financial consequences of the test results. People may feel angry, depressed, anxious, or guilty about their results. The potential negative impact of genetic testing has led to an increasing recognition of a “right not to know”. In some cases, genetic testing creates tension within a family because the results can reveal information about other family members in addition to the person who is tested. The possibility of genetic discrimination in employment or insurance is also a concern. Some individuals avoid genetic testing out of fear it will affect their ability to purchase insurance or find a job. Health insurers do not currently require applicants for coverage to undergo genetic testing, and when insurers encounter genetic information, it is subject to the same confidentiality protections as any other sensitive health information. In the United States, the use of genetic information is governed by the Genetic Information Nondiscrimination Act (GINA) (see discussion below in the section on government regulation). Genetic testing can provide only limited information about an inherited condition. The test often can’t determine if a person will show symptoms of a disorder, how severe the symptoms will be, or whether the disorder will progress over time. Another major limitation is the lack of treatment strategies for many genetic disorders once they are diagnosed. Another limitation to genetic testing for a hereditary linked cancer, is the variants of unknown clinical significance. Because the human genome has over 22,000 genes, there are 3.5 million variants in the average person’s genome. These variants of unknown clinical significance means there is a change in the DNA sequence, however the increase for cancer is unclear because it is unknown if the change affects the gene’s function. A genetics professional can explain in detail the benefits, risks, and limitations of a particular test. It is important that any person who is considering genetic testing understand and weigh these factors before making a decision. Other risks include incidental findings—a discovery of some possible problem found while looking for something else. In 2013 the American College of Medical Genetics and Genomics (ACMG) that certain genes always be included any time a genomic sequencing was done, and that labs should report the results. Direct-to-consumer (DTC) genetic testing (also called at-home genetic testing) is a type of genetic test that is accessible directly to the consumer without having to go through a health care professional. Usually, to obtain a genetic test, health care professionals such as physicians, nurse practitioners, or genetic counselors acquire their patient’s permission and then order the desired test, which may or may not be covered by health insurance. DTC genetic tests, however, allow consumers to bypass this process and purchase DNA tests themselves. DTC genetic testing can entail primarily genealogical/ancestry-related information, health and trait-related information, or both. There is a variety of DTC tests, ranging from tests for breast cancer alleles to mutations linked to cystic fibrosis. Possible benefits of DTC testing are the accessibility of tests to consumers, promotion of proactive healthcare, and the privacy of genetic information. Possible additional risks of DTC testing are the lack of governmental regulation, the potential misinterpretation of genetic information, issues related to testing minors, privacy of data, and downstream expenses for the public health care system. In the United States, most DTC genetic test kits are not reviewed by the Food and Drug Administration (FDA), with the exception of a few tests offered by the company 23andMe. As of 2019, the tests that have received marketing authorization by the FDA include 23andMe’s genetic health risk reports for select variants of BRCA1/BRCA2, pharmacogenetic reports that test for selected variants associated with metabolism of certain pharmaceutical compounds, a carrier screening test for Bloom syndrome, and genetic health risk reports for a handful of other medical conditions, such as celiac disease and late-onset Alzheimer’s. DTC genetic testing has been controversial due to outspoken opposition within the medical community. Critics of DTC testing argue against the risks involved, the unregulated advertising and marketing claims, and the overall lack of governmental oversight. DTC testing involves many of the same risks associated with any genetic test. One of the more obvious and dangerous of these is the possibility of misreading of test results. Without professional guidance, consumers can potentially misinterpret genetic information, causing them to be deluded about their personal health. Some advertising for DTC genetic testing has been criticized as conveying an exaggerated and inaccurate message about the connection between genetic information and disease risk, utilizing emotions as a selling factor. An advertisement for a BRCA-predictive genetic test for breast cancer stated: “There is no stronger antidote for fear than information.” Apart from rare diseases that are directly caused by specific, single-gene mutation, diseases “have complicated, multiple genetic links that interact strongly with personal environment, lifestyle, and behavior.” With regard to genetic testing and information in general, legislation in the United States called the Genetic Information Nondiscrimination Act prohibits group health plans and health insurers from denying coverage to a healthy individual or charging that person higher premiums based solely on a genetic predisposition to developing a disease in the future. The legislation also bars employers from using individuals’ genetic information when making hiring, firing, job placement, or promotion decisions. The legislation, the first of its kind in the United States, was passed by the United States Senate on April 24, 2008, on a vote of 95-0, and was signed into law by President George W. Bush on May 21, 2008. It went into effect on November 21, 2009. In June 2013 the US Supreme Court issued two rulings on human genetics. The Court struck down patents on human genes, opening up competition in the field of genetic testing. The Supreme Court also ruled that police were allowed to collect DNA from people arrested for serious offenses. "],["physical-and-chemical-agents-for-microbial-control.html", "11 Physical And Chemical Agents for Microbial Control 11.1 Sterilization 11.2 Pasteurization 11.3 Disinfectants 11.4 Antiseptics", " 11 Physical And Chemical Agents for Microbial Control Sterilization refers to any process that removes, kills, or deactivates all forms of life (in particular referring to microorganisms such as fungi, bacteria, spores, unicellular eukaryotic organisms such as Plasmodium, etc.) and other biological agents like prions present in a specific surface, object or fluid, for example food or biological culture media. Sterilization can be achieved through various means, including heat, chemicals, irradiation, high pressure, and filtration. Sterilization is distinct from disinfection, sanitization, and pasteurization, in that those methods reduce rather than eliminate all forms of life and biological agents present. After sterilization, an object is referred to as being sterile or aseptic. Pasteurization or pasteurisation is a process in which packaged and non-packaged foods (such as milk and fruit juice) are treated with mild heat, usually to less than 100 °C (212 °F), to eliminate pathogens and extend shelf life. The process is intended to destroy or deactivate organisms and enzymes that contribute to spoilage or risk of disease, including vegetative bacteria, but not bacterial spores. A disinfectant is a chemical substance or compound used to inactivate or destroy microorganisms on inert surfaces. Disinfection does not necessarily kill all microorganisms, especially resistant bacterial spores; it is less effective than sterilization, which is an extreme physical or chemical process that kills all types of life. Disinfectants are generally distinguished from other antimicrobial agents such as antibiotics, which destroy microorganisms within the body, and antiseptics, which destroy microorganisms on living tissue. Disinfectants are also different from biocides—the latter are intended to destroy all forms of life, not just microorganisms. Disinfectants work by destroying the cell wall of microbes or interfering with their metabolism. It is also a form of decontamination, and can be defined as the process whereby physical or chemical methods are used to reduce the amount of pathogenic microorganisms on a surface. Disinfectants can also be used to destroy microorganisms on the skin and mucous membrane, as in the medical dictionary historically the word simply meant that it destroys microbes. Sanitizers are substances that simultaneously clean and disinfect. Disinfectants kill more germs than sanitizers. Disinfectants are frequently used in hospitals, dental surgeries, kitchens, and bathrooms to kill infectious organisms. Sanitizers are mild compared to disinfectants and are used majorly to clean things which are in human contact whereas disinfectants are concentrated and are used to clean surfaces like floors and building premises. Bacterial endospores are most resistant to disinfectants, but some fungi, viruses and bacteria also possess some resistance. An antiseptic (from Greek ἀντί anti, “against” and σηπτικός sēptikos, “putrefactive”) is an antimicrobial substance or compound that is applied to living tissue/skin to reduce the possibility of infection, sepsis, or putrefaction. Antiseptics are generally distinguished from antibiotics by the latter’s ability to safely destroy bacteria within the body, and from disinfectants, which destroy microorganisms found on non-living objects. Antibacterials include antiseptics that have the proven ability to act against bacteria. Microbicides which destroy virus particles are called viricides or antivirals. Antifungals, also known as antimycotics, are pharmaceutical fungicides used to treat and prevent mycosis (fungal infection). The widespread introduction of antiseptic surgical methods was initiated by the publishing of the paper Antiseptic Principle of the Practice of Surgery in 1867 by Joseph Lister, which was inspired by Louis Pasteur’s germ theory of putrefaction. In this paper, Lister advocated the use of carbolic acid (phenol) as a method of ensuring that any germs present were killed. Some of this work was anticipated by: Ancient Greek physicians Galen (circa 130–200) and Hippocrates (circa 400 BC) and Sumerian clay tablets dating from 2150 BC that advocate the use of similar techniques. Medieval surgeons Hugh of Lucca, Theoderic of Servia, and his pupil Henri de Mondeville were opponents of Galen’s opinion that pus was important to healing, which had led ancient and medieval surgeons to let pus remain in wounds. They advocated draining and cleaning the wound edges with wine, dressing the wound after suturing, if necessary and leaving the dressing on for ten days, soaking it in warm wine all the while, before changing it. Their theories were bitterly opposed by Galenist Guy de Chauliac and others trained in the classical tradition. Oliver Wendell Holmes, Sr., who published The Contagiousness of Puerperal Fever in 1843 Florence Nightingale, who contributed substantially to the report of the Royal Commission on the Health of the Army (1856–1857), based on her earlier work Ignaz Semmelweis, who published his work The Cause, Concept and Prophylaxis of Childbed Fever in 1861, summarizing experiments and observations since 1847] Antiseptics can be subdivided into about eight classes of materials. These classes can be subdivided according to their mechanism of action: small molecules that indescrimantly react with organic compounds and kill microorganisms (peroxides, iodine, phenols) and more complex molecules that disrupt the cell walls of the bacteria. Phenols such as phenol itself (as introduced by Lister) and triclosan, hexachlorophene, chlorocresol, and chloroxylenol. The latter is used for skin disinfection and cleaning surgical instruments. It is also used within a number of household disinfectants and wound cleaners. Diguanides including chlorhexidine gluconate, a bacteriocidal antiseptic which (with an alcoholic solvent) is the most effective at reducing the risk of infection after surgery. It is also used in mouthwashes to treat inflammation of the gums (gingivitis). Polyhexanide (polyhexamethylene biguanide, PHMB) is an antimicrobial compound suitable for clinical use in critically colonized or infected acute and chronic wounds. The physicochemical action on the bacterial envelope prevents or impedes the development of resistant bacterial strains. Quinolines such as hydroxyquinolone, dequalium chloride, or chlorquinaldol. Alcohols, including ethanol and 2-propanol/isopropanol are sometimes referred to as surgical spirit. They are used to disinfect the skin before injections, among other uses. Peroxides, such as hydrogen peroxide and benzoyl peroxide. Commonly, 3% solutions of hydrogen peroxide have been used in household first aid for scrapes, etc. However, the strong oxidization causes scar formation and increases healing time during fetal development. Iodine, especially in the form of povidone-iodine, is widely used because it is well tolerated, does not negatively affect wound healing, leaves a deposit of active iodine, thereby creating the so-called “remnant”, or persistent, effect, and has wide scope of antimicrobial activity. The traditional iodine antiseptic is an alcohol solution (called tincture of iodine) or as Lugol’s iodine solution. Some studies do not recommend disinfecting minor wounds with iodine because of concern that it may induce scar tissue formation and increase healing time. However, concentrations of 1% iodine or less have not been shown to increase healing time and are not otherwise distinguishable from treatment with saline. Iodine will kill all principal pathogens and, given enough time, even spores, which are considered to be the most difficult form of microorganisms to be inactivated by disinfectants and antiseptics. Octenidine dihydrochloride, currently increasingly used in continental Europe, often as a chlorhexidine substitute. Quat salts such as benzalkonium chloride, cetylpyridinium chloride, or cetrimide. These surfactants disrupt cell walls. 11.1 Sterilization One of the first steps toward modernized sterilization was made by Nicolas Appert who discovered that thorough application of heat over a suitable period slowed the decay of foods and various liquids, preserving them for safe consumption for a longer time than was typical. Canning of foods is an extension of the same principle and has helped to reduce food borne illness (“food poisoning”). Other methods of sterilizing foods include food irradiation and high pressure (pascalization). One process by which food is sterilized is heat treatment. Heat treatment ceases bacterial and enzyme activity which then leads to decreasing the chances of low quality foods while maintaining the life of non-perishable foods. One specific type of heat treatment used is UHT (Ultra-High Temperature) sterilization. This type of heat treatment focuses on sterilization over 100 degrees Celsius. Two types of UHT sterilization are moist and dry heat sterilization. During moist heat sterilization, the temperatures that are used vary from 110 to 130 degrees Celsius. Moist heat sterilization takes between 20 and 40 minutes, the time being shorter the higher the temperature. The use of dry heat sterilization uses longer times of susceptibility that may last up to 2 hours and that use much higher temperatures compared to moist heat sterilization. These temperatures may range from 160 to 180 degrees Celsius. In general, surgical instruments and medications that enter an already aseptic part of the body (such as the bloodstream, or penetrating the skin) must be sterile. Examples of such instruments include scalpels, hypodermic needles, and artificial pacemakers. This is also essential in the manufacture of parenteral pharmaceuticals. Preparation of injectable medications and intravenous solutions for fluid replacement therapy requires not only sterility but also well-designed containers to prevent entry of adventitious agents after initial product sterilization. Most medical and surgical devices used in healthcare facilities are made of materials that are able to go under steam sterilization. However, since 1950, there has been an increase in medical devices and instruments made of materials (e.g., plastics) that require low-temperature sterilization. Ethylene oxide gas has been used since the 1950s for heat- and moisture-sensitive medical devices. Within the past 15 years, a number of new, low-temperature sterilization systems (e.g., vaporized hydrogen peroxide, peracetic acid immersion, ozone) have been developed and are being used to sterilize medical devices. Steam sterilization is the most widely used and the most dependable. Steam sterilization is nontoxic, inexpensive, rapidly microbicidal, sporicidal, and rapidly heats and penetrates fabrics. The aim of sterilization is the reduction of initially present microorganisms or other potential pathogens. The degree of sterilization is commonly expressed by multiples of the decimal reduction time, or D-value, denoting the time needed to reduce the initial number N0 tenth (10-1) of its original value. Then the number of microorganisms N after sterilization time t￼is given by: \\[\\frac {N}{N_{0}}}=10^{\\left(-{\\frac {t}{D}}\\right)}\\] The D-value is a function of sterilization conditions and varies with the type of microorganism, temperature, water activity, pH etc.. For steam sterilization (see below) typically the temperature, in degrees Celsius, is given as an index. Theoretically, the likelihood of the survival of an individual microorganism is never zero. To compensate for this, the overkill method is often used. Using the overkill method, sterilization is performed by sterilizing for longer than is required to kill the bioburden present on or in the item being sterilized. This provides a sterility assurance level (SAL) equal to the probability of a non-sterile unit. For high-risk applications, such as medical devices and injections, a sterility assurance level of at least 10−6 is required by the United States Food and Drug Administration (FDA).[11] 11.1.1 Methods of Sterilization 11.1.2 Steam A widely used method for heat sterilization is the autoclave, sometimes called a converter or steam sterilizer. Autoclaves use steam heated to 121–134 °C (250–273 °F) under pressure. To achieve sterility, the article is placed in a chamber and heated by injected steam until the article reaches a temperature and time setpoint. Almost all the air is removed from the chamber, because air is undesired in the moist heat sterilization process (this is one trait that differs from a typical pressure cooker used for food cooking). The article is held at the temperature setpoint for a period of time which varies depending on what bioburden is present on the article being sterilized and its resistance (D-value) to steam sterilization. A general cycle would be anywhere between 3 and 15 minutes, (depending on the generated heat) at 121 °C (250 °F) at 100 kPa (15 psi), which is sufficient to provide a sterility assurance level of 10−4 for a product with a bioburden of 106 and a D-value of 2.0 minutes. Following sterilization, liquids in a pressurized autoclave must be cooled slowly to avoid boiling over when the pressure is released. This may be achieved by gradually depressurizing the sterilization chamber and allowing liquids to evaporate under a negative pressure, while cooling the contents. Proper autoclave treatment will inactivate all resistant bacterial spores in addition to fungi, bacteria, and viruses, but is not expected to eliminate all prions, which vary in their resistance. For prion elimination, various recommendations state 121–132 °C (250–270 °F) for 60 minutes or 134 °C (273 °F) for at least 18 minutes. The 263K scrapie prion is inactivated relatively quickly by such sterilization procedures; however, other strains of scrapie, and strains of Creutzfeldt-Jakob disease (CKD) and bovine spongiform encephalopathy (BSE) are more resistant. Using mice as test animals, one experiment showed that heating BSE positive brain tissue at 134–138 °C (273–280 °F) for 18 minutes resulted in only a 2.5 log decrease in prion infectivity. Most autoclaves have meters and charts that record or display information, particularly temperature and pressure as a function of time. The information is checked to ensure that the conditions required for sterilization have been met. Indicator tape is often placed on the packages of products prior to autoclaving, and some packaging incorporates indicators. The indicator changes color when exposed to steam, providing a visual confirmation. Bioindicators can also be used to independently confirm autoclave performance. Simple bioindicator devices are commercially available, based on microbial spores. Most contain spores of the heat-resistant microbe Geobacillus stearothermophilus (formerly Bacillus stearothermophilus), which is extremely resistant to steam sterilization. Biological indicators may take the form of glass vials of spores and liquid media, or as spores on strips of paper inside glassine envelopes. These indicators are placed in locations where it is difficult for steam to reach to verify that steam is penetrating there. For autoclaving, cleaning is critical. Extraneous biological matter or grime may shield organisms from steam penetration. Proper cleaning can be achieved through physical scrubbing, sonication, ultrasound, or pulsed air. Moist heat causes the destruction of microorganisms by denaturation of macromolecules, primarily proteins. This method is a faster process than dry heat sterilization. To sterilize waste materials that are chiefly composed of liquid, a purpose-built effluent decontamination system can be utilized. These devices can function using a variety of sterilants, although using heat via steam is most common. 11.1.3 Dry Heat Dry heat was the first method of sterilization and is a longer process than moist heat sterilization. The destruction of microorganisms through the use of dry heat is a gradual phenomenon. With longer exposure to lethal temperatures, the number of killed microorganisms increases. Forced ventilation of hot air can be used to increase the rate at which heat is transferred to an organism and reduce the temperature and amount of time needed to achieve sterility. At higher temperatures, shorter exposure times are required to kill organisms. This can reduce heat-induced damage to food products. The standard setting for a hot air oven is at least two hours at 160 °C (320 °F). A rapid method heats air to 190 °C (374 °F) for 6 minutes for unwrapped objects and 12 minutes for wrapped objects. Dry heat has the advantage that it can be used on powders and other heat-stable items that are adversely affected by steam (e.g. it does not cause rusting of steel objects). 11.1.4 Flaming Flaming is done to inoculation loops and straight-wires in microbiology labs for streaking. Leaving the loop in the flame of a Bunsen burner or alcohol burner until it glows red ensures that any infectious agent is inactivated. This is commonly used for small metal or glass objects, but not for large objects (see Incineration below). However, during the initial heating, infectious material may be sprayed from the wire surface before it is killed, contaminating nearby surfaces and objects. Therefore, special heaters have been developed that surround the inoculating loop with a heated cage, ensuring that such sprayed material does not further contaminate the area. Another problem is that gas flames may leave carbon or other residues on the object if the object is not heated enough. A variation on flaming is to dip the object in a 70% or more concentrated solution of ethanol, then briefly touch the object to a Bunsen burner flame. The ethanol will ignite and burn off rapidly, leaving less residue than a gas flame 11.1.5 Incineration Incineration is a waste treatment process that involves the combustion of organic substances contained in waste materials. This method also burns any organism to ash. It is used to sterilize medical and other biohazardous waste before it is discarded with non-hazardous waste. Bacteria incinerators are mini furnaces that incinerate and kill off any microorganisms that may be on an inoculating loop or wire. 11.1.6 Tyndallization Named after John Tyndall, Tyndallization is an obsolete and lengthy process designed to reduce the level of activity of sporulating bacteria that are left by a simple boiling water method. The process involves boiling for a period (typically 20 minutes) at atmospheric pressure, cooling, incubating for a day, and then repeating the process a total of three to four times. The incubation periods are to allow heat-resistant spores surviving the previous boiling period to germinate to form the heat-sensitive vegetative (growing) stage, which can be killed by the next boiling step. This is effective because many spores are stimulated to grow by the heat shock. The procedure only works for media that can support bacterial growth, and will not sterilize non-nutritive substrates like water. Tyndallization is also ineffective against prions. Glass bead sterilizers Glass bead sterilizers work by heating glass beads to 250 °C (482 °F). Instruments are then quickly doused in these glass beads, which heat the object while physically scraping contaminants off their surface. Glass bead sterilizers were once a common sterilization method employed in dental offices as well as biological laboratories, but are not approved by the U.S. Food and Drug Administration (FDA) and Centers for Disease Control and Prevention (CDC) to be used as a sterilizers since 1997. They are still popular in European and Israeli dental practices, although there are no current evidence-based guidelines for using this sterilizer. 11.1.7 Chemical Sterilization Chemicals are also used for sterilization. Heating provides a reliable way to rid objects of all transmissible agents, but it is not always appropriate if it will damage heat-sensitive materials such as biological materials, fiber optics, electronics, and many plastics. In these situations chemicals, either in a gaseous or liquid form, can be used as sterilants. While the use of gas and liquid chemical sterilants avoids the problem of heat damage, users must ensure that the article to be sterilized is chemically compatible with the sterilant being used and that the sterilant is able to reach all surfaces that must be sterilized (typically cannot penetrate packaging). In addition, the use of chemical sterilants poses new challenges for workplace safety, as the properties that make chemicals effective sterilants usually make them harmful to humans. The procedure for removing sterilant residue from the sterilized materials varies depending on the chemical and process that is used. 11.1.8 Ethylene oxide Ethylene oxide (EO, EtO) gas treatment is one of the common methods used to sterilize, pasteurize, or disinfect items because of its wide range of material compatibility. It is also used to process items that are sensitive to processing with other methods, such as radiation (gamma, electron beam, X-ray), heat (moist or dry), or other chemicals. Ethylene oxide treatment is the most common chemical sterilization method, used for approximately 70% of total sterilizations, and for over 50% of all disposable medical devices. Ethylene oxide treatment is generally carried out between 30 and 60 °C (86 and 140 °F) with relative humidity above 30% and a gas concentration between 200 and 800 mg/l. Typically, the process lasts for several hours. Ethylene oxide is highly effective, as it penetrates all porous materials, and it can penetrate through some plastic materials and films. Ethylene oxide kills all known microorganisms, such as bacteria (including spores), viruses, and fungi (including yeasts and moulds), and is compatible with almost all materials even when repeatedly applied. It is flammable, toxic, and carcinogenic; however, only with a reported potential for some adverse health effects when not used in compliance with published requirements. Ethylene oxide sterilizers and processes require biological validation after sterilizer installation, significant repairs or process changes. The traditional process consists of a preconditioning phase (in a separate room or cell), a processing phase (more commonly in a vacuum vessel and sometimes in a pressure rated vessel), and an aeration phase (in a separate room or cell) to remove EO residues and lower by-products such as ethylene chlorohydrin (EC or ECH) and, of lesser importance, ethylene glycol (EG). An alternative process, known as all-in-one processing, also exists for some products whereby all three phases are performed in the vacuum or pressure rated vessel. This latter option can facilitate faster overall processing time and residue dissipation. The most common EO processing method is the gas chamber method. To benefit from economies of scale, EO has traditionally been delivered by filling a large chamber with a combination of gaseous EO either as pure EO, or with other gases used as diluents; diluents include chlorofluorocarbons (CFCs), hydrochlorofluorocarbons (HCFCs), and carbon dioxide. Ethylene oxide is still widely used by medical device manufacturers. Since EO is explosive at concentrations above 3%, EO was traditionally supplied with an inert carrier gas, such as a CFC or HCFC. The use of CFCs or HCFCs as the carrier gas was banned because of concerns of ozone depletion. These halogenated hydrocarbons are being replaced by systems using 100% EO, because of regulations and the high cost of the blends. In hospitals, most EO sterilizers use single-use cartridges because of the convenience and ease of use compared to the former plumbed gas cylinders of EO blends. It is important to adhere to patient and healthcare personnel government specified limits of EO residues in and/or on processed products, operator exposure after processing, during storage and handling of EO gas cylinders, and environmental emissions produced when using EO. The U.S. Occupational Safety and Health Administration (OSHA) has set the permissible exposure limit (PEL) at 1 ppm – calculated as an eight-hour time-weighted average (TWA) – and 5 ppm as a 15-minute excursion limit (EL). The National Institute for Occupational Safety and Health’s (NIOSH) immediately dangerous to life and health limit (IDLH) for EO is 800 ppm. The odor threshold is around 500 ppm, so EO is imperceptible until concentrations are well above the OSHA PEL. Therefore, OSHA recommends that continuous gas monitoring systems be used to protect workers using EO for processing. 11.1.9 Nitrogen Dioxide Nitrogen dioxide (NO2) gas is a rapid and effective sterilant for use against a wide range of microorganisms, including common bacteria, viruses, and spores. The unique physical properties of NO2 gas allow for sterilant dispersion in an enclosed environment at room temperature and atmospheric pressure. The mechanism for lethality is the degradation of DNA in the spore core through nitration of the phosphate backbone, which kills the exposed organism as it absorbs NO2. This degradations occurs at even very low concentrations of the gas. NO2 has a boiling point of 21 °C (70 °F) at sea level, which results in a relatively highly saturated vapour pressure at ambient temperature. Because of this, liquid NO2 may be used as a convenient source for the sterilant gas. Liquid NO2 is often referred to by the name of its dimer, dinitrogen tetroxide (N2O4). Additionally, the low levels of concentration required, coupled with the high vapour pressure, assures that no condensation occurs on the devices being sterilized. This means that no aeration of the devices is required immediately following the sterilization cycle. NO2 is also less corrosive than other sterilant gases, and is compatible with most medical materials and adhesives. The most-resistant organism (MRO) to sterilization with NO2 gas is the spore of Geobacillus stearothermophilus, which is the same MRO for both steam and hydrogen peroxide sterilization processes. The spore form of G. stearothermophilus has been well characterized over the years as a biological indicator in sterilization applications. Microbial inactivation of G. stearothermophilus with NO2 gas proceeds rapidly in a log-linear fashion, as is typical of other sterilization processes. Noxilizer, Inc. has commercialized this technology to offer contract sterilization services for medical devices at its Baltimore, Maryland (U.S.) facility. This has been demonstrated in Noxilizer’s lab in multiple studies and is supported by published reports from other labs. These same properties also allow for quicker removal of the sterilant and residual gases through aeration of the enclosed environment. The combination of rapid lethality and easy removal of the gas allows for shorter overall cycle times during the sterilization (or decontamination) process and a lower level of sterilant residuals than are found with other sterilization methods. Eniware, LLC has developed a portable, power-free sterilizer that uses no electricity, heat or water. The 25 liter unit makes sterilization of surgical instruments possible for austere forward surgical teams, in health centers throughout the world with intermittent or no electricity and in disaster relief and humanitarian crisis situations. The four hour cycle uses a single use gas generation ampoule and a disposable scrubber to remove nitrogen dioxide gas. 11.1.10 Ozone Ozone is used in industrial settings to sterilize water and air, as well as a disinfectant for surfaces. It has the benefit of being able to oxidize most organic matter. On the other hand, it is a toxic and unstable gas that must be produced on-site, so it is not practical to use in many settings. Ozone offers many advantages as a sterilant gas; ozone is a very efficient sterilant because of its strong oxidizing properties (E=2.076 vs SHE) capable of destroying a wide range of pathogens, including prions, without the need for handling hazardous chemicals since the ozone is generated within the sterilizer from medical-grade oxygen. The high reactivity of ozone means that waste ozone can be destroyed by passing over a simple catalyst that reverts it to oxygen and ensures that the cycle time is relatively short. The disadvantage of using ozone is that the gas is very reactive and very hazardous. The NIOSH’s immediately dangerous to life and health limit (IDLH) for ozone is 5 ppm, 160 times smaller than the 800 ppm IDLH for ethylene oxide. NIOSH and OSHA has set the PEL for ozone at 0.1 ppm, calculated as an eight-hour time-weighted average. The sterilant gas manufacturers include many safety features in their products but prudent practice is to provide continuous monitoring of exposure to ozone, in order to provide a rapid warning in the event of a leak. Monitors for determining workplace exposure to ozone are commercially available. 11.1.11 Glutaraldehyde And Formaldehyde Glutaraldehyde and formaldehyde solutions (also used as fixatives) are accepted liquid sterilizing agents, provided that the immersion time is sufficiently long. To kill all spores in a clear liquid can take up to 22 hours with glutaraldehyde and even longer with formaldehyde. The presence of solid particles may lengthen the required period or render the treatment ineffective. Sterilization of blocks of tissue can take much longer, due to the time required for the fixative to penetrate. Glutaraldehyde and formaldehyde are volatile, and toxic by both skin contact and inhalation. Glutaraldehyde has a short shelf-life (&lt;2 weeks), and is expensive. Formaldehyde is less expensive and has a much longer shelf-life if some methanol is added to inhibit polymerization to paraformaldehyde, but is much more volatile. Formaldehyde is also used as a gaseous sterilizing agent; in this case, it is prepared on-site by depolymerization of solid paraformaldehyde. Many vaccines, such as the original Salk polio vaccine, are sterilized with formaldehyde. 11.1.12 Hydrogen Peroxide Hydrogen peroxide, in both liquid and as vaporized hydrogen peroxide (VHP), is another chemical sterilizing agent. Hydrogen peroxide is a strong oxidant, which allows it to destroy a wide range of pathogens. Hydrogen peroxide is used to sterilize heat- or temperature-sensitive articles, such as rigid endoscopes. In medical sterilization, hydrogen peroxide is used at higher concentrations, ranging from around 35% up to 90%. The biggest advantage of hydrogen peroxide as a sterilant is the short cycle time. Whereas the cycle time for ethylene oxide may be 10 to 15 hours, some modern hydrogen peroxide sterilizers have a cycle time as short as 28 minutes. Drawbacks of hydrogen peroxide include material compatibility, a lower capability for penetration and operator health risks. Products containing cellulose, such as paper, cannot be sterilized using VHP and products containing nylon may become brittle. The penetrating ability of hydrogen peroxide is not as good as ethylene oxide and so there are limitations on the length and diameter of the lumen of objects that can be effectively sterilized. Hydrogen peroxide is a primary irritant and the contact of the liquid solution with skin will cause bleaching or ulceration depending on the concentration and contact time. It is relatively non-toxic when diluted to low concentrations, but is a dangerous oxidizer at high concentrations (&gt; 10% w/w). The vapour is also hazardous, primarily affecting the eyes and respiratory system. Even short term exposures can be hazardous and NIOSH has set the IDLH at 75 ppm, less than one tenth the IDLH for ethylene oxide (800 ppm). Prolonged exposure to lower concentrations can cause permanent lung damage and consequently, OSHA has set the permissible exposure limit to 1.0 ppm, calculated as an eight-hour time-weighted average. Sterilizer manufacturers go to great lengths to make their products safe through careful design and incorporation of many safety features, though there are still workplace exposures of hydrogen peroxide from gas sterilizers documented in the FDA MAUDE database. When using any type of gas sterilizer, prudent work practices should include good ventilation, a continuous gas monitor for hydrogen peroxide and good work practices and training. Vaporized hydrogen peroxide (VHP) is used to sterilize large enclosed and sealed areas, such as entire rooms and aircraft interiors. Although toxic, VHP breaks down in a short time to water and oxygen. 11.1.13 Peracetic Acid Peracetic acid (0.2%) is a recognized sterilant by the FDA for use in sterilizing medical devices such as endoscopes. Peracetic acid which is also known as peroxyacetic acid is a chemical compound often used in disinfectants such as sanitizers. It is most commonly produced by the reaction of acetic acid and hydrogen peroxide with each other by using an acid catalyst. Peracetic acid is never sold in unstabilized solutions which is why it is considered to be environmentally friendly. Peracetic acid is a colorless liquid and the molecular formula of peracetic acid is C2H4O3 or CH3COOOH. More recently, peracetic acid is being used throughout the world as more people are using fumigation to decontaminate surfaces to reduce the risk of Covid-19 and other diseases. 11.1.14 Potential For Chemical Sterilization Of Prions Prions are highly resistant to chemical sterilization. Treatment with aldehydes, such as formaldehyde, have actually been shown to increase prion resistance. Hydrogen peroxide (3%) for one hour was shown to be ineffective, providing less than 3 logs (10−3) reduction in contamination. Iodine, formaldehyde, glutaraldehyde, and peracetic acid also fail this test (one hour treatment). Only chlorine, phenolic compounds, guanidinium thiocyanate, and sodium hydroxide reduce prion levels by more than 4 logs; chlorine (too corrosive to use on certain objects) and sodium hydroxide are the most consistent. Many studies have shown the effectiveness of sodium hydroxide. 11.1.15 Radiation Sterilization Sterilization can be achieved using electromagnetic radiation, such as ultraviolet light, X-rays and gamma rays, or irradiation by subatomic particles such as by electron beams. Electromagnetic or particulate radiation can be energetic enough to ionize atoms or molecules (ionizing radiation), or less energetic (non-ionizing radiation). 11.1.16 Non-Ionizing Radiation Sterilization Further information: Ultraviolet germicidal irradiation Ultraviolet light irradiation (UV, from a germicidal lamp) is useful for sterilization of surfaces and some transparent objects. Many objects that are transparent to visible light absorb UV. UV irradiation is routinely used to sterilize the interiors of biological safety cabinets between uses, but is ineffective in shaded areas, including areas under dirt (which may become polymerized after prolonged irradiation, so that it is very difficult to remove). It also damages some plastics, such as polystyrene foam if exposed for prolonged periods of time. 11.1.17 Ionizing Radiation Sterilization The safety of irradiation facilities is regulated by the International Atomic Energy Agency of the United Nations and monitored by the different national Nuclear Regulatory Commissions (NRC). The radiation exposure accidents that have occurred in the past are documented by the agency and thoroughly analyzed to determine the cause and improvement potential. Such improvements are then mandated to retrofit existing facilities and future design. Gamma radiation is very penetrating, and is commonly used for sterilization of disposable medical equipment, such as syringes, needles, cannulas and IV sets, and food. It is emitted by a radioisotope, usually cobalt-60 (60Co) or caesium-137 (137Cs), which have photon energies of up to 1.3 and 0.66 MeV, respectively. Use of a radioisotope requires shielding for the safety of the operators while in use and in storage. With most designs, the radioisotope is lowered into a water-filled source storage pool, which absorbs radiation and allows maintenance personnel to enter the radiation shield. One variant keeps the radioisotope under water at all times and lowers the product to be irradiated in the water in hermetically-sealed bells; no further shielding is required for such designs. Other uncommonly used designs use dry storage, providing movable shields that reduce radiation levels in areas of the irradiation chamber. An incident in Decatur, Georgia, US, where water-soluble caesium-137 leaked into the source storage pool, requiring NRC intervention has led to use of this radioisotope being almost entirely discontinued in favour of the more costly, non-water-soluble cobalt-60. Cobalt-60 gamma photons have about twice the energy, and hence greater penetrating range, of caesium-137-produced radiation. Electron beam processing is also commonly used for sterilization. Electron beams use an on-off technology and provide a much higher dosing rate than gamma or X-rays. Due to the higher dose rate, less exposure time is needed and thereby any potential degradation to polymers is reduced. Because electrons carry a charge, electron beams are less penetrating than both gamma and X-rays. Facilities rely on substantial concrete shields to protect workers and the environment from radiation exposure. High-energy X-rays (produced by bremsstrahlung) allow irradiation of large packages and pallet loads of medical devices. They are sufficiently penetrating to treat multiple pallet loads of low-density packages with very good dose uniformity ratios. X-ray sterilization does not require chemical or radioactive material: high-energy X-rays are generated at high intensity by an X-ray generator that does not require shielding when not in use. X-rays are generated by bombarding a dense material (target) such as tantalum or tungsten with high-energy electrons, in a process known as bremsstrahlung conversion. These systems are energy-inefficient, requiring much more electrical energy than other systems for the same result. Irradiation with X-rays, gamma rays, or electrons does not make materials radioactive, because the energy used is too low. Generally an energy of at least 10 MeV is needed to induce radioactivity in a material. Neutrons and very high-energy particles can make materials radioactive, but have good penetration, whereas lower energy particles (other than neutrons) cannot make materials radioactive, but have poorer penetration. Sterilization by irradiation with gamma rays may however affect material properties. Irradiation is used by the United States Postal Service to sterilize mail in the Washington, D.C. area. Some foods (e.g. spices and ground meats) are sterilized by irradiation. Subatomic particles may be more or less penetrating and may be generated by a radioisotope or a device, depending upon the type of particle. 11.1.18 Sterile filtration Fluids that would be damaged by heat, irradiation or chemical sterilization, such as drug solution, can be sterilized by microfiltration using membrane filters. This method is commonly used for heat labile pharmaceuticals and protein solutions in medicinal drug processing. A microfilter with pore size of usually 0.22 µm will effectively remove microorganisms. Some staphylococcal species have, however, been shown to be flexible enough to pass through 0.22 µm filters. In the processing of biologics, viruses must be removed or inactivated, requiring the use of nanofilters with a smaller pore size (20–50 nm). Smaller pore sizes lower the flow rate, so in order to achieve higher total throughput or to avoid premature blockage, pre-filters might be used to protect small pore membrane filters. Tangential flow filtration (TFF) and alternating tangential flow (ATF) systems also reduce particulate accumulation and blockage. Membrane filters used in production processes are commonly made from materials such as mixed cellulose ester or polyethersulfone (PES). The filtration equipment and the filters themselves may be purchased as pre-sterilized disposable units in sealed packaging or must be sterilized by the user, generally by autoclaving at a temperature that does not damage the fragile filter membranes. To ensure proper functioning of the filter, the membrane filters are integrity tested post-use and sometimes before use. The nondestructive integrity test assures the filter is undamaged and is a regulatory requirement. Typically, terminal pharmaceutical sterile filtration is performed inside of a cleanroom to prevent contamination. Instruments that have undergone sterilization can be maintained in such condition by containment in sealed packaging until use. Aseptic technique is the act of maintaining sterility during procedures. 11.2 Pasteurization The process was named after the French microbiologist, Louis Pasteur, whose research in the 1860s demonstrated that thermal processing would deactivate unwanted microorganisms in wine. Spoilage enzymes are also inactivated during pasteurization. Today, pasteurization is used widely in the dairy industry and other food processing industries to achieve food preservation and food safety. By the year 1999, most liquid products were heat treated in a continuous system where heat can be applied using a plate heat exchanger or the direct or indirect use of hot water and steam. Due to the mild heat, there are minor changes to the nutritional quality and sensory characteristics of the treated foods. Pascalization or high pressure processing (HPP) and pulsed electric field (PEF) are non-thermal processes that are also used to pasteurize foods. The process of heating wine for preservation purposes has been known in China since AD 1117, and was documented in Japan in the diary Tamonin-nikki, written by a series of monks between 1478 and 1618. Much later, in 1768, research performed by Italian priest and scientist Lazzaro Spallanzani proved a product could be made “sterile” after thermal processing. Spallanzani boiled meat broth for one hour, sealed the container immediately after boiling, and noticed that the broth did not spoil and was free from microorganisms. In 1795, a Parisian chef and confectioner named Nicolas Appert began experimenting with ways to preserve foodstuffs, succeeding with soups, vegetables, juices, dairy products, jellies, jams, and syrups. He placed the food in glass jars, sealed them with cork and sealing wax and placed them in boiling water. In that same year, the French military offered a cash prize of 12,000 francs for a new method to preserve food. After some 14 or 15 years of experimenting, Appert submitted his invention and won the prize in January 1810. Later that year, Appert published L’Art de conserver les substances animales et végétales (“The Art of Preserving Animal and Vegetable Substances”). This was the first cookbook of its kind on modern food preservation methods. La Maison Appert (English: The House of Appert), in the town of Massy, near Paris, became the first food-bottling factory in the world, preserving a variety of foods in sealed bottles. Appert’s method was to fill thick, large-mouthed glass bottles with produce of every description, ranging from beef and fowl to eggs, milk and prepared dishes. He left air space at the top of the bottle, and the cork would then be sealed firmly in the jar by using a vise. The bottle was then wrapped in canvas to protect it while it was dunked into boiling water and then boiled for as much time as Appert deemed appropriate for cooking the contents thoroughly. Appert patented his method, sometimes called appertisation in his honor. Appert’s method was so simple and workable that it quickly became widespread. In 1810, British inventor and merchant Peter Durand, also of French origin, patented his own method, but this time in a tin can, so creating the modern-day process of canning foods. In 1812, Englishmen Bryan Donkin and John Hall purchased both patents and began producing preserves. Just a decade later, Appert’s method of canning had made its way to America.[full citation needed] Tin can production was not common until the beginning of the 20th century, partly because a hammer and chisel were needed to open cans until the invention of a can opener by Robert Yeates in 1855. A less aggressive method was developed by French chemist Louis Pasteur during an 1864 summer holiday in Arbois. To remedy the frequent acidity of the local aged wines, he found out experimentally that it is sufficient to heat a young wine to only about 50–60 °C (122–140 °F) for a short time to kill the microbes, and that the wine could subsequently be aged without sacrificing the final quality. In honour of Pasteur, this process is known as “pasteurization”. Pasteurization was originally used as a way of preventing wine and beer from souring, and it would be many years before milk was pasteurized. In the United States in the 1870s, before milk was regulated, it was common for milk to contain substances intended to mask spoilage. Milk Milk is an excellent medium for microbial growth, and when it is stored at ambient temperature bacteria and other pathogens soon proliferate. The US Centers for Disease Control (CDC) says improperly handled raw milk is responsible for nearly three times more hospitalizations than any other food-borne disease source, making it one of the world’s most dangerous food products. Diseases prevented by pasteurization can include tuberculosis, brucellosis, diphtheria, scarlet fever, and Q-fever; it also kills the harmful bacteria Salmonella, Listeria, Yersinia, Campylobacter, Staphylococcus aureus, and Escherichia coli O157:H7, among others. Prior to industrialization, dairy cows were kept in urban areas to limit the time between milk production and consumption, hence the risk of disease transmission via raw milk was reduced. As urban densities increased and supply chains lengthened to the distance from country to city, raw milk (often days old) became recognized as a source of disease. For example, between 1912 and 1937, some 65,000 people died of tuberculosis contracted from consuming milk in England and Wales alone. Because tuberculosis has a long incubation period in humans, it was difficult to link unpasteurized milk consumption with the disease. In 1892, chemist Ernst Lederle experimentally inoculated milk from tuberculosis-diseased cows into guinea pigs, which caused them to develop the disease. In 1910, Lederle, then in the role of Commissioner of Health, introduced mandatory pasteurization of milk in New York City. Developed countries adopted milk pasteurization to prevent such disease and loss of life, and as a result milk is now considered a safer food. A traditional form of pasteurization by scalding and straining of cream to increase the keeping qualities of butter was practiced in Great Britain in the 18th century and was introduced to Boston in the British Colonies by 1773, although it was not widely practiced in the United States for the next 20 years. Pasteurization of milk was suggested by Franz von Soxhlet in 1886. In the early 20th century, Milton Joseph Rosenau established the standards – i.e. low-temperature, slow heating at 60 °C (140 °F) for 20 minutes – for the pasteurization of milk while at the United States Marine Hospital Service, notably in his publication of The Milk Question (1912). States in the U.S. soon began enacting mandatory dairy pasteurization laws, with the first in 1947, and in 1973 the U.S. federal government required pasteurization of milk used in any interstate commerce. The shelf life of refrigerated pasteurized milk is greater than that of raw milk. For example, high-temperature, short-time (HTST) pasteurized milk typically has a refrigerated shelf life of two to three weeks, whereas ultra-pasteurized milk can last much longer, sometimes two to three months. When ultra-heat treatment (UHT) is combined with sterile handling and container technology (such as aseptic packaging), it can even be stored non-refrigerated for up to 9 months. According to the Centers for Disease Control, between 1998 and 2011, 79% of dairy-related disease outbreaks in the United States were due to raw milk or cheese products. They report 148 outbreaks and 2,384 illnesses (with 284 requiring hospitalization), as well as two deaths due to raw milk or cheese products during the same time period. Medical equipment Medical equipment, notably respiratory and anesthesia equipment, is often disinfected using hot water, as an alternative to chemical disinfection. The temperature is raised to 70 °C (158 °F) for 30 minutes. Pasteurization processPasteurization is a mild heat treatment of liquid foods (both packaged and unpackaged) where products are typically heated to below 100 °C. The heat treatment and cooling process are designed to inhibit a phase change of the product. The acidity of the food determines the parameters (time and temperature) of the heat treatment as well as the duration of shelf life. Parameters also take into account nutritional and sensory qualities that are sensitive to heat. In acidic foods (pH &lt;4.6), such as fruit juice and beer, the heat treatments are designed to inactivate enzymes (pectin methylesterase and polygalacturonase in fruit juices) and destroy spoilage microbes (yeast and lactobacillus). Due to the low pH of acidic foods, pathogens are unable to grow. The shelf-life is thereby extended several weeks. In less acidic foods (pH &gt;4.6), such as milk and liquid eggs, the heat treatments are designed to destroy pathogens and spoilage organisms (yeast and molds). Not all spoilage organisms are destroyed under pasteurization parameters, thus subsequent refrigeration is necessary. Equipment Food can be pasteurized in two ways: either before or after being packaged into containers. When food is packaged in glass, hot water is used to lower the risk of thermal shock. Plastics and metals are also used to package foods, and these are generally pasteurized with steam or hot water since the risk of thermal shock is low. Most liquid foods are pasteurized using continuous systems that have a heating zone, hold tube, and cooling zone, after which the product is filled into the package. Plate heat exchangers are used for low-viscosity products such as animal milks, nut milks and juices. A plate heat exchanger is composed of many thin vertical stainless steel plates which separate the liquid from the heating or cooling medium. Scraped surface heat exchangers contain an inner rotating shaft in the tube, and serve to scrape highly viscous material which might accumulate on the wall of the tube. Shell or tube heat exchangers are designed for the pasteurization of foods that are non-Newtonian fluids, such as dairy products, tomato ketchup and baby foods. A tube heat exchanger is made up of concentric stainless steel tubes. Food passes through the inner tube while the heating/cooling medium is circulated through the outer or inner tube. The benefits of using a heat exchanger to pasteurize non-packaged foods versus pasteurizing foods in containers are: Heat exchangers provide uniform treatment, and there is greater flexibility with regards to the products which can be pasteurized on these plates The process is more energy-efficient compared to pasteurizing foods in packaged containers Greater throughput After being heated in a heat exchanger, the product flows through a hold tube for a set period of time to achieve the required treatment. If pasteurization temperature or time is not achieved, a flow diversion valve is utilized to divert under-processed product back to the raw product tank. If the product is adequately processed, it is cooled in a heat exchanger, then filled. High-temperature short-time (HTST) pasteurization, such as that used for milk (71.5 °C (160.7 °F) for 15 seconds) ensures safety of milk and provides a refrigerated shelf life of approximately two weeks. In ultra-high-temperature (UHT) pasteurization, milk is pasteurized at 135 °C (275 °F) for 1–2 seconds, which provides the same level of safety, but along with the packaging, extends shelf life to three months under refrigeration. Verification Direct microbiological techniques are the ultimate measurement of pathogen contamination, but these are costly and time-consuming, which means that products have a reduced shelf-life by the time pasteurization is verified. As a result of the unsuitability of microbiological techniques, milk pasteurization efficacy is typically monitored by checking for the presence of alkaline phosphatase, which is denatured by pasteurization. Destruction of alkaline phosphatase ensures the destruction of common milk pathogens. Therefore, the presence of alkaline phosphatase is an ideal indicator of pasteurization efficacy. For liquid eggs, the effectiveness of the heat treatment is measured by the residual activity of α-amylase. Efficacy against pathogenic bacteria During the early 20th century, there was no robust knowledge of what time and temperature combinations would inactivate pathogenic bacteria in milk, and so a number of different pasteurization standards were in use. By 1943, both HTST pasteurization conditions of 72 °C (162 °F) for 15 seconds, as well as batch pasteurization conditions of 63 °C (145 °F) for 30 minutes, were confirmed by studies of the complete thermal death (as best as could be measured at that time) for a range of pathogenic bacteria in milk. Complete inactivation of Coxiella burnetii (which was thought at the time to cause Q fever by oral ingestion of infected milk) as well as of Mycobacterium tuberculosis (which causes tuberculosis) were later demonstrated. For all practical purposes, these conditions were adequate for destroying almost all yeasts, molds, and common spoilage bacteria and also for ensuring adequate destruction of common pathogenic, heat-resistant organisms. However, the microbiological techniques used until the 1960s did not allow for the actual reduction of bacteria to be enumerated. Demonstration of the extent of inactivation of pathogenic bacteria by milk pasteurization came from a study of surviving bacteria in milk that was heat-treated after being deliberately spiked with high levels of the most heat-resistant strains of the most significant milk-borne pathogens. The mean log10 reductions and temperatures of inactivation of the major milk-borne pathogens during a 15-second treatment are: Staphylococcus aureus &gt; 6.7 at 66.5 °C (151.7 °F) Yersinia enterocolitica &gt; 6.8 at 62.5 °C (144.5 °F) pathogenic Escherichia coli &gt; 6.8 at 65 °C (149 °F) Cronobacter sakazakii &gt; 6.7 at 67.5 °C (153.5 °F) Listeria monocytogenes &gt; 6.9 at 65.5 °C (149.9 °F) Salmonella ser. Typhimurium &gt; 6.9 at 61.5 °C (142.7 °F) (A log10 reduction between 6 and 7 means that 1 bacterium out of 1 million (106) to 10 million (107) bacteria survive the treatment.) The Codex Alimentarius Code of Hygienic Practice for Milk notes that milk pasteurization is designed to achieve at least a 5 log10 reduction of Coxiella burnetii. The Code also notes that: “The minimum pasteurization conditions are those having bactericidal effects equivalent to heating every particle of the milk to 72 °C for 15 seconds (continuous flow pasteurization) or 63 °C for 30 minutes (batch pasteurization)” and that “To ensure that each particle is sufficiently heated, the milk flow in heat exchangers should be turbulent, i.e. the Reynolds number should be sufficiently high”. The point about turbulent flow is important because simplistic laboratory studies of heat inactivation that use test tubes, without flow, will have less bacterial inactivation than larger-scale experiments that seek to replicate conditions of commercial pasteurization. As a precaution, modern HTST pasteurization processes must be designed with flow-rate restriction as well as divert valves which ensure that the milk is heated evenly and that no part of the milk is subject to a shorter time or a lower temperature. It is common for the temperatures to exceed 72 °C by 1.5 °C or 2 °C. Double pasteurization Since pasteurization is not sterilization, and does not kill spores, a second “double” pasteurization will extend the shelf life by killing spores that have germinated. The acceptance of double pasteurization vary by jurisdiction. In places where it is allowed, an initial pasteurization usually happens when the milk was collected at the farm, so that it does not spoil before processing. Many countries disallow such milk to be simply labelled as “pasturized”, so thermization, a lower-temperature process, is used instead. 11.3 Disinfectants Disinfectants are used to rapidly kill bacteria. They kill off the bacteria by causing the proteins to become damaged and outer layers of the bacteria cell to rupture. The DNA material subsequently leaks out. In wastewater treatment, a disinfection step with chlorine, ultra-violet (UV) radiation or ozonation can be included as tertiary treatment to remove pathogens from wastewater, for example if it is to be discharged to a river or the sea where there body contact immersion recreations is practiced (Europe) or reused to irrigate golf courses (US). An alternative term used in the sanitation sector for disinfection of waste streams, sewage sludge or fecal sludge is sanitisation or sanitization. Sterilant Sterilant means a chemical agent which is used to sterilise critical medical devices or medical instruments. A sterilant kills all micro-organisms with the result that the sterility assurance level of a microbial survivor is less than 10^-6. Sterilant gases are not within this scope. Low level disinfectant Low level disinfectant means a disinfectant that rapidly kills most vegetative bacteria as well as medium sized lipid containing viruses, when used according to labelling. It cannot be relied upon to destroy, within a practical period, bacterial endospores, mycobacteria, fungi, or all small nonlipid viruses. Intermediate level disinfectant Intermediate level disinfectant means a disinfectant that kills all microbial pathogens except bacterial endospores, when used as recommended by the manufacturer. It is bactericidal, tuberculocidal, fungicidal (against asexual spores but not necessarily dried chlamydospores or sexual spores), and virucidal. High level disinfectant High level disinfectant means a disinfectant that kills all microbial pathogens, except large numbers of bacterial endospores when used as recommended by its manufacturer. Instrument grade Instrument grade disinfectant means: a disinfectant which is used to reprocess reusable therapeutic devices; and when associated with the words “low”, “intermediate” or “high” means “low”, “intermediate” or “high” level disinfectant respectively. Hospital grade Hospital grade disinfectant means a disinfectant that is suitable for general purpose disinfection of building and fitting surfaces, and purposes not involving instruments or surfaces likely to come into contact with broken skin. Household/commercial grade Household/commercial grade disinfectant means a disinfectant that is suitable for general purpose disinfection of building or fitting surfaces, and for other purposes, in premises or involving procedures other than those specified for a hospital grade disinfectant, but is not: an antibacterial clothes preparation; or * a sanitary fluid; or * a sanitary powder; or * a sanitiser One way to compare disinfectants is to compare how well they do against a known disinfectant and rate them accordingly. Phenol is the standard, and the corresponding rating system is called the “Phenol coefficient”. The disinfectant to be tested is compared with phenol on a standard microbe (usually Salmonella typhi or Staphylococcus aureus). Disinfectants that are more effective than phenol have a coefficient &gt; 1. Those that are less effective have a coefficient &lt; 1. The standard European approach for disinfectant validation consists of a basic suspension test, a quantitative suspension test (with low and high levels of organic material added to act as ‘interfering substances’) and a two part simulated-use surface test. A less specific measurement of effectiveness is the United States Environmental Protection Agency (EPA) classification into either high, intermediate or low levels of disinfection. “High-level disinfection kills all organisms, except high levels of bacterial spores” and is done with a chemical germicide marketed as a sterilant by the U.S. Food and Drug Administration (FDA). “Intermediate-level disinfection kills mycobacteria, most viruses, and bacteria with a chemical germicide registered as a ‘tuberculocide’ by the Environmental Protection Agency. Low-level disinfection kills some viruses and bacteria with a chemical germicide registered as a hospital disinfectant by the EPA.” An alternative assessment is to measure the Minimum inhibitory concentrations (MICs) of disinfectants against selected (and representative) microbial species, such as through the use of microbroth dilution testing. However, those methods are obtained at standard inoculum levels without considering the inoculum effect. More informative methods are nowadays in demand to determine the minimum disinfectant dose as a function of the density of the target microbial species. A perfect disinfectant would also offer complete and full microbiological sterilisation, without harming humans and useful form of life, be inexpensive, and noncorrosive. However, most disinfectants are also, by nature, potentially harmful (even toxic) to humans or animals. Most modern household disinfectants contain denatonium, an exceptionally bitter substance added to discourage ingestion, as a safety measure. Those that are used indoors should never be mixed with other cleaning products as chemical reactions can occur. The choice of disinfectant to be used depends on the particular situation. Some disinfectants have a wide spectrum (kill many different types of microorganisms), while others kill a smaller range of disease-causing organisms but are preferred for other properties (they may be non-corrosive, non-toxic, or inexpensive). There are arguments for creating or maintaining conditions that are not conducive to bacterial survival and multiplication, rather than attempting to kill them with chemicals. Bacteria can increase in number very quickly, which enables them to evolve rapidly. Should some bacteria survive a chemical attack, they give rise to new generations composed completely of bacteria that have resistance to the particular chemical used. Under a sustained chemical attack, the surviving bacteria in successive generations are increasingly resistant to the chemical used, and ultimately the chemical is rendered ineffective. For this reason, some question the wisdom of impregnating cloths, cutting boards and worktops in the home with bactericidal chemicals. 11.3.1 Types Of Disinfectants 11.3.2 Air Disinfectants Air disinfectants are typically chemical substances capable of disinfecting microorganisms suspended in the air. Disinfectants are generally assumed to be limited to use on surfaces, but that is not the case. In 1928, a study found that airborne microorganisms could be killed using mists of dilute bleach. An air disinfectant must be dispersed either as an aerosol or vapour at a sufficient concentration in the air to cause the number of viable infectious microorganisms to be significantly reduced. In the 1940s and early 1950s, further studies showed inactivation of diverse bacteria, influenza virus, and Penicillium chrysogenum (previously P. notatum) mold fungus using various glycols, principally propylene glycol and triethylene glycol. In principle, these chemical substances are ideal air disinfectants because they have both high lethality to microorganisms and low mammalian toxicity. Although glycols are effective air disinfectants in controlled laboratory environments, it is more difficult to use them effectively in real-world environments because the disinfection of air is sensitive to continuous action. Continuous action in real-world environments with outside air exchanges at door, HVAC, and window interfaces, and in the presence of materials that adsorb and remove glycols from the air, poses engineering challenges that are not critical for surface disinfection. The engineering challenge associated with creating a sufficient concentration of the glycol vapours in the air have not to date been sufficiently addressed. 11.3.3 Alcohols Alcohol and alcohol plus Quaternary ammonium cation based compounds comprise a class of proven surface sanitizers and disinfectants approved by the EPA and the Centers for Disease Control for use as a hospital grade disinfectant. Alcohols are most effective when combined with distilled water to facilitate diffusion through the cell membrane; 100% alcohol typically denatures only external membrane proteins. A mixture of 70% ethanol or isopropanol diluted in water is effective against a wide spectrum of bacteria, though higher concentrations are often needed to disinfect wet surfaces. Additionally, high-concentration mixtures (such as 80% ethanol + 5% isopropanol) are required to effectively inactivate lipid-enveloped viruses (such as HIV, hepatitis B, and hepatitis C). The efficacy of alcohol is enhanced when in solution with the wetting agent dodecanoic acid (coconut soap). The synergistic effect of 29.4% ethanol with dodecanoic acid is effective against a broad spectrum of bacteria, fungi, and viruses. Further testing is being performed against Clostridium difficile (C.Diff) spores with higher concentrations of ethanol and dodecanoic acid, which proved effective with a contact time of ten minutes. 11.3.4 Aldehydes Aldehydes, such as formaldehyde and glutaraldehyde, have a wide microbicidal activity and are sporicidal and fungicidal. They are partly inactivated by organic matter and have slight residual activity. Some bacteria have developed resistance to glutaraldehyde, and it has been found that glutaraldehyde can cause asthma and other health hazards, hence ortho-phthalaldehyde is replacing glutaraldehyde. 11.3.5 Oxidizing agents Oxidizing agents act by oxidizing the cell membrane of microorganisms, which results in a loss of structure and leads to cell lysis and death. A large number of disinfectants operate in this way. Chlorine and oxygen are strong oxidizers, so their compounds figure heavily here. Electrolyzed water or “Anolyte” is an oxidizing, acidic hypochlorite solution made by electrolysis of sodium chloride into sodium hypochlorite and hypochlorous acid. Anolyte has an oxidation-reduction potential of +600 to +1200 mV and a typical pH range of 3.5––8.5, but the most potent solution is produced at a controlled pH 5.0–6.3 where the predominant oxychlorine species is hypochlorous acid. Hydrogen peroxide is used in hospitals to disinfect surfaces and it is used in solution alone or in combination with other chemicals as a high level disinfectant. Hydrogen peroxide is sometimes mixed with colloidal silver. It is often preferred because it causes far fewer allergic reactions than alternative disinfectants. Also used in the food packaging industry to disinfect foil containers. A 3% solution is also used as an antiseptic. Hydrogen peroxide vapor is used as a medical sterilant and as room disinfectant. Hydrogen peroxide has the advantage that it decomposes to form oxygen and water thus leaving no long term residues, but hydrogen peroxide as with most other strong oxidants is hazardous, and solutions are a primary irritant. The vapor is hazardous to the respiratory system and eyes and consequently the OSHA permissible exposure limit is 1 ppm (29 CFR 1910.1000 Table Z-1) calculated as an eight-hour time weighted average and the NIOSH immediately dangerous to life and health limit is 75 ppm. Therefore, engineering controls, personal protective equipment, gas monitoring etc. should be employed where high concentrations of hydrogen peroxide are used in the workplace. Vaporized hydrogen peroxide is one of the chemicals approved for decontamination of anthrax spores from contaminated buildings, such as occurred during the 2001 anthrax attacks in the U.S. It has also been shown to be effective in removing exotic animal viruses, such as avian influenza and Newcastle disease from equipment and surfaces. The antimicrobial action of hydrogen peroxide can be enhanced by surfactants and organic acids. The resulting chemistry is known as Accelerated Hydrogen Peroxide. A 2% solution, stabilized for extended use, achieves high-level disinfection in 5 minutes, and is suitable for disinfecting medical equipment made from hard plastic, such as in endoscopes. The evidence available suggests that products based on Accelerated Hydrogen Peroxide, apart from being good germicides, are safer for humans and benign to the environment. Ozone is a gas used for disinfecting water, laundry, foods, air, and surfaces. It is chemically aggressive and destroys many organic compounds, resulting in rapid decolorization and deodorization in addition to disinfection. Ozone decomposes relatively quickly. However, due to this characteristic of ozone, tap water chlorination cannot be entirely replaced by ozonation, as the ozone would decompose already in the water piping. Instead, it is used to remove the bulk of oxidizable matter from the water, which would produce small amounts of organochlorides if treated with chlorine only. Regardless, ozone has a very wide range of applications from municipal to industrial water treatment due to its powerful reactivity. Potassium permanganate (KMnO4) is a purplish-black crystalline powder that colours everything it touches, through a strong oxidising action. This includes staining “stainless” steel, which somehow limits its use and makes it necessary to use plastic or glass containers. It is used to disinfect aquariums and is used in some community swimming pools as a foot disinfectant before entering the pool. Typically, a large shallow basin of KMnO4 / water solution is kept near the pool ladder. Participants are required to step in the basin and then go into the pool. Additionally, it is widely used to disinfect community water ponds and wells in tropical countries, as well as to disinfect the mouth before pulling out teeth. It can be applied to wounds in dilute solution. 11.3.6 Peroxy And Peroxo Acids Peroxycarboxylic acids and inorganic peroxo acids are strong oxidants and extremely effective disinfectants. Peroxyformic acid Peracetic acid Peroxypropionic acid Monoperoxyglutaric acid Monoperoxysuccinic acid Peroxybenzoic acid Peroxyanisic acid Chloroperbenzoic acid Monoperoxyphthalic acid Peroxymonosulfuric acid 11.3.7 Phenolics Phenolics are active ingredients in some household disinfectants. They are also found in some mouthwashes and in disinfectant soap and handwashes. Phenols are toxic to cats and newborn humans Phenol is probably the oldest known disinfectant as it was first used by Lister, when it was called carbolic acid. It is rather corrosive to the skin and sometimes toxic to sensitive people. Impure preparations of phenol were originally made from coal tar, and these contained low concentrations of other aromatic hydrocarbons including benzene, which is an IARC Group 1 carcinogen. o-Phenylphenol is often used instead of phenol, since it is somewhat less corrosive. Chloroxylenol is the principal ingredient in Dettol, a household disinfectant and antiseptic. Hexachlorophene is a phenolic that was once used as a germicidal additive to some household products but was banned due to suspected harmful effects. Thymol, derived from the herb thyme, is the active ingredient in some “broad spectrum” disinfectants that often bear ecological claims. It is used as a stabilizer in pharmaceutic preparations. It has been used for its antiseptic, antibacterial, and antifungal actions, and was formerly used as a vermifuge. Amylmetacresol is found in Strepsils, a throat disinfectant. Although not a phenol, 2,4-dichlorobenzyl alcohol has similar effects as phenols, but it cannot inactivate viruses. 11.3.8 Quaternary ammonium compounds Quaternary ammonium compounds (“quats”), such as benzalkonium chloride, are a large group of related compounds. Some concentrated formulations have been shown to be effective low-level disinfectants. Quaternary ammonia at or above 200ppm plus alcohol solutions exhibit efficacy against difficult to kill non-enveloped viruses such as norovirus, rotavirus, or polio virus. Newer synergous, low-alcohol formulations are highly effective broad-spectrum disinfectants with quick contact times (3–5 minutes) against bacteria, enveloped viruses, pathogenic fungi, and mycobacteria. Quats are biocides that also kill algae and are used as an additive in large-scale industrial water systems to minimize undesired biological growth. 11.3.9 Inorganic compounds 11.3.10 Chlorine This group comprises aqueous solution of chlorine, hypochlorite, or hypochlorous acid. Occasionally, chlorine-releasing compounds and their salts are included in this group. Frequently, a concentration of &lt; 1 ppm of available chlorine is sufficient to kill bacteria and viruses, spores and mycobacteria requiring higher concentrations. Chlorine has been used for applications, such as the deactivation of pathogens in drinking water, swimming pool water and wastewater, for the disinfection of household areas and for textile bleaching Sodium hypochlorite Calcium hypochlorite Monochloramine Chloramine-T Trichloroisocyanuric acid Chlorine dioxide Hypochlorous acid 11.3.11 Iodine Iodine Iodophors 11.3.12 Acids And Bases Sodium hydroxide Potassium hydroxide Calcium hydroxide Magnesium hydroxide Sulfurous acid Sulfur dioxide 11.3.13 Metals Most metals, especially those with high atomic weights can inhibit the growth of pathogens by disrupting their metabolism. 11.3.14 Terpenes Thymol Pine oil 11.3.15 Other The biguanide polymer polyaminopropyl biguanide is specifically bactericidal at very low concentrations (10 mg/l). It has a unique method of action: The polymer strands are incorporated into the bacterial cell wall, which disrupts the membrane and reduces its permeability, which has a lethal effect to bacteria. It is also known to bind to bacterial DNA, alter its transcription, and cause lethal DNA damage. It has very low toxicity to higher organisms such as human cells, which have more complex and protective membranes. Common sodium bicarbonate (NaHCO3) has antifungal properties, and some antiviral and antibacterial properties, though those are too weak to be effective at a home environment. 11.3.16 Non-chemical Ultraviolet germicidal irradiation is the use of high-intensity shortwave ultraviolet light for disinfecting smooth surfaces such as dental tools, but not porous materials that are opaque to the light such as wood or foam. Ultraviolet light is also used for municipal water treatment. Ultraviolet light fixtures are often present in microbiology labs, and are activated only when there are no occupants in a room (e.g., at night). Heat treatment can be used for disinfection and sterilization. The phrase “sunlight is the best disinfectant” was popularized in 1913 by United States Supreme Court Justice Louis Brandeis and later advocates of government transparency. While sunlight’s ultraviolet rays can act as a disinfectant, the Earth’s ozone layer blocks the rays’ most effective wavelengths. Ultraviolet light-emitting machines, such as those used to disinfect some hospital rooms, make for better disinfectants than sunlight. 11.4 Antiseptics An antiseptic (from Greek ἀντί anti, “against” and σηπτικός sēptikos, “putrefactive”) is an antimicrobial substance or compound that is applied to living tissue/skin to reduce the possibility of infection, sepsis, or putrefaction. Antiseptics are generally distinguished from antibiotics by the latter’s ability to safely destroy bacteria within the body, and from disinfectants, which destroy microorganisms found on non-living objects. Antibacterials include antiseptics that have the proven ability to act against bacteria. Microbicides which destroy virus particles are called viricides or antivirals. Antifungals, also known as antimycotics, are pharmaceutical fungicides used to treat and prevent mycosis (fungal infection). The widespread introduction of antiseptic surgical methods was initiated by the publishing of the paper Antiseptic Principle of the Practice of Surgery in 1867 by Joseph Lister, which was inspired by Louis Pasteur’s germ theory of putrefaction. In this paper, Lister advocated the use of carbolic acid (phenol) as a method of ensuring that any germs present were killed. Some of this work was anticipated by: Ancient Greek physicians Galen (circa 130–200) and Hippocrates (circa 400 BC) and Sumerian clay tablets dating from 2150 BC that advocate the use of similar techniques. Medieval surgeons Hugh of Lucca, Theoderic of Servia, and his pupil Henri de Mondeville were opponents of Galen’s opinion that pus was important to healing, which had led ancient and medieval surgeons to let pus remain in wounds. They advocated draining and cleaning the wound edges with wine, dressing the wound after suturing, if necessary and leaving the dressing on for ten days, soaking it in warm wine all the while, before changing it. Their theories were bitterly opposed by Galenist Guy de Chauliac and others trained in the classical tradition. Oliver Wendell Holmes, Sr., who published The Contagiousness of Puerperal Fever in 1843 Florence Nightingale, who contributed substantially to the report of the Royal Commission on the Health of the Army (1856–1857), based on her earlier work Ignaz Semmelweis, who published his work The Cause, Concept and Prophylaxis of Childbed Fever in 1861, summarizing experiments and observations since 1847] Some common antiseptics ￼ Structure of povidone-iodine complex, the most common antiseptic in use today. Antiseptics can be subdivided into about eight classes of materials. These classes can be subdivided according to their mechanism of action: small molecules that indescrimantly react with organic compounds and kill microorganisms (peroxides, iodine, phenols) and more complex molecules that disrupt the cell walls of the bacteria. Phenols such as phenol itself (as introduced by Lister) and triclosan, hexachlorophene, chlorocresol, and chloroxylenol. The latter is used for skin disinfection and cleaning surgical instruments. It is also used within a number of household disinfectants and wound cleaners. Diguanides including chlorhexidine gluconate, a bacteriocidal antiseptic which (with an alcoholic solvent) is the most effective at reducing the risk of infection after surgery. It is also used in mouthwashes to treat inflammation of the gums (gingivitis). Polyhexanide (polyhexamethylene biguanide, PHMB) is an antimicrobial compound suitable for clinical use in critically colonized or infected acute and chronic wounds. The physicochemical action on the bacterial envelope prevents or impedes the development of resistant bacterial strains. Quinolines such as hydroxyquinolone, dequalium chloride, or chlorquinaldol. Alcohols, including ethanol and 2-propanol/isopropanol are sometimes referred to as surgical spirit. They are used to disinfect the skin before injections, among other uses. Peroxides, such as hydrogen peroxide and benzoyl peroxide. Commonly, 3% solutions of hydrogen peroxide have been used in household first aid for scrapes, etc. However, the strong oxidization causes scar formation and increases healing time during fetal development. Iodine, especially in the form of povidone-iodine, is widely used because it is well tolerated, does not negatively affect wound healing, leaves a deposit of active iodine, thereby creating the so-called “remnant”, or persistent, effect, and has wide scope of antimicrobial activity. The traditional iodine antiseptic is an alcohol solution (called tincture of iodine) or as Lugol’s iodine solution. Some studies do not recommend disinfecting minor wounds with iodine because of concern that it may induce scar tissue formation and increase healing time. However, concentrations of 1% iodine or less have not been shown to increase healing time and are not otherwise distinguishable from treatment with saline. Iodine will kill all principal pathogens and, given enough time, even spores, which are considered to be the most difficult form of microorganisms to be inactivated by disinfectants and antiseptics. Octenidine dihydrochloride, currently increasingly used in continental Europe, often as a chlorhexidine substitute. Quat salts such as benzalkonium chloride, cetylpyridinium chloride, or cetrimide. These surfactants disrupt cell walls. "],["drugs-microbes-and-the-host.html", "12 Drugs, Microbes, And The Host 12.1 Antibacterials 12.2 Antifungals 12.3 Antivirals 12.4 Antiparasitics 12.5 Broad-Spectrum Therapeutics 12.6 Antibiotics 12.7 Drug Resistance 12.8 Testing For Antibiotic Sensitivity 12.9 Replenishing The Antibiotic Pipeline And Developing Other New Therapies", " 12 Drugs, Microbes, And The Host An antimicrobial is an agent that kills microorganisms or stops their growth. Antimicrobial medicines can be grouped according to the microorganisms they act primarily against. For example, antibiotics are used against bacteria, and antifungals are used against fungi. They can also be classified according to their function. Agents that kill microbes are microbicides, while those that merely inhibit their growth are called bacteriostatic agents. The use of antimicrobial medicines to treat infection is known as antimicrobial chemotherapy, while the use of antimicrobial medicines to prevent infection is known as antimicrobial prophylaxis. The main classes of antimicrobial agents are disinfectants (non-selective agents, such as bleach), which kill a wide range of microbes on non-living surfaces to prevent the spread of illness, antiseptics (which are applied to living tissue and help reduce infection during surgery), and antibiotics (which destroy microorganisms within the body). The term ‘antibiosis’, meaning “against life”, was introduced by the French bacteriologist Jean Paul Vuillemin as a descriptive name of the phenomenon exhibited by these early antibacterial drugs. Antibiosis was first described in 1877 in bacteria when Louis Pasteur and Robert Koch observed that an airborne bacillus could inhibit the growth of Bacillus anthracis. These drugs were later renamed antibiotics by Selman Waksman, an American microbiologist, in 1947. The term “antibiotic” derives from anti + βιωτικός (biōtikos), “fit for life, lively”, which comes from βίωσις (biōsis), “way of life”, and that from βίος (bios), “life”. The term “antibacterial” derives from Greek ἀντί (anti), “against” + βακτήριον (baktērion), diminutive of βακτηρία (baktēria), “staff, cane”, because the first bacteria to be discovered were rod. The term antibiotic was first used in 1942 by Selman Waksman and his collaborators in journal articles to describe any substance produced by a microorganism that is antagonistic to the growth of other microorganisms in high dilution. The term “antibiotic” originally described only those formulations derived from living microorganisms but is now also applied to synthetic agents, such as sulfonamides or fluoroquinolones. Though the term used to be restricted to antibacterials (and is often used as a synonym for them by medical professionals and in medical literature), its context has broadened to include all antimicrobials. Antibacterial agents can be further subdivided into bactericidal agents, which kill bacteria, and bacteriostatic agents, which slow down or stall bacterial growth. In response, further advancements in antimicrobial technologies have resulted in solutions that can go beyond simply inhibiting microbial growth. Instead, certain types of porous media have been developed to kill microbes on contact. Antimicrobial use has been common practice for at least 2000 years. Ancient Egyptians and ancient Greeks used specific molds and plant extracts to treat infection. In the 19th century, microbiologists such as Louis Pasteur and Jules Francois Joubert observed antagonism between some bacteria and discussed the merits of controlling these interactions in medicine. Louis Pasteur’s work in fermentation and spontaneous generation led to the distinction between anaerobic and aerobic bacteria. The information garnered by Pasteur led Joseph Lister to incorporate antiseptic methods, such as sterilizing surgical tools and debriding wounds into surgical procedures. The implementation of these antiseptic techniques drastically reduced the number of infections and subsequent deaths associated with surgical procedures. Louis Pasteur’s work in microbiology also led to the development of many vaccines for life-threatening diseases such as anthrax and rabies. On September 3, 1928, Alexander Fleming returned from a vacation and discovered that a Petri dish filled with Staphylococcus was separated into colonies due to the antimicrobial fungus Penicillium rubens. Fleming and his associates struggled to isolate the antimicrobial but referenced its therapeutic potential in 1929 in the British Journal of Experimental Pathology. In 1942, Howard Florey, Ernst Chain, and Edward Abraham utilized Fleming’s work to purify and extract penicillin for medicinal uses earning them the 1945 Nobel Prize in Medicine. 12.1 Antibacterials Antibacterials are used to treat bacterial infections. Antibiotics are classified generally as beta-lactams, macrolides, quinolones, tetracyclines or aminoglycosides. Their classification within these categories depends on their antimicrobial spectra, pharmacodynamics, and chemical composition. Prolonged use of certain antibacterials can decrease the number of enteric bacteria, which may have a negative impact on health. Consumption of probiotics and reasonable eating may help to replace destroyed gut flora. Stool transplants may be considered for patients who are having difficulty recovering from prolonged antibiotic treatment, as for recurrent Clostridioides difficile infections. The discovery, development and use of antibacterials during the 20th century have reduced mortality from bacterial infections. The antibiotic era began with the therapeutic application of sulfonamide drugs in 1936, followed by a “golden” period of discovery from about 1945 to 1970, when a number of structurally diverse and highly effective agents were discovered and developed. Since 1980, the introduction of new antimicrobial agents for clinical use has declined, in part because of the enormous expense of developing and testing new drugs. In parallel, there has been an alarming increase in antimicrobial resistance of bacteria, fungi, parasites and some viruses to multiple existing agents. Antibacterials are among the most commonly used drugs and among the drugs commonly misused by physicians, for example, in viral respiratory tract infections. As a consequence of widespread and injudicious use of antibacterials, there has been an accelerated emergence of antibiotic-resistant pathogens, resulting in a serious threat to global public health. The resistance problem demands that a renewed effort be made to seek antibacterial agents effective against pathogenic bacteria resistant to current antibacterials. Possible strategies towards this objective include increased sampling from diverse environments and application of metagenomics to identify bioactive compounds produced by currently unknown and uncultured microorganisms as well as the development of small-molecule libraries customized for bacterial targets. 12.2 Antifungals Antifungals are used to kill or prevent further growth of fungi. In medicine, they are used as a treatment for infections such as athlete’s foot, ringworm and thrush and work by exploiting differences between mammalian and fungal cells. Unlike bacteria, both fungi and humans are eukaryotes. Thus, fungal and human cells are similar at the molecular level, making it more difficult to find a target for an antifungal drug to attack that does not also exist in the host organism. Consequently, there are often side effects to some of these drugs. Some of these side effects can be life-threatening if the drug is not used properly. As well as their use in medicine, antifungals are frequently sought after to control indoor mold in damp or wet home materials. Sodium bicarbonate (baking soda) blasted on to surfaces acts as an antifungal. Another antifungal solution applied after or without blasting by soda is a mix of hydrogen peroxide and a thin surface coating that neutralizes mold and encapsulates the surface to prevent spore release. Some paints are also manufactured with an added antifungal agent for use in high humidity areas such as bathrooms or kitchens. Other antifungal surface treatments typically contain variants of metals known to suppress mold growth e.g. pigments or solutions containing copper, silver or zinc. These solutions are not usually available to the general public because of their toxicity. 12.3 Antivirals Antiviral drugs are a class of medication used specifically for treating viral infections. Like antibiotics, specific antivirals are used for specific viruses. They should be distinguished from viricides, which actively deactivate virus particles outside the body. Many antiviral drugs are designed to treat infections by retroviruses, including HIV. Important antiretroviral drugs include the class of protease inhibitors. Herpes viruses, best known for causing cold sores and genital herpes, are usually treated with the nucleoside analogue acyclovir. Viral hepatitis is caused by five unrelated hepatotropic viruses (A-E) and may be treated with antiviral drugs depending on the type of infection. Some influenza A and B viruses have become resistant to neuraminidase inhibitors such as oseltamivir, and the search for new substances continues. 12.4 Antiparasitics Antiparasitics are a class of medications indicated for the treatment of infectious diseases such as leishmaniasis, malaria and Chagas disease, which are caused by parasites such as nematodes, cestodes, trematodes and infectious protozoa. Antiparasitic medications include metronidazole, iodoquinol and albendazole. Like all therapeutic antimicrobials, they must kill the infecting organism without serious damage to the host. 12.5 Broad-Spectrum Therapeutics Broad-spectrum therapeutics are active against multiple classes of pathogens. Such therapeutics have been suggested as potential emergency treatments for pandemics. Azithromycin is currently the only identified broad-spectrum therapeutic. 12.6 Antibiotics An antibiotic is a type of antimicrobial substance active against bacteria. It is the most important type of antibacterial agent for fighting bacterial infections, and antibiotic medications are widely used in the treatment and prevention of such infections. They may either kill or inhibit the growth of bacteria. A limited number of antibiotics also possess antiprotozoal activity. Antibiotics are not effective against viruses such as the common cold or influenza; drugs which inhibit viruses are termed antiviral drugs or antivirals rather than antibiotics. Sometimes, the term antibiotic—literally “opposing life”, from the Greek roots ἀντι anti, “against” and βίος bios, “life”—is broadly used to refer to any substance used against microbes, but in the usual medical usage, antibiotics (such as penicillin) are those produced naturally (by one microorganism fighting another), whereas nonantibiotic antibacterials (such as sulfonamides and antiseptics) are fully synthetic. However, both classes have the same goal of killing or preventing the growth of microorganisms, and both are included in antimicrobial chemotherapy. “Antibacterials” include antiseptic drugs, antibacterial soaps, and chemical disinfectants, whereas antibiotics are an important class of antibacterials used more specifically in medicine and sometimes in livestock feed. Antibiotics have been used since ancient times. Many civilizations used topical application of mouldy bread, with many references to its beneficial effects arising from ancient Egypt, Nubia, China, Serbia, Greece, and Rome. The first person to directly document the use of molds to treat infections was John Parkinson (1567–1650). Antibiotics revolutionized medicine in the 20th century. Alexander Fleming (1881–1955) discovered modern day penicillin in 1928, the widespread use of which proved significantly beneficial during wartime. However, the effectiveness and easy access to antibiotics have also led to their overuse and some bacteria have evolved resistance to them. The World Health Organization has classified antimicrobial resistance as a widespread “serious threat [that] is no longer a prediction for the future, it is happening right now in every region of the world and has the potential to affect anyone, of any age, in any country”. Antibiotics are used to treat or prevent bacterial infections, and sometimes protozoan infections. (Metronidazole is effective against a number of parasitic diseases). When an infection is suspected of being responsible for an illness but the responsible pathogen has not been identified, an empiric therapy is adopted. This involves the administration of a broad-spectrum antibiotic based on the signs and symptoms presented and is initiated pending laboratory results that can take several days. When the responsible pathogenic microorganism is already known or has been identified, definitive therapy can be started. This will usually involve the use of a narrow-spectrum antibiotic. The choice of antibiotic given will also be based on its cost. Identification is critically important as it can reduce the cost and toxicity of the antibiotic therapy and also reduce the possibility of the emergence of antimicrobial resistance. To avoid surgery, antibiotics may be given for non-complicated acute appendicitis. Figure 12.1: Antibiotics coverage diagram. Antibiotics may be given as a preventive measure and this is usually limited to at-risk populations such as those with a weakened immune system (particularly in HIV cases to prevent pneumonia), those taking immunosuppressive drugs, cancer patients, and those having surgery. Their use in surgical procedures is to help prevent infection of incisions. They have an important role in dental antibiotic prophylaxis where their use may prevent bacteremia and consequent infective endocarditis. Antibiotics are also used to prevent infection in cases of neutropenia particularly cancer-related. There are many different routes of administration for antibiotic treatment. Antibiotics are usually taken by mouth. In more severe cases, particularly deep-seated systemic infections, antibiotics can be given intravenously or by injection. Where the site of infection is easily accessed, antibiotics may be given topically in the form of eye drops onto the conjunctiva for conjunctivitis or ear drops for ear infections and acute cases of swimmer’s ear. Topical use is also one of the treatment options for some skin conditions including acne and cellulitis. Advantages of topical application include achieving high and sustained concentration of antibiotic at the site of infection; reducing the potential for systemic absorption and toxicity, and total volumes of antibiotic required are reduced, thereby also reducing the risk of antibiotic misuse. Topical antibiotics applied over certain types of surgical wounds have been reported to reduce the risk of surgical site infections. However, there are certain general causes for concern with topical administration of antibiotics. Some systemic absorption of the antibiotic may occur; the quantity of antibiotic applied is difficult to accurately dose, and there is also the possibility of local hypersensitivity reactions or contact dermatitis occurring. It is recommended to administer antibiotics as soon as possible, especially in life-threatening infections. Many emergency departments stock antibiotics for this purpose. Prevalence Antibiotic consumption varies widely between countries. The WHO report on surveillance of antibiotic consumption’ published in 2018 analysed 2015 data from 65 countries. As measured in defined daily doses per 1,000 inhabitants per day. Mongolia had the highest consumption with a rate of 64.4. Burundi had the lowest at 4.4. Amoxicillin and amoxicillin/clavulanic acid were the most frequently consumed. 12.6.1 Classes of Antibiotics Antibiotics are commonly classified based on their mechanism of action, chemical structure, or spectrum of activity. Most target bacterial functions or growth processes. Those that target the bacterial cell wall (penicillins and cephalosporins) or the cell membrane (polymyxins), or interfere with essential bacterial enzymes (rifamycins, lipiarmycins, quinolones, and sulfonamides) have bactericidal activities. Protein synthesis inhibitors (macrolides, lincosamides, and tetracyclines) are usually bacteriostatic (with the exception of bactericidal aminoglycosides). Further categorization is based on their target specificity. “Narrow-spectrum” antibiotics target specific types of bacteria, such as gram-negative or gram-positive, whereas broad-spectrum antibiotics affect a wide range of bacteria. Following a 40-year break in discovering classes of antibacterial compounds, four new classes of antibiotics were introduced to clinical use in the late 2000s and early 2010s: cyclic lipopeptides (such as daptomycin), glycylcyclines (such as tigecycline), oxazolidinones (such as linezolid), and lipiarmycins (such as fidaxomicin). With advances in medicinal chemistry, most modern antibacterials are semisynthetic modifications of various natural compounds. These include, for example, the beta-lactam antibiotics, which include the penicillins (produced by fungi in the genus Penicillium), the cephalosporins, and the carbapenems. Compounds that are still isolated from living organisms are the aminoglycosides, whereas other antibacterials—for example, the sulfonamides, the quinolones, and the oxazolidinones—are produced solely by chemical synthesis. Many antibacterial compounds are relatively small molecules with a molecular weight of less than 1000 daltons. Since the first pioneering efforts of Howard Florey and Chain in 1939, the importance of antibiotics, including antibacterials, to medicine has led to intense research into producing antibacterials at large scales. Following screening of antibacterials against a wide range of bacteria, production of the active compounds is carried out using fermentation, usually in strongly aerobic conditions. The emergence of resistance of bacteria to antibiotics is a common phenomenon. Emergence of resistance often reflects evolutionary processes that take place during antibiotic therapy. The antibiotic treatment may select for bacterial strains with physiologically or genetically enhanced capacity to survive high doses of antibiotics. Under certain conditions, it may result in preferential growth of resistant bacteria, while growth of susceptible bacteria is inhibited by the drug. For example, antibacterial selection for strains having previously acquired antibacterial-resistance genes was demonstrated in 1943 by the Luria–Delbrück experiment. Antibiotics such as penicillin and erythromycin, which used to have a high efficacy against many bacterial species and strains, have become less effective, due to the increased resistance of many bacterial strains. Resistance may take the form of biodegradation of pharmaceuticals, such as sulfamethazine-degrading soil bacteria introduced to sulfamethazine through medicated pig feces. The survival of bacteria often results from an inheritable resistance, but the growth of resistance to antibacterials also occurs through horizontal gene transfer. Horizontal transfer is more likely to happen in locations of frequent antibiotic use. Antibacterial resistance may impose a biological cost, thereby reducing fitness of resistant strains, which can limit the spread of antibacterial-resistant bacteria, for example, in the absence of antibacterial compounds. Additional mutations, however, may compensate for this fitness cost and can aid the survival of these bacteria. Paleontological data show that both antibiotics and antibiotic resistance are ancient compounds and mechanisms. Useful antibiotic targets are those for which mutations negatively impact bacterial reproduction or viability. Several molecular mechanisms of antibacterial resistance exist. Intrinsic antibacterial resistance may be part of the genetic makeup of bacterial strains. For example, an antibiotic target may be absent from the bacterial genome. Acquired resistance results from a mutation in the bacterial chromosome or the acquisition of extra-chromosomal DNA. Antibacterial-producing bacteria have evolved resistance mechanisms that have been shown to be similar to, and may have been transferred to, antibacterial-resistant strains. The spread of antibacterial resistance often occurs through vertical transmission of mutations during growth and by genetic recombination of DNA by horizontal genetic exchange. For instance, antibacterial resistance genes can be exchanged between different bacterial strains or species via plasmids that carry these resistance genes. Plasmids that carry several different resistance genes can confer resistance to multiple antibacterials. Cross-resistance to several antibacterials may also occur when a resistance mechanism encoded by a single gene conveys resistance to more than one antibacterial compound. Antibacterial-resistant strains and species, sometimes referred to as “superbugs”, now contribute to the emergence of diseases that were for a while well controlled. For example, emergent bacterial strains causing tuberculosis that are resistant to previously effective antibacterial treatments pose many therapeutic challenges. Every year, nearly half a million new cases of multidrug-resistant tuberculosis (MDR-TB) are estimated to occur worldwide. For example, NDM-1 is a newly identified enzyme conveying bacterial resistance to a broad range of beta-lactam antibacterials. The United Kingdom’s Health Protection Agency has stated that “most isolates with NDM-1 enzyme are resistant to all standard intravenous antibiotics for treatment of severe infections.” On 26 May 2016, an E. coli “superbug” was identified in the United States resistant to colistin, “the last line of defence” antibiotic. Before the early 20th century, treatments for infections were based primarily on medicinal folklore. Mixtures with antimicrobial properties that were used in treatments of infections were described over 2,000 years ago. Many ancient cultures, including the ancient Egyptians and ancient Greeks, used specially selected mold and plant materials to treat infections. Nubian mummies studied in the 1990s were found to contain significant levels of tetracycline. The beer brewed at that time was conjectured to have been the source. The use of antibiotics in modern medicine began with the discovery of synthetic antibiotics derived from dyes. Synthetic antibiotic chemotherapy as a science and development of antibacterials began in Germany with Paul Ehrlich in the late 1880s. Ehrlich noted certain dyes would color human, animal, or bacterial cells, whereas others did not. He then proposed the idea that it might be possible to create chemicals that would act as a selective drug that would bind to and kill bacteria without harming the human host. After screening hundreds of dyes against various organisms, in 1907, he discovered a medicinally useful drug, the first synthetic antibacterial organoarsenic compound salvarsan, now called arsphenamine. This heralded the era of antibacterial treatment that was begun with the discovery of a series of arsenic-derived synthetic antibiotics by both Alfred Bertheim and Ehrlich in 1907. Ehrlich and Bertheim had experimented with various chemicals derived from dyes to treat trypanosomiasis in mice and spirochaeta infection in rabbits. While their early compounds were too toxic, Ehrlich and Sahachiro Hata, a Japanese bacteriologist working with Erlich in the quest for a drug to treat syphilis, achieved success with the 606th compound in their series of experiments. In 1910 Ehrlich and Hata announced their discovery, which they called drug “606”, at the Congress for Internal Medicine at Wiesbaden. The Hoechst company began to market the compound toward the end of 1910 under the name Salvarsan, now known as arsphenamine. The drug was used to treat syphilis in the first half of the 20th century. In 1908, Ehrlich received the Nobel Prize in Physiology or Medicine for his contributions to immunology. Hata was nominated for the Nobel Prize in Chemistry in 1911 and for the Nobel Prize in Physiology or Medicine in 1912 and 1913. The first sulfonamide and the first systemically active antibacterial drug, Prontosil, was developed by a research team led by Gerhard Domagk in 1932 or 1933 at the Bayer Laboratories of the IG Farben conglomerate in Germany, for which Domagk received the 1939 Nobel Prize in Physiology or Medicine. Sulfanilamide, the active drug of Prontosil, was not patentable as it had already been in use in the dye industry for some years. Prontosil had a relatively broad effect against Gram-positive cocci, but not against enterobacteria. Research was stimulated apace by its success. The discovery and development of this sulfonamide drug opened the era of antibacterials. 12.6.2 Penicillin And Other Natural Antibiotics Penicillins (P, PCN or PEN) are a group of antibiotics originally obtained from Penicillium moulds, principally P. chrysogenum and P. rubens. Most penicillins in clinical use are chemically synthesised from naturally-produced penicillins. A number of natural penicillins have been discovered, but only two purified compounds are in clinical use: penicillin G (intravenous use) and penicillin V (given by mouth). Penicillins were among the first medications to be effective against many bacterial infections caused by staphylococci and streptococci. They are members of the β-lactam antibiotics. They are still widely used today for different bacterial infections, though many types of bacteria have developed resistance following extensive use. About 10% of people report that they are allergic to penicillin; however, up to 90% of this group may not actually be allergic. Serious allergies only occur in about 0.03%.[for whom?] Those who are allergic to penicillin are most often given cephalosporin C (another β-lactam antibiotic) because there is only 10% crossover in allergy between the penicillins and cephalosporins. Starting in the late 19th century there had been reports of the antibacterial properties of Penicillium mould, but scientists were unable to discern what process was causing the effect. Scottish physician Alexander Fleming at St Mary’s Hospital in London (now part of Imperial College) was the first to show that Penicillium rubens had antibacterial properties. On 3 September 1928 he observed that fungal contamination of a bacterial culture (Staphylococcus aureus) appeared to kill the bacteria. He confirmed this observation with a new experiment on 28 September 1928. He published his experiment in 1929, and called the antibacterial substance (the fungal extract) penicillin. C. J. La Touche identified the fungus as Penicillium rubrum (later reclassified by Charles Thom as P. notatum and P. chrysogenum, but later corrected as P. rubens). Fleming expressed initial optimism that penicillin would be a useful antiseptic, because of its high potency and minimal toxicity in comparison to other antiseptics of the day, and noted its laboratory value in the isolation of Bacillus influenzae (now called Haemophilus influenzae). Fleming did not convince anyone that his discovery was important. This was largely because penicillin was so difficult to isolate that its development as a drug seemed impossible. It is speculated that had Fleming been more successful at making other scientists interested in his work, penicillin would possibly have been developed years earlier. The importance of his work has been recognized by the placement of an International Historic Chemical Landmark at the Alexander Fleming Laboratory Museum in London on November 19, 1999. In 1930, Cecil George Paine, a pathologist at the Royal Infirmary in Sheffield, successfully treated ophthalmia neonatorum, a gonococcal infection in infants, with penicillin (fungal extract) on November 25, 1930. In 1940, Australian scientist Howard Florey (later Baron Florey) and a team of researchers (Ernst Chain, Edward Abraham, Arthur Duncan Gardner, Norman Heatley, Margaret Jennings, Jean Orr-Ewing and Arthur Gordon Sanders) at the Sir William Dunn School of Pathology, University of Oxford made progress in making concentrated penicillin from fungal culture broth that showed both in vitro and in vivo bactericidal action. In 1941, they treated a policeman, Albert Alexander, with a severe face infection; his condition improved, but then supplies of penicillin ran out and he died. Subsequently, several other patients were treated successfully. In December 1942, survivors of the Cocoanut Grove fire in Boston were the first burn patients to be successfully treated with penicillin. The first successful use of pure penicillin was when Fleming treated Harry Lambert of fatal infection of the nervous system (streptococcal meningitis) in 1942. By that time the Oxford team could produce only small amount. Florey willingly gave the only available sample to Fleming. Lambert showed improvement from the very next day of the treatment, and was completely cured within a week. Fleming published his clinical trial in The Lancet in 1943. Following the medical breakthrough the British War Cabinet set up the Penicillin Committee on 5 April 1943 that led to projects for mass production. As the medical application was established, the Oxford team found that it was impossible to produce usable amounts in their laboratory. Failing to persuade the British government, Florey and Heatley travelled to the US in June 1941 with their mould samples in order to interest the US government for large-scale production. They approached the USDA Northern Regional Research Laboratory (NRRL, now the National Center for Agricultural Utilization Research) at Peoria, Illinois, where facilities for large-scale fermentations were established. Mass culture of the mould and search for better moulds immediately followed. On March 14, 1942, the first patient was treated for streptococcal sepsis with US-made penicillin produced by Merck &amp; Co. Half of the total supply produced at the time was used on that one patient, Anne Miller. By June 1942, just enough US penicillin was available to treat ten patients. In July 1943, the War Production Board drew up a plan for the mass distribution of penicillin stocks to Allied troops fighting in Europe. The results of fermentation research on corn steep liquor at the NRRL allowed the United States to produce 2.3 million doses in time for the invasion of Normandy in the spring of 1944. After a worldwide search in 1943, a mouldy cantaloupe in a Peoria, Illinois market was found to contain the best strain of mould for production using the corn steep liquor process. Pfizer scientist Jasper H. Kane suggested using a deep-tank fermentation method for producing large quantities of pharmaceutical-grade penicillin.:109 Large-scale production resulted from the development of a deep-tank fermentation plant by chemical engineer Margaret Hutchinson Rousseau. As a direct result of the war and the War Production Board, by June 1945, over 646 billion units per year were being produced. After World War II, Australia was the first country to make the drug available for civilian use. In the U.S., penicillin was made available to the general public on March 15, 1945. Fleming, Florey, and Chain shared the 1945 Nobel Prize in Physiology or Medicine for the development of penicillin. Several semisynthetic penicillins are effective against a broader spectrum of bacteria: these include the antistaphylococcal penicillins, aminopenicillins and the antipseudomonal penicillins. The term “penicillin” is defined as the natural product of Penicillium mould with antimicrobial activity. It was coined by Alexander Fleming on 7 March 1929 when he discovered the antibacterial property of Penicillium rubens. The name was “to avoid the repetition of the rather cumbersome phrase ‘Mould broth filtrate,’ the name ‘penicillin’ will be used,” as Fleming explained in his 1929 paper in the British Journal of Experimental Pathology. The name thus refers to the scientific name of the mould, as described by Fleming in his Nobel lecture in 1945: I have been frequently asked why I invented the name “Penicillin”. I simply followed perfectly orthodox lines and coined a word which explained that the substance penicillin was derived from a plant of the genus Penicillium just as many years ago the word “Digitalin” was invented for a substance derived from the plant Digitalis. In modern usage, the term penicillin is used more broadly to refer to any β-lactam antimicrobial that contains a thiazolidine ring fused to the β-lactam core, and may or may not be a natural product. Like most natural products, penicillin is present in Penicillium moulds as a mixture of active constituents (gentamicin is another example of a natural product that is an ill-defined mixture of active components). The precise constitution of the penicillin extracted depends on the species of Penicillium mould used and on the nutrient media used to culture the mould. Fleming’s original strain of Penicillium rubens produces principally penicillin F, named after Fleming. But penicillin F is unstable, difficult to isolate, and produced by the mould in small quantities. The principal commercial strain of Penicillium chrysogenum (the Peoria strain) produces penicillin G as the principal component when corn steep liquor is used as the culture medium. When phenoxyethanol or phenoxyacetic acid are added to the culture medium, the mould produces penicillin V as the main penicillin instead. 6-Aminopenicillanic acid (6-APA) is a compound derived from penicillin G. 6-APA contains the beta-lactam core of penicillin G, but with the side chains stripped off; 6-APA is a useful precursor for manufacturing other penicillins. There are many semi-synthetic penicillins derived from 6-APA and these are in three groups: antistaphylococcal penicillins, broad-spectrum penicillins, and antipseudomonal penicillins. The semi-synthetic penicillins are all referred to as penicillins because they are all derived ultimately from penicillin G. Penicillin G (benzylpenicillin) was first produced from a penicillium fungus that occurs in nature. The strain of fungus used today for the manufacture of penicillin G was created by genetic engineering to improve the yield in the manufacturing process. None of the other natural penicillins (F, K, N, X, O, U1 or U6) are currently in clinical use. Penicillin V (phenoxymethylpenicillin) is produced by adding the precursor phenoxyacetic acid to the medium in which a genetically modified strain of the penicillium fungus is being cultured. There are three major groups of other semi-synthetic antibiotics related to the penicillins. They are synthesised by adding various side-chains to the precursor 6-APA, which is isolated from penicillin G. These are the antistaphylococcal antibiotics, broad-spectrum antibiotics, and antipseudomonal antibiotics. 12.6.3 Antistaphylococcal antibiotics Cloxacillin (by mouth or by injection) Dicloxacillin (by mouth or by injection) Flucloxacillin (by mouth or by injection) Methicillin (injection only) Nafcillin (injection only) Oxacillin (by mouth or by injection) Antistaphylococcal antibiotics are so-called because they are resistant to being broken down by staphylococcal penicillinase. They are also, therefore, referred to as being penicillinase-resistant. 12.6.4 Broad-spectrum antibiotics This group of antibiotics is called “broad-spectrum” because they are active against a wide range of Gram-negative bacteria such as Escherichia coli and Salmonella typhi, for which penicillin is not suitable. However, resistance in these organisms is now common. Ampicillin Amoxycillin There are many ampicillin precursors in existence. These are inactive compounds that are broken down in the gut to release ampicillin. None of these pro-drugs of ampicillin are in current use: Pivampicillin (pivaloyloxymethyl ester of ampicillin) Bacampicillin Metampicillin (formaldehyde ester of ampicillin) Talampicillin Hetacillin (ampicillin conjugated to acetone) Epicillin is an aminopenicillin that has never seen widespread clinical use. 12.6.5 Antipseudomonal antibiotics The Gram-negative species, Pseudomonas aeruginosa, is naturally resistant to many antibiotic classes. There were many efforts in the 1960s and 1970s to develop antibiotics that are active against Pseudomonas species. There are two chemical classes within the group: carboxypenicillins and ureidopenicillins. All are given by injection: none can be given by mouth. Carboxypenicillins * Carbenicillin * Ticarcillin * Temocillin Ureidopenicillins * Mezlocillin * Piperacillin * Azlocillin β-lactamase inhibitors * Clavulanic acid * Sulbactam * Tazobactam The term “penicillin”, when used by itself, may refer to either of two chemical compounds, penicillin G or penicillin V. Table 12.1: The three essential polymeric macromolecules of life Common name Chemical name Method ofadministration Penicillin V phenoxymethylpenicillin oral Penicillin G benzylpenicillin intravenous intramuscular Penicillin G is destroyed by stomach acid, so it cannot be taken by mouth, but doses as high as 2.4 g can be given (much higher than penicillin V). It is given by intravenous or intramuscular injection. It can be formulated as an insoluble salt, and there are two such formulations in current use: procaine penicillin and benzathine benzylpenicillin, which are used only in the treatment of syphilis. When a high concentration in the blood must be maintained, penicillin G must be administered at relatively frequent intervals, because it is eliminated quite rapidly from the bloodstream by the kidney. Penicillin G is licensed for use to treat septicaemia, empyema, pneumonia, pericarditis, endocarditis and meningitis caused by susceptible strains of staphylococci and streptococci. It is also licensed for the treatment of anthrax, actinomycosis, cervicofacial disease, thoracic and abdominal disease, clostridial infections, botulism, gas gangrene (with accompanying debridement and/or surgery as indicated), tetanus (as an adjunctive therapy to human tetanus immune globulin), diphtheria (as an adjunctive therapy to antitoxin and for the prevention of the carrier state), erysipelothrix endocarditis, fusospirochetosis (severe infections of the oropharynx, lower respiratory tract and genital area), Listeria infections, meningitis, endocarditis, Pasteurella infections including bacteraemia and meningitis, Haverhill fever; rat-bite fever and disseminated gonococcal infections, meningococcal meningitis and/or septicaemia caused by penicillin-susceptible organisms and syphilis. Penicillin V can be taken by mouth because it is relatively resistant to stomach acid. Doses higher than 500 mg are not fully effective because of poor absorption. It is used for the same bacterial infections as those of penicillin G and is the most widely used form of penicillin. However, it is not used for diseases, such as endocarditis, where high blood levels of penicillin are required. Because penicillin resistance is now so common, other antibiotics are now the preferred choice for treatments. For example, penicillin used to be the first-line treatment for infections with Neisseria gonorrhoeae and Neisseria meningitidis, but it is longer recommended for treatment of these infections. Table 12.2: The three essential polymeric macromolecules of life Bacterium Susceptible (S) Intermediate (I) Resistant (R) Staphylococcus aureus ≤0.12 mcg/ml ≥0.25 mcg/ml Streptococcus pneumoniae meningitis ≤0.06 mcg/ml ≥0.12 mcg/ml Streptococcus pneumoniae (not meningitis) ≤2 mcg/ml ≥8 mcg/ml Streptococcus Viridans group 0.12 mcg/ml 0.25–2 mcg/ml 4 mcg/ml Listeria monocytogenes ≤2 mcg/ml Bacillus anthracis ≤0.12 mcg/ml ≥0.25 mcg/ml Observations about the growth of some microorganisms inhibiting the growth of other microorganisms have been reported since the late 19th century. These observations of antibiosis between microorganisms led to the discovery of natural antibacterials. Louis Pasteur observed, “if we could intervene in the antagonism observed between some bacteria, it would offer perhaps the greatest hopes for therapeutics”. Common (≥ 1% of people) adverse drug reactions associated with use of the penicillins include diarrhoea, hypersensitivity, nausea, rash, neurotoxicity, urticaria, and superinfection (including candidiasis). Infrequent adverse effects (0.1–1% of people) include fever, vomiting, erythema, dermatitis, angioedema, seizures (especially in people with epilepsy), and pseudomembranous colitis. Penicillin can also induce serum sickness or a serum sickness-like reaction in some individuals. Serum sickness is a type III hypersensitivity reaction that occurs one to three weeks after exposure to drugs including penicillin. It is not a true drug allergy, because allergies are type I hypersensitivity reactions, but repeated exposure to the offending agent can result in an anaphylactic reaction. Allergy will occur in 1-10% of people, presenting as a skin rash after exposure. IgE-mediated anaphylaxis will occur in approximately 0.01% of patients. Pain and inflammation at the injection site are also common for parenterally administered benzathine benzylpenicillin, benzylpenicillin, and, to a lesser extent, procaine benzylpenicillin. The condition is known as livedoid dermatitis or Nicolau syndrome. 12.6.6 Chemical Structure Of Penicillins The term “penam” is used to describe the common core skeleton of a member of the penicillins. This core has the molecular formula R-C9H11N2O4~S, where R is the variable side chain that differentiates the penicillins from one another. The penam core has a molar mass of 243 g/mol, with larger penicillins having molar mass near 450—for example, cloxacillin has a molar mass of 436 g/mol. 6-APA (C8H12N2O3S) forms the basic structure of penicillins. It is made up of an enclosed dipeptide formed by the condensation of L-cystein and D-valine. This results in the formations of β-lactam and thiazolidinic rings. The key structural feature of the penicillins is the four-membered β-lactam ring; this structural moiety is essential for penicillin’s antibacterial activity. The β-lactam ring is itself fused to a five-membered thiazolidine ring. The fusion of these two rings causes the β-lactam ring to be more reactive than monocyclic β-lactams because the two fused rings distort the β-lactam amide bond and therefore remove the resonance stabilisation normally found in these chemical bonds. An acyl side side chain attached to the β-lactam ring. A variety of β-lactam antibiotics have been produced following chemical modification from the 6-APA structure during synthesis, specifically by making chemical substitutions in the acyl side chain. For example, the first chemically altered penicillin, methicillin, had substitutions by methoxy groups at positions 2’ and 6’ of the 6-APA benzene ring from penicillin G. This difference makes methicillin resistant to the activity of β-lactamase, an enzyme by which many bacteria are naturally unsusceptible to penicillins. 12.6.7 Mechanism Of Action Of Penicillin Penicillin can easily enter bacterial cell in case of Gram-positive species. This is because Gram-positive bacteria do not have an outer cell membrane and are simply enclosed in a thick cell wall. Penicillin molecules are small enough to pass through the spaces of glycoproteins in the cell wall. For this reason Gram-positive bacteria are very susceptible to penicillin (as first evidenced by the discovery of penicillin in 1928). Penicillin, or any other molecule, enters Gram-negative bacteria in a different manner. The bacteria have thinner cell walls but the external surface is coated with an additional cell membrane, called the outer membrane. The outer membrane is a lipid layer (lipopolysaccharide chain) that blocks passage of water-soluble (hydrophilic) molecules like penicillin. It thus acts as the first line of defence against any toxic substance, which is the reason for relative resistance to antibiotics compared to Gram-positive species But penicillin can still enter Gram-negative species by diffusing through aqueous channels called porins (outer membrane proteins), which are dispersed among the fatty molecules and can transport nutrients and antibiotics into the bacteria. Porins are large enough to allow diffusion of most penicillins, but the rate of diffusion through them is determined by the specific size of the drug molecules. For instance, penicillin G is large and enters through porins slowly; while smaller ampicillin and amoxicillin diffuse much faster. In contrast, large vancomycin can not pass through porins and is thus ineffective for Gram-negative bacteria. The size and number of porins are different in different bacteria. As a result of the two factors—size of penicillin and porin—Gram-negative bacteria can be unsusceptible or have varying degree of susceptibility to specific penicillin. The chemical structure of penicillin is triggered with a very precise, pH-dependent directed mechanism, affected by a unique spatial assembly of molecular components, which can activate by protonation. It can travel through bodily fluids, targeting and inactivating enzymes responsible for cell-wall synthesis in gram-positive bacteria, meanwhile avoiding the surrounding non-targets. Penicillin can protect itself from spontaneous hydrolysis in the body in its anionic form while storing its potential as a strong acylating agent, activated only upon approach to the target transpeptidase enzyme and protonated in the active centre. This targeted protonation neutralizes the carboxylic acid moiety, which is weakening of the β-lactam ring N–C(=O) bond, resulting in a self-activation. Specific structural requirements are equated to constructing the perfect mousetrap for catching targeted prey. Penicillin kills bacteria by inhibiting the completion of the synthesis of peptidoglycans, the structural component of bacterial cell wall. It specifically inhibits the activity of enzymes that are needed for the cross-linking of peptidoglycans during the final step in cell wall biosynthesis. It does this by binding to penicillin binding proteins with the β-lactam ring, a structure found on penicillin molecules. This causes the cell wall to weaken due to fewer cross-links and means water uncontrollably flows into the cell because it cannot maintain the correct osmotic gradient. This results in cell lysis and death. Bacteria constantly remodel their peptidoglycan cell walls, simultaneously building and breaking down portions of the cell wall as they grow and divide. During the last stages of peptidoglycan biosynthesis, uridine diphosphate-N-acetylmuramic acid pentapeptide (UDP-MurNAc) is formed in which the fourth and fifth amino acids are both D-alanyl-D-alanine. The transfer of D-alanine is done (catalysed) by the enzyme DD-transpeptidase (penicillin-binding proteins are such type). The structural integrity of bacterial cell wall depends on the cross linking of UDP-MurNAc and N-acetyl glucosamine. Penicillin and other β-lactam antibiotics act as an analogue of D-alanine-D-alanine (the dipeptide) in UDP-MurNAc owing to conformational similarities. The DD-transpeptidase then binds the four-membered β-lactam ring of penicillin in stead of UDP-MurNAc. As a consequence, DD-transpeptidase is inactivated, the formation of cross-links between UDP-MurNAc and N-acetyl glucosamine is blocked so that an imbalance between cell wall production and degradation develops, causing the cell to rapidly die. The enzymes that hydrolyze the peptidoglycan cross-links continue to function, even while those that form such cross-links do not. This weakens the cell wall of the bacterium, and osmotic pressure becomes increasingly uncompensated—eventually causing cell death (cytolysis). In addition, the build-up of peptidoglycan precursors triggers the activation of bacterial cell wall hydrolases and autolysins, which further digest the cell wall’s peptidoglycans. The small size of the penicillins increases their potency, by allowing them to penetrate the entire depth of the cell wall. This is in contrast to the glycopeptide antibiotics vancomycin and teicoplanin, which are both much larger than the penicillins. Gram-positive bacteria are called protoplasts when they lose their cell walls. Gram-negative bacteria do not lose their cell walls completely and are called spheroplasts after treatment with penicillin. Penicillin shows a synergistic effect with aminoglycosides, since the inhibition of peptidoglycan synthesis allows aminoglycosides to penetrate the bacterial cell wall more easily, allowing their disruption of bacterial protein synthesis within the cell. This results in a lowered MBC for susceptible organisms. Penicillins, like other β-lactam antibiotics, block not only the division of bacteria, including cyanobacteria, but also the division of cyanelles, the photosynthetic organelles of the glaucophytes, and the division of chloroplasts of bryophytes. In contrast, they have no effect on the plastids of the highly developed vascular plants. This supports the endosymbiotic theory of the evolution of plastid division in land plants. Some bacteria produce enzymes that break down the β-lactam ring, called β-lactamases, which make the bacteria resistant to penicillin. Therefore, some penicillins are modified or given with other drugs for use against antibiotic-resistant bacteria or in immunocompromised patients. The use of clavulanic acid or tazobactam, β-lactamase inhibitors, alongside penicillin gives penicillin activity against β-lactamase-producing bacteria. β-Lactamase inhibitors irreversibly bind to β-lactamase preventing it from breaking down the beta-lactam rings on the antibiotic molecule. Alternatively, flucloxacillin is a modified penicillin that has activity against β-lactamase-producing bacteria due to an acyl side chain that protects the beta-lactam ring from β-lactamase. Penicillin has low protein binding in plasma. The bioavailability of penicillin depends on the type: penicillin G has low bioavailability, below 30%, whereas penicillin V has higher bioavailability, between 60 and 70%.[citation needed] Penicillin has a short half-life and is excreted via the kidneys. This means it must be dosed at least four times a day to maintain adequate levels of penicillin in the blood. Early manuals on the use of penicillin, therefore, recommended injections of penicillin as frequently as every three hours, and dosing penicillin has been described as being similar to trying to fill a bath with the plug out. This is no longer required since much larger doses of penicillin are cheaply and easily available; however, some authorities recommend the use of continuous penicillin infusions for this reason. In 1895 Vincenzo Tiberio, Italian physician, published a paper on the antibacterial power of some extracts of mold. In 1897, doctoral student Ernest Duchesne submitted a dissertation, “Contribution à l’étude de la concurrence vitale chez les micro-organismes: antagonisme entre les moisissures et les microbes” (Contribution to the study of vital competition in micro-organisms: antagonism between molds and microbes), the first known scholarly work to consider the therapeutic capabilities of molds resulting from their anti-microbial activity. In his thesis, Duchesne proposed that bacteria and molds engage in a perpetual battle for survival. Duchesne observed that E. coli was eliminated by Penicillium glaucum when they were both grown in the same culture. He also observed that when he inoculated laboratory animals with lethal doses of typhoid bacilli together with Penicillium glaucum, the animals did not contract typhoid. Unfortunately Duchesne’s army service after getting his degree prevented him from doing any further research. Duchesne died of tuberculosis, a disease now treated by antibiotics.In 1928, Sir Alexander Fleming postulated the existence of penicillin, a molecule produced by certain molds that kills or stops the growth of certain kinds of bacteria. Fleming was working on a culture of disease-causing bacteria when he noticed the spores of a green mold, Penicillium chrysogenum, in one of his culture plates. He observed that the presence of the mold killed or prevented the growth of the bacteria. Fleming postulated that the mold must secrete an antibacterial substance, which he named penicillin in 1928. Fleming believed that its antibacterial properties could be exploited for chemotherapy. He initially characterized some of its biological properties, and attempted to use a crude preparation to treat some infections, but he was unable to pursue its further development without the aid of trained chemists. Ernst Chain, Howard Florey and Edward Abraham succeeded in purifying the first penicillin, penicillin G, in 1942, but it did not become widely available outside the Allied military before 1945. Later, Norman Heatley developed the back extraction technique for efficiently purifying penicillin in bulk. The chemical structure of penicillin was first proposed by Abraham in 1942 and then later confirmed by Dorothy Crowfoot Hodgkin in 1945. Purified penicillin displayed potent antibacterial activity against a wide range of bacteria and had low toxicity in humans. Furthermore, its activity was not inhibited by biological constituents such as pus, unlike the synthetic sulfonamides. (see below) The development of penicillin led to renewed interest in the search for antibiotic compounds with similar efficacy and safety. For their successful development of penicillin, which Fleming had accidentally discovered but could not develop himself, as a therapeutic drug, Chain and Florey shared the 1945 Nobel Prize in Medicine with Fleming. Florey credited Rene Dubos with pioneering the approach of deliberately and systematically searching for antibacterial compounds, which had led to the discovery of gramicidin and had revived Florey’s research in penicillin. In 1939, coinciding with the start of World War II, Dubos had reported the discovery of the first naturally derived antibiotic, tyrothricin, a compound of 20% gramicidin and 80% tyrocidine, from Bacillus brevis. It was one of the first commercially manufactured antibiotics and was very effective in treating wounds and ulcers during World War II. Gramicidin, however, could not be used systemically because of toxicity. Tyrocidine also proved too toxic for systemic usage. Research results obtained during that period were not shared between the Axis and the Allied powers during World War II and limited access during the Cold War. During the mid-20th century, the number of new antibiotic substances introduced for medical use increased significantly. From 1935 to 1968, 12 new classes were launched. However, after this, the number of new classes dropped markedly, with only two new classes introduced between 1969 and 2003. Both the WHO and the Infectious Disease Society of America report that the weak antibiotic pipeline does not match bacteria’s increasing ability to develop resistance. The Infectious Disease Society of America report noted that the number of new antibiotics approved for marketing per year had been declining and identified seven antibiotics against the Gram-negative bacilli currently in phase 2 or phase 3 clinical trials. However, these drugs did not address the entire spectrum of resistance of Gram-negative bacilli. According to the WHO fifty one new therapeutic entities - antibiotics (including combinations), are in phase 1-3 clinical trials as of May 2017. Antibiotics targeting multidrug-resistant Gram-positive pathogens remains a high priority. A few antibiotics have received marketing authorization in the last seven years. The cephalosporin ceftaroline and the lipoglycopeptides oritavancin and telavancin for the treatment of acute bacterial skin and skin structure infection and community-acquired bacterial pneumonia. The lipoglycopeptide dalbavancin and the oxazolidinone tedizolid has also been approved for use for the treatment of acute bacterial skin and skin structure infection. The first in a new class of narrow spectrum macrocyclic antibiotics, fidaxomicin, has been approved for the treatment of C. difficile colitis. New cephalosporin-lactamase inhibitor combinations also approved include ceftazidime-avibactam and ceftolozane-avibactam for complicated urinary tract infection and intra-abdominal infection. Ceftolozane/tazobactam (CXA-201; CXA-101/tazobactam): Antipseudomonal cephalosporin/β-lactamase inhibitor combination (cell wall synthesis inhibitor). FDA approved on 19 December 2014. Ceftazidime/avibactam (ceftazidime/NXL104): antipseudomonal cephalosporin/β-lactamase inhibitor combination (cell wall synthesis inhibitor). FDA approved on 25 February 2015. Ceftaroline/avibactam (CPT-avibactam; ceftaroline/NXL104): Anti-MRSA cephalosporin/ β-lactamase inhibitor combination (cell wall synthesis inhibitor). Cefiderocol: cephalosporin siderophore. FDA approved on 14 November 2019. Imipenem/relebactam: carbapenem/ β-lactamase inhibitor combination (cell wall synthesis inhibitor). FDA approved on 16 July 2019. Meropenem/vaborbactam: carbapenem/ β-lactamase inhibitor combination (cell wall synthesis inhibitor). FDA approved on 29 August 2017. Delafloxacin: quinolone (inhibitor of DNA synthesis). FDA approved on 19 June 2017. Plazomicin (ACHN-490): semi-synthetic aminoglycoside derivative (protein synthesis inhibitor). FDA approved 25 June 2018. Eravacycline (TP-434): synthetic tetracycline derivative (protein synthesis inhibitor targeting bacterial ribosomes). FDA approved on 27 August 2018. Omadacycline: semi-synthetic tetracycline derivative (protein synthesis inhibitor targeting bacterial ribosomes). FDA approved on 2 October 2018. Lefamulin: pleuromutilin antibiotic. FDA approved on 19 August 2019. Brilacidin (PMX-30063): peptide defense protein mimetic (cell membrane disruption). In phase 2. Possible improvements include clarification of clinical trial regulations by FDA. Furthermore, appropriate economic incentives could persuade pharmaceutical companies to invest in this endeavor. In the US, the Antibiotic Development to Advance Patient Treatment (ADAPT) Act was introduced with the aim of fast tracking the drug development of antibiotics to combat the growing threat of ‘superbugs’. Under this Act, FDA can approve antibiotics and antifungals treating life-threatening infections based on smaller clinical trials. The CDC will monitor the use of antibiotics and the emerging resistance, and publish the data. The FDA antibiotics labeling process, ‘Susceptibility Test Interpretive Criteria for Microbial Organisms’ or ‘breakpoints’, will provide accurate data to healthcare professionals. According to Allan Coukell, senior director for health programs at The Pew Charitable Trusts, “By allowing drug developers to rely on smaller datasets, and clarifying FDA’s authority to tolerate a higher level of uncertainty for these drugs when making a risk/benefit calculation, ADAPT would make the clinical trials more feasible.” 12.6.8 Aminoglycoside Antibiotics Aminoglycoside is a medicinal and bacteriologic category of traditional Gram-negative antibacterial medications that inhibit protein synthesis and contain as a portion of the molecule an amino-modified glycoside (sugar). The term can also refer more generally to any organic molecule that contains amino sugar substructures. Aminoglycoside antibiotics display bactericidal activity against Gram-negative aerobes and some anaerobic bacilli where resistance has not yet arisen but generally not against Gram-positive and anaerobic Gram-negative bacteria. Streptomycin is the first-in-class aminoglycoside antibiotic. It is derived from Streptomyces griseus and is the earliest modern agent used against tuberculosis. Streptomycin lacks the common 2-deoxystreptamine moiety (image right, below) present in most other members of this class. Other examples of aminoglycosides include the deoxystreptamine-containing agents kanamycin, tobramycin, gentamicin, and neomycin 12.6.9 Mechanism Of Action Of Amimoglycoside Antibiotics Aminoglycosides display concentration-dependent bactericidal activity against “most gram-negative aerobic and facultative anaerobic bacilli” but not against gram-negative anaerobes and most gram-positive bacteria. They require only short contact time, and are most effective against susceptible bacterial populations that are rapidly multiplying. These activities are attributed to a primary mode of action as protein synthesis inhibitors, though additional mechanisms are implicated for some specific agents, and/or thorough mechanistic descriptions are as yet unavailable. The inhibition of protein synthesis is mediated through aminoglycosides’ energy-dependent, sometimes irreversible binding, to the cytosolic, membrane-associated bacterial ribosome (image at right). (Aminoglycosides first cross bacterial cell walls—lipopolysaccharide in gram-negative bacteria—and cell membranes, where they are actively transported.) While specific steps in protein synthesis affected may vary somewhat between specific aminoglycoside agents, as can their affinity and degree of binding, aminoglycoside presence in the cytosol generally disturbs peptide elongation at the 30S ribosomal subunit, giving rise to inaccurate mRNA translation and therefore biosynthesis of proteins that are truncated, or bear altered amino acid compositions at particular points. Specifically, binding impairs translational proofreading leading to misreading of the RNA message, premature termination, or both, and so to inaccuracy of the translated protein product. The subset of aberrant proteins that are incorporated into the bacterial cell membrane may then lead to changes in its permeability and then to “further stimulation of aminoglycoside transport”. Recent single-molecule tracking experiments in live E. coli showed an ongoing but slower protein synthesis upon treatment with different aminoglycoside drugs. Finally, a further “cell-membrane effect” also occurs with aminoglycosides; “functional integrity of the bacterial cell membrane” can be lost, later in time courses of aminoglycoside exposure and transport. Aminoglycosides are useful primarily in infections involving aerobic, Gram-negative bacteria, such as Pseudomonas, Acinetobacter, and Enterobacter. Aminoglycosides are mostly ineffective against anaerobic bacteria, fungi, and viruses. Aminoglycoside can cause inner ear toxicity which can result in sensorineural hearing loss. The incidence of inner ear toxicity varies from 7 to 90%, depending on the types of antibiotics used, susceptibility of the patient to such antibiotics, and the duration of antibiotic administration. 12.7 Drug Resistance Drug resistance is the reduction in effectiveness of a medication such as an antimicrobial or an antineoplastic in treating a disease or condition.[1] The term is used in the context of resistance that pathogens or cancers have “acquired”, that is, resistance has evolved. Antimicrobial resistance and antineoplastic resistance challenge clinical care and drive research. When an organism is resistant to more than one drug, it is said to be multidrug-resistant. The development of antibiotic resistance in particular stems from the drugs targeting only specific bacterial molecules (almost always proteins). Because the drug is so specific, any mutation in these molecules will interfere with or negate its destructive effect, resulting in antibiotic resistance.[2] Furthermore, there is mounting concern over the abuse of antibiotics in the farming of livestock, which in the European Union alone accounts for three times the volume dispensed to humans – leading to development of super-resistant bacteria.[3][4] Bacteria are capable of not only altering the enzyme targeted by antibiotics, but also by the use of enzymes to modify the antibiotic itself and thus neutralize it. Examples of target-altering pathogens are Staphylococcus aureus, vancomycin-resistant enterococci and macrolide-resistant Streptococcus, while examples of antibiotic-modifying microbes are Pseudomonas aeruginosa and aminoglycoside-resistant Acinetobacter baumannii.[5] In short, the lack of concerted effort by governments and the pharmaceutical industry, together with the innate capacity of microbes to develop resistance at a rate that outpaces development of new drugs, suggests that existing strategies for developing viable, long-term anti-microbial therapies are ultimately doomed to failure. Without alternative strategies, the acquisition of drug resistance by pathogenic microorganisms looms as possibly one of the most significant public health threats facing humanity in the 21st century.[6] Some of the best alternative sources to reduce the chance of antibiotic resistance are probiotics, prebiotics, dietary fibers, enzymes, organic acids, phytogenics. Drug, toxin, or chemical resistance is a consequence of evolution and is a response to pressures imposed on any living organism. Individual organisms vary in their sensitivity to the drug used and some with greater fitness may be capable of surviving drug treatment. Drug-resistant traits are accordingly inherited by subsequent offspring, resulting in a population that is more drug-resistant. Unless the drug used makes sexual reproduction or cell-division or horizontal gene transfer impossible in the entire target population, resistance to the drug will inevitably follow. This can be seen in cancerous tumors where some cells may develop resistance to the drugs used in chemotherapy.[9] Chemotherapy causes fibroblasts near tumors to produce large amounts of the protein WNT16B. This protein stimulates the growth of cancer cells which are drug-resistant.[10] MicroRNAs have also been shown to affect acquired drug resistance in cancer cells and this can be used for therapeutic purposes.[11] Malaria in 2012 has become a resurgent threat in South East Asia and sub-Saharan Africa, and drug-resistant strains of Plasmodium falciparum are posing massive problems for health authorities.[12][13] Leprosy has shown an increasing resistance to dapsone. A rapid process of sharing resistance exists among single-celled organisms, and is termed horizontal gene transfer in which there is a direct exchange of genes, particularly in the biofilm state.[14] A similar asexual method is used by fungi and is called “parasexuality”. Examples of drug-resistant strains are to be found in microorganisms[15] such as bacteria and viruses, parasites both endo- and ecto-, plants, fungi, arthropods,[16][17] mammals,[18] birds,[19] reptiles,[20] fish, and amphibians.[20] In the domestic environment, drug-resistant strains of organism may arise from seemingly safe activities such as the use of bleach,[21] tooth-brushing and mouthwashing,[22] the use of antibiotics, disinfectants and detergents, shampoos, and soaps, particularly antibacterial soaps,[23][24] hand-washing,[25] surface sprays, application of deodorants, sunblocks and any cosmetic or health-care product, insecticides, and dips.[26] The chemicals contained in these preparations, besides harming beneficial organisms, may intentionally or inadvertently target organisms that have the potential to develop resistance.[27] The four main mechanisms by which microorganisms exhibit resistance to antimicrobials are:[28][29] Drug inactivation or modification: e.g., enzymatic deactivation of Penicillin G in some penicillin-resistant bacteria through the production of β-lactamases. Alteration of target site: e.g., alteration of PBP — the binding target site of penicillins — in MRSA and other penicillin-resistant bacteria. Alteration of metabolic pathway: e.g., some sulfonamide-resistant bacteria do not require para-aminobenzoic acid (PABA), an important precursor for the synthesis of folic acid and nucleic acids in bacteria inhibited by sulfonamides. Instead, like mammalian cells, they turn to utilizing preformed folic acid. Reduced drug accumulation: by decreasing drug permeability and/or increasing active efflux (pumping out) of the drugs across the cell surface. Table 12.3: The three essential polymeric macromolecules of life Mechanism Antimicrobial Agent Drug Action Mechanism of Resistance Destroy drug Aminoglycoside Beta-lactam antibiotics (penicillin and cephalosporin) Chloramphenicol Binds to 30S Ribosome subunit, inhibiting protein synthesis Binds to penicillin-binding proteins, Inhibiting peptidoglycan synthesis Bind to 50S ribosome subunit, inhibiting formation of peptide bonds Plasmid encode enzymes that chemically alter the drug (e.g., by acetylation or phosphorylation), thereby inactivating it. Plasmid encode beta-lactamase, which open the beta-lactam ring, inactivating it. Plasmid encode an enzyme that acetylate the drug, thereby inactivating it. Alters drug target Aminoglycosides Beta-lactam antibiotics (penicillin and cephalosporin) Erythromycin Quinolones Rifampin Trimethoprim Binds to 30S Ribosome subunit, inhibiting protein synthesis Binds to penicillin-binding proteins, Inhibiting peptidoglycan synthesis Bind to 50S ribosome subunit, inhibiting protein synthesis Binds to DNA topoisomerase, an enzyme essential for DNA synthesis Binds to the RNA polymerase; inhibiting initiation of RNA synthesis Inhibit the enzyme dihydrofolate reduces, blocking the folic acid pathway Bacteria make an altered 30S ribosomes that does not bind to the drug. Bacteria make an altered penicillin-binding proteins, that do not bind to the drug. Bacteria make a form of 50S ribosome that does not binds to the drug. Bacteria make an altered DNA topoisomerase that does not binds to the drug. Bacteria make an altered polymerase that does not binds to the drug. Bacteria make an altered enzyme that does not binds to the drug. Inhibits drug entry or removes drug Penicillin Erythromycin Tetracycline Binds to penicillin-binding proteins, Inhibiting peptidoglycan synthesis Bind to 50S ribosome subunit, inhibiting protein synthesis Binds to 30S Ribosome subunit, inhibiting protein synthesis by blocking tRNA Bacteria change shape of the outer membrane porin proteins, preventing drug from entering cell. New membrane transport system prevent drug from entering cell. New membrane transport system pumps drug out of cell. 12.7.1 Bacterial Resistence To Penicillin When Alexander Fleming discovered the crude penicillin in 1928, one important observation he made was that many bacteria were not affected by penicillin. This phenomenon was realised by Ernst Chain and Edward Abraham while trying to identify the exact of penicillin. In 1940, they discovered that unsusceptible bacteria like Escherichia coli produced specific enzymes that can break down penicillin molecules, thus making them resistant to the antibiotic. They named the enzyme penicillinase. Penicillinase is now classified as member of enzymes called β-lactamases. These β-lactamases are naturally present in many other bacteria, and many bacteria produce them upon constant exposure to antibiotics. In most bacteria, resistance can be through three different mechanisms: reduced permeability in bacteria reduced binding affinity of the penicillin-binding proteins (PBPs) or destruction of the antibiotic through the expression of β-lactamase. Using any of these, bacteria commonly develop resistance to different antibiotics, a phenomenon called multi-drug resistance. The actual process of resistance mechanism can be very complex. In case of reduced permeability in bacteria, the mechanisms are different between Gram-positive and Gram-negative bacteria. In Gram-positive bacteria, blockage of penicillin is due to changes in the cell wall. For example, resistance to vancomycin in S. aureus is due to additional peptidoglycan synthesis that makes the cell wall much thicker preventing effective penicillin entry. Resistance in Gram-negative bacteria is due to mutational variations in the structure and number of porins. In bacteria like Pseudomonas aeruginosa, there is reduced number of porins; whereas in bacteria like Enterobacter species, Escherichia coli and Klebsiella pneumoniae, there are modified porins such as non-specific porins (such as OmpC and OmpF groups) that cannot transport penicillin. Resistance due to PBP alterations is highly varied. A common case is found in Streptococcus pneumoniae where there is mutation in the gene for PBP, and the mutant PBPs have decreased binding affinity for penicillins. There are six mutant PBPs in S. pneumoniae, of which PBP1a, PBP2b, PBP2x and sometimes PBP2a are responsible for reduced binding affinity. S. aureus can activate a hidden gene that produces a different PBP, PBD2, which has low binding affinity for penicillins. There is a different strain of S. aureus named methicillin-resistant S. aureus (MRSA) which is resistant not only to penicllin and other β-lactams, but also to most antibiotics. The bacterial strain developed after introduction of methicillin in 1959. In MRSA, mutations in the genes (mec system) for PBP produce a variant protein called PBP2a (also termed PBP2’), while making four normal PBPs. PBP2a has poor binding affinity for penicillin and also lacks glycosyltransferase activity required for complete peptidoglycan synthesis (which is carried out by the four normal PBPs). In Helicobacter cinaedi, there are multiple mutations in different genes that make PBP variants. Enzymatic destruction by β-lactamases is the most important mechanism of penicillin resistance, and is described as “the greatest threat to the usage [of penicillins]”. It was the first discovered mechanism of penicillin resistance. During the experiments when purification and biological activity tests of penicillin were performed in 1940, it was found that E. coli was unsusceptible. The reason was discovered as production of an enzyme penicillinase (hence, the first β-lactamase known) in E. coli that easily degraded penicillin. There are over 2,000 types of β-lactamases each of which has unique amino acid sequence, and thus, enzymatic activity. All of them are able to hydrolyse β-lactam rings but their exact target sites are different. They are secreted on the bacterial surface in large quantities in Gram-positive bacteria but less so in Gram-negative species. Therefore, in a mixed bacterial infection, the Gram-positive bacteria can protect the otherwise penicillin-susceptible Gram-negative cells. There are unusual mechanisms in P. aeruginosa, in which there can be biofilm-mediated resistance and formation of multidrug-tolerant persister cells. In 1874, physician Sir William Roberts noted that cultures of the mold Penicillium glaucum that is used in the making of some types of blue cheese did not display bacterial contamination. In 1876, physicist John Tyndall also contributed to this field. 12.8 Testing For Antibiotic Sensitivity Antibiotic sensitivity testing or antibiotic susceptibility testing is the measurement of the susceptibility of bacteria to antibiotics. It is used because bacteria may have resistance to some antibiotics. Sensitivity testing results can allow a clinician to change the choice of antibiotics from empiric therapy, which is when an antibiotic is selected based on clinical suspicion about the site of an infection and common causative bacteria, to directed therapy, in which the choice of antibiotic is based on knowledge of the organism and its sensitivities. Sensitivity testing usually occurs in a medical laboratory, and may be based on culture methods that expose bacteria to antibiotics, or genetic methods that test to see if bacteria have genes that confer resistance. Culture methods often involve measuring the diameter of areas without bacterial growth, called zones of inhibition, around paper discs containing antibiotics on agar culture dishes that have been evenly inoculated with bacteria. The minimum inhibitory concentration, which is the lowest concentration of the antibiotic that stops the growth of bacteria, can be estimated from the size of the zone of inhibition. Antibiotic susceptibility testing has occurred since the discovery of the beta-lactam antibiotic penicillin. Initial methods were phenotypic, and involved culture or dilution. The Etest, an antibiotic impregnated strip, has been available since the 1980s, and genetic methods such as polymerase chain reaction (PCR) testing have been available since the early 2000s. Research is ongoing into improving current methods by making them faster or more accurate, as well as developing new methods for testing, such as microfluidics. 12.8.1 The Disk Diffusion Test The disk diffusion test (also known as the agar diffusion test, Kirby–Bauer test, disc-diffusion antibiotic susceptibility test, disc-diffusion antibiotic sensitivity test and KB test) is a culture-based microbiology assay used in diagnostic and drug discovery laboratories. In diagnostic labs, the assay is used to determine the susceptibility of bacteria isolated from a patient’s infection to clinically approved antibiotics. This allows physicians to prescribe the most appropriate antibiotic treatment. In drug discovery labs, especially bioprospecting labs, the assay is used to screen biological material (e.g. plant extracts, bacterial fermentation broths) and drug candidates for antibacterial activity. When bioprospecting, the assay can be performed with paired strains of bacteria to achieve dereplication and provisionally identify antibacterial mechanism of action. In diagnostic laboratories, the test is performed by inoculating the surface of an agar plate with bacteria isolated from a patient’s infection. Antibiotic-containing paper disks are then applied to the agar and the plate is incubated. If an antibiotic stops the bacteria from growing or kills the bacteria, there will be an area around the disk where the bacteria have not grown enough to be visible. This is called a zone of inhibition. The susceptibility of the bacterial isolate to each antibiotic can then be semi-quantified by comparing the size of these zones of inhibition to databases of information on known antibiotic-susceptible, moderately susceptible and resistant bacteria. In this way, it is possible to identify the most appropriate antibiotic for treating a patient’s infection. Although the disk diffusion test cannot be used to differentiate bacteriostatic and bactericidal activity, it is less cumbersome than other susceptibility test methods such as broth dilution. In drug discovery labs, the disk diffusion test is performed slightly differently than in diagnostic labs. In this setting, it is not the bacterial strain that must be characterized, but a test extract (e.g. a plant or microbial extract). The agar plate is therefore inoculated with a bacterial strain of known phenotype (often an ATCC or NCTC strain), and disks containing the test extract are applied to the surface. Zone of inhibition sizes cannot be used as a semi-quantitative measure of antibacterial potency because different extracts contain molecules with different diffusion characteristics (different molecular sizes, hydrophilicities etc.). Zone of inhibition sizes can be used for the purpose of dereplication though. This is achieved by testing each extract against paired strains of bacteria (e.g. streptomycin-susceptible and -resistant strains to identify streptomycin-containing extracts). Paired strains (e.g. wild type and target overexpressing strains) can also be used to identify antibacterial mechanism of action. 12.9 Replenishing The Antibiotic Pipeline And Developing Other New Therapies Because antibiotic-resistant bacterial strains continue to emerge and spread, there is a constant need to develop new antibacterial treatments. Current strategies include traditional chemistry-based approaches such as natural product-based drug discovery, newer chemistry-based approaches such as drug design, traditional biology-based approaches such as immunoglobulin therapy, and experimental biology-based approaches such as phage therapy, fecal microbiota transplants, antisense RNA-based treatments, and CRISPR-Cas9-based treatments. 12.9.1 Natural Product-Based Antibiotic Discovery Most of the antibiotics in current use are natural products or natural product derivatives, and bacterial, fungal, plant and animal extracts are being screened in the search for new antibiotics. Organisms may be selected for testing based on ecological, ethnomedical, genomic or historical rationales. Medicinal plants, for example, are screened on the basis that they are used by traditional healers to prevent or cure infection and may therefore contain antibacterial compounds. Also, soil bacteria are screened on the basis that, historically, they have been a very rich source of antibiotics (with 70 to 80% of antibiotics in current use derived from the actinomycetes). In addition to screening natural products for direct antibacterial activity, they are sometimes screened for the ability to suppress antibiotic resistance and antibiotic tolerance. For example, some secondary metabolites inhibit drug efflux pumps, thereby increasing the concentration of antibiotic able to reach its cellular target and decreasing bacterial resistance to the antibiotic. Natural products known to inhibit bacterial efflux pumps include the alkaloid lysergol, the carotenoids capsanthin and capsorubin, and the flavonoids rotenone and chrysin. Other natural products, this time primary metabolites rather than secondary metabolites, have been shown to eradicate antibiotic tolerance. For example, glucose, mannitol, and fructose reduce antibiotic tolerance in Escherichia coli and Staphylococcus aureus, rendering them more susceptible to killing by aminoglycoside antibiotics. Natural products may be screened for the ability to suppress bacterial virulence factors too. Virulence factors are molecules, cellular structures and regulatory systems that enable bacteria to evade the body’s immune defenses (e.g. urease, staphyloxanthin), move towards, attach to, and/or invade human cells (e.g. type IV pili, adhesins, internalins), coordinate the activation of virulence genes (e.g. quorum sensing), and cause disease (e.g. exotoxins). Examples of natural products with antivirulence activity include the flavonoid epigallocatechin gallate (which inhibits listeriolysin O), the quinone tetrangomycin (which inhibits staphyloxanthin), and the sesquiterpene zerumbone (which inhibits Acinetobacter baumannii motility). 12.9.2 Immunoglobulin Therapy Antibodies (anti-tetanus immunoglobulin) have been used in the treatment and prevention of tetanus since the 1910s, and this approach continues to be a useful way of controlling bacterial disease. The monoclonal antibody bezlotoxumab, for example, has been approved by the US FDA and EMA for recurrent Clostridium difficile infection, and other monoclonal antibodies are in development (e.g. AR-301 for the adjunctive treatment of S. aureus ventilator-associated pneumonia). Antibody treatments act by binding to and neutralizing bacterial exotoxins and other virulence factors. 12.9.3 Phage Therapy Phage therapy is under investigation as a method of treating antibiotic-resistant strains of bacteria. Phage therapy involves infecting bacterial pathogens with viruses. Bacteriophages and their host ranges are extremely specific for certain bacteria, thus, unlike antibiotics, they do not disturb the host organism’s intestinal microbiota. Bacteriophages, also known simply as phages, infect and kill bacteria primarily during lytic cycles. Phages insert their DNA into the bacterium, where it is transcribed and used to make new phages, after which the cell will lyse, releasing new phage that are able to infect and destroy further bacteria of the same strain. The high specificity of phage protects “good” bacteria from destruction. Some disadvantages to the use of bacteriophages also exist, however. Bacteriophages may harbour virulence factors or toxic genes in their genomes and, prior to use, it may be prudent to identify genes with similarity to known virulence factors or toxins by genomic sequencing. In addition, the oral and IV administration of phages for the eradication of bacterial infections poses a much higher safety risk than topical application. Also, there is the additional concern of uncertain immune responses to these large antigenic cocktails. There are considerable regulatory hurdles that must be cleared for such therapies. Despite numerous challenges, the use of bacteriophages as a replacement for antimicrobial agents against MDR pathogens that no longer respond to conventional antibiotics, remains an attractive option. 12.9.4 Fecal Microbiota Transplants ￼ Fecal microbiota transplants are an experimental treatment for C. difficile infection. Fecal microbiota transplants involve transferring the full intestinal microbiota from a healthy human donor (in the form of stool) to patients with C. difficile infection. Although this procedure has not been officially approved by the US FDA, its use is permitted under some conditions in patients with antibiotic-resistant C. difficile infection. Cure rates are around 90%, and work is underway to develop stool banks, standardized products, and methods of oral delivery. 12.9.5 Antisense RNA-Based Treatments Antisense RNA-based treatment (also known as gene silencing therapy) involves (a) identifying bacterial genes that encode essential proteins (e.g. the Pseudomonas aeruginosa genes acpP, lpxC, and rpsJ), (b) synthesizing single stranded RNA that is complementary to the mRNA encoding these essential proteins, and (c) delivering the single stranded RNA to the infection site using cell-penetrating peptides or liposomes. The antisense RNA then hybridizes with the bacterial mRNA and blocks its translation into the essential protein. Antisense RNA-based treatment has been shown to be effective in in vivo models of P. aeruginosa pneumonia. In addition to silencing essential bacterial genes, antisense RNA can be used to silence bacterial genes responsible for antibiotic resistance. For example, antisense RNA has been developed that silences the S. aureus mecA gene (the gene that encodes modified penicillin-binding protein 2a and renders S. aureus strains methicillin-resistant). Antisense RNA targeting mecA mRNA has been shown to restore the susceptibility of methicillin-resistant staphylococci to oxacillin in both in vitro and in vivo studies. 12.9.6 CRISPR-Cas9-Based Treatments In the early 2000s, a system was discovered that enables bacteria to defend themselves against invading viruses. The system, known as CRISPR-Cas9, consists of (a) an enzyme that destroys DNA (the nuclease Cas9) and (b) the DNA sequences of previously encountered viral invaders (CRISPR). These viral DNA sequences enable the nuclease to target foreign (viral) rather than self (bacterial) DNA. Although the function of CRISPR-Cas9 in nature is to protect bacteria, the DNA sequences in the CRISPR component of the system can be modified so that the Cas9 nuclease targets bacterial resistance genes or bacterial virulence genes instead of viral genes. The modified CRISPR-Cas9 system can then be administered to bacterial pathogens using plasmids or bacteriophages. This approach has successfully been used to silence antibiotic resistance and reduce the virulence of enterohemorrhagic E. coli in an in vivo model of infection. In addition to developing new antibacterial treatments, it is important to reduce the selection pressure for the emergence and spread of antibiotic resistance. Strategies to accomplish this include well-established infection control measures such as infrastructure improvement (e.g. less crowded housing), better sanitation (e.g. safe drinking water and food) and vaccine development, other approaches such as antibiotic stewardship, and experimental approaches such as the use of prebiotics and probiotics to prevent infection. "],["infection-and-disease.html", "13 Infection And Disease 13.1 Pathogenic Bacteria 13.2 Pathogenic Susceptibility 13.3 Infection 13.4 Disease 13.5 Epidemiology 13.6 Pandemics", " 13 Infection And Disease 13.1 Pathogenic Bacteria Pathogenic bacteria are bacteria that can cause disease. This chapter focuses on the bacteria that are pathogenic to humans. Most species of bacteria are harmless and are often beneficial but others can cause infectious diseases. The number of these pathogenic species in humans is estimated to be fewer than a hundred. By contrast, several thousand species are part of the gut flora present in the digestive tract. The body is continually exposed to many species of bacteria, including beneficial commensals, which grow on the skin and mucous membranes, and saprophytes, which grow mainly in the soil and in decaying matter. The blood and tissue fluids contain nutrients sufficient to sustain the growth of many bacteria. The body has defence mechanisms that enable it to resist microbial invasion of its tissues and give it a natural immunity or innate resistance against many microorganisms. Pathogenic bacteria are specially adapted and endowed with mechanisms for overcoming the normal body defences, and can invade parts of the body, such as the blood, where bacteria are not normally found. Some pathogens invade only the surface epithelium, skin or mucous membrane, but many travel more deeply, spreading through the tissues and disseminating by the lymphatic and blood streams. In some rare cases a pathogenic microbe can infect an entirely healthy person, but infection usually occurs only if the body’s defence mechanisms are damaged by some local trauma or an underlying debilitating disease, such as wounding, intoxication, chilling, fatigue, and malnutrition. In many cases, it is important to differentiate infection and colonization, which is when the bacteria are causing little or no harm. Caused by Mycobacterium tuberculosis bacteria, one of the diseases with the highest disease burden is tuberculosis, which killed 1.4 million people in 2019, mostly in sub-Saharan Africa. Pathogenic bacteria contribute to other globally important diseases, such as pneumonia, which can be caused by bacteria such as Streptococcus, Pneumococcus and Pseudomonas, and foodborne illnesses, which can be caused by bacteria such as Shigella, Campylobacter, and Salmonella. Pathogenic bacteria also cause infections such as tetanus, typhoid fever, diphtheria, syphilis, and leprosy. Pathogenic bacteria are also the cause of high infant mortality rates in developing countries. Most pathogenic bacteria can be grown in cultures and identifed by Gram stain and other methods. Bacteria grown in this way are often tested to find which antibiotics will be an effective treatment for the infection. For hitherto unknown pathogens, Koch’s postulates are the standard to establish a causative relationship between a microbe and a disease. Each species has specific effect and causes symptoms in people who are infected. Some people who are infected with a pathogenic bacteria do not have symptoms. Immunocompromised individuals are more susceptible to pathogenic bacteria. 13.2 Pathogenic Susceptibility Some pathogenic bacteria cause disease under certain conditions, such as entry through the skin via a cut, through sexual activity or through a compromised immune function. Some species of Streptococcus and Staphylococcus are part of the normal skin microbiota and typically reside on healthy skin or in the nasopharangeal region. Yet these species can potentially initiate skin infections. Streptoccal infections include sepsis, pneumonia, and meningitis. These infections can become serious creating a systemic inflammatory response resulting in massive vasodilation, shock, and death. Other bacteria are opportunistic pathogens and cause disease mainly in people suffering from immunosuppression or cystic fibrosis. Examples of these opportunistic pathogens include Pseudomonas aeruginosa, Burkholderia cenocepacia, and Mycobacterium avium. Obligate intracellular parasites (e.g. Chlamydophila, Ehrlichia, Rickettsia) have the ability to only grow and replicate inside other cells. Even these intracellular infections may be asymptomatic, requiring an incubation period. An example of this is Rickettsia which causes typhus. Another causes Rocky Mountain spotted fever. Chlamydia are intracellular parasites. These pathogens can cause pneumonia or urinary tract infection and may be involved in coronary heart disease. Other groups of intracellular bacterial pathogens include Salmonella, Neisseria, Brucella, Mycobacterium, Nocardia, Listeria, Francisella, Legionella, and Yersinia pestis. These can exist intracellularly, but can exist outside of host cells. Bacterial pathogens often cause infection in specific areas of the body. Others are generalists. Caused by Gardnerella vaginalis, bacterial vaginosis results from a change in the vaginal microbiota. Gardnerella and anaerobic bacteria displace the beneficial Lactobacilli species that maintain healthy vaginal microbial populations. Bacterial meningitis is a bacterial inflammation of the meninges, which are the protective membranes covering the brain and spinal cord. Bacterial pneumonia is a bacterial infection of the lungs. Urinary tract infection is predominantly caused by bacteria. Symptoms include the strong and frequent sensation or urge to urinate, pain during urination, and urine that is cloudy. The most frequent cause is Escherichia coli. Urine is typically sterile but contains a variety of salts, and waste products. Bacteria can ascend into the bladder or kidney and causing cystitis and nephritis. Bacterial gastroenteritis is caused by enteric, pathogenic bacteria. These pathogenic species are usually distinct from the usually harmless bacteria of the normal gut flora. But a different strain of the same species may be pathogenic. The distinction is sometimes difficult as in the case of Escherichia. Bacterial skin infections include: Impetigo is a highly contagious bacterial skin infection commonly seen in children. It is caused by Staphylococcus aureus, and Streptococcus pyogenes. Erysipelas is an acute streptococcus bacterial infection of the deeper skin layers that spreads via with lymphatic system. Cellulitis is a diffuse inflammation of connective tissue with severe inflammation of dermal and subcutaneous layers of the skin. Cellulitis can be caused by normal skin flora or by contagious contact, and usually occurs through open skin, cuts, blisters, cracks in the skin, insect bites, animal bites, burns, surgical wounds, intravenous drug injection, or sites of intravenous catheter insertion. In most cases it is the skin on the face or lower legs that is affected, though cellulitis can occur in other tissues. The symptoms of disease appear as pathogenic bacteria damage host tissues or interfere with their function. The bacteria can damage host cells directly or indirectly by provoking an immune response that inadvertently damages host cells, or by releasing toxins. Once pathogens attach to host cells, they can cause direct damage as the pathogens use the host cell for nutrients and produce waste products. For example, Streptococcus mutans, a component of dental plaque, metabolizes dietary sugar and produces acid as a waste product. The acid decalcifies the tooth surface to cause dental caries. Endotoxins are the lipid portions of lipopolysaccharides that are part of the outer membrane of the cell wall of gram-negative bacteria. Endotoxins are released when the bacteria lyses, which is why after antibiotic treatment, symptoms can worsen at first as the bacteria are killed and they release their endotoxins. Exotoxins are secreted into the surrounding medium or released when the bacteria die and the cell wall breaks apart. An excessive or inappropriate immune response triggered by an infection may damage host cells. Iron is required for humans, as well as the growth of most bacteria. To obtain free iron, some pathogens secrete proteins called siderophores, which take the iron away from iron-transport proteins by binding to the iron even more tightly. Once the iron-siderophore complex is formed, it is taken up by siderophore receptors on the bacterial surface and then that iron is brought into the bacterium. Typically identification is done by growing the organism in a wide range of cultures which can take up to 48 hours. The growth is then visually or genomically identified. The cultured organism is then subjected to various assays to observe reactions to help further identify species and strain. Bacterial infections may be treated with antibiotics, which are classified as bacteriocidal if they kill bacteria or bacteriostatic if they just prevent bacterial growth. There are many types of antibiotics and each class inhibits a process that is different in the pathogen from that found in the host. For example, the antibiotics chloramphenicol and tetracyclin inhibit the bacterial ribosome but not the structurally different eukaryotic ribosome, so they exhibit selective toxicity. Antibiotics are used both in treating human disease and in intensive farming to promote animal growth. Both uses may be contributing to the rapid development of antibiotic resistance in bacterial populations. Phage therapy, using bacteriophages can also be used to treat certain bacterial infections. Infections can be prevented by antiseptic measures such as sterilizing the skin prior to piercing it with the needle of a syringe and by proper care of indwelling catheters. Surgical and dental instruments are also sterilized to prevent infection by bacteria. Disinfectants such as bleach are used to kill bacteria or other pathogens on surfaces to prevent contamination and further reduce the risk of infection. Bacteria in food are killed by cooking to temperatures above 73 °C (163 °F). 13.2.1 List of genera and microscopy features Many genera contain pathogenic bacterial species. They often possess characteristics that help to classify and organize them into groups. The following is a partial listing. Table 13.1: The three essential polymeric macromolecules of life Genus Species Gram staining Shape Oxygen requirement Intra/Extracellular Bacillus[27] Bacillus anthracis Bacillus cereus Positive Rods Facultative anaerobic Extracellular Bartonella[27] Bartonella henselae Bartonella quintana Negative Rods Aerobic Facultative intracellular Bordetella[27] Bordetella pertussis[28][29] Negative Small coccobacilli Aerobic Extracellular Borrelia[27] Borrelia burgdorferi Borrelia garinii Borrelia afzelii Borrelia recurrentis Negative, stains poorly Spirochete Anaerobic Extracellular Brucella[27] Brucella abortus Brucella canis Brucella melitensis Brucella suis Negative Coccobacilli Aerobic Intracellular Campylobacter[27] Campylobacter jejuni Negative Spiral rods[30] coccoid in older cultures[30] Microaerophilic[30] Extracellular Chlamydia and Chlamydophila[27] Chlamydia pneumoniae Chlamydia trachomatis Chlamydophila psittaci (not Gram-stained) Small, round, ovoid Facultative or strictly aerobic Obligate intracellular Clostridium[27] Clostridium botulinum Clostridium difficile Clostridium perfringens Clostridium tetani Positive Large, blunt-ended rods Obligate anaerobic Extracellular Corynebacterium[27] Corynebacterium diphtheriae[29][31][32] Positive (unevenly) Rods Mostly facultative anaerobic Extracellular Enterococcus[29][33] Enterococcus faecalis Enterococcus faecium Positive Cocci Facultative Anaerobic Extracellular Escherichia[4][29][34] Escherichia coli Negative Rods Facultative anaerobic Extracellular or Intracellular Francisella[27] Francisella tularensis Negative Coccobacillus Strictly aerobic Facultative intracellular Haemophilus Haemophilus influenzae[29][35] Negative Coccobacilli to long and slender filaments Facultative anaerobic 5 - 10% CO2 Extracellular Helicobacter Helicobacter pylori[36] Negative Spiral rod Microaerophile Extracellular Legionella[27] Legionella pneumophila Negative, stains poorly Cocobacilli Aerobic Facultative intracellular Leptospira[29][37] Leptospira interrogans Leptospira santarosai Leptospira weilii Leptospira noguchii Negative, stains poorly Spirochete Strictly aerobic Extracellular Listeria[27] Listeria monocytogenes Positive, darkly Slender, short rods Facultative Anaerobic Facultative intracellular Mycobacterium[27] Mycobacterium leprae Mycobacterium tuberculosis Mycobacterium ulcerans (none) Long, slender rods Aerobic Intracellular Mycoplasma[27] Mycoplasma pneumoniae (none) Indistinct ‘fried egg’ appearance, no cell wall Mostly facultative anaerobic; M. pneumoniae strictly aerobic Extracellular Neisseria[29][38] Neisseria gonorrhoeae Neisseria meningitidis Negative Kidney bean-shaped Aerobic Gonococcus: facultative intracellularN. meningitidis: extracellular Pseudomonas[29][39] Pseudomonas aeruginosa Negative Rods Obligate aerobic Extracellular Rickettsia[27] Rickettsia rickettsii Negative, stains poorly Small, rod-like coccobacillary Aerobic Obligate intracellular Salmonella[27] Salmonella typhi Salmonella typhimurium Negative Rods Facultative anaerobica Facultative intracellular Shigella[29][40] Shigella sonnei Negative Rods Facultative anaerobic Extracellular Staphylococcus[4] Staphylococcus aureus Staphylococcus epidermidis Staphylococcus saprophyticus Positive, darkly Round cocci Facultative anaerobic Extracellular, facultative intracellular Streptococcus[27] Streptococcus agalactiae Streptococcus pneumoniae Streptococcus pyogenes Positive Ovoid to spherical Facultative anaerobic Extracellular Treponema[27] Treponema pallidum Negative, stains poorly Spirochete Aerobic Extracellular Ureaplasma[4] Ureaplasma urealyticum Stains poorly[41] Indistinct, ‘fried egg’ appearance, no cell wall Anaerobic Extracellular Vibrio[29][42] Vibrio cholerae Negative Spiral with single polar flagellum Facultative anaerobic Extracellular Yersinia[29][43] Yersinia pestis Yersinia enterocolitica Yersinia pseudotuberculosis Negative, bipolarly Small rods Facultative anaerobe Intracellular 13.3 Infection An infection is the invasion of an organism’s body tissues by disease-causing agents, their multiplication, and the reaction of host tissues to the infectious agents and the toxins they produce. An infectious disease, also known as a transmissible disease or communicable disease, is an illness resulting from an infection. Infections can be caused by a wide range of pathogens, most prominently bacteria and viruses. Hosts can fight infections using their immune system. Mammalian hosts react to infections with an innate response, often involving inflammation, followed by an adaptive response. Specific medications used to treat infections include antibiotics, antivirals, antifungals, antiprotozoals, and antihelminthics. Infectious diseases resulted in 9.2 million deaths in 2013 (about 17% of all deaths). The branch of medicine that focuses on infections is referred to as infectious disease. Infections are caused by infectious agents (pathogens) including: Bacteria (Mycobacterium tuberculosis, Staphylococcus aureus, Escherichia coli, Clostridium botulinum, and Salmonella spp.) Viruses and related agents such as viroids (HIV, Rhinovirus, Lyssaviruses such as Rabies virus, Ebolavirus and Severe acute respiratory syndrome coronavirus 2) Fungi, further subclassified into: Ascomycota, including yeasts such as Candida, filamentous fungi such as Aspergillus, Pneumocystis species, and dermatophytes, a group of organisms causing infection of skin and other superficial structures in humans. Basidiomycota, including the human-pathogenic genus Cryptococcus. Prions (although they don’t secrete toxins) Parasites, which are usually divided into: Unicellular organisms (e.g. malaria, Toxoplasma, Babesia) Macroparasites (worms or helminths) including nematodes such as parasitic roundworms and pinworms, tapeworms (cestodes), and flukes (trematodes, such as schistosomiasis) Arthropods such as ticks, mites, fleas, and lice, can also cause human disease, which conceptually are similar to infections, but invasion of a human or animal body by these macroparasites is usually termed infestation. (Diseases caused by helminths, which are also macroparasites, are sometimes termed infestations as well, but are sometimes called infections.) Symptomatic infections are apparent and clinical, whereas an infection that is active but does not produce noticeable symptoms may be called inapparent, silent, subclinical, or occult. An infection that is inactive or dormant is called a latent infection. An example of a latent bacterial infection is latent tuberculosis. Some viral infections can also be latent, examples of latent viral infections are any of those from the Herpesviridae family. The word infection can denote any presence of a particular pathogen at all (no matter how little) but also is often used in a sense implying a clinically apparent infection (in other words, a case of infectious disease). This fact occasionally creates some ambiguity or prompts some usage discussion; to get around this it is common for health professionals to speak of colonization (rather than infection) when they mean that some of the pathogens are present but that no clinically apparent infection (no disease) is present. Different terms are used to describe how and where infections present over time. In an acute infection, symptoms develop rapidly; its course can either be rapid or protracted. In chronic infection, symptoms usually develop gradually over weeks or months and are slow to resolve. In subacute infections, symptoms take longer to develop than in acute infections but arise more quickly than those of chronic infections. A focal infection is an initial site of infection from which organisms travel via the bloodstream to another area of the body. Among the many varieties of microorganisms, relatively few cause disease in otherwise healthy individuals. Infectious disease results from the interplay between those few pathogens and the defenses of the hosts they infect. The appearance and severity of disease resulting from any pathogen depend upon the ability of that pathogen to damage the host as well as the ability of the host to resist the pathogen. However, a host’s immune system can also cause damage to the host itself in an attempt to control the infection. Clinicians, therefore, classify infectious microorganisms or microbes according to the status of host defenses - either as primary pathogens or as opportunistic pathogens. Primary pathogens cause disease as a result of their presence or activity within the normal, healthy host, and their intrinsic virulence (the severity of the disease they cause) is, in part, a necessary consequence of their need to reproduce and spread. Many of the most common primary pathogens of humans only infect humans, however, many serious diseases are caused by organisms acquired from the environment or that infect non-human hosts. Opportunistic pathogens can cause an infectious disease in a host with depressed resistance (immunodeficiency) or if they have unusual access to the inside of the body (for example, via trauma). Opportunistic infection may be caused by microbes ordinarily in contact with the host, such as pathogenic bacteria or fungi in the gastrointestinal or the upper respiratory tract, and they may also result from (otherwise innocuous) microbes acquired from other hosts (as in Clostridium difficile colitis) or from the environment as a result of traumatic introduction (as in surgical wound infections or compound fractures). An opportunistic disease requires impairment of host defenses, which may occur as a result of genetic defects (such as Chronic granulomatous disease,exposure to antimicrobial drugs or immunosuppressive chemicals (as might occur following poisoning or cancer chemotherapy), exposure to ionizing radiation, or as a result of an infectious disease with immunosuppressive activity (such as with measles, malaria or HIV disease). Primary pathogens may also cause more severe disease in a host with depressed resistance than would normally occur in an immunosufficient host. Secondary infection While a primary infection can practically be viewed as the root cause of an individual’s current health problem, a secondary infection is a sequela or complication of that root cause. For example, an infection due to a burn or penetrating trauma (the root cause) is a secondary infection. Primary pathogens often cause primary infection and often cause secondary infection. Usually, opportunistic infections are viewed as secondary infections (because immunodeficiency or injury was the predisposing factor). Other types of infection consist of mixed, iatrogenic, nosocomial, and community-acquired infection. A mixed infection is an infection that is caused by two or more pathogens. An example of this is Appendicitis, which is caused by Bacteroides fragilis and Escherichia coli. The second is an iatrogenic infection. This type of infection is one that is transmitted from a health care worker to a patient. A nosocomial infection is also one that occurs in a health care setting. Nosocomial infections are those that are acquired during a hospital stay. Lastly, a community-acquired infection is one in which the infection is acquired from a whole community. One manner of proving that a given disease is infectious, is to satisfy Koch’s postulates (first proposed by Robert Koch), which require that first, the infectious agent be identifiable only in patients who have the disease, and not in healthy controls, and second, that patients who contract the infectious agent also develop the disease. These postulates were first used in the discovery that Mycobacteria species cause tuberculosis. However, Koch’s postulates cannot usually be tested in modern practice for ethical reasons. Proving them would require experimental infection of a healthy individual with a pathogen produced as a pure culture. Conversely, even clearly infectious diseases do not always meet the infectious criteria; for example, Treponema pallidum, the causative spirochete of syphilis, cannot be cultured in vitro – however the organism can be cultured in rabbit testes. It is less clear that a pure culture comes from an animal source serving as host than it is when derived from microbes derived from plate culture. Epidemiology, or the study and analysis of who, why and where disease occurs, and what determines whether various populations have a disease, is another important tool used to understand infectious disease. Epidemiologists may determine differences among groups within a population, such as whether certain age groups have a greater or lesser rate of infection; whether groups living in different neighborhoods are more likely to be infected; and by other factors, such as gender and race. Researchers also may assess whether a disease outbreak is sporadic, or just an occasional occurrence; endemic, with a steady level of regular cases occurring in a region; epidemic, with a fast arising, and unusually high number of cases in a region; or pandemic, which is a global epidemic. If the cause of the infectious disease is unknown, epidemiology can be used to assist with tracking down the sources of infection. Infectious diseases are sometimes called contagious diseases when they are easily transmitted by contact with an ill person or their secretions (e.g., influenza). Thus, a contagious disease is a subset of infectious disease that is especially infective or easily transmitted. Other types of infectious, transmissible, or communicable diseases with more specialized routes of infection, such as vector transmission or sexual transmission, are usually not regarded as “contagious”, and often do not require medical isolation (sometimes loosely called quarantine) of victims. However, this specialized connotation of the word “contagious” and “contagious disease” (easy transmissibility) is not always respected in popular use. Infectious diseases are commonly transmitted from person to person through direct contact. The types of contact are through person to person and droplet spread. Indirect contact such as airborne transmission, contaminated objects, food and drinking water, animal person contact, animal reservoirs, insect bites, and environmental reservoirs are another way infectious diseases are transmitted.) The symptoms of an infection depend on the type of disease. Some signs of infection affect the whole body generally, such as fatigue, loss of appetite, weight loss, fevers, night sweats, chills, aches and pains. Others are specific to individual body parts, such as skin rashes, coughing, or a runny nose. In certain cases, infectious diseases may be asymptomatic for much or even all of their course in a given host. In the latter case, the disease may only be defined as a “disease” (which by definition means an illness) in hosts who secondarily become ill after contact with an asymptomatic carrier. An infection is not synonymous with an infectious disease, as some infections do not cause illness in a host. Bacterial or viral As bacterial and viral infections can both cause the same kinds of symptoms, it can be difficult to distinguish which is the cause of a specific infection. Distinguishing the two is important, since viral infections cannot be cured by antibiotics whereas bacterial infections can. There is a general chain of events that applies to infections. The chain of events involves several steps – which include the infectious agent, reservoir, entering a susceptible host, exit and transmission to new hosts. Each of the links must be present in a chronological order for an infection to develop. Understanding these steps helps health care workers target the infection and prevent it from occurring in the first place. Infection begins when an organism successfully enters the body, grows and multiplies. This is referred to as colonization. Most humans are not easily infected. Those with compromised or weakened immune systems have an increased susceptibility to chronic or persistent infections. Individuals who have a suppressed immune system are particularly susceptible to opportunistic infections. Entrance to the host at host-pathogen interface, generally occurs through the mucosa in orifices like the oral cavity, nose, eyes, genitalia, anus, or the microbe can enter through open wounds. While a few organisms can grow at the initial site of entry, many migrate and cause systemic infection in different organs. Some pathogens grow within the host cells (intracellular) whereas others grow freely in bodily fluids. Wound colonization refers to non-replicating microorganisms within the wound, while in infected wounds, replicating organisms exist and tissue is injured. All multicellular organisms are colonized to some degree by extrinsic organisms, and the vast majority of these exist in either a mutualistic or commensal relationship with the host. An example of the former is the anaerobic bacteria species, which colonizes the mammalian colon, and an example of the latter are the various species of staphylococcus that exist on human skin. Neither of these colonizations are considered infections. The difference between an infection and a colonization is often only a matter of circumstance. Non-pathogenic organisms can become pathogenic given specific conditions, and even the most virulent organism requires certain circumstances to cause a compromising infection. Some colonizing bacteria, such as Corynebacteria sp. and viridans streptococci, prevent the adhesion and colonization of pathogenic bacteria and thus have a symbiotic relationship with the host, preventing infection and speeding wound healing. ￼ The variables involved in the outcome of a host becoming inoculated by a pathogen and the ultimate outcome include: the route of entry of the pathogen and the access to host regions that it gains the intrinsic virulence of the particular organism the quantity or load of the initial inoculant the immune status of the host being colonized As an example, several staphylococcal species remain harmless on the skin, but, when present in a normally sterile space, such as in the capsule of a joint or the peritoneum, multiply without resistance and cause harm. An interesting fact that gas chromatography–mass spectrometry, 16S ribosomal RNA analysis, omics, and other advanced technologies have made more apparent to humans in recent decades is that microbial colonization is very common even in environments that humans think of as being nearly sterile. Because it is normal to have bacterial colonization, it is difficult to know which chronic wounds can be classified as infected and how much risk of progression exists. Despite the huge number of wounds seen in clinical practice, there are limited quality data for evaluated symptoms and signs. A review of chronic wounds in the Journal of the American Medical Association’s “Rational Clinical Examination Series” quantified the importance of increased pain as an indicator of infection. The review showed that the most useful finding is an increase in the level of pain [likelihood ratio (LR) range, 11–20] makes infection much more likely, but the absence of pain (negative likelihood ratio range, 0.64–0.88) does not rule out infection (summary LR 0.64–0.88). 13.4 Disease Disease can arise if the host’s protective immune mechanisms are compromised and the organism inflicts damage on the host. Microorganisms can cause tissue damage by releasing a variety of toxins or destructive enzymes. For example, Clostridium tetani releases a toxin that paralyzes muscles, and staphylococcus releases toxins that produce shock and sepsis. Not all infectious agents cause disease in all hosts. For example, less than 5% of individuals infected with polio develop disease. On the other hand, some infectious agents are highly virulent. The prion causing mad cow disease and Creutzfeldt–Jakob disease invariably kills all animals and people that are infected. Persistent infections occur because the body is unable to clear the organism after the initial infection. Persistent infections are characterized by the continual presence of the infectious organism, often as latent infection with occasional recurrent relapses of active infection. There are some viruses that can maintain a persistent infection by infecting different cells of the body. Some viruses once acquired never leave the body. A typical example is the herpes virus, which tends to hide in nerves and become reactivated when specific circumstances arise. Persistent infections cause millions of deaths globally each year. Chronic infections by parasites account for a high morbidity and mortality in many underdeveloped countries. For infecting organisms to survive and repeat the infection cycle in other hosts, they (or their progeny) must leave an existing reservoir and cause infection elsewhere. Infection transmission can take place via many potential routes: Droplet contact, also known as the respiratory route, and the resultant infection can be termed airborne disease. If an infected person coughs or sneezes on another person the microorganisms, suspended in warm, moist droplets, may enter the body through the nose, mouth or eye surfaces. Fecal-oral transmission, wherein foodstuffs or water become contaminated (by people not washing their hands before preparing food, or untreated sewage being released into a drinking water supply) and the people who eat and drink them become infected. Common fecal-oral transmitted pathogens include Vibrio cholerae, Giardia species, rotaviruses, Entameba histolytica, Escherichia coli, and tape worms. Most of these pathogens cause gastroenteritis. Sexual transmission, with the resulting disease being called sexually transmitted disease Oral transmission, Diseases that are transmitted primarily by oral means may be caught through direct oral contact such as kissing, or by indirect contact such as by sharing a drinking glass or a cigarette. Transmission by direct contact, Some diseases that are transmissible by direct contact include athlete’s foot, impetigo and warts Vehicle transmission, transmission by an inanimate reservoir (food, water, soil). Vertical transmission, directly from the mother to an embryo, fetus or baby during pregnancy or childbirth. It can occur as a result of a pre-existing infection or one acquired during pregnancy. Iatrogenic transmission, due to medical procedures such as injection or transplantation of infected material. Vector-borne transmission, transmitted by a vector, which is an organism that does not cause disease itself but that transmits infection by conveying pathogens from one host to another. The relationship between virulence versus transmissibility is complex; if a disease is rapidly fatal, the host may die before the microbe can be passed along to another host. Diagnosis of infectious disease sometimes involves identifying an infectious agent either directly or indirectly. In practice most minor infectious diseases such as warts, cutaneous abscesses, respiratory system infections and diarrheal diseases are diagnosed by their clinical presentation and treated without knowledge of the specific causative agent. Conclusions about the cause of the disease are based upon the likelihood that a patient came in contact with a particular agent, the presence of a microbe in a community, and other epidemiological considerations. Given sufficient effort, all known infectious agents can be specifically identified. The benefits of identification, however, are often greatly outweighed by the cost, as often there is no specific treatment, the cause is obvious, or the outcome of an infection is benign. Diagnosis of infectious disease is nearly always initiated by medical history and physical examination. More detailed identification techniques involve the culture of infectious agents isolated from a patient. Culture allows identification of infectious organisms by examining their microscopic features, by detecting the presence of substances produced by pathogens, and by directly identifying an organism by its genotype. Other techniques (such as X-rays, CAT scans, PET scans or NMR) are used to produce images of internal abnormalities resulting from the growth of an infectious agent. The images are useful in detection of, for example, a bone abscess or a spongiform encephalopathy produced by a prion. Symptomatic diagnostics The diagnosis is aided by the presenting symptoms in any individual with an infectious disease, yet it usually needs additional diagnostic techniques to confirm the suspicion. Some signs are specifically characteristic and indicative of a disease and are called pathognomonic signs; but these are rare. Not all infections are symptomatic. In children the presence of cyanosis, rapid breathing, poor peripheral perfusion, or a petechial rash increases the risk of a serious infection by greater than 5 fold. Other important indicators include parental concern, clinical instinct, and temperature greater than 40 °C. Many diagnostic approaches depend on microbiological culture to isolate a pathogen from the appropriate clinical specimen. In a microbial culture, a growth medium is provided for a specific agent. A sample taken from potentially diseased tissue or fluid is then tested for the presence of an infectious agent able to grow within that medium. Many pathogenic bacteria are easily grown on nutrient agar, a form of solid medium that supplies carbohydrates and proteins necessary for growth, along with copious amounts of water. A single bacterium will grow into a visible mound on the surface of the plate called a colony, which may be separated from other colonies or melded together into a “lawn”. The size, color, shape and form of a colony is characteristic of the bacterial species, its specific genetic makeup (its strain), and the environment that supports its growth. Other ingredients are often added to the plate to aid in identification. Plates may contain substances that permit the growth of some bacteria and not others, or that change color in response to certain bacteria and not others. Bacteriological plates such as these are commonly used in the clinical identification of infectious bacterium. Microbial culture may also be used in the identification of viruses: the medium, in this case, being cells grown in culture that the virus can infect, and then alter or kill. In the case of viral identification, a region of dead cells results from viral growth, and is called a “plaque”. Eukaryotic parasites may also be grown in culture as a means of identifying a particular agent. In the absence of suitable plate culture techniques, some microbes require culture within live animals. Bacteria such as Mycobacterium leprae and Treponema pallidum can be grown in animals, although serological and microscopic techniques make the use of live animals unnecessary. Viruses are also usually identified using alternatives to growth in culture or animals. Some viruses may be grown in embryonated eggs. Another useful identification method is Xenodiagnosis, or the use of a vector to support the growth of an infectious agent. Chagas disease is the most significant example, because it is difficult to directly demonstrate the presence of the causative agent, Trypanosoma cruzi in a patient, which therefore makes it difficult to definitively make a diagnosis. In this case, xenodiagnosis involves the use of the vector of the Chagas agent T. cruzi, an uninfected triatomine bug, which takes a blood meal from a person suspected of having been infected. The bug is later inspected for growth of T. cruzi within its gut. Microscopy Another principal tool in the diagnosis of infectious disease is microscopy. Virtually all of the culture techniques discussed above rely, at some point, on microscopic examination for definitive identification of the infectious agent. Microscopy may be carried out with simple instruments, such as the compound light microscope, or with instruments as complex as an electron microscope. Samples obtained from patients may be viewed directly under the light microscope, and can often rapidly lead to identification. Microscopy is often also used in conjunction with biochemical staining techniques, and can be made exquisitely specific when used in combination with antibody based techniques. For example, the use of antibodies made artificially fluorescent (fluorescently labeled antibodies) can be directed to bind to and identify a specific antigens present on a pathogen. A fluorescence microscope is then used to detect fluorescently labeled antibodies bound to internalized antigens within clinical samples or cultured cells. This technique is especially useful in the diagnosis of viral diseases, where the light microscope is incapable of identifying a virus directly. Other microscopic procedures may also aid in identifying infectious agents. Almost all cells readily stain with a number of basic dyes due to the electrostatic attraction between negatively charged cellular molecules and the positive charge on the dye. A cell is normally transparent under a microscope, and using a stain increases the contrast of a cell with its background. Staining a cell with a dye such as Giemsa stain or crystal violet allows a microscopist to describe its size, shape, internal and external components and its associations with other cells. The response of bacteria to different staining procedures is used in the taxonomic classification of microbes as well. Two methods, the Gram stain and the acid-fast stain, are the standard approaches used to classify bacteria and to diagnosis of disease. The Gram stain identifies the bacterial groups Firmicutes and Actinobacteria, both of which contain many significant human pathogens. The acid-fast staining procedure identifies the Actinobacterial genera Mycobacterium and Nocardia. Biochemical tests Biochemical tests used in the identification of infectious agents include the detection of metabolic or enzymatic products characteristic of a particular infectious agent. Since bacteria ferment carbohydrates in patterns characteristic of their genus and species, the detection of fermentation products is commonly used in bacterial identification. Acids, alcohols and gases are usually detected in these tests when bacteria are grown in selective liquid or solid media. The isolation of enzymes from infected tissue can also provide the basis of a biochemical diagnosis of an infectious disease. For example, humans can make neither RNA replicases nor reverse transcriptase, and the presence of these enzymes are characteristic., of specific types of viral infections. The ability of the viral protein hemagglutinin to bind red blood cells together into a detectable matrix may also be characterized as a biochemical test for viral infection, although strictly speaking hemagglutinin is not an enzyme and has no metabolic function. Serological methods are highly sensitive, specific and often extremely rapid tests used to identify microorganisms. These tests are based upon the ability of an antibody to bind specifically to an antigen. The antigen, usually a protein or carbohydrate made by an infectious agent, is bound by the antibody. This binding then sets off a chain of events that can be visibly obvious in various ways, dependent upon the test. For example, “Strep throat” is often diagnosed within minutes, and is based on the appearance of antigens made by the causative agent, S. pyogenes, that is retrieved from a patient’s throat with a cotton swab. Serological tests, if available, are usually the preferred route of identification, however the tests are costly to develop and the reagents used in the test often require refrigeration. Some serological methods are extremely costly, although when commonly used, such as with the “strep test”, they can be inexpensive. Complex serological techniques have been developed into what are known as Immunoassays. Immunoassays can use the basic antibody – antigen binding as the basis to produce an electro-magnetic or particle radiation signal, which can be detected by some form of instrumentation. Signal of unknowns can be compared to that of standards allowing quantitation of the target antigen. To aid in the diagnosis of infectious diseases, immunoassays can detect or measure antigens from either infectious agents or proteins generated by an infected organism in response to a foreign agent. For example, immunoassay A may detect the presence of a surface protein from a virus particle. Immunoassay B on the other hand may detect or measure antibodies produced by an organism’s immune system that are made to neutralize and allow the destruction of the virus. Instrumentation can be used to read extremely small signals created by secondary reactions linked to the antibody – antigen binding. Instrumentation can control sampling, reagent use, reaction times, signal detection, calculation of results, and data management to yield a cost-effective automated process for diagnosis of infectious disease. PCR-based diagnostics Technologies based upon the polymerase chain reaction (PCR) method will become nearly ubiquitous gold standards of diagnostics of the near future, for several reasons. First, the catalog of infectious agents has grown to the point that virtually all of the significant infectious agents of the human population have been identified. Second, an infectious agent must grow within the human body to cause disease; essentially it must amplify its own nucleic acids in order to cause a disease. This amplification of nucleic acid in infected tissue offers an opportunity to detect the infectious agent by using PCR. Third, the essential tools for directing PCR, primers, are derived from the genomes of infectious agents, and with time those genomes will be known, if they are not already. Thus, the technological ability to detect any infectious agent rapidly and specifically are currently available. The only remaining blockades to the use of PCR as a standard tool of diagnosis are in its cost and application, neither of which is insurmountable. The diagnosis of a few diseases will not benefit from the development of PCR methods, such as some of the clostridial diseases (tetanus and botulism). These diseases are fundamentally biological poisonings by relatively small numbers of infectious bacteria that produce extremely potent neurotoxins. A significant proliferation of the infectious agent does not occur, this limits the ability of PCR to detect the presence of any bacteria. Metagenomic sequencing Given the wide range of bacterial, viral, fungal, protozoal, and helminthic pathogens that cause debilitating and life-threatening illnesses, the ability to quickly identify the cause of infection is important yet often challenging. For example, more than half of cases of encephalitis, a severe illness affecting the brain, remain undiagnosed, despite extensive testing using the standard of care (microbiological culture) and state-of-the-art clinical laboratory methods. Metagenomic sequencing-based diagnostic tests are currently being developed for clinical use and show promise as a sensitive, specific, and rapid way to diagnose infection using a single all-encompassing test. This test is similar to current PCR tests; however, an untargeted whole genome amplification is used rather than primers for a specific infectious agent. This amplification step is followed by next-generation sequencing or third-generation sequencing, alignment comparisons, and taxonomic classification using large databases of thousands of pathogen and commensal reference genomes. Simultaneously, antimicrobial resistance genes within pathogen and plasmid genomes are sequenced and aligned to the taxonomically-classified pathogen genomes to generate an antimicrobial resistance profile – analogous to antibiotic sensitivity testing – to facilitate antimicrobial stewardship and allow for the optimization of treatment using the most effective drugs for a patient’s infection. Metagenomic sequencing could prove especially useful for diagnosis when the patient is immunocompromised. An ever-wider array of infectious agents can cause serious harm to individuals with immunosuppression, so clinical screening must often be broader. Additionally, the expression of symptoms is often atypical, making a clinical diagnosis based on presentation more difficult. Thirdly, diagnostic methods that rely on the detection of antibodies are more likely to fail. A rapid, sensitive, specific, and untargeted test for all known human pathogens that detects the presence of the organism’s DNA rather than antibodies is therefore highly desirable.Techniques like hand washing, wearing gowns, and wearing face masks can help prevent infections from being passed from one person to another. Aseptic technique was introduced in medicine and surgery in the late 19th century and greatly reduced the incidence of infections caused by surgery. Frequent hand washing remains the most important defense against the spread of unwanted organisms. There are other forms of prevention such as avoiding the use of illicit drugs, using a condom, wearing gloves, and having a healthy lifestyle with a balanced diet and regular exercise. Cooking foods well and avoiding foods that have been left outside for a long time is also important. Antimicrobial substances used to prevent transmission of infections include: antiseptics, which are applied to living tissue/skin disinfectants, which destroy microorganisms found on non-living objects. antibiotics, called prophylactic when given as prevention rather as treatment of infection. However, long term use of antibiotics leads to resistance of bacteria. While humans do not become immune to antibiotics, the bacteria does. Thus, avoiding using antibiotics longer than necessary helps preventing bacteria from forming mutations that aide in antibiotic resistance. One of the ways to prevent or slow down the transmission of infectious diseases is to recognize the different characteristics of various diseases. Some critical disease characteristics that should be evaluated include virulence, distance traveled by victims, and level of contagiousness. The human strains of Ebola virus, for example, incapacitate their victims extremely quickly and kill them soon after. As a result, the victims of this disease do not have the opportunity to travel very far from the initial infection zone. Also, this virus must spread through skin lesions or permeable membranes such as the eye. Thus, the initial stage of Ebola is not very contagious since its victims experience only internal hemorrhaging. As a result of the above features, the spread of Ebola is very rapid and usually stays within a relatively confined geographical area. In contrast, the Human Immunodeficiency Virus (HIV) kills its victims very slowly by attacking their immune system. As a result, many of its victims transmit the virus to other individuals before even realizing that they are carrying the disease. Also, the relatively low virulence allows its victims to travel long distances, increasing the likelihood of an epidemic. Another effective way to decrease the transmission rate of infectious diseases is to recognize the effects of small-world networks. In epidemics, there are often extensive interactions within hubs or groups of infected individuals and other interactions within discrete hubs of susceptible individuals. Despite the low interaction between discrete hubs, the disease can jump and spread in a susceptible hub via a single or few interactions with an infected hub. Thus, infection rates in small-world networks can be reduced somewhat if interactions between individuals within infected hubs are eliminated (Figure 1). However, infection rates can be drastically reduced if the main focus is on the prevention of transmission jumps between hubs. The use of needle exchange programs in areas with a high density of drug users with HIV is an example of the successful implementation of this treatment method. [full citation needed] Another example is the use of ring culling or vaccination of potentially susceptible livestock in adjacent farms to prevent the spread of the foot-and-mouth virus in 2001. A general method to prevent transmission of vector-borne pathogens is pest control. In cases where infection is merely suspected, individuals may be quarantined until the incubation period has passed and the disease manifests itself or the person remains healthy. Groups may undergo quarantine, or in the case of communities, a cordon sanitaire may be imposed to prevent infection from spreading beyond the community, or in the case of protective sequestration, into a community. Public health authorities may implement other forms of social distancing, such as school closings, to control an epidemic. Immunity Infection with most pathogens does not result in death of the host and the offending organism is ultimately cleared after the symptoms of the disease have waned. This process requires immune mechanisms to kill or inactivate the inoculum of the pathogen. Specific acquired immunity against infectious diseases may be mediated by antibodies and/or T lymphocytes. Immunity mediated by these two factors may be manifested by: a direct effect upon a pathogen, such as antibody-initiated complement-dependent bacteriolysis, opsonoization, phagocytosis and killing, as occurs for some bacteria, neutralization of viruses so that these organisms cannot enter cells, or by T lymphocytes, which will kill a cell parasitized by a microorganism. The immune system response to a microorganism often causes symptoms such as a high fever and inflammation, and has the potential to be more devastating than direct damage caused by a microbe. Resistance to infection (immunity) may be acquired following a disease, by asymptomatic carriage of the pathogen, by harboring an organism with a similar structure (crossreacting), or by vaccination. Knowledge of the protective antigens and specific acquired host immune factors is more complete for primary pathogens than for opportunistic pathogens. There is also the phenomenon of herd immunity which offers a measure of protection to those otherwise vulnerable people when a large enough proportion of the population has acquired immunity from certain infections. Immune resistance to an infectious disease requires a critical level of either antigen-specific antibodies and/or T cells when the host encounters the pathogen. Some individuals develop natural serum antibodies to the surface polysaccharides of some agents although they have had little or no contact with the agent, these natural antibodies confer specific protection to adults and are passively transmitted to newborns. Host genetic factors The organism that is the target of an infecting action of a specific infectious agent is called the host. The host harbouring an agent that is in a mature or sexually active stage phase is called the definitive host. The intermediate host comes in contact during the larvae stage. A host can be anything living and can attain to asexual and sexual reproduction. The clearance of the pathogens, either treatment-induced or spontaneous, it can be influenced by the genetic variants carried by the individual patients. For instance, for genotype 1 hepatitis C treated with Pegylated interferon-alpha-2a or Pegylated interferon-alpha-2b (brand names Pegasys or PEG-Intron) combined with ribavirin, it has been shown that genetic polymorphisms near the human IL28B gene, encoding interferon lambda 3, are associated with significant differences in the treatment-induced clearance of the virus. This finding, originally reported in Nature, showed that genotype 1 hepatitis C patients carrying certain genetic variant alleles near the IL28B gene are more possibly to achieve sustained virological response after the treatment than others. Later report from Nature demonstrated that the same genetic variants are also associated with the natural clearance of the genotype 1 hepatitis C virus. Treatments When infection attacks the body, anti-infective drugs can suppress the infection. Several broad types of anti-infective drugs exist, depending on the type of organism targeted; they include antibacterial (antibiotic; including antitubercular), antiviral, antifungal and antiparasitic (including antiprotozoal and antihelminthic) agents. Depending on the severity and the type of infection, the antibiotic may be given by mouth or by injection, or may be applied topically. Severe infections of the brain are usually treated with intravenous antibiotics. Sometimes, multiple antibiotics are used in case there is resistance to one antibiotic. Antibiotics only work for bacteria and do not affect viruses. Antibiotics work by slowing down the multiplication of bacteria or killing the bacteria. The most common classes of antibiotics used in medicine include penicillin, cephalosporins, aminoglycosides, macrolides, quinolones and tetracyclines. Not all infections require treatment, and for many self-limiting infections the treatment may cause more side-effects than benefits. Antimicrobial stewardship is the concept that healthcare providers should treat an infection with an antimicrobial that specifically works well for the target pathogen for the shortest amount of time and to only treat when there is a known or highly suspected pathogen that will respond to the medication. 13.5 Epidemiology Epidemiology is the study and analysis of the distribution (who, when, and where), patterns and determinants of health and disease conditions in defined populations. It is a cornerstone of public health, and shapes policy decisions and evidence-based practice by identifying risk factors for disease and targets for preventive healthcare. Epidemiologists help with study design, collection, and statistical analysis of data, amend interpretation and dissemination of results (including peer review and occasional systematic review). Epidemiology has helped develop methodology used in clinical research, public health studies, and, to a lesser extent, basic research in the biological sciences. Major areas of epidemiological study include disease causation, transmission, outbreak investigation, disease surveillance, environmental epidemiology, forensic epidemiology, occupational epidemiology, screening, biomonitoring, and comparisons of treatment effects such as in clinical trials. Epidemiologists rely on other scientific disciplines like biology to better understand disease processes, statistics to make efficient use of the data and draw appropriate conclusions, social sciences to better understand proximate and distal causes, and engineering for exposure assessment. Epidemiology, literally meaning “the study of what is upon the people”, is derived from Greek epi ‘upon, among’, demos ‘people, district’, and logos ‘study, word, discourse’, suggesting that it applies only to human populations. However, the term is widely used in studies of zoological populations (veterinary epidemiology), although the term “epizoology” is available, and it has also been applied to studies of plant populations (botanical or plant disease epidemiology). The distinction between “epidemic” and “endemic” was first drawn by Hippocrates, to distinguish between diseases that are “visited upon” a population (epidemic) from those that “reside within” a population (endemic). The term “epidemiology” appears to have first been used to describe the study of epidemics in 1802 by the Spanish physician Villalba in Epidemiología Española. Epidemiologists also study the interaction of diseases in a population, a condition known as a syndemic. The term epidemiology is now widely applied to cover the description and causation of not only epidemic, infectious disease, but of disease in general, including related conditions. Some examples of topics examined through epidemiology include as high blood pressure, mental illness and obesity. Therefore, this epidemiology is based upon how the pattern of the disease causes change in the function of human beings. In the middle of the 16th century, a doctor from Verona named Girolamo Fracastoro was the first to propose a theory that these very small, unseeable, particles that cause disease were alive. They were considered to be able to spread by air, multiply by themselves and to be destroyable by fire. In this way he refuted Galen’s miasma theory (poison gas in sick people). In 1543 he wrote a book De contagione et contagiosis morbis, in which he was the first to promote personal and environmental hygiene to prevent disease. The development of a sufficiently powerful microscope by Antonie van Leeuwenhoek in 1675 provided visual evidence of living particles consistent with a germ theory of disease. A physician ahead of his time, Quinto Tiberio Angelerio, managed the 1582 plague in the town of Alghero, Sardinia. He was fresh from Sicily, which had endured a plague epidemic of its own in 1575. Later he published a manual “ECTYPA PESTILENSIS STATUS ALGHERIAE SARDINIAE”, detailing the 57 rules he had imposed upon the city. A second edition, “EPIDEMIOLOGIA, SIVE TRACTATUS DE PESTE” was published in 1598. Some of the rules he instituted, several as unpopular then as they are today, included lockdowns, physical distancing, washing groceries and textiles, restricting shopping to one person per household, quarantines, health passports, and others. Taken from Zaria Gorvett, BBC FUTURE 8th Jan 2021. During the Ming Dynasty, Wu Youke (1582–1652) developed the idea that some diseases were caused by transmissible agents, which he called Li Qi (戾气 or pestilential factors) when he observed various epidemics rage around him between 1641 and 1644. His book Wen Yi Lun (瘟疫论，Treatise on Pestilence/Treatise of Epidemic Diseases) can be regarded as the main etiological work that brought forward the concept. His concepts were still being considered in analysing SARS outbreak by WHO in 2004 in the context of traditional Chinese medicine. Another pioneer, Thomas Sydenham (1624–1689), was the first to distinguish the fevers of Londoners in the later 1600s. His theories on cures of fevers met with much resistance from traditional physicians at the time. He was not able to find the initial cause of the smallpox fever he researched and treated. John Graunt, a haberdasher and amateur statistician, published Natural and Political Observations … upon the Bills of Mortality in 1662. In it, he analysed the mortality rolls in London before the Great Plague, presented one of the first life tables, and reported time trends for many diseases, new and old. He provided statistical evidence for many theories on disease, and also refuted some widespread ideas on them. John Snow is famous for his investigations into the causes of the 19th-century cholera epidemics, and is also known as the father of (modern) epidemiology. He began with noticing the significantly higher death rates in two areas supplied by Southwark Company. His identification of the Broad Street pump as the cause of the Soho epidemic is considered the classic example of epidemiology. Snow used chlorine in an attempt to clean the water and removed the handle; this ended the outbreak. This has been perceived as a major event in the history of public health and regarded as the founding event of the science of epidemiology, having helped shape public health policies around the world. However, Snow’s research and preventive measures to avoid further outbreaks were not fully accepted or put into practice until after his death due to the prevailing Miasma Theory of the time, a model of disease in which poor air quality was blamed for illness. This was used to rationalize high rates of infection in impoverished areas instead of addressing the underlying issues of poor nutrition and sanitation, and was proven false by his work. Other pioneers include Danish physician Peter Anton Schleisner, who in 1849 related his work on the prevention of the epidemic of neonatal tetanus on the Vestmanna Islands in Iceland. Another important pioneer was Hungarian physician Ignaz Semmelweis, who in 1847 brought down infant mortality at a Vienna hospital by instituting a disinfection procedure. His findings were published in 1850, but his work was ill-received by his colleagues, who discontinued the procedure. Disinfection did not become widely practiced until British surgeon Joseph Lister ‘discovered’ antiseptics in 1865 in light of the work of Louis Pasteur. In the early 20th century, mathematical methods were introduced into epidemiology by Ronald Ross, Janet Lane-Claypon, Anderson Gray McKendrick, and others. In a parallel development during the 1920s, German-Swiss pathologist Max Askanazy and others founded the International Society for Geographical Pathology to systematically investigate the geographical pathology of cancer and other non-infectious diseases across populations in different regions. After World War II, Richard Doll and other non-pathologists joined the field and advanced methods to study cancer, a disease with patterns and mode of occurrences that could not be suitably studied with the methods developed for epidemics of infectious diseases. Geography pathology eventually combined with infectious disease epidemiology to make the field that is epidemiology today. Another breakthrough was the 1954 publication of the results of a British Doctors Study, led by Richard Doll and Austin Bradford Hill, which lent very strong statistical support to the link between tobacco smoking and lung cancer. In the late 20th century, with the advancement of biomedical sciences, a number of molecular markers in blood, other biospecimens and environment were identified as predictors of development or risk of a certain disease. Epidemiology research to examine the relationship between these biomarkers analyzed at the molecular level and disease was broadly named “molecular epidemiology”. Specifically, “genetic epidemiology” has been used for epidemiology of germline genetic variation and disease. Genetic variation is typically determined using DNA from peripheral blood leukocytes.Since the 2000s, genome-wide association studies (GWAS) have been commonly performed to identify genetic risk factors for many diseases and health conditions. While most molecular epidemiology studies are still using conventional disease diagnosis and classification systems, it is increasingly recognized that disease progression represents inherently heterogeneous processes differing from person to person. Conceptually, each individual has a unique disease process different from any other individual (“the unique disease principle”), considering uniqueness of the exposome (a totality of endogenous and exogenous / environmental exposures) and its unique influence on molecular pathologic process in each individual. Studies to examine the relationship between an exposure and molecular pathologic signature of disease (particularly cancer) became increasingly common throughout the 2000s. However, the use of molecular pathology in epidemiology posed unique challenges, including lack of research guidelines and standardized statistical methodologies, and paucity of interdisciplinary experts and training programs. Furthermore, the concept of disease heterogeneity appears to conflict with the long-standing premise in epidemiology that individuals with the same disease name have similar etiologies and disease processes. To resolve these issues and advance population health science in the era of molecular precision medicine, “molecular pathology” and “epidemiology” was integrated to create a new interdisciplinary field of “molecular pathological epidemiology” (MPE), defined as “epidemiology of molecular pathology and heterogeneity of disease”. In MPE, investigators analyze the relationships between (A) environmental, dietary, lifestyle and genetic factors; (B) alterations in cellular or extracellular molecules; and (C) evolution and progression of disease. A better understanding of heterogeneity of disease pathogenesis will further contribute to elucidate etiologies of disease. The MPE approach can be applied to not only neoplastic diseases but also non-neoplastic diseases. The concept and paradigm of MPE have become widespread in the 2010s. By 2012, it was recognized that many pathogens’ evolution is rapid enough to be highly relevant to epidemiology, and that therefore much could be gained from an interdisciplinary approach to infectious disease integrating epidemiology and molecular evolution to “inform control strategies, or even patient treatment.” Modern epidemiological studies can use advanced statistics and machine learning to create predictive models as well as to define treatment effects. Since the 2000s, genome-wide association studies (GWAS) have been commonly performed to identify genetic risk factors for many diseases and health conditions. While most molecular epidemiology studies are still using conventional disease diagnosis and classification systems, it is increasingly recognized that disease progression represents inherently heterogeneous processes differing from person to person. Conceptually, each individual has a unique disease process different from any other individual (“the unique disease principle”), considering uniqueness of the exposome (a totality of endogenous and exogenous / environmental exposures) and its unique influence on molecular pathologic process in each individual. Studies to examine the relationship between an exposure and molecular pathologic signature of disease (particularly cancer) became increasingly common throughout the 2000s. However, the use of molecular pathology in epidemiology posed unique challenges, including lack of research guidelines and standardized statistical methodologies, and paucity of interdisciplinary experts and training programs. Furthermore, the concept of disease heterogeneity appears to conflict with the long-standing premise in epidemiology that individuals with the same disease name have similar etiologies and disease processes. To resolve these issues and advance population health science in the era of molecular precision medicine, “molecular pathology” and “epidemiology” was integrated to create a new interdisciplinary field of “molecular pathological epidemiology” (MPE), defined as “epidemiology of molecular pathology and heterogeneity of disease”. In MPE, investigators analyze the relationships between (A) environmental, dietary, lifestyle and genetic factors; (B) alterations in cellular or extracellular molecules; and (C) evolution and progression of disease. A better understanding of heterogeneity of disease pathogenesis will further contribute to elucidate etiologies of disease. The MPE approach can be applied to not only neoplastic diseases but also non-neoplastic diseases. The concept and paradigm of MPE have become widespread in the 2010s. By 2012, it was recognized that many pathogens’ evolution is rapid enough to be highly relevant to epidemiology, and that therefore much could be gained from an interdisciplinary approach to infectious disease integrating epidemiology and molecular evolution to “inform control strategies, or even patient treatment.” Modern epidemiological studies can use advanced statistics and machine learning to create predictive models as well as to define treatment effects. In 2010, about 10 million people died of infectious diseases. The World Health Organization collects information on global deaths by International Classification of Disease (ICD) code categories. The following table lists the top infectious disease by number of deaths in 2002. 1993 data is included for comparison. The top three single agent/disease killers are HIV/AIDS, TB and malaria. While the number of deaths due to nearly every disease have decreased, deaths due to HIV/AIDS have increased fourfold. Childhood diseases include pertussis, poliomyelitis, diphtheria, measles and tetanus. Children also make up a large percentage of lower respiratory and diarrheal deaths. In 2012, approximately 3.1 million people have died due to lower respiratory infections, making it the number 4 leading cause of death in the world. 13.6 Pandemics With their potential for unpredictable and explosive impacts, infectious diseases have been major actors in human history. A pandemic (or global epidemic) is a disease that affects people over an extensive geographical area. For example: Plague of Justinian, from 541 to 542, killed between 50% and 60% of Europe’s population. The Black Death of 1347 to 1352 killed 25 million in Europe over 5 years. The plague reduced the old world population from an estimated 450 million to between 350 and 375 million in the 14th century. The introduction of smallpox, measles, and typhus to the areas of Central and South America by European explorers during the 15th and 16th centuries caused pandemics among the native inhabitants. Between 1518 and 1568 disease pandemics are said to have caused the population of Mexico to fall from 20 million to 3 million. The first European influenza epidemic occurred between 1556 and 1560, with an estimated mortality rate of 20%. Smallpox killed an estimated 60 million Europeans during the 18th century (approximately 400,000 per year). Up to 30% of those infected, including 80% of the children under 5 years of age, died from the disease, and one-third of the survivors went blind. In the 19th century, tuberculosis killed an estimated one-quarter of the adult population of Europe; by 1918 one in six deaths in France were still caused by TB. The Influenza Pandemic of 1918 (or the Spanish flu) killed 25–50 million people (about 2% of world population of 1.7 billion). Today Influenza kills about 250,000 to 500,000 worldwide each year. Emerging diseases In most cases, microorganisms live in harmony with their hosts via mutual or commensal interactions. Diseases can emerge when existing parasites become pathogenic or when new pathogenic parasites enter a new host. Coevolution between parasite and host can lead to hosts becoming resistant to the parasites or the parasites may evolve greater virulence, leading to immunopathological disease. Human activity is involved with many emerging infectious diseases, such as environmental change enabling a parasite to occupy new niches. When that happens, a pathogen that had been confined to a remote habitat has a wider distribution and possibly a new host organism. Parasites jumping from nonhuman to human hosts are known as zoonoses. Under disease invasion, when a parasite invades a new host species, it may become pathogenic in the new host. Several human activities have led to the emergence of zoonotic human pathogens, including viruses, bacteria, protozoa, and rickettsia, and spread of vector-borne diseases, see also globalization and disease and wildlife disease: Encroachment on wildlife habitats. The construction of new villages and housing developments in rural areas force animals to live in dense populations, creating opportunities for microbes to mutate and emerge. Changes in agriculture. The introduction of new crops attracts new crop pests and the microbes they carry to farming communities, exposing people to unfamiliar diseases. The destruction of rain forests. As countries make use of their rain forests, by building roads through forests and clearing areas for settlement or commercial ventures, people encounter insects and other animals harboring previously unknown microorganisms. Uncontrolled urbanization. The rapid growth of cities in many developing countries tends to concentrate large numbers of people into crowded areas with poor sanitation. These conditions foster transmission of contagious diseases. Modern transport. Ships and other cargo carriers often harbor unintended “passengers”, that can spread diseases to faraway destinations. While with international jet-airplane travel, people infected with a disease can carry it to distant lands, or home to their families, before their first symptoms appear. 13.6.1 COVID-19 Pandemic The global pandemic of coronavirus disease 2019 (COVID-19) is caused by severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2). The novel virus was identified in Wuhan, China, in December 2019; a lockdown in Wuhan and other cities in Hubei province failed to contain the outbreak, and it spread to other parts of mainland China and around the world. The World Health Organization (WHO) declared the outbreak a Public Health Emergency of International Concern on 30 January 2020, and a pandemic on 11 March 2020. Since 2021, variants of the virus have emerged or become dominant in many countries, with the Delta, Alpha and Beta variants being the most virulent. As of 9 August 2021, more than 202 million cases have been confirmed, with more than 4.29 million confirmed deaths attributed to COVID-19, making it one of the deadliest pandemics in history. COVID-19 symptoms range from unnoticeable to life-threatening. Severe illness is more likely in elderly COVID-19 patients, as well as those who have certain underlying medical conditions. COVID-19 transmits when people breathe in air contaminated by droplets and small airborne particles. The risk of breathing these in is highest when people are in close proximity, but they can be inhaled over longer distances, particularly indoors. Transmission can also occur if splashed or sprayed with contaminated fluids, in the eyes, nose or mouth, and, rarely, via contaminated surfaces. People remain contagious for up to 20 days, and can spread the virus even if they do not develop any symptoms. Recommended preventive measures include social distancing, wearing face masks in public, ventilation and air-filtering, hand washing, covering one’s mouth when sneezing or coughing, disinfecting surfaces, and monitoring and self-isolation for people exposed or symptomatic. Several vaccines have been distributed in many countries since December 2020. Treatments focus on addressing symptoms, but work is underway to develop medications that inhibit the virus. Authorities worldwide have responded by implementing travel restrictions, lockdowns and quarantines, workplace hazard controls, and business closures. There are also efforts to increase testing capacity and trace contacts of the infected. The pandemic has resulted in severe global, social and economic disruption, including the largest global recession since the Great Depression of the 1930s. It has led to widespread supply shortages exacerbated by panic buying, agricultural disruption, and food shortages. However, it has also caused temporary decreases in emissions of pollutants and greenhouse gases. Numerous educational institutions and public areas have been partially or fully closed, and many events have been cancelled or postponed. Misinformation has circulated through social media and mass media, and political tensions have been exacerbated. The pandemic has raised issues of racial and geographic discrimination, health equity, wealth inequality and the balance between public health imperatives and individual rights. "],["an-introduction-to-host-defenses-and-innate-immune-systems.html", "14 An Introduction To Host Defenses And Innate Immune Systems 14.1 Layered defense 14.2 Surface Barriers 14.3 Innate immune system 14.4 Anatomical barriers 14.5 Inflammation 14.6 Complement system 14.7 White blood cells", " 14 An Introduction To Host Defenses And Innate Immune Systems The immune system is a network of biological processes that protects an organism from diseases. It detects and responds to a wide variety of pathogens, from viruses to parasitic worms, as well as cancer cells and objects such as wood splinters, distinguishing them from the organism’s own healthy tissue. Many species have two major subsystems of the immune system. The innate immune system provides a preconfigured response to broad groups of situations and stimuli. The adaptive immune system provides a tailored response to each stimulus by learning to recognize molecules it has previously encountered. Both use molecules and cells to perform their functions. Nearly all organisms have some kind of immune system. Bacteria have a rudimentary immune system in the form of enzymes that protect against virus infections. Other basic immune mechanisms evolved in ancient plants and animals and remain in their modern descendants. These mechanisms include phagocytosis, antimicrobial peptides called defensins, and the complement system. Jawed vertebrates, including humans, have even more sophisticated defense mechanisms, including the ability to adapt to recognize pathogens more efficiently. Adaptive (or acquired) immunity creates an immunological memory leading to an enhanced response to subsequent encounters with that same pathogen. This process of acquired immunity is the basis of vaccination. Dysfunction of the immune system can cause autoimmune diseases, inflammatory diseases and cancer. Immunodeficiency occurs when the immune system is less active than normal, resulting in recurring and life-threatening infections. In humans, immunodeficiency can be the result of a genetic disease such as severe combined immunodeficiency, acquired conditions such as HIV/AIDS, or the use of immunosuppressive medication. Autoimmunity results from a hyperactive immune system attacking normal tissues as if they were foreign organisms. Common autoimmune diseases include Hashimoto’s thyroiditis, rheumatoid arthritis, diabetes mellitus type 1, and systemic lupus erythematosus. Immunology covers the study of all aspects of the immune system. 14.1 Layered defense The immune system protects its host from infection with layered defenses of increasing specificity. Physical barriers prevent pathogens such as bacteria and viruses from entering the organism. If a pathogen breaches these barriers, the innate immune system provides an immediate, but non-specific response. Innate immune systems are found in all animals. If pathogens successfully evade the innate response, vertebrates possess a second layer of protection, the adaptive immune system, which is activated by the innate response. Here, the immune system adapts its response during an infection to improve its recognition of the pathogen. This improved response is then retained after the pathogen has been eliminated, in the form of an immunological memory, and allows the adaptive immune system to mount faster and stronger attacks each time this pathogen is encountered. Both innate and adaptive immunity depend on the ability of the immune system to distinguish between self and non-self molecules. In immunology, self molecules are components of an organism’s body that can be distinguished from foreign substances by the immune system. Conversely, non-self molecules are those recognized as foreign molecules. One class of non-self molecules are called antigens (originally named for being antibody generators) and are defined as substances that bind to specific immune receptors and elicit an immune response. 14.2 Surface Barriers Several barriers protect organisms from infection, including mechanical, chemical, and biological barriers. The waxy cuticle of most leaves, the exoskeleton of insects, the shells and membranes of externally deposited eggs, and skin are examples of mechanical barriers that are the first line of defense against infection. Organisms cannot be completely sealed from their environments, so systems act to protect body openings such as the lungs, intestines, and the genitourinary tract. In the lungs, coughing and sneezing mechanically eject pathogens and other irritants from the respiratory tract. The flushing action of tears and urine also mechanically expels pathogens, while mucus secreted by the respiratory and gastrointestinal tract serves to trap and entangle microorganisms. Chemical barriers also protect against infection. The skin and respiratory tract secrete antimicrobial peptides such as the β-defensins. Enzymes such as lysozyme and phospholipase A2 in saliva, tears, and breast milk are also antibacterials. Vaginal secretions serve as a chemical barrier following menarche, when they become slightly acidic, while semen contains defensins and zinc to kill pathogens. In the stomach, gastric acid serves as a chemical defense against ingested pathogens. Within the genitourinary and gastrointestinal tracts, commensal flora serve as biological barriers by competing with pathogenic bacteria for food and space and, in some cases, changing the conditions in their environment, such as pH or available iron. As a result, the probability that pathogens will reach sufficient numbers to cause illness is reduced. 14.3 Innate immune system The innate immune system is one of the two main immunity strategies found in vertebrates (the other being the adaptive immune system). The innate immune system is an older evolutionary defense strategy, relatively speaking, and is the dominant immune system response found in plants, fungi, insects, and primitive multicellular organisms. The major functions of the vertebrate innate immune system include: Recruiting immune cells to sites of infection through the production of chemical factors, including specialized chemical mediators called cytokines Activation of the complement cascade to identify bacteria, activate cells, and promote clearance of antibody complexes or dead cells Identification and removal of foreign substances present in organs, tissues, blood and lymph, by specialized white blood cells Activation of the adaptive immune system through a process known as antigen presentation Acting as a physical and chemical barrier to infectious agents; via physical measures like skin or tree bark and chemical measures like clotting factors in blood or sap from a tree, which are released following a contusion or other injury that breaks through the first-line physical barrier (not to be confused with a second-line physical or chemical barrier, such as the blood-brain barrier, which protects the extremely vital and highly sensitive nervous system from pathogens that have already gained access to the host’s body). 14.4 Anatomical barriers Anatomical barriers include physical, chemical and biological barriers. The epithelial surfaces form a physical barrier that is impermeable to most infectious agents, acting as the first line of defense against invading organisms. Desquamation (shedding) of skin epithelium also helps remove bacteria and other infectious agents that have adhered to the epithelial surfaces. Lack of blood vessels, the inability of the epidermis to retain moisture, and the presence of sebaceous glands in the dermis, produces an environment unsuitable for the survival of microbes. In the gastrointestinal and respiratory tract, movement due to peristalsis or cilia, respectively, helps remove infectious agents. Also, mucus traps infectious agents. The gut flora can prevent the colonization of pathogenic bacteria by secreting toxic substances or by competing with pathogenic bacteria for nutrients or attachment to cell surfaces. The flushing action of tears and saliva helps prevent infection of the eyes and mouth. 14.5 Inflammation Inflammation is one of the first responses of the immune system to infection or irritation. Inflammation is stimulated by chemical factors released by injured cells and serves to establish a physical barrier against the spread of infection, and to promote healing of any damaged tissue following the clearance of pathogens. The process of acute inflammation is initiated by cells already present in all tissues, mainly resident macrophages, dendritic cells, histiocytes, Kupffer cells, and mast cells. These cells present receptors contained on the surface or within the cell, named pattern recognition receptors (PRRs), which recognize molecules that are broadly shared by pathogens but distinguishable from host molecules, collectively referred to as pathogen-associated molecular patterns (PAMPs). At the onset of an infection, burn, or other injuries, these cells undergo activation (one of their PRRs recognizes a PAMP) and release inflammatory mediators responsible for the clinical signs of inflammation. Chemical factors produced during inflammation (histamine, bradykinin, serotonin, leukotrienes, and prostaglandins) sensitize pain receptors, cause local vasodilation of the blood vessels, and attract phagocytes, especially neutrophils. Neutrophils then trigger other parts of the immune system by releasing factors that summon additional leukocytes and lymphocytes. Cytokines produced by macrophages and other cells of the innate immune system mediate the inflammatory response. These cytokines include TNF, HMGB1, and IL-1. The inflammatory response is characterized by the following symptoms: redness of the skin, due to locally increased blood circulation; heat, either increased local temperature, such as a warm feeling around a localized infection, or a systemic fever; swelling of affected tissues, such as the upper throat during the common cold or joints affected by rheumatoid arthritis; increased production of mucus, which can cause symptoms like a runny nose or a productive cough; pain, either local pain, such as painful joints or a sore throat, or affecting the whole body, such as body aches; and possible dysfunction of the organs or tissues involved. 14.6 Complement system The complement system is a biochemical cascade of the immune system that helps, or “complements”, the ability of antibodies to clear pathogens or mark them for destruction by other cells. The cascade is composed of many plasma proteins, synthesized in the liver, primarily by hepatocytes. The proteins work together to: trigger the recruitment of inflammatory cells “tag” pathogens for destruction by other cells by opsonizing, or coating, the surface of the pathogen form holes in the plasma membrane of the pathogen, resulting in cytolysis of the pathogen cell, causing the death of the pathogen rid the body of neutralised antigen-antibody complexes. There are three different complement systems: Classical, alternative, Lectin Classical: starts when antibody binds to bacteria Alternative: starts “spontaneously” Lectin: starts when lectins bind to mannose on bacteria Elements of the complement cascade can be found in many non-mammalian species including plants, birds, fish, and some species of invertebrates. 14.7 White blood cells All white blood cells (WBCs) are known as leukocytes. Most leukocytes differ from other cells of the body in that they are not tightly associated with a particular organ or tissue; thus, their function is similar to that of independent, single-cell organisms. Most leukocytes are able to move freely and interact with and capture cellular debris, foreign particles, and invading microorganisms (although macrophages, mast cells, and dendritic cells are less mobile). Unlike many other cells in the body, most innate immune leukocytes cannot divide or reproduce on their own, but are the products of multipotent hematopoietic stem cells present in the bone marrow. The innate leukocytes include: natural killer cells, mast cells, eosinophils, basophils; and the phagocytic cells include macrophages, neutrophils, and dendritic cells, and function within the immune system by identifying and eliminating pathogens that might cause infection. Mast cells Main article: Mast cell Mast cells are a type of innate immune cell that resides in connective tissue and in mucous membranes. They are intimately associated with wound healing and defense against pathogens, but are also often associated with allergy and anaphylaxis (serious allergic reactions that can cause death). When activated, mast cells rapidly release characteristic granules, rich in histamine and heparin, along with various hormonal mediators and chemokines, or chemotactic cytokines into the environment. Histamine dilates blood vessels, causing the characteristic signs of inflammation, and recruits neutrophils and macrophages. Phagocytes Main article: Phagocyte The word ‘phagocyte’ literally means ‘eating cell’. These are immune cells that engulf, or ‘phagocytose’, pathogens or particles. To engulf a particle or pathogen, a phagocyte extends portions of its plasma membrane, wrapping the membrane around the particle until it is enveloped (i.e., the particle is now inside the cell). Once inside the cell, the invading pathogen is contained inside a phagosome, which merges with a lysosome. The lysosome contains enzymes and acids that kill and digest the particle or organism. In general, phagocytes patrol the body searching for pathogens, but are also able to react to a group of highly specialized molecular signals produced by other cells, called cytokines. The phagocytic cells of the immune system include macrophages, neutrophils, and dendritic cells. Phagocytosis of the hosts’ own cells is common as part of regular tissue development and maintenance. When host cells die, either by programmed cell death (also called apoptosis) or by cell injury due to a bacterial or viral infection, phagocytic cells are responsible for their removal from the affected site. By helping to remove dead cells preceding growth and development of new healthy cells, phagocytosis is an important part of the healing process following tissue injury. Macrophages Main article: Macrophages Macrophages, from the Greek, meaning “large eaters”, are large phagocytic leukocytes, which are able to move outside of the vascular system by migrating through the walls of capillary vessels and entering the areas between cells in pursuit of invading pathogens. In tissues, organ-specific macrophages are differentiated from phagocytic cells present in the blood called monocytes. Macrophages are the most efficient phagocytes and can phagocytose substantial numbers of bacteria or other cells or microbes. The binding of bacterial molecules to receptors on the surface of a macrophage triggers it to engulf and destroy the bacteria through the generation of a “respiratory burst”, causing the release of reactive oxygen species. Pathogens also stimulate the macrophage to produce chemokines, which summon other cells to the site of infection. Neutrophils Main article: Neutrophils Neutrophils, along with two other cell types (eosinophils and basophils; see below), are known as granulocytes due to the presence of granules in their cytoplasm, or as polymorphonuclear cells (PMNs) due to their distinctive lobed nuclei. Neutrophil granules contain a variety of toxic substances that kill or inhibit growth of bacteria and fungi. Similar to macrophages, neutrophils attack pathogens by activating a respiratory burst. The main products of the neutrophil respiratory burst are strong oxidizing agents including hydrogen peroxide, free oxygen radicals and hypochlorite. Neutrophils are the most abundant type of phagocyte, normally representing 50-60% of the total circulating leukocytes, and are usually the first cells to arrive at the site of an infection. The bone marrow of a normal healthy adult produces more than 100 billion neutrophils per day, and more than 10 times that many per day during acute inflammation. Dendritic cells Main article: Dendritic cell Dendritic cells (DCs) are phagocytic cells present in tissues that are in contact with the external environment, mainly the skin (where they are often called Langerhans cells), and the inner mucosal lining of the nose, lungs, stomach, and intestines. They are named for their resemblance to neuronal dendrites, but dendritic cells are not connected to the nervous system. Dendritic cells are very important in the process of antigen presentation, and serve as a link between the innate and adaptive immune systems. Basophils and eosinophils Main articles: Basophil granulocyte and Eosinophil granulocyte Basophils and eosinophils are cells related to the neutrophil (see above). When activated by a pathogen encounter, histamine-releasing basophils are important in the defense against parasites and play a role in allergic reactions, such as asthma. Upon activation, eosinophils secrete a range of highly toxic proteins and free radicals that are highly effective in killing parasites, but may also damage tissue during an allergic reaction. Activation and release of toxins by eosinophils are, therefore, tightly regulated to prevent any inappropriate tissue destruction. Natural killer cells Main article: Natural killer cell Natural killer cells (NK cells) are a component of the innate immune system that does not directly attack invading microbes. Rather, NK cells destroy compromised host cells, such as tumor cells or virus-infected cells, recognizing such cells by a condition known as “missing self.” This term describes cells with abnormally low levels of a cell-surface marker called MHC I (major histocompatibility complex) - a situation that can arise in viral infections of host cells. They were named “natural killer” because of the initial notion that they do not require activation in order to kill cells that are “missing self.” For many years, it was unclear how NK cell recognize tumor cells and infected cells. It is now known that the MHC makeup on the surface of those cells is altered and the NK cells become activated through recognition of “missing self”. Normal body cells are not recognized and attacked by NK cells because they express intact self MHC antigens. Those MHC antigens are recognized by killer cell immunoglobulin receptors (KIR) that, in essence, put the brakes on NK cells. The NK-92 cell line does not express KIR and is developed for tumor therapy. γδ T cells Main article: gamma/delta T cells Like other ‘unconventional’ T cell subsets bearing invariant T cell receptors (TCRs), such as CD1d-restricted Natural Killer T cells, γδ T cells exhibit characteristics that place them at the border between innate and adaptive immunity. On one hand, γδ T cells may be considered a component of adaptive immunity in that they rearrange TCR genes to produce junctional diversity and develop a memory phenotype. However, the various subsets may also be considered part of the innate immune system where a restricted TCR or NK receptors may be used as a pattern recognition receptor. For example, according to this paradigm, large numbers of Vγ9/Vδ2 T cells respond within hours to common molecules produced by microbes, and highly restricted intraepithelial Vδ1 T cells will respond to stressed epithelial cells. Other vertebrate mechanisms The coagulation system overlaps with the immune system. Some products of the coagulation system can contribute to the non-specific defenses by their ability to increase vascular permeability and act as chemotactic agents for phagocytic cells. In addition, some of the products of the coagulation system are directly antimicrobial. For example, beta-lysine, a protein produced by platelets during coagulation, can cause lysis of many Gram-positive bacteria by acting as a cationic detergent. Many acute-phase proteins of inflammation are involved in the coagulation system. Also increased levels of lactoferrin and transferrin inhibit bacterial growth by binding iron, an essential nutrient for bacteria. Neural regulation The innate immune response to infectious and sterile injury is modulated by neural circuits that control cytokine production period. The inflammatory reflex is a prototypical neural circuit that controls cytokine production in the spleen. Action potentials transmitted via the vagus nerve to spleen mediate the release of acetylcholine, the neurotransmitter that inhibits cytokine release by interacting with alpha7 nicotinic acetylcholine receptors (CHRNA7) expressed on cytokine-producing cells. The motor arc of the inflammatory reflex is termed the cholinergic anti-inflammatory pathway. Pathogen-specificity The parts of the innate immune system have different specificity for different pathogens. Immune evasion Cells of the innate immune system prevent free growth of microorganisms within the body, but many pathogens have evolved mechanisms to evade it. One strategy is intracellular replication, as practised by Mycobacterium tuberculosis, or wearing a protective capsule, which prevents lysis by complement and by phagocytes, as in Salmonella. Bacteroides species are normally mutualistic bacteria, making up a substantial portion of the mammalian gastrointestinal flora. Some species like B. fragilis for example are opportunistic pathogens, causing infections of the peritoneal cavity inhibit phagocytosis by affecting the phagocytes receptors used to engulf bacteria. They may also mimick host cells so the immune system does not recognize them as foreign. Staphylococcus aureus inhibits the ability of the phagocyte to respond to chemokine signals. M. tuberculosis, Streptococcus pyogenes, and Bacillus anthracis utilize mechanisms that directly kill the phagocyte. Bacteria and fungi may form complex biofilms, protecting from immune cells and proteins; biofilms are present in the chronic Pseudomonas aeruginosa and Burkholderia cenocepacia infections characteristic of cystic fibrosis. Viruses Type I interferons (IFN), secreted mainly by dendritic cells, play a central role in antiviral host defense and a cell’s antiviral state. Viral components are recognized by different receptors: Toll-like receptors are located in the endosomal membrane and recognize double-stranded RNA (dsRNA), MDA5 and RIG-I receptors are located in the cytoplasm and recognize long dsRNA and phosphate-containing dsRNA respectively. When the cytoplasmic receptors MDA5 and RIG-I recognize a virus the conformation between the caspase-recruitment domain (CARD) and the CARD-containing adaptor MAVS changes. In parallel, when toll-like receptors in the endocytic compartments recognize a virus the activation of the adaptor protein TRIF is induced. Both pathways converge in the recruitment and activation of the IKKε/TBK-1 complex, inducing dimerization of transcription factors IRF3 and IRF7, which are translocated in the nucleus, where they induce IFN production with the presence of a particular transcription factor and activate transcription factor 2. IFN is secreted through secretory vesicles, where it can activate receptors on both the same cell it was released from (autocrine) or nearby cells (paracrine). This induces hundreds of interferon-stimulated genes to be expressed. This leads to antiviral protein production, such as protein kinase R, which inhibits viral protein synthesis, or the 2′,5′-oligoadenylate synthetase family, which degrades viral RNA. Some viruses evade this by producing molecules which interfere with IFN production. For example, the Influenza A virus produces NS1 protein, which can bind to host and viral RNA, interact with immune signaling proteins or block their activation by ubiquitination, thus inhibiting type I IFN production. Influenza A also blocks protein kinase R activation and establishment of the antiviral state. The dengue virus also inhibits type I IFN production by blocking IRF-3 phosophorylation using NS2B3 protease complex. In other species Prokaryotes Bacteria (and perhaps other prokaryotic organisms), utilize a unique defense mechanism, called the restriction modification system to protect themselves from pathogens, such as bacteriophages. In this system, bacteria produce enzymes, called restriction endonucleases, that attack and destroy specific regions of the viral DNA of invading bacteriophages. Methylation of the host’s own DNA marks it as “self” and prevents it from being attacked by endonucleases. Restriction endonucleases and the restriction modification system exist exclusively in prokaryotes. Invertebrates Invertebrates do not possess lymphocytes or an antibody-based humoral immune system, and it is likely that a multicomponent, adaptive immune system arose with the first vertebrates. Nevertheless, invertebrates possess mechanisms that appear to be precursors of these aspects of vertebrate immunity. Pattern recognition receptors are proteins used by nearly all organisms to identify molecules associated with microbial pathogens. Toll-like receptors are a major class of pattern recognition receptor, that exists in all coelomates (animals with a body-cavity), including humans. The complement system, as discussed above, is a biochemical cascade of the immune system that helps clear pathogens from an organism, and exists in most forms of life. Some invertebrates, including various insects, crabs, and worms utilize a modified form of the complement response known as the prophenoloxidase (proPO) system. Antimicrobial peptides are an evolutionarily conserved component of the innate immune response found among all classes of life and represent the main form of invertebrate systemic immunity. Several species of insect produce antimicrobial peptides known as defensins and cecropins. Proteolytic cascades In invertebrates, pattern recognition receptors (PRRs) trigger proteolytic cascades that degrade proteins and control many of the mechanisms of the innate immune system of invertebrates—including hemolymph coagulation and melanization. Proteolytic cascades are important components of the invertebrate immune system because they are turned on more rapidly than other innate immune reactions because they do not rely on gene changes. Proteolytic cascades have been found to function the same in both vertebrate and invertebrates, even though different proteins are used throughout the cascades. Clotting mechanisms In the hemolymph, which makes up the fluid in the circulatory system of arthropods, a gel-like fluid surrounds pathogen invaders, similar to the way blood does in other animals. There are various different proteins and mechanisms that are involved in invertebrate clotting. In crustaceans, transglutaminase from blood cells and mobile plasma proteins make up the clotting system, where the transglutaminase polymerizes 210 kDa subunits of a plasma-clotting protein. On the other hand, in the horseshoe crab species clotting system, components of proteolytic cascades are stored as inactive forms in granules of hemocytes, which are released when foreign molecules, like lipopolysaccharides enter. Plants Main article: Plant disease resistance § Immune system Members of every class of pathogen that infect humans also infect plants. Although the exact pathogenic species vary with the infected species, bacteria, fungi, viruses, nematodes, and insects can all cause plant disease. As with animals, plants attacked by insects or other pathogens use a set of complex metabolic responses which lead to the formation of defensive chemical compounds that fight infection or make the plant less attractive to insects and other herbivores. (see: plant defense against herbivory). Like invertebrates, plants neither generate antibody or T-cell responses nor possess mobile cells that detect and attack pathogens. In addition, in case of infection, parts of some plants are treated as disposable and replaceable, in ways that very few animals are able to do. Walling off or discarding a part of a plant helps stop spread of an infection. Most plant immune responses involve systemic chemical signals sent throughout a plant. Plants use pattern-recognition receptors to recognize conserved microbial signatures. This recognition triggers an immune response. The first plant receptors of conserved microbial signatures were identified in rice (XA21, 1995) and in Arabidopsis (FLS2, 2000). Plants also carry immune receptors that recognize highly variable pathogen effectors. These include the NBS-LRR class of proteins. When a part of a plant becomes infected with a microbial or viral pathogen, in case of an incompatible interaction triggered by specific elicitors, the plant produces a localized hypersensitive response (HR), in which cells at the site of infection undergo rapid programmed cell death to prevent the spread of the disease to other parts of the plant. HR has some similarities to animal pyroptosis, such as a requirement of caspase-1-like proteolytic activity of VPEγ, a cysteine protease that regulates cell disassembly during cell death. “Resistance” (R) proteins, encoded by R genes, are widely present in plants and detect pathogens. These proteins contain domains similar to the NOD Like Receptors and Toll-like receptors utilized in animal innate immunity. Systemic acquired resistance (SAR) is a type of defensive response that renders the entire plant resistant to a broad spectrum of infectious agents. SAR involves the production of chemical messengers, such as salicylic acid or jasmonic acid. Some of these travel through the plant and signal other cells to produce defensive compounds to protect uninfected parts, e.g., leaves. Salicylic acid itself, although indispensable for expression of SAR, is not the translocated signal responsible for the systemic response. Recent evidence indicates a role for jasmonates in transmission of the signal to distal portions of the plant. RNA silencing mechanisms are also important in the plant systemic response, as they can block virus replication. The jasmonic acid response, is stimulated in leaves damaged by insects, and involves the production of methyl jasmonate. "],["the-adaptive-immune-system-and-immunization.html", "15 The Adaptive Immune System And Immunization 15.1 Lymphocytes 15.2 Antigen presentation 15.3 Exogenous antigens 15.4 Endogenous antigens 15.5 T lymphocytes", " 15 The Adaptive Immune System And Immunization The adaptive immune system, also referred as the acquired immune system, is a subsystem of the immune system that is composed of specialized, systemic cells and processes that eliminate pathogens or prevent their growth. The acquired immune system is one of the two main immunity strategies found in vertebrates (the other being the innate immune system). ￼ Google Ngram of “acquired immunity” vs. “adaptive immunity”. The peak for “adaptive” in the 1960s reflects its introduction to immunology by Robert A. Good and use by colleagues; the explosive increase in the 1990s was correlated with the use of the phrase “innate immunity”. Like the innate system, the adaptive immune system includes both humoral immunity components and cell-mediated immunity components and destroys invading pathogens. Unlike the innate immune system, which is pre-programmed to react to common broad categories of pathogen, the adaptive immune system is highly specific to each particular pathogen the body has encountered. Adaptive immunity creates immunological memory after an initial response to a specific pathogen, and leads to an enhanced response to future encounters with that pathogen. Antibodies are a critical part of the adaptive immune system. Adaptive immunity can provide long-lasting protection, sometimes for the person’s entire lifetime. For example, someone who recovers from measles is now protected against measles for their lifetime; in other cases it does not provide lifetime protection, as with chickenpox. This process of adaptive immunity is the basis of vaccination. The cells that carry out the adaptive immune response are white blood cells known as lymphocytes. B cells and T cells, two different types of lymphocytes, carry out the main activities: antibody responses, and cell-mediated immune response. In antibody responses, B cells are activated to secrete antibodies, which are proteins also known as immunoglobulins. Antibodies travel through the bloodstream and bind to the foreign antigen causing it to inactivate, which does not allow the antigen to bind to the host. Antigens are any substances that elicit the adaptive immune response. Sometimes the adaptive system is unable to distinguish harmful from harmless foreign molecules; the effects of this may be hayfever, asthma, or any other allergy. In adaptive immunity, pathogen-specific receptors are “acquired” during the lifetime of the organism (whereas in innate immunity pathogen-specific receptors are already encoded in the genome). This acquired response is called “adaptive” because it prepares the body’s immune system for future challenges (though it can actually also be maladaptive when it results in allergies or autoimmunity). The system is highly adaptable because of two factors. First, somatic hypermutation is a process of accelerated random genetic mutations in the antibody-coding genes, which allows antibodies with novel specificity to be created. Second, V(D)J recombination randomly selects one variable (V), one diversity (D), and one joining (J) region for genetic recombination and discards the rest, which produces a highly unique combination of antigen-receptor gene segments in each lymphocyte. This mechanism allows a small number of genetic segments to generate a vast number of different antigen receptors, which are then uniquely expressed on each individual lymphocyte. Since the gene rearrangement leads to an irreversible change in the DNA of each cell, all progeny (offspring) of that cell inherit genes that encode the same receptor specificity, including the memory B cells and memory T cells that are the keys to long-lived specific immunity. The term “adaptive” was first used by Robert Good in reference to antibody responses in frogs as a synonym for “acquired immune response” in 1964. Good acknowledged he used the terms as synonyms but explained only that he preferred to use the term “adaptive”. He might have been thinking of the then not implausible theory of antibody formation in which antibodies were plastic and could adapt themselves to the molecular shape of antigens, and/or to the concept of “adaptive enzymes” as described by Monod in bacteria, that is, enzymes whose expression could be induced by their substrates. The phrase was used almost exclusively by Good and his students and a few other immunologists working with marginal organisms until the 1990s when it became widely used in tandem with the term “innate immunity” which became a popular subject after the discovery of the Toll receptor system in Drosophila, a previously marginal organism for the study of immunology. The term “adaptive” as used in immunology is problematic as acquired immune responses can be both adaptive and maladaptive in the physiological sense. Indeed, both acquired and innate immune responses can be both adaptive and maladaptive in the evolutionary sense. Most textbooks today, following the early use by Janeway, use “adaptive” almost exclusively and noting in glossaries that the term is synonymous with “acquired”. The classic sense of “acquired immunity” came to mean, since Tonegawa’s discovery, “antigen-specific immunity mediated by somatic gene rearrangements that create clone-defining antigen receptors”. In the last decade, the term “adaptive” has been increasingly applied to another class of immune response not so-far associated with somatic gene rearrangements. These include expansion of natural killer (NK) cells with so-far unexplained specificity for antigens, expansion of NK cells expressing germ-line encoded receptors, and activation of other innate immune cells to an activated state that confers a short-term “immune memory”. In this sense, “adaptive immunity” more closely resembles the concept of “activated state” or “heterostasis”, thus returning in sense to the physiological sense of “adaptation” to environmental changes. Acquired immunity is triggered in vertebrates when a pathogen evades the innate immune system and (1) generates a threshold level of antigen and (2) generates “stranger” or “danger” signals activating dendritic cells. The major functions of the acquired immune system include: Recognition of specific “non-self” antigens in the presence of “self”, during the process of antigen presentation. Generation of responses that are tailored to maximally eliminate specific pathogens or pathogen-infected cells. Development of immunological memory, in which pathogens are “remembered” through memory B cells and memory T cells. In humans, it takes 4-7 days for the adaptive immune system to mount a significant response. 15.1 Lymphocytes T and B lymphocytes are the cells of the adaptive immune system. The human body has about 2 trillion lymphocytes, which are 20–40% of white blood cells; their total mass is about the same as the brain or liver. The peripheral bloodstream contains only 2% of all circulating lymphocytes; the other 98% move within tissues and the lymphatic system, which includes the lymph nodes and spleen. In humans, approximately 1–2% of the lymphocyte pool recirculates each hour to increase the opportunity for the cells to encounter the specific pathogen and antigen that they react to. B cells and T cells are derived from the same multipotent hematopoietic stem cells, and look identical to one another until after they are activated. B cells play a large role in the humoral immune response, whereas T cells are intimately involved in cell-mediated immune responses. In all vertebrates except Agnatha, B cells and T cells are produced by stem cells in the bone marrow. T cell progenitors then migrate from the bone marrow to the thymus, where they develop further. In an adult animal, the peripheral lymphoid organs contain a mixture of B and T cells in at least three stages of differentiation: Naive B and naive T cells, which have left the bone marrow or thymus and entered the lymphatic system, but have yet to encounter their matching antigen Effector cells that have been activated by their matching antigen, and are actively involved in eliminating a pathogen Memory cells, the survivors of past infections 15.2 Antigen presentation Acquired immunity relies on the capacity of immune cells to distinguish between the body’s own cells and unwanted invaders. The host’s cells express “self” antigens. These antigens are different from those on the surface of bacteria or on the surface of virus-infected host cells (“non-self” or “foreign” antigens). The acquired immune response is triggered by recognizing foreign antigen in the cellular context of an activated dendritic cell. With the exception of non-nucleated cells (including erythrocytes), all cells are capable of presenting antigen through the function of major histocompatibility complex (MHC) molecules. Some cells are specially equipped to present antigen, and to prime naive T cells. Dendritic cells, B-cells, and macrophages are equipped with special “co-stimulatory” ligands recognized by co-stimulatory receptors on T cells, and are termed professional antigen-presenting cells (APCs). Several T cells subgroups can be activated by professional APCs, and each type of T cell is specially equipped to deal with each unique toxin or microbial pathogen. The type of T cell activated, and the type of response generated, depends, in part, on the context in which the APC first encountered the antigen. 15.3 Exogenous antigens Dendritic cells engulf exogenous pathogens, such as bacteria, parasites or toxins in the tissues and then migrate, via chemotactic signals, to the T cell-enriched lymph nodes. During migration, dendritic cells undergo a process of maturation in which they lose most of their ability to engulf other pathogens, and develop an ability to communicate with T-cells. The dendritic cell uses enzymes to chop the pathogen into smaller pieces, called antigens. In the lymph node, the dendritic cell displays these non-self antigens on its surface by coupling them to a receptor called the major histocompatibility complex, or MHC (also known in humans as human leukocyte antigen (HLA)). This MHC-antigen complex is recognized by T-cells passing through the lymph node. Exogenous antigens are usually displayed on MHC class II molecules, which activate CD4+T helper cells. 15.4 Endogenous antigens Endogenous antigens are produced by intracellular bacteria and viruses replicating within a host cell. The host cell uses enzymes to digest virally associated proteins and displays these pieces on its surface to T-cells by coupling them to MHC. Endogenous antigens are typically displayed on MHC class I molecules, and activate CD8+ cytotoxic T-cells. With the exception of non-nucleated cells (including erythrocytes), MHC class I is expressed by all host cells. 15.5 T lymphocytes CD8+ T lymphocytes and cytotoxicity Main article: Cytotoxic T cell Cytotoxic T cells (also known as TC, killer T cell, or cytotoxic T-lymphocyte (CTL)) are a sub-group of T cells that induce the death of cells that are infected with viruses (and other pathogens), or are otherwise damaged or dysfunctional. Naive cytotoxic T cells are activated when their T-cell receptor (TCR) strongly interacts with a peptide-bound MHC class I molecule. This affinity depends on the type and orientation of the antigen/MHC complex, and is what keeps the CTL and infected cell bound together. Once activated, the CTL undergoes a process called clonal selection, in which it gains functions and divides rapidly to produce an army of “armed” effector cells. Activated CTL then travels throughout the body searching for cells that bear that unique MHC Class I + peptide. When exposed to these infected or dysfunctional somatic cells, effector CTL release perforin and granulysin: cytotoxins that form pores in the target cell’s plasma membrane, allowing ions and water to flow into the infected cell, and causing it to burst or lyse. CTL release granzyme, a serine protease encapsulated in a granule that enters cells via pores to induce apoptosis (cell death). To limit extensive tissue damage during an infection, CTL activation is tightly controlled and in general requires a very strong MHC/antigen activation signal, or additional activation signals provided by “helper” T-cells (see below). On resolution of the infection, most effector cells die and phagocytes clear them away—but a few of these cells remain as memory cells. On a later encounter with the same antigen, these memory cells quickly differentiate into effector cells, dramatically shortening the time required to mount an effective response. Helper T-cells Main article: T helper cell CD4+ lymphocytes, also called “helper” T cells, are immune response mediators, and play an important role in establishing and maximizing the capabilities of the acquired immune response. These cells have no cytotoxic or phagocytic activity; and cannot kill infected cells or clear pathogens, but, in essence “manage” the immune response, by directing other cells to perform these tasks. Helper T cells express T cell receptors (TCR) that recognize antigen bound to Class II MHC molecules. The activation of a naive helper T-cell causes it to release cytokines, which influences the activity of many cell types, including the APC (Antigen-Presenting Cell) that activated it. Helper T-cells require a much milder activation stimulus than cytotoxic T cells. Helper T cells can provide extra signals that “help” activate cytotoxic cells. Th1 and Th2: helper T cell responses Classically, two types of effector CD4+ T helper cell responses can be induced by a professional APC, designated Th1 and Th2, each designed to eliminate different types of pathogens. The factors that dictate whether an infection triggers a Th1 or Th2 type response are not fully understood, but the response generated does play an important role in the clearance of different pathogens. The Th1 response is characterized by the production of Interferon-gamma, which activates the bactericidal activities of macrophages, and induces B cells to make opsonizing (marking for phagocytosis) and complement-fixing antibodies, and leads to cell-mediated immunity. In general, Th1 responses are more effective against intracellular pathogens (viruses and bacteria that are inside host cells). The Th2 response is characterized by the release of Interleukin 5, which induces eosinophils in the clearance of parasites. Th2 also produce Interleukin 4, which facilitates B cell isotype switching. In general, Th2 responses are more effective against extracellular bacteria, parasites including helminths and toxins. Like cytotoxic T cells, most of the CD4+ helper cells die on resolution of infection, with a few remaining as CD4+ memory cells. Increasingly, there is strong evidence from mouse and human-based scientific studies of a broader diversity in CD4+ effector T helper cell subsets. Regulatory T (Treg) cells, have been identified as important negative regulators of adaptive immunity as they limit and suppress the immune system to control aberrant immune responses to self-antigens; an important mechanism in controlling the development of autoimmune diseases. Follicular helper T (Tfh) cells are another distinct population of effector CD4+ T cells that develop from naive T cells post-antigen activation. Tfh cells are specialized in helping B cell humoral immunity as they are uniquely capable of migrating to follicular B cells in secondary lymphoid organs and provide them positive paracrine signals to enable the generation and recall production of high-quality affinity-matured antibodies. Similar to Tregs, Tfh cells also play a role in immunological tolerance as an abnormal expansion of Tfh cell numbers can lead to unrestricted autoreactive antibody production causing severe systemic autoimmune disorders. The relevance of CD4+ T helper cells is highlighted during an HIV infection. HIV is able to subvert the immune system by specifically attacking the CD4+ T cells, precisely the cells that could drive the clearance of the virus, but also the cells that drive immunity against all other pathogens encountered during an organism’s lifetime. Gamma delta T cells Main article: Gamma delta T cell Gamma delta T cells (γδ T cells) possess an alternative T cell receptor (TCR) as opposed to CD4+ and CD8+ αβ T cells and share characteristics of helper T cells, cytotoxic T cells and natural killer cells. Like other ‘unconventional’ T cell subsets bearing invariant TCRs, such as CD1d-restricted natural killer T cells, γδ T cells exhibit characteristics that place them at the border between innate and acquired immunity. On one hand, γδ T cells may be considered a component of adaptive immunity in that they rearrange TCR genes via V(D)J recombination, which also produces junctional diversity, and develop a memory phenotype. On the other hand, however, the various subsets may also be considered part of the innate immune system where a restricted TCR or NK receptors may be used as a pattern recognition receptor. For example, according to this paradigm, large numbers of Vγ9/Vδ2 T cells respond within hours to common molecules produced by microbes, and highly restricted intraepithelial Vδ1 T cells respond to stressed epithelial cells. B lymphocytes and antibody production B Cells are the major cells involved in the creation of antibodies that circulate in blood plasma and lymph, known as humoral immunity. Antibodies (also known as immunoglobulin, Ig), are large Y-shaped proteins used by the immune system to identify and neutralize foreign objects. In mammals, there are five types of antibody: IgA, IgD, IgE, IgG, and IgM, differing in biological properties; each has evolved to handle different kinds of antigens. Upon activation, B cells produce antibodies, each of which recognize a unique antigen, and neutralizing specific pathogens. Antigen and antibody binding would cause five different protective mechanisms: Agglutination: Reduces number of infectious units to be dealt with Activation of complement: Cause inflammation and cell lysis Opsonization: Coating antigen with antibody enhances phagocytosis Antibody-dependent cell-mediated cytotoxicity: Antibodies attached to target cell cause destruction by macrophages, eosinophils, and NK cells Neutralization: Blocks adhesion of bacteria and viruses to mucosa Like the T cell, B cells express a unique B cell receptor (BCR), in this case, a membrane-bound antibody molecule. All the BCR of any one clone of B cells recognizes and binds to only one particular antigen. A critical difference between B cells and T cells is how each cell “sees” an antigen. T cells recognize their cognate antigen in a processed form – as a peptide in the context of an MHC molecule, whereas B cells recognize antigens in their native form. Once a B cell encounters its cognate (or specific) antigen (and receives additional signals from a helper T cell (predominately Th2 type)), it further differentiates into an effector cell, known as a plasma cell. Plasma cells are short-lived cells (2–3 days) that secrete antibodies. These antibodies bind to antigens, making them easier targets for phagocytes, and trigger the complement cascade. About 10% of plasma cells survive to become long-lived antigen-specific memory B cells. Already primed to produce specific antibodies, these cells can be called upon to respond quickly if the same pathogen re-infects the host, while the host experiences few, if any, symptoms. Alternative systems In jawless vertebrates Main article: Adaptive immunity in jawless vertebrates Primitive jawless vertebrates, such as the lamprey and hagfish, have an adaptive immune system that shows 3 different cell lineages, each sharing a common origin with B cells, αβ T cells, and innate-like γΔ T cells. Instead of the classical antibodies and T cell receptors, these animals possess a large array of molecules called variable lymphocyte receptors (VLRs for short) that, like the antigen receptors of jawed vertebrates, are produced from only a small number (one or two) of genes. These molecules are believed to bind pathogenic antigens in a similar way to antibodies, and with the same degree of specificity. In insects For a long time it was thought that insects and other invertebrates possess only innate immune system. However, in recent years some of the basic hallmarks of adaptive immunity have been discovered in insects. Those traits are immune memory and specificity. Although the hallmarks are present the mechanisms are different from those in vertebrates. Immune memory in insects was discovered through the phenomenon of priming. When insects are exposed to non-lethal dose or heat killed bacteria they are able to develop a memory of that infection that allows them to withstand otherwise lethal dose of the same bacteria they were exposed to before. Unlike in vertebrates, insects do not possess cells specific for adaptive immunity. Instead those mechanisms are mediated by hemocytes. Hemocytes function similarly to phagocytes and after priming they are able to more effectively recognize and engulf the pathogen. It was also shown that it is possible to transfer the memory into offspring. For example, in honeybees if the queen is infected with bacteria then the newly born workers have enhanced abilities in fighting with the same bacteria. Other experimental model based on red flour beetle also showed pathogen specific primed memory transfer into offspring from both mothers and fathers. Most commonly accepted theory of the specificity is based on Dscam gene. Dscam gene also known as Down syndrome cell adhesive molecule is a gene that contains 3 variable Ig domains. Those domains can be alternatively spliced reaching high numbers of variations. It was shown that after exposure to different pathogens there are different splice forms of dscam produced. After the animals with different splice forms are exposed to the same pathogen only the individuals with the splice form specific for that pathogen survive. Other mechanisms supporting the specificity of insect immunity is RNA interference (RNAi). RNAi is a form of antiviral immunity with high specificity. It has several different pathways that all end with the virus being unable to replicate. One of the pathways is siRNA in which long double stranded RNA is cut into pieces that serve as templates for protein complex Ago2-RISC that finds and degrades complementary RNA of the virus. MiRNA pathway in cytoplasm binds to Ago1-RISC complex and functions as a template for viral RNA degradation. Last one is piRNA where small RNA binds to the Piwi protein family and controls transposones and other mobile elements. Despite the research the exact mechanisms responsible for immune priming and specificity in insects are not well described. Immunological memory Further information: Immunity (medical) When B cells and T cells are activated some become memory B cells and some memory T cells. Throughout the lifetime of an animal these memory cells form a database of effective B and T lymphocytes. Upon interaction with a previously encountered antigen, the appropriate memory cells are selected and activated. In this manner, the second and subsequent exposures to an antigen produce a stronger and faster immune response. This is “adaptive” in the sense that the body’s immune system prepares itself for future challenges, but is “maladaptive” of course if the receptors are autoimmune. Immunological memory can be in the form of either passive short-term memory or active long-term memory. Passive memory Passive memory is usually short-term, lasting between a few days and several months. Newborn infants have had no prior exposure to microbes and are particularly vulnerable to infection. Several layers of passive protection are provided by the mother. In utero, maternal IgG is transported directly across the placenta, so that, at birth, human babies have high levels of antibodies, with the same range of antigen specificities as their mother. Breast milk contains antibodies (mainly IgA) that are transferred to the gut of the infant, protecting against bacterial infections, until the newborn can synthesize its own antibodies. This is passive immunity because the fetus does not actually make any memory cells or antibodies: It only borrows them. Short-term passive immunity can also be transferred artificially from one individual to another via antibody-rich serum. Active memory In general, active immunity is long-term and can be acquired by infection followed by B cell and T cell activation, or artificially acquired by vaccines, in a process called immunization. Immunization Historically, infectious disease has been the leading cause of death in the human population. Over the last century, two important factors have been developed to combat their spread: sanitation and immunization. Immunization (commonly referred to as vaccination) is the deliberate induction of an immune response, and represents the single most effective manipulation of the immune system that scientists have developed. Immunizations are successful because they utilize the immune system’s natural specificity as well as its inducibility. The principle behind immunization is to introduce an antigen, derived from a disease-causing organism, that stimulates the immune system to develop protective immunity against that organism, but that does not itself cause the pathogenic effects of that organism. An antigen (short for antibody generator), is defined as any substance that binds to a specific antibody and elicits an adaptive immune response. Most viral vaccines are based on live attenuated viruses, whereas many bacterial vaccines are based on acellular components of microorganisms, including harmless toxin components. Many antigens derived from acellular vaccines do not strongly induce an adaptive response, and most bacterial vaccines require the addition of adjuvants that activate the antigen-presenting cells of the innate immune system to enhance immunogenicity. Immunological diversity Most large molecules, including virtually all proteins and many polysaccharides, can serve as antigens. The parts of an antigen that interact with an antibody molecule or a lymphocyte receptor, are called epitopes, or antigenic determinants. Most antigens contain a variety of epitopes and can stimulate the production of antibodies, specific T cell responses, or both. A very small proportion (less than 0.01%) of the total lymphocytes are able to bind to a particular antigen, which suggests that only a few cells respond to each antigen. For the acquired response to “remember” and eliminate a large number of pathogens the immune system must be able to distinguish between many different antigens, and the receptors that recognize antigens must be produced in a huge variety of configurations, in essence one receptor (at least) for each different pathogen that might ever be encountered. Even in the absence of antigen stimulation, a human can produce more than 1 trillion different antibody molecules. Millions of genes would be required to store the genetic information that produces these receptors, but, the entire human genome contains fewer than 25,000 genes. Myriad receptors are produced through a process known as clonal selection. According to the clonal selection theory, at birth, an animal randomly generates a vast diversity of lymphocytes (each bearing a unique antigen receptor) from information encoded in a small family of genes. To generate each unique antigen receptor, these genes have undergone a process called V(D)J recombination, or combinatorial diversification, in which one gene segment recombines with other gene segments to form a single unique gene. This assembly process generates the enormous diversity of receptors and antibodies, before the body ever encounters antigens, and enables the immune system to respond to an almost unlimited diversity of antigens. Throughout an animal’s lifetime, lymphocytes that can react against the antigens an animal actually encounters are selected for action—directed against anything that expresses that antigen. Note that the innate and acquired portions of the immune system work together, not in spite of each other. The acquired arm, B, and T cells couldn’t function without the innate system input. T cells are useless without antigen-presenting cells to activate them, and B cells are crippled without T cell help. On the other hand, the innate system would likely be overrun with pathogens without the specialized action of the adaptive immune response. Acquired immunity during pregnancy The cornerstone of the immune system is the recognition of “self” versus “non-self”. Therefore, the mechanisms that protect the human fetus (which is considered “non-self”) from attack by the immune system, are particularly interesting. Although no comprehensive explanation has emerged to explain this mysterious, and often repeated, lack of rejection, two classical reasons may explain how the fetus is tolerated. The first is that the fetus occupies a portion of the body protected by a non-immunological barrier, the uterus, which the immune system does not routinely patrol. The second is that the fetus itself may promote local immunosuppression in the mother, perhaps by a process of active nutrient depletion. A more modern explanation for this induction of tolerance is that specific glycoproteins expressed in the uterus during pregnancy suppress the uterine immune response (see eu-FEDS). During pregnancy in viviparous mammals (all mammals except Monotremes), endogenous retroviruses (ERVs) are activated and produced in high quantities during the implantation of the embryo. They are currently known to possess immunosuppressive properties, suggesting a role in protecting the embryo from its mother’s immune system. Also, viral fusion proteins cause the formation of the placental syncytium to limit exchange of migratory cells between the developing embryo and the body of the mother (something an epithelium can’t do sufficiently, as certain blood cells specialize to insert themselves between adjacent epithelial cells). The immunodepressive action was the initial normal behavior of the virus, similar to HIV. The fusion proteins were a way to spread the infection to other cells by simply merging them with the infected one (HIV does this too). It is believed that the ancestors of modern viviparous mammals evolved after an infection by this virus, enabling the fetus to survive the immune system of the mother. The human genome project found several thousand ERVs classified into 24 families. "]]
